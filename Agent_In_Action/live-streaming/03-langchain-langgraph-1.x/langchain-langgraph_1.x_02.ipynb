{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangGraph è¿›é˜¶æ¦‚å¿µï¼šä¸­é—´ä»¶ (Middleware) & äººæœºäº¤äº’ (Human-in-the-Loop)\n",
    "\n",
    "æ¬¢è¿æ¥åˆ°è¿›é˜¶è¯¾ç¨‹ï¼æœ¬ Notebook å»ºç«‹åœ¨ `langchain-langgraph_1.x_01.ipynb` çš„åŸºç¡€ä¹‹ä¸Šï¼Œä»‹ç»æ„å»ºç”Ÿäº§çº§ Agent çš„å‡ ä¸ªå¼ºå¤§åŠŸèƒ½ã€‚\n",
    "\n",
    "**ä½ å°†å­¦åˆ°ï¼š**\n",
    "- **Human-in-the-Loop (äººæœºäº¤äº’)** - æš‚åœ Agent ä»¥è¿›è¡Œäººå·¥å®¡æŸ¥å’Œæ‰¹å‡†\n",
    "- **Middleware (ä¸­é—´ä»¶)** - åœ¨æ‰§è¡Œçš„å…³é”®ç‚¹ä¿®æ”¹ Agent çš„è¡Œä¸º\n",
    "- **Tool Review (å·¥å…·å®¡æŸ¥)** - ä¸ºæ•æ„Ÿå·¥å…·æ·»åŠ å®¡æ‰¹å·¥ä½œæµ\n",
    "- **Dynamic Behavior (åŠ¨æ€è¡Œä¸º)** - æ ¹æ®ä¸Šä¸‹æ–‡è°ƒæ•´ Agent çš„å“åº”\n",
    "\n",
    "**å…ˆå†³æ¡ä»¶ï¼š** å®Œæˆ `langchain-langgraph_1.x_01.ipynb`\n",
    "\n",
    "---\n",
    "\n",
    "> **æ³¨æ„ï¼š** è¿™äº›æ¨¡å¼å¯¹äºç”Ÿäº§çº§ Agent è‡³å…³é‡è¦ï¼Œ **å› ä¸ºåœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œå®‰å…¨æ€§ã€åˆè§„æ€§å’Œç”¨æˆ·æ§åˆ¶æ˜¯å¿…ä¸å¯å°‘çš„** ã€‚LangGraph 1.0 å¼•å…¥äº† `interrupt` å’Œ `Command` ç­‰æ–°åŸè¯­ï¼Œè®©è¿™äº›æ¨¡å¼çš„å®ç°å˜å¾—æ›´åŠ ç›´è§‚å’Œå¼ºå¤§ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”„ å¿«é€Ÿå‚è€ƒï¼š1.0 ç‰ˆæœ¬çš„å…³é”®æ–°ç‰¹æ€§\n",
    "\n",
    "æœ¬ Notebook é‡ç‚¹å±•ç¤º LangGraph 1.0 çš„ä»¥ä¸‹æ–°ç‰¹æ€§ï¼š\n",
    "\n",
    "### 1. åŠ¨æ€ `interrupt()` æ›¿ä»£é™æ€é…ç½®\n",
    "\n",
    "```python\n",
    "# âŒ æ—§ç‰ˆ (0.x) - åœ¨ç¼–è¯‘æ—¶é™æ€æŒ‡å®š\n",
    "graph = builder.compile(interrupt_before=[\"node_name\"])\n",
    "\n",
    "# âœ… æ–°ç‰ˆ (1.0) - åœ¨è¿è¡Œæ—¶åŠ¨æ€ä¸­æ–­\n",
    "from langgraph.types import interrupt\n",
    "\n",
    "@tool\n",
    "def sensitive_action():\n",
    "    approval = interrupt({\"message\": \"éœ€è¦æ‰¹å‡†å—?\"})\n",
    "    if approval[\"approved\"]:\n",
    "        return \"å·²æ‰¹å‡†\"\n",
    "```\n",
    "\n",
    "**ä¼˜åŠ¿**ï¼šå¯ä»¥åŸºäºè¿è¡Œæ—¶æ¡ä»¶ï¼ˆå¦‚ç½®ä¿¡åº¦ï¼‰åŠ¨æ€å†³å®šæ˜¯å¦ä¸­æ–­ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### 2. `Command` å¯¹è±¡ç»Ÿä¸€çŠ¶æ€æ›´æ–°å’Œè·¯ç”±\n",
    "\n",
    "```python\n",
    "# âŒ æ—§ç‰ˆ (0.x) - çŠ¶æ€å’Œè·¯ç”±åˆ†ç¦»\n",
    "def node(state):\n",
    "    return {\"key\": \"value\"}  # åªèƒ½è¿”å›çŠ¶æ€\n",
    "\n",
    "# âœ… æ–°ç‰ˆ (1.0) - ç”¨ Command åŒæ—¶æŒ‡å®šçŠ¶æ€å’Œè·¯ç”±\n",
    "from langgraph.types import Command\n",
    "\n",
    "def node(state):\n",
    "    return Command(\n",
    "        update={\"key\": \"value\"},\n",
    "        goto=\"next_node\"\n",
    "    )\n",
    "```\n",
    "\n",
    "**ç”¨äºæ¢å¤ä¸­æ–­**ï¼š\n",
    "```python\n",
    "agent.invoke(Command(resume={\"approved\": True}), config=config)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Middleware æœºåˆ¶ï¼ˆLangChain 1.0 æ–°å¢ï¼‰\n",
    "\n",
    "```python\n",
    "# âœ… æ–°ç‰ˆ (1.0) - ä½¿ç”¨ä¸­é—´ä»¶\n",
    "from langchain.agents.middleware import PIIMiddleware\n",
    "\n",
    "agent = create_agent(\n",
    "    model,\n",
    "    tools,\n",
    "    middleware=[\n",
    "        PIIMiddleware(\"email\", strategy=\"redact\")\n",
    "    ]\n",
    ")\n",
    "```\n",
    "\n",
    "**æ ¸å¿ƒ Hooks**ï¼š\n",
    "- `before_model` / `after_model` - åœ¨ LLM è°ƒç”¨å‰åæ‰§è¡Œ\n",
    "- `wrap_model_call` / `wrap_tool_call` - æ‹¦æˆªå¹¶ä¿®æ”¹è°ƒç”¨\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”· LangGraph 1.0 ä¸»è¦å˜åŒ–\n",
    "\n",
    "### 1. **æ ¸å¿ƒ API ç¨³å®šæ€§æ‰¿è¯º**\n",
    "\n",
    "**å˜åŒ–**ï¼šLangGraph 1.0 æ ‡å¿—ç€æ ¸å¿ƒ API çš„ç¨³å®šï¼Œæ‰¿è¯ºä¸ä¼šæœ‰ç ´åæ€§å˜åŒ–ã€‚\n",
    "\n",
    "**ç¨³å®šçš„æ ¸å¿ƒåŸè¯­**ï¼š\n",
    "- `StateGraph` - çŠ¶æ€å›¾æ„å»ºå™¨\n",
    "- `add_node()` / `add_edge()` / `add_conditional_edges()` - å›¾æ„å»ºæ–¹æ³•\n",
    "- `compile()` - å›¾ç¼–è¯‘\n",
    "- `invoke()` / `stream()` - æ‰§è¡Œæ–¹æ³•\n",
    "- `Checkpointer` æ¥å£ - æŒä¹…åŒ–\n",
    "\n",
    "**è¿ç§»å»ºè®®**ï¼š\n",
    "- å¦‚æœä½ åœ¨ 0.x ä½¿ç”¨äº†å®éªŒæ€§ APIï¼Œç°åœ¨åº”è¿ç§»åˆ°ç¨³å®š API\n",
    "- æŸ¥é˜…å®˜æ–¹è¿ç§»æŒ‡å—ç¡®è®¤ä½ ä½¿ç”¨çš„ API æ˜¯å¦ç¨³å®š\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **`create_react_agent` å¼ƒç”¨**\n",
    "\n",
    "**å˜åŒ–**ï¼š`langgraph.prebuilt.create_react_agent` ç°å·²è¢« LangChain çš„ `create_agent` å–ä»£ã€‚\n",
    "\n",
    "```python\n",
    "# âŒ æ—§ç‰ˆ (LangGraph 0.x)\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "agent = create_react_agent(model, tools, messages_modifier=system_message)\n",
    "\n",
    "# âœ… æ–°ç‰ˆ (LangChain 1.0 / LangGraph 1.0)\n",
    "from langchain.agents import create_agent\n",
    "agent = create_agent(model, tools, system_prompt=\"You are helpful\")\n",
    "```\n",
    "\n",
    "**ä¸ºä»€ä¹ˆå¼ƒç”¨ï¼Ÿ**\n",
    "- **æ¶æ„é‡ç»„**ï¼šAgent æŠ½è±¡åº”å±äº LangChain å±‚ï¼ŒLangGraph ä¸“æ³¨äºå›¾æ‰§è¡Œå¼•æ“\n",
    "- **åŠŸèƒ½å¢å¼º**ï¼šæ–° API æ”¯æŒä¸­é—´ä»¶ï¼Œæä¾›æ›´å¼ºçš„å¯å®šåˆ¶æ€§\n",
    "- **ç®€åŒ–ä¾èµ–**ï¼šå‡å°‘ LangGraph å¯¹é«˜å±‚æŠ½è±¡çš„ä¾èµ–\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **æ–°çš„ä¸­æ–­æœºåˆ¶ï¼š`interrupt()`**\n",
    "\n",
    "**å˜åŒ–**ï¼šå¼•å…¥åŠ¨æ€ `interrupt()` å‡½æ•°ï¼Œå–ä»£é™æ€çš„ `interrupt_before` é…ç½®ã€‚\n",
    "\n",
    "```python\n",
    "# âŒ æ—§ç‰ˆ (LangGraph 0.x) - é™æ€é…ç½®\n",
    "from langgraph.graph import StateGraph\n",
    "\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"risky_action\", risky_action_node)\n",
    "graph = builder.compile(\n",
    "    interrupt_before=[\"risky_action\"]  # ç¼–è¯‘æ—¶æŒ‡å®š\n",
    ")\n",
    "\n",
    "# âœ… æ–°ç‰ˆ (LangGraph 1.0) - åŠ¨æ€ä¸­æ–­\n",
    "# LangGraph0.6.x ä½¿ç”¨ `NodeInterrupt` å¼‚å¸¸ å®ç°åŠ¨æ€ä¸­æ–­ï¼Œä¸å¤Ÿå‹å¥½\n",
    "from langgraph.types import interrupt\n",
    "\n",
    "@tool\n",
    "def risky_action():\n",
    "    # å¯ä»¥åŸºäºæ¡ä»¶åŠ¨æ€å†³å®šæ˜¯å¦ä¸­æ–­\n",
    "    if needs_approval():\n",
    "        response = interrupt({\n",
    "            \"message\": \"éœ€è¦æ‰¹å‡†\",\n",
    "            \"action\": \"...\"\n",
    "        })\n",
    "        if not response[\"approved\"]:\n",
    "            return \"æ“ä½œå–æ¶ˆ\"\n",
    "    return \"æ“ä½œå®Œæˆ\"\n",
    "```\n",
    "\n",
    "**åŠ¨æ€ä¸­æ–­çš„ä¼˜åŠ¿**ï¼š\n",
    "- **æ¡ä»¶æ€§**ï¼šåŸºäºè¿è¡Œæ—¶é€»è¾‘å†³å®šæ˜¯å¦ä¸­æ–­ï¼ˆå¦‚\"ç½®ä¿¡åº¦ä½æ—¶æ‰ä¸­æ–­\"ï¼‰\n",
    "- **ä¸Šä¸‹æ–‡ä¼ é€’**ï¼šå¯ä»¥å‘ç”¨æˆ·ä¼ é€’ä»»æ„æ•°æ®\n",
    "- **çµæ´»æ§åˆ¶**ï¼šåœ¨å·¥å…·ã€èŠ‚ç‚¹å†…éƒ¨ä»»æ„ä½ç½®è°ƒç”¨\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **`Command` å¯¹è±¡ç»Ÿä¸€çŠ¶æ€æ›´æ–°å’Œè·¯ç”±**\n",
    "\n",
    "**å˜åŒ–**ï¼šèŠ‚ç‚¹ç°åœ¨å¯ä»¥è¿”å› `Command` å¯¹è±¡ï¼ŒåŒæ—¶æŒ‡å®šçŠ¶æ€æ›´æ–°å’Œè·¯ç”±ç›®æ ‡ã€‚\n",
    "\n",
    "```python\n",
    "# âŒ æ—§ç‰ˆ (LangGraph 0.x) - åˆ†ç¦»çš„çŠ¶æ€å’Œè·¯ç”±\n",
    "def node(state):\n",
    "    # åªèƒ½è¿”å›çŠ¶æ€æ›´æ–°\n",
    "    return {\"messages\": [...]}\n",
    "\n",
    "def route_fn(state):\n",
    "    # éœ€è¦å•ç‹¬çš„å‡½æ•°å†³å®šä¸‹ä¸€æ­¥\n",
    "    if condition:\n",
    "        return \"next_node\"\n",
    "    return \"end\"\n",
    "\n",
    "# âœ… æ–°ç‰ˆ (LangGraph 1.0) - Command ç»Ÿä¸€ä¸¤è€…\n",
    "from langgraph.types import Command\n",
    "\n",
    "def node(state):\n",
    "    # å¯ä»¥åŒæ—¶æŒ‡å®šçŠ¶æ€æ›´æ–°å’Œè·¯ç”±\n",
    "    return Command(\n",
    "        update={\"messages\": [...]},\n",
    "        goto=\"next_node\"\n",
    "    )\n",
    "```\n",
    "\n",
    "**`Command` å¯¹è±¡çš„å¨åŠ›**ï¼š\n",
    "```python\n",
    "# æ¢å¤ä¸­æ–­æ—¶ä¹Ÿä½¿ç”¨ Command\n",
    "## LangGraph0.6.Xç‰ˆæœ¬ä½¿ç”¨ `None` è°ƒç”¨å›¾æ—¶ï¼Œå°†ä»æœ€åä¸€ä¸ªçŠ¶æ€æ£€æŸ¥ç‚¹ç»§ç»­æ‰§è¡Œï¼\n",
    "agent.invoke(\n",
    "    Command(resume={\"approved\": True}),\n",
    "    config=config\n",
    ")\n",
    "\n",
    "# å¤šç›®æ ‡è·¯ç”±ï¼ˆå¹¿æ’­ï¼‰\n",
    "return Command(\n",
    "    update={...},\n",
    "    goto=[\"node1\", \"node2\"]  # å¹¶è¡Œæ‰§è¡Œ\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 5. **Checkpointer æ¥å£ç»Ÿä¸€**\n",
    "\n",
    "**å˜åŒ–**ï¼šç»Ÿä¸€äº†æŒä¹…åŒ–æ¥å£ï¼ŒåºŸå¼ƒäº†æ—§ç‰ˆæ··ä¹±çš„é…ç½®æ–¹å¼ã€‚\n",
    "\n",
    "```python\n",
    "# âœ… æ ‡å‡† Checkpointer ä½¿ç”¨æ–¹å¼\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "# å¼€å‘ç¯å¢ƒ\n",
    "checkpointer = MemorySaver()\n",
    "\n",
    "# ç”Ÿäº§ç¯å¢ƒ\n",
    "checkpointer = SqliteSaver.from_conn_string(\"sqlite:///checkpoints.db\")\n",
    "\n",
    "agent = create_agent(\n",
    "    model,\n",
    "    tools,\n",
    "    checkpointer=checkpointer\n",
    ")\n",
    "```\n",
    "\n",
    "**æ”¯æŒçš„ Checkpointer**ï¼š\n",
    "- `MemorySaver` - å†…å­˜ï¼ˆå¼€å‘/æµ‹è¯•ï¼‰\n",
    "- `SqliteSaver` - SQLite æ•°æ®åº“\n",
    "- `PostgresSaver` - PostgreSQLï¼ˆç”Ÿäº§æ¨èï¼‰\n",
    "- è‡ªå®šä¹‰å®ç° `BaseCheckpointSaver` æ¥å£\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangGraph 1.0 å‡çº§æŒ‡å— - äººæœºäº¤äº’ä¸æ§åˆ¶æµ\n",
    "\n",
    "åœ¨ LangGraph 1.0 ä¸­ï¼Œ**Human-in-the-Loop** å’Œ **æ§åˆ¶æµ** å‘ç”Ÿäº†é‡å¤§å˜åŒ–ï¼Œå˜å¾—æ›´åŠ åŠ¨æ€å’Œçµæ´»ã€‚\n",
    "\n",
    "**ä¸»è¦åŒºåˆ«ï¼š**\n",
    "\n",
    "#### 1. ä¸­æ–­æœºåˆ¶ï¼š`interrupt()` vs é™æ€é…ç½®\n",
    "- **æ—§ç‰ˆ (0.x)**: éœ€è¦åœ¨ç¼–è¯‘ Graph æ—¶é€šè¿‡ `interrupt_before=[\"node_name\"]` é™æ€æŒ‡å®šåœ¨å“ªåœã€‚\n",
    "- **æ–°ç‰ˆ (1.0)**: å¼•å…¥äº†åŠ¨æ€ **`interrupt()`** å‡½æ•°ã€‚ä½ å¯ä»¥åœ¨ä»»ä½•èŠ‚ç‚¹æˆ–å·¥å…·å†…éƒ¨è°ƒç”¨å®ƒã€‚è¿™å…è®¸åŸºäºé€»è¾‘ï¼ˆå¦‚â€œç½®ä¿¡åº¦ä½æ—¶æ‰ä¸­æ–­â€ï¼‰åŠ¨æ€å†³å®šæ˜¯å¦æš‚åœã€‚\n",
    "\n",
    "#### 2. çŠ¶æ€æ›´æ–°ä¸å¯¼èˆªï¼š`Command` å¯¹è±¡\n",
    "- **æ—§ç‰ˆ (0.x)**: èŠ‚ç‚¹è¿”å›çŠ¶æ€æ›´æ–°ï¼Œè·¯ç”±ç”±å•ç‹¬çš„æ¡ä»¶è¾¹å‡½æ•°å¤„ç†ã€‚\n",
    "- **æ–°ç‰ˆ (1.0)**: å¼•å…¥ **`Command`** å¯¹è±¡ã€‚ä¸€ä¸ªèŠ‚ç‚¹å¯ä»¥åŒæ—¶è¿”å›çŠ¶æ€æ›´æ–° (`update`) å’Œè·¯ç”±æŒ‡ä»¤ (`goto`)ï¼Œæå¤§ç®€åŒ–äº†å¤æ‚é€»è¾‘çš„ç¼–å†™ã€‚\n",
    "\n",
    "æœ¬æ•™ç¨‹çš„â€œç¬¬ 1 éƒ¨åˆ†â€å’Œâ€œç¬¬ 2 éƒ¨åˆ†â€å°†è¯¦ç»†æ¼”ç¤ºè¿™äº›æ–°ç‰¹æ€§çš„ç”¨æ³•ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å‰ç½®éƒ¨åˆ†ï¼šç¯å¢ƒé…ç½®å’Œæ¨¡å‹é…ç½®"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### åˆ›å»ºlangchain1.x ç¯å¢ƒï¼ˆåœ¨shellä¸­æ‰§è¡Œï¼‰\n",
    "```\n",
    "# åˆ›å»ºlangchain1.x ç¯å¢ƒ\n",
    "conda create -n langchain1.x python=3.10.18 -y\n",
    "\n",
    "# ç¡®ä¿åœ¨ langchain1.x ç¯å¢ƒä¸­\n",
    "conda activate langchain1.x\n",
    "\n",
    "# å®‰è£… ipykernel\n",
    "pip install ipykernel\n",
    "\n",
    "# å°†ç¯å¢ƒæ³¨å†Œä¸º Jupyter å†…æ ¸\n",
    "python -m ipykernel install --user --name=langchain1.x --display-name=\"Python (langchain1.x)\"\n",
    "\n",
    "# éªŒè¯å†…æ ¸å®‰è£…\n",
    "jupyter kernelspec list\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ”§ ç¯å¢ƒé…ç½®å’Œæ£€æŸ¥\n",
    "\n",
    "#### æ¦‚è¿°\n",
    "\n",
    "æœ¬æ•™ç¨‹éœ€è¦ç‰¹å®šçš„ç¯å¢ƒé…ç½®ä»¥ç¡®ä¿æœ€ä½³å­¦ä¹ ä½“éªŒã€‚ä»¥ä¸‹é…ç½®å°†å¸®åŠ©ä½ ï¼š\n",
    "\n",
    "- ä½¿ç”¨ç»Ÿä¸€çš„condaç¯å¢ƒï¼šæ¿€æ´»ç»Ÿä¸€çš„å­¦ä¹ ç¯å¢ƒ\n",
    "- é€šè¿‡å›½å†…é•œåƒæºå¿«é€Ÿå®‰è£…ä¾èµ–ï¼šé…ç½®pipä½¿ç”¨æ¸…åé•œåƒæº\n",
    "- åŠ é€Ÿæ¨¡å‹ä¸‹è½½ï¼šè®¾ç½®HuggingFaceé•œåƒä»£ç†\n",
    "- æ£€æŸ¥ç³»ç»Ÿé…ç½®ï¼šæ£€æŸ¥ç¡¬ä»¶å’Œè½¯ä»¶é…ç½®\n",
    "\n",
    "#### é…ç½®\n",
    "\n",
    "- **æ‰€éœ€ç¯å¢ƒåŠå…¶ä¾èµ–å·²ç»éƒ¨ç½²å¥½**\n",
    "- åœ¨`Notebook`å³ä¸Šè§’é€‰æ‹©`jupyterå†…æ ¸`ä¸º`python(langchain1.x)`ï¼Œå³å¯æ‰§è¡Œä¸‹æ–¹ä»£ç "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================\n",
      "== Conda ç¯å¢ƒæ£€æŸ¥æŠ¥å‘Š (ä»…é’ˆå¯¹å½“å‰ Bash å­è¿›ï¿½ï¿½) ==\n",
      "=========================================\n",
      "âœ… å½“å‰å•å…ƒæ ¼å·²æˆåŠŸæ¿€æ´»åˆ° langchain1.x ç¯å¢ƒã€‚\n",
      "âœ… æ­£åœ¨ä½¿ç”¨çš„ç¯å¢ƒè·¯å¾„: /root/miniconda3/envs/langchain1.x\n",
      "\n",
      "ğŸ’¡ æç¤º: åç»­çš„Pythonå•å…ƒæ ¼å°†ä½¿ç”¨Notebookå½“å‰é€‰æ‹©çš„Jupyterå†…æ ¸ã€‚\n",
      "   å¦‚æœéœ€è¦åç»­å•å…ƒæ ¼ä¹Ÿä½¿ç”¨æ­¤ç¯å¢ƒï¼Œè¯·æ‰§è¡Œä»¥ä¸‹æ“ä½œ:\n",
      "   1. æ£€ï¿½ï¿½ï¿½ Notebook å³ä¸Šè§’æ˜¯å¦å·²é€‰æ‹© 'python(langchain1.x)'ã€‚\n",
      "=========================================\n"
     ]
    }
   ],
   "source": [
    "%%script bash\n",
    "\n",
    "# 1. æ¿€æ´» conda ç¯å¢ƒ (ä»…å¯¹å½“å‰å•å…ƒæ ¼æœ‰æ•ˆ)\n",
    "eval \"$(conda shell.bash hook)\"\n",
    "conda activate langchain1.x\n",
    "\n",
    "echo \"=========================================\"\n",
    "echo \"== Conda ç¯å¢ƒæ£€æŸ¥æŠ¥å‘Š (ä»…é’ˆå¯¹å½“å‰ Bash å­è¿›ç¨‹) ==\"\n",
    "echo \"=========================================\"\n",
    "\n",
    "# 2. æ£€æŸ¥å½“å‰æ¿€æ´»çš„ç¯å¢ƒ\n",
    "CURRENT_ENV_NAME=$(basename $CONDA_PREFIX)\n",
    "\n",
    "if [ \"$CURRENT_ENV_NAME\" = \"langchain1.x\" ]; then\n",
    "    echo \"âœ… å½“å‰å•å…ƒæ ¼å·²æˆåŠŸæ¿€æ´»åˆ° langchain1.x ç¯å¢ƒã€‚\"\n",
    "    echo \"âœ… æ­£åœ¨ä½¿ç”¨çš„ç¯å¢ƒè·¯å¾„: $CONDA_PREFIX\"\n",
    "    echo \"\"\n",
    "    echo \"ğŸ’¡ æç¤º: åç»­çš„Pythonå•å…ƒæ ¼å°†ä½¿ç”¨Notebookå½“å‰é€‰æ‹©çš„Jupyterå†…æ ¸ã€‚\"\n",
    "    echo \"   å¦‚æœéœ€è¦åç»­å•å…ƒæ ¼ä¹Ÿä½¿ç”¨æ­¤ç¯å¢ƒï¼Œè¯·æ‰§è¡Œä»¥ä¸‹æ“ä½œ:\"\n",
    "    echo \"   1. æ£€æŸ¥ Notebook å³ä¸Šè§’æ˜¯å¦å·²é€‰æ‹© 'python(langchain1.x)'ã€‚\"\n",
    "else\n",
    "    echo \"âŒ æ¿€æ´»å¤±è´¥æˆ–ç¯å¢ƒåç§°ä¸åŒ¹é…ã€‚å½“å‰ç¯å¢ƒ: $CURRENT_ENV_NAME\"\n",
    "    echo \"\"\n",
    "    echo \"âš ï¸ ä¸¥é‡æç¤º: å»ºè®®å°† Notebook çš„ Jupyter **å†…æ ¸ (Kernel)** åˆ‡æ¢ä¸º 'python(langchain1.x)'ã€‚\"\n",
    "    echo \"   (é€šå¸¸ä½äº Notebook å³ä¸Šè§’æˆ– 'å†…æ ¸' èœå•ä¸­)\"\n",
    "    echo \"\"\n",
    "    echo \"ğŸ“š å¤‡ç”¨æ–¹æ³• (ä¸æ¨è): å¦‚æœæ— æ³•åˆ‡æ¢å†…æ ¸ï¼Œåˆ™å¿…é¡»åœ¨**æ¯ä¸ª**ä»£ç å•å…ƒæ ¼çš„å¤´éƒ¨é‡å¤ä»¥ä¸‹å‘½ä»¤:\"\n",
    "    echo \"\"\n",
    "    echo \"%%script bash\"\n",
    "    echo \"# å¿…é¡»åœ¨æ¯ä¸ªå•å…ƒæ ¼éƒ½æ‰§è¡Œ\"\n",
    "    echo \"eval \\\"\\$(conda shell.bash hook)\\\"\"\n",
    "    echo \"conda activate langchain1.x\"\n",
    "fi\n",
    "\n",
    "echo \"=========================================\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ” ç¯å¢ƒä¿¡æ¯æ‰“å°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: pandas==2.2.2 in /root/miniconda3/envs/langchain1.x/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: tabulate==0.9.0 in /root/miniconda3/envs/langchain1.x/lib/python3.10/site-packages (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /root/miniconda3/envs/langchain1.x/lib/python3.10/site-packages (from pandas==2.2.2) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /root/miniconda3/envs/langchain1.x/lib/python3.10/site-packages (from pandas==2.2.2) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /root/miniconda3/envs/langchain1.x/lib/python3.10/site-packages (from pandas==2.2.2) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /root/miniconda3/envs/langchain1.x/lib/python3.10/site-packages (from pandas==2.2.2) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /root/miniconda3/envs/langchain1.x/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas==2.2.2) (1.17.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "### ç¯å¢ƒä¿¡æ¯\n",
      "| é¡¹ç›®         | ä¿¡æ¯                                                                               |\n",
      "|:-------------|:-----------------------------------------------------------------------------------|\n",
      "| æ“ä½œç³»ç»Ÿ     | Linux Ubuntu 22.04.4 LTS                                                           |\n",
      "| CPU ä¿¡æ¯     | 11th Gen Intel(R) Core(TM) i5-1135G7 @ 2.40GHz (1 physical cores, 4 logical cores) |\n",
      "| å†…å­˜ä¿¡æ¯     | 5.75 GB (Available: 4.91 GB)                                                       |\n",
      "| GPU ä¿¡æ¯     | No GPU found (nvidia-smi not found)                                                |\n",
      "| CUDA ä¿¡æ¯    | CUDA not found                                                                     |\n",
      "| Python ç‰ˆæœ¬  | 3.10.18                                                                            |\n",
      "| Conda ç‰ˆæœ¬   | conda 24.4.0                                                                       |\n",
      "| ç‰©ç†ç£ç›˜ç©ºé—´ | Total: 145.49 GB, Used: 59.55 GB, Free: 79.71 GB                                   |\n"
     ]
    }
   ],
   "source": [
    "# ğŸ” ç¯å¢ƒä¿¡æ¯æ£€æŸ¥è„šæœ¬\n",
    "#\n",
    "# æœ¬è„šæœ¬çš„ä½œç”¨ï¼š\n",
    "# 1. å®‰è£… pandas åº“ç”¨äºæ•°æ®è¡¨æ ¼å±•ç¤º\n",
    "# 2. æ£€æŸ¥ç³»ç»Ÿçš„å„é¡¹é…ç½®ä¿¡æ¯\n",
    "# 3. ç”Ÿæˆè¯¦ç»†çš„ç¯å¢ƒæŠ¥å‘Šè¡¨æ ¼\n",
    "#\n",
    "# å¯¹äºåˆå­¦è€…æ¥è¯´ï¼Œè¿™ä¸ªæ­¥éª¤å¸®åŠ©ä½ ï¼š\n",
    "# - äº†è§£å½“å‰è¿è¡Œç¯å¢ƒçš„ç¡¬ä»¶é…ç½®\n",
    "# - ç¡®è®¤æ˜¯å¦æ»¡è¶³æ¨¡å‹è¿è¡Œçš„æœ€ä½è¦æ±‚\n",
    "# - å­¦ä¹ å¦‚ä½•é€šè¿‡ä»£ç è·å–ç³»ç»Ÿä¿¡æ¯\n",
    "\n",
    "# å®‰è£… pandas åº“ - ç”¨äºåˆ›å»ºå’Œå±•ç¤ºæ•°æ®è¡¨æ ¼\n",
    "# pandas æ˜¯ Python ä¸­æœ€æµè¡Œçš„æ•°æ®å¤„ç†å’Œåˆ†æåº“\n",
    "%pip install pandas==2.2.2 tabulate==0.9.0\n",
    "\n",
    "import platform # å¯¼å…¥ platform æ¨¡å—ä»¥è·å–ç³»ç»Ÿä¿¡æ¯\n",
    "import os # å¯¼å…¥ os æ¨¡å—ä»¥ä¸æ“ä½œç³»ç»Ÿäº¤äº’\n",
    "import subprocess # å¯¼å…¥ subprocess æ¨¡å—ä»¥è¿è¡Œå¤–éƒ¨å‘½ä»¤\n",
    "import pandas as pd # å¯¼å…¥ pandas æ¨¡å—ï¼Œé€šå¸¸ç”¨äºæ•°æ®å¤„ç†ï¼Œè¿™é‡Œç”¨äºåˆ›å»ºè¡¨æ ¼\n",
    "import shutil # å¯¼å…¥ shutil æ¨¡å—ä»¥è·å–ç£ç›˜ç©ºé—´ä¿¡æ¯\n",
    "\n",
    "# è·å– CPU ä¿¡æ¯çš„å‡½æ•°ï¼ŒåŒ…æ‹¬æ ¸å¿ƒæ•°é‡\n",
    "def get_cpu_info():\n",
    "    cpu_info = \"\" # åˆå§‹åŒ– CPU ä¿¡æ¯å­—ç¬¦ä¸²\n",
    "    physical_cores = \"N/A\"\n",
    "    logical_cores = \"N/A\"\n",
    "\n",
    "    if platform.system() == \"Windows\": # å¦‚æœæ˜¯ Windows ç³»ç»Ÿ\n",
    "        cpu_info = platform.processor() # ä½¿ç”¨ platform.processor() è·å– CPU ä¿¡æ¯\n",
    "        try:\n",
    "            # è·å– Windows ä¸Šçš„æ ¸å¿ƒæ•°é‡ (éœ€è¦ WMI)\n",
    "            import wmi\n",
    "            c = wmi.WMI()\n",
    "            for proc in c.Win32_Processor():\n",
    "                physical_cores = proc.NumberOfCores\n",
    "                logical_cores = proc.NumberOfLogicalProcessors\n",
    "        except:\n",
    "            pass # å¦‚æœ WMI ä¸å¯ç”¨ï¼Œå¿½ç•¥é”™è¯¯\n",
    "\n",
    "    elif platform.system() == \"Darwin\": # å¦‚æœæ˜¯ macOS ç³»ç»Ÿ\n",
    "        # åœ¨ macOS ä¸Šä½¿ç”¨ sysctl å‘½ä»¤è·å– CPU ä¿¡æ¯å’Œæ ¸å¿ƒæ•°é‡\n",
    "        os.environ['PATH'] = os.environ['PATH'] + os.pathsep + '/usr/sbin' # æ›´æ–° PATH ç¯å¢ƒå˜é‡\n",
    "        try:\n",
    "            process_brand = subprocess.Popen(['sysctl', \"machdep.cpu.brand_string\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_brand, stderr_brand = process_brand.communicate()\n",
    "            cpu_info = stdout_brand.decode().split(': ')[1].strip() if stdout_brand else \"Could not retrieve CPU info\"\n",
    "\n",
    "            process_physical = subprocess.Popen(['sysctl', \"hw.physicalcpu\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_physical, stderr_physical = process_physical.communicate()\n",
    "            physical_cores = stdout_physical.decode().split(': ')[1].strip() if stdout_physical else \"N/A\"\n",
    "\n",
    "            process_logical = subprocess.Popen(['sysctl', \"hw.logicalcpu\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_logical, stderr_logical = process_logical.communicate()\n",
    "            logical_cores = stdout_logical.decode().split(': ')[1].strip() if stdout_logical else \"N/A\"\n",
    "\n",
    "        except:\n",
    "            cpu_info = \"Could not retrieve CPU info\"\n",
    "            physical_cores = \"N/A\"\n",
    "            logical_cores = \"N/A\"\n",
    "\n",
    "    else:  # Linux ç³»ç»Ÿ\n",
    "        try:\n",
    "            # åœ¨ Linux ä¸Šè¯»å– /proc/cpuinfo æ–‡ä»¶è·å– CPU ä¿¡æ¯å’Œæ ¸å¿ƒæ•°é‡\n",
    "            with open('/proc/cpuinfo') as f:\n",
    "                physical_cores_count = 0\n",
    "                logical_cores_count = 0\n",
    "                cpu_info_lines = []\n",
    "                for line in f:\n",
    "                    if line.startswith('model name'): # æŸ¥æ‰¾ä»¥ 'model name'å¼€å¤´çš„è¡Œ\n",
    "                        if not cpu_info: # åªè·å–ç¬¬ä¸€ä¸ª model name\n",
    "                            cpu_info = line.split(': ')[1].strip()\n",
    "                    elif line.startswith('cpu cores'): # æŸ¥æ‰¾ä»¥ 'cpu cores' å¼€å¤´çš„è¡Œ\n",
    "                        physical_cores_count = int(line.split(': ')[1].strip())\n",
    "                    elif line.startswith('processor'): # æŸ¥æ‰¾ä»¥ 'processor' å¼€å¤´çš„è¡Œ\n",
    "                        logical_cores_count += 1\n",
    "                physical_cores = str(physical_cores_count) if physical_cores_count > 0 else \"N/A\"\n",
    "                logical_cores = str(logical_cores_count) if logical_cores_count > 0 else \"N/A\"\n",
    "                if not cpu_info:\n",
    "                     cpu_info = \"Could not retrieve CPU info\"\n",
    "\n",
    "        except:\n",
    "            cpu_info = \"Could not retrieve CPU info\"\n",
    "            physical_cores = \"N/A\"\n",
    "            logical_cores = \"N/A\"\n",
    "\n",
    "    return f\"{cpu_info} ({physical_cores} physical cores, {logical_cores} logical cores)\" # è¿”å› CPU ä¿¡æ¯å’Œæ ¸å¿ƒæ•°é‡\n",
    "\n",
    "\n",
    "# è·å–å†…å­˜ä¿¡æ¯çš„å‡½æ•°\n",
    "def get_memory_info():\n",
    "    mem_info = \"\" # åˆå§‹åŒ–å†…å­˜ä¿¡æ¯å­—ç¬¦ä¸²\n",
    "    if platform.system() == \"Windows\":\n",
    "        # åœ¨ Windows ä¸Šä¸å®¹æ˜“é€šè¿‡æ ‡å‡†åº“è·å–ï¼Œéœ€è¦å¤–éƒ¨åº“æˆ– PowerShell\n",
    "        mem_info = \"Requires external tools on Windows\" # è®¾ç½®æç¤ºä¿¡æ¯\n",
    "    elif platform.system() == \"Darwin\": # å¦‚æœæ˜¯ macOS ç³»ç»Ÿ\n",
    "        # åœ¨ macOS ä¸Šä½¿ç”¨ sysctl å‘½ä»¤è·å–å†…å­˜å¤§å°\n",
    "        process = subprocess.Popen(['sysctl', \"hw.memsize\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE) # è¿è¡Œ sysctl å‘½ä»¤\n",
    "        stdout, stderr = process.communicate() # è·å–æ ‡å‡†è¾“å‡ºå’Œæ ‡å‡†é”™è¯¯\n",
    "        mem_bytes = int(stdout.decode().split(': ')[1].strip()) # è§£æè¾“å‡ºï¼Œè·å–å†…å­˜å¤§å°ï¼ˆå­—èŠ‚ï¼‰\n",
    "        mem_gb = mem_bytes / (1024**3) # è½¬æ¢ä¸º GB\n",
    "        mem_info = f\"{mem_gb:.2f} GB\" # æ ¼å¼åŒ–è¾“å‡º\n",
    "    else:  # Linux ç³»ç»Ÿ\n",
    "        try:\n",
    "            # åœ¨ Linux ä¸Šè¯»å– /proc/meminfo æ–‡ä»¶è·å–å†…å­˜ä¿¡æ¯\n",
    "            with open('/proc/meminfo') as f:\n",
    "                total_mem_kb = 0\n",
    "                available_mem_kb = 0\n",
    "                for line in f:\n",
    "                    if line.startswith('MemTotal'): # æŸ¥æ‰¾ä»¥ 'MemTotal' å¼€å¤´çš„è¡Œ\n",
    "                        total_mem_kb = int(line.split(':')[1].strip().split()[0]) # è§£æè¡Œï¼Œè·å–æ€»å†…å­˜ï¼ˆKBï¼‰\n",
    "                    elif line.startswith('MemAvailable'): # æŸ¥æ‰¾ä»¥ 'MemAvailable' å¼€å¤´çš„è¡Œ\n",
    "                         available_mem_kb = int(line.split(':')[1].strip().split()[0]) # è§£æè¡Œï¼Œè·å–å¯ç”¨å†…å­˜ï¼ˆKBï¼‰\n",
    "\n",
    "                if total_mem_kb > 0:\n",
    "                    total_mem_gb = total_mem_kb / (1024**2) # è½¬æ¢ä¸º GB\n",
    "                    mem_info = f\"{total_mem_gb:.2f} GB\" # æ ¼å¼åŒ–è¾“å‡ºæ€»å†…å­˜\n",
    "                    if available_mem_kb > 0:\n",
    "                        available_mem_gb = available_mem_kb / (1024**2)\n",
    "                        mem_info += f\" (Available: {available_mem_gb:.2f} GB)\" # æ·»åŠ å¯ç”¨å†…å­˜ä¿¡æ¯\n",
    "                else:\n",
    "                     mem_info = \"Could not retrieve memory info\" # å¦‚æœè¯»å–æ–‡ä»¶å‡ºé”™ï¼Œè®¾ç½®é”™è¯¯ä¿¡æ¯\n",
    "\n",
    "        except:\n",
    "            mem_info = \"Could not retrieve memory info\" # å¦‚æœè¯»å–æ–‡ä»¶å‡ºé”™ï¼Œè®¾ç½®é”™è¯¯ä¿¡æ¯\n",
    "    return mem_info # è¿”å›å†…å­˜ä¿¡æ¯\n",
    "\n",
    "# è·å– GPU ä¿¡æ¯çš„å‡½æ•°ï¼ŒåŒ…æ‹¬æ˜¾å­˜\n",
    "def get_gpu_info():\n",
    "    try:\n",
    "        # å°è¯•ä½¿ç”¨ nvidia-smi è·å– NVIDIA GPU ä¿¡æ¯å’Œæ˜¾å­˜\n",
    "        result = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total', '--format=csv,noheader'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # å¦‚æœå‘½ä»¤æˆåŠŸæ‰§è¡Œ\n",
    "            gpu_lines = result.stdout.strip().split('\\n') # è§£æè¾“å‡ºï¼Œè·å– GPU åç§°å’Œæ˜¾å­˜\n",
    "            gpu_info_list = []\n",
    "            for line in gpu_lines:\n",
    "                name, memory = line.split(', ')\n",
    "                gpu_info_list.append(f\"{name} ({memory})\") # æ ¼å¼åŒ– GPU ä¿¡æ¯\n",
    "            return \", \".join(gpu_info_list) if gpu_info_list else \"NVIDIA GPU found, but info not listed\" # è¿”å› GPU ä¿¡æ¯æˆ–æç¤ºä¿¡æ¯\n",
    "        else:\n",
    "             # å°è¯•ä½¿ç”¨ lshw è·å–å…¶ä»– GPU ä¿¡æ¯ (éœ€è¦å®‰è£… lshw)\n",
    "            try:\n",
    "                result_lshw = subprocess.run(['lshw', '-C', 'display'], capture_output=True, text=True)\n",
    "                if result_lshw.returncode == 0: # å¦‚æœå‘½ä»¤æˆåŠŸæ‰§è¡Œ\n",
    "                     # ç®€å•è§£æè¾“å‡ºä¸­çš„ product åç§°å’Œæ˜¾å­˜\n",
    "                    gpu_info_lines = []\n",
    "                    current_gpu = {}\n",
    "                    for line in result_lshw.stdout.splitlines():\n",
    "                        if 'product:' in line:\n",
    "                             if current_gpu:\n",
    "                                 gpu_info_lines.append(f\"{current_gpu.get('product', 'GPU')} ({current_gpu.get('memory', 'N/A')})\")\n",
    "                             current_gpu = {'product': line.split('product:')[1].strip()}\n",
    "                        elif 'size:' in line and 'memory' in line:\n",
    "                             current_gpu['memory'] = line.split('size:')[1].strip()\n",
    "\n",
    "                    if current_gpu: # æ·»åŠ æœ€åä¸€ä¸ª GPU çš„ä¿¡æ¯\n",
    "                        gpu_info_lines.append(f\"{current_gpu.get('product', 'GPU')} ({current_gpu.get('memory', 'N/A')})\")\n",
    "\n",
    "                    return \", \".join(gpu_info_lines) if gpu_info_lines else \"GPU found (via lshw), but info not parsed\" # å¦‚æœæ‰¾åˆ° GPU ä½†ä¿¡æ¯æ— æ³•è§£æï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "                else:\n",
    "                    return \"No GPU found (checked nvidia-smi and lshw)\" # å¦‚æœä¸¤ä¸ªå‘½ä»¤éƒ½æ‰¾ä¸åˆ° GPUï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "            except FileNotFoundError:\n",
    "                 return \"No GPU found (checked nvidia-smi, lshw not found)\" # å¦‚æœæ‰¾ä¸åˆ° lshw å‘½ä»¤ï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "    except FileNotFoundError:\n",
    "        return \"No GPU found (nvidia-smi not found)\" # å¦‚æœæ‰¾ä¸åˆ° nvidia-smi å‘½ä»¤ï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "\n",
    "\n",
    "# è·å– CUDA ç‰ˆæœ¬çš„å‡½æ•°\n",
    "def get_cuda_version():\n",
    "    try:\n",
    "        # å°è¯•ä½¿ç”¨ nvcc --version è·å– CUDA ç‰ˆæœ¬\n",
    "        result = subprocess.run(['nvcc', '--version'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # å¦‚æœå‘½ä»¤æˆåŠŸæ‰§è¡Œ\n",
    "            for line in result.stdout.splitlines():\n",
    "                if 'release' in line: # æŸ¥æ‰¾åŒ…å« 'release' çš„è¡Œ\n",
    "                    return line.split('release ')[1].split(',')[0] # è§£æè¡Œï¼Œæå–ç‰ˆæœ¬å·\n",
    "        return \"CUDA not found or version not parsed\" # å¦‚æœæ‰¾ä¸åˆ° CUDA æˆ–ç‰ˆæœ¬æ— æ³•è§£æï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "    except FileNotFoundError:\n",
    "        return \"CUDA not found\" # å¦‚æœæ‰¾ä¸åˆ° nvcc å‘½ä»¤ï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "\n",
    "# è·å– Python ç‰ˆæœ¬çš„å‡½æ•°\n",
    "def get_python_version():\n",
    "    return platform.python_version() # è·å– Python ç‰ˆæœ¬\n",
    "\n",
    "# è·å– Conda ç‰ˆæœ¬çš„å‡½æ•°\n",
    "def get_conda_version():\n",
    "    try:\n",
    "        # å°è¯•ä½¿ç”¨ conda --version è·å– Conda ç‰ˆæœ¬\n",
    "        result = subprocess.run(['conda', '--version'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # å¦‚æœå‘½ä»¤æˆåŠŸæ‰§è¡Œ\n",
    "            return result.stdout.strip() # è¿”å› Conda ç‰ˆæœ¬\n",
    "        return \"Conda not found or version not parsed\" # å¦‚æœæ‰¾ä¸åˆ° Conda æˆ–ç‰ˆæœ¬æ— æ³•è§£æï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "    except FileNotFoundError:\n",
    "        return \"Conda not found\" # å¦‚æœæ‰¾ä¸åˆ° conda å‘½ä»¤ï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "\n",
    "# è·å–ç‰©ç†ç£ç›˜ç©ºé—´ä¿¡æ¯çš„å‡½æ•°\n",
    "def get_disk_space():\n",
    "    try:\n",
    "        total, used, free = shutil.disk_usage(\"/\") # è·å–æ ¹ç›®å½•çš„ç£ç›˜ä½¿ç”¨æƒ…å†µ\n",
    "        total_gb = total / (1024**3) # è½¬æ¢ä¸º GB\n",
    "        used_gb = used / (1024**3) # è½¬æ¢ä¸º GB\n",
    "        free_gb = free / (1024**3) # è½¬æ¢ä¸º GB\n",
    "        return f\"Total: {total_gb:.2f} GB, Used: {used_gb:.2f} GB, Free: {free_gb:.2f} GB\" # æ ¼å¼åŒ–è¾“å‡º\n",
    "    except Exception as e:\n",
    "        return f\"Could not retrieve disk info: {e}\" # å¦‚æœè·å–ä¿¡æ¯å‡ºé”™ï¼Œè®¾ç½®é”™è¯¯ä¿¡æ¯\n",
    "\n",
    "# è·å–ç¯å¢ƒä¿¡æ¯\n",
    "os_name = platform.system() # è·å–æ“ä½œç³»ç»Ÿåç§°\n",
    "os_version = platform.release() # è·å–æ“ä½œç³»ç»Ÿç‰ˆæœ¬\n",
    "if os_name == \"Linux\":\n",
    "    try:\n",
    "        # åœ¨ Linux ä¸Šå°è¯•è·å–å‘è¡Œç‰ˆå’Œç‰ˆæœ¬\n",
    "        lsb_info = subprocess.run(['lsb_release', '-a'], capture_output=True, text=True)\n",
    "        if lsb_info.returncode == 0: # å¦‚æœå‘½ä»¤æˆåŠŸæ‰§è¡Œ\n",
    "            for line in lsb_info.stdout.splitlines():\n",
    "                if 'Description:' in line: # æŸ¥æ‰¾åŒ…å« 'Description:' çš„è¡Œ\n",
    "                    os_version = line.split('Description:')[1].strip() # æå–æè¿°ä¿¡æ¯ä½œä¸ºç‰ˆæœ¬\n",
    "                    break # æ‰¾åˆ°åé€€å‡ºå¾ªç¯\n",
    "                elif 'Release:' in line: # æŸ¥æ‰¾åŒ…å« 'Release:' çš„è¡Œ\n",
    "                     os_version = line.split('Release:')[1].strip() # æå–ç‰ˆæœ¬å·\n",
    "                     # å°è¯•è·å– codename\n",
    "                     try:\n",
    "                         codename_info = subprocess.run(['lsb_release', '-c'], capture_output=True, text=True)\n",
    "                         if codename_info.returncode == 0:\n",
    "                             os_version += f\" ({codename_info.stdout.split(':')[1].strip()})\" # å°† codename æ·»åŠ åˆ°ç‰ˆæœ¬ä¿¡æ¯ä¸­\n",
    "                     except:\n",
    "                         pass # å¦‚æœè·å– codename å¤±è´¥åˆ™å¿½ç•¥\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        pass # lsb_release å¯èƒ½æœªå®‰è£…ï¼Œå¿½ç•¥é”™è¯¯\n",
    "\n",
    "full_os_info = f\"{os_name} {os_version}\" # ç»„åˆå®Œæ•´çš„æ“ä½œç³»ç»Ÿä¿¡æ¯\n",
    "cpu_info = get_cpu_info() # è°ƒç”¨å‡½æ•°è·å– CPU ä¿¡æ¯å’Œæ ¸å¿ƒæ•°é‡\n",
    "memory_info = get_memory_info() # è°ƒç”¨å‡½æ•°è·å–å†…å­˜ä¿¡æ¯\n",
    "gpu_info = get_gpu_info() # è°ƒç”¨å‡½æ•°è·å– GPU ä¿¡æ¯å’Œæ˜¾å­˜\n",
    "cuda_version = get_cuda_version() # è°ƒç”¨å‡½æ•°è·å– CUDA ç‰ˆæœ¬\n",
    "python_version = get_python_version() # è°ƒç”¨å‡½æ•°è·å– Python ç‰ˆæœ¬\n",
    "conda_version = get_conda_version() # è°ƒç”¨å‡½æ•°è·å– Conda ç‰ˆæœ¬\n",
    "disk_info = get_disk_space() # è°ƒç”¨å‡½æ•°è·å–ç‰©ç†ç£ç›˜ç©ºé—´ä¿¡æ¯\n",
    "\n",
    "\n",
    "# åˆ›å»ºç”¨äºå­˜å‚¨æ•°æ®çš„å­—å…¸\n",
    "env_data = {\n",
    "    \"é¡¹ç›®\": [ # é¡¹ç›®åç§°åˆ—è¡¨\n",
    "        \"æ“ä½œç³»ç»Ÿ\",\n",
    "        \"CPU ä¿¡æ¯\",\n",
    "        \"å†…å­˜ä¿¡æ¯\",\n",
    "        \"GPU ä¿¡æ¯\",\n",
    "        \"CUDA ä¿¡æ¯\",\n",
    "        \"Python ç‰ˆæœ¬\",\n",
    "        \"Conda ç‰ˆæœ¬\",\n",
    "        \"ç‰©ç†ç£ç›˜ç©ºé—´\" # æ·»åŠ ç‰©ç†ç£ç›˜ç©ºé—´\n",
    "    ],\n",
    "    \"ä¿¡æ¯\": [ # å¯¹åº”çš„ä¿¡æ¯åˆ—è¡¨\n",
    "        full_os_info,\n",
    "        cpu_info,\n",
    "        memory_info,\n",
    "        gpu_info,\n",
    "        cuda_version,\n",
    "        python_version,\n",
    "        conda_version,\n",
    "        disk_info # æ·»åŠ ç‰©ç†ç£ç›˜ç©ºé—´ä¿¡æ¯\n",
    "    ]\n",
    "}\n",
    "\n",
    "# åˆ›å»ºä¸€ä¸ª pandas DataFrame\n",
    "df = pd.DataFrame(env_data)\n",
    "\n",
    "# æ‰“å°è¡¨æ ¼\n",
    "print(\"### ç¯å¢ƒä¿¡æ¯\") # æ‰“å°æ ‡é¢˜\n",
    "print(df.to_markdown(index=False)) # å°† DataFrame è½¬æ¢ä¸º Markdown æ ¼å¼å¹¶æ‰“å°ï¼Œä¸åŒ…å«ç´¢å¼•\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç¬¬ 0 éƒ¨åˆ†: è®¾ç½®ä¸å®‰è£…\n",
    "\n",
    "é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦å®‰è£…å¿…è¦çš„ Python åŒ…å¹¶è®¾ç½®ç¯å¢ƒã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: langchain==1.1.3 in /root/miniconda3/envs/langchain1.x/lib/python3.10/site-packages (1.1.3)\n",
      "Requirement already satisfied: langchain-openai==1.1.1 in /root/miniconda3/envs/langchain1.x/lib/python3.10/site-packages (1.1.1)\n",
      "Requirement already satisfied: python-dotenv==1.2.1 in /root/miniconda3/envs/langchain1.x/lib/python3.10/site-packages (1.2.1)\n",
      "Requirement already satisfied: langgraph==1.0.4 in /root/miniconda3/envs/langchain1.x/lib/python3.10/site-packages (1.0.4)\n",
      "Requirement already satisfied: sqlalchemy==2.0.44 in /root/miniconda3/envs/langchain1.x/lib/python3.10/site-packages (2.0.44)\n",
      "Requirement already satisfied: requests==2.32.5 in /root/miniconda3/envs/langchain1.x/lib/python3.10/site-packages (2.32.5)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.1.2 in /root/miniconda3/envs/langchain1.x/lib/python3.10/site-packages (from langchain==1.1.3) (1.1.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /root/miniconda3/envs/langchain1.x/lib/python3.10/site-packages (from langchain==1.1.3) (2.12.5)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /root/miniconda3/envs/langchain1.x/lib/python3.10/site-packages (from langgraph==1.0.4) (3.0.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /root/miniconda3/envs/langchain1.x/lib/python3.10/site-packages (from langgraph==1.0.4) (1.0.5)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /root/miniconda3/envs/langchain1.x/lib/python3.10/site-packages (from langgraph==1.0.4) (0.2.14)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in /root/miniconda3/envs/langchain1.x/lib/python3.10/site-packages (from langgraph==1.0.4) (3.6.0)\n",
      "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /root/miniconda3/envs/langchain1.x/lib/python3.10/site-packages (from langchain-openai==1.1.1) (2.9.0)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /root/miniconda3/envs/langchain1.x/lib/python3.10/site-packages (from langchain-openai==1.1.1) (0.12.0)\n",
      "Requirement already satisfied: greenlet>=1 in /root/miniconda3/envs/langchain1.x/lib/python3.10/site-packages (from sqlalchemy==2.0.44) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /root/miniconda3/envs/langchain1.x/lib/python3.10/site-packages (from sqlalchemy==2.0.44) (4.15.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /root/miniconda3/envs/langchain1.x/lib/python3.10/site-packages (from requests==2.32.5) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/miniconda3/envs/langchain1.x/lib/python3.10/site-packages (from requests==2.32.5) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/miniconda3/envs/langchain1.x/lib/python3.10/site-packages (from requests==2.32.5) (2.6.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniconda3/envs/langchain1.x/lib/python3.10/site-packages (from requests==2.32.5) (2025.11.12)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /root/miniconda3/envs/langchain1.x/lib/python3.10/site-packages (from langchain-core<2.0.0,>=1.1.2->langchain==1.1.3) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /root/miniconda3/envs/langchain1.x/lib/python3.10/site-packages (from langchain-core<2.0.0,>=1.1.2->langchain==1.1.3) (0.4.56)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /root/miniconda3/envs/langchain1.x/lib/python3.10/site-packages (from langchain-core<2.0.0,>=1.1.2->langchain==1.1.3) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /root/miniconda3/envs/langchain1.x/lib/python3.10/site-packages (from langchain-core<2.0.0,>=1.1.2->langchain==1.1.3) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /root/miniconda3/envs/langchain1.x/lib/python3.10/site-packages (from langchain-core<2.0.0,>=1.1.2->langchain==1.1.3) (9.1.2)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /root/miniconda3/envs/langchain1.x/lib/python3.10/site-packages (from langchain-core<2.0.0,>=1.1.2->langchain==1.1.3) (0.12.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /root/miniconda3/envs/langchain1.x/lib/python3.10/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.1.2->langchain==1.1.3) (3.0.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in /root/miniconda3/envs/langchain1.x/lib/python3.10/site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph==1.0.4) (1.12.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in /root/miniconda3/envs/langchain1.x/lib/python3.10/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph==1.0.4) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /root/miniconda3/envs/langchain1.x/lib/python3.10/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph==1.0.4) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /root/miniconda3/envs/langchain1.x/lib/python3.10/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.2->langchain==1.1.3) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /root/miniconda3/envs/langchain1.x/lib/python3.10/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.2->langchain==1.1.3) (0.25.0)\n",
      "Requirement already satisfied: anyio in /root/miniconda3/envs/langchain1.x/lib/python3.10/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph==1.0.4) (4.12.0)\n",
      "Requirement already satisfied: httpcore==1.* in /root/miniconda3/envs/langchain1.x/lib/python3.10/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph==1.0.4) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /root/miniconda3/envs/langchain1.x/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph==1.0.4) (0.16.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /root/miniconda3/envs/langchain1.x/lib/python3.10/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai==1.1.1) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /root/miniconda3/envs/langchain1.x/lib/python3.10/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai==1.1.1) (0.12.0)\n",
      "Requirement already satisfied: sniffio in /root/miniconda3/envs/langchain1.x/lib/python3.10/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai==1.1.1) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /root/miniconda3/envs/langchain1.x/lib/python3.10/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai==1.1.1) (4.67.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /root/miniconda3/envs/langchain1.x/lib/python3.10/site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph==1.0.4) (1.3.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /root/miniconda3/envs/langchain1.x/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain==1.1.3) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /root/miniconda3/envs/langchain1.x/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain==1.1.3) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /root/miniconda3/envs/langchain1.x/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain==1.1.3) (0.4.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /root/miniconda3/envs/langchain1.x/lib/python3.10/site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai==1.1.1) (2025.11.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# å®‰è£…æ‰€éœ€çš„åŒ…\n",
    "!pip install langchain==1.1.3 \\\n",
    "langchain-openai==1.1.1 \\\n",
    "python-dotenv==1.2.1 \\\n",
    "langgraph==1.0.4 \\\n",
    "sqlalchemy==2.0.44 \\\n",
    "requests==2.32.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### é…ç½®æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¼å…¥å¿…è¦çš„æ¨¡å—\n",
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    \"\"\"\n",
    "    è®¾ç½®ç¯å¢ƒå˜é‡çš„è¾…åŠ©å‡½æ•°\n",
    "    å¦‚æœç¯å¢ƒå˜é‡ä¸å­˜åœ¨ï¼Œåˆ™æç¤ºç”¨æˆ·è¾“å…¥\n",
    "    \"\"\"\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "\n",
    "# sk-AGnnT4BAKJBA22uYA32fF98e9d1645739916347057D2A14f\n",
    "\n",
    "# è®¾ç½® OpenAI API å¯†é’¥ \n",
    "# è¿™æ˜¯ä½¿ç”¨ OpenAI æ¨¡å‹æ‰€å¿…éœ€çš„\n",
    "_set_env(\"OPENAI_API_KEY\")\n",
    "# è®¾ç½® OpenAI APIä»£ç†åœ°å€ (ä¾‹å¦‚ï¼šhttps://api.apiyi.com/v1ï¼‰\n",
    "_set_env(\"OPENAI_BASE_URL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "æ¨¡å‹åˆå§‹åŒ–æ–‡ä»¶\n",
    "\n",
    "æ­¤æ–‡ä»¶é…ç½®åº”ç”¨ç¨‹åºä¸­ä½¿ç”¨çš„ LLM (å¤§è¯­è¨€æ¨¡å‹)ã€‚\n",
    "\n",
    "é»˜è®¤é…ç½®:\n",
    "- é»˜è®¤æä¾›å•†æ˜¯ OpenAI (ä½¿ç”¨ o3-mini æ¨¡å‹)\n",
    "- ä½ ä¹Ÿå¯ä»¥é€šè¿‡å–æ¶ˆæ³¨é‡Šç›¸åº”çš„è¡Œæ¥åˆ‡æ¢åˆ° Anthropic\n",
    "\n",
    "å¤‡é€‰æä¾›å•†:\n",
    "è¦ä½¿ç”¨ä¸åŒçš„ LLM æä¾›å•†ï¼Œè¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤æ“ä½œ:\n",
    "1. æ³¨é‡Šæ‰ä¸‹æ–¹çš„ \"Default Models\" (é»˜è®¤æ¨¡å‹) éƒ¨åˆ†\n",
    "2. å–æ¶ˆæ³¨é‡Šä½ æƒ³è¦çš„æä¾›å•†éƒ¨åˆ†:\n",
    "   - Azure OpenAI: éœ€è¦è®¾ç½® AZURE_OPENAI_API_KEY å’Œ AZURE_OPENAI_ENDPOINT\n",
    "   - AWS Bedrock: éœ€è¦è®¾ç½® AWS å‡­è¯å’Œé…ç½®\n",
    "   - Google Vertex AI: éœ€è¦è®¾ç½® GOOGLE_APPLICATION_CREDENTIALS\n",
    "3. æŒ‰ç…§æ¯ä¸ªéƒ¨åˆ†å†…çš„è®¾ç½®è¯´æ˜è¿›è¡Œæ“ä½œ\n",
    "\"\"\"\n",
    "\n",
    "# \"\"\"é»˜è®¤æ¨¡å‹ (Default Models)\"\"\"\n",
    "from langchain.chat_models import init_chat_model\n",
    "# åˆå§‹åŒ–èŠå¤©æ¨¡å‹ï¼Œè¿™é‡Œä½¿ç”¨ OpenAI çš„ o3-mini\n",
    "model = init_chat_model(\"openai:o3-mini\")\n",
    "\n",
    "# ä½¿ç”¨ Anthropic æ›¿ä»£ OpenAI\n",
    "# model = init_chat_model(\"anthropic:claude-haiku-4-5\")\n",
    "\n",
    "\n",
    "# \"\"\"AZURE OpenAI Version\"\"\"\n",
    "# from langchain_openai import AzureChatOpenAI\n",
    "# # from langchain_anthropic import ChatAnthropic\n",
    "# # from langchain_google_vertexai import ChatVertexAI\n",
    "# from azure.identity import InteractiveBrowserCredential\n",
    "\n",
    "# credential = InteractiveBrowserCredential()\n",
    "\n",
    "# def get_token():\n",
    "#     token = credential.get_token(\"https://cognitiveservices.azure.com/.default\")\n",
    "#     return token.token\n",
    "\n",
    "# For AzureOpenAI, make sure you set AZURE_OPENAI_API_KEY and AZURE_OPENAI_ENDPOINT\n",
    "\n",
    "# Azure OpenAI: Using Environment Variables\n",
    "# AZURE_OPENAI_GPT_4O = AzureChatOpenAI(\n",
    "#     azure_deployment=\"gpt-4o\",\n",
    "#     streaming=True\n",
    "# )\n",
    "\n",
    "# Azure OpenAI: Using Azure AD\n",
    "# AZURE_OPENAI_GPT_4O = AzureChatOpenAI(\n",
    "#     api_version=\"2024-03-01-preview\",\n",
    "#     azure_endpoint=\"https://deployment.openai.azure.com/\",\n",
    "#     azure_deployment=\"gpt-4o\",\n",
    "#     azure_ad_token_provider=get_token\n",
    "# )\n",
    "\n",
    "\n",
    "# \"\"\"Bedrock Version\"\"\"\n",
    "# from dotenv import load_dotenv\n",
    "# from langchain_aws import ChatBedrockConverse\n",
    "# import os\n",
    "\n",
    "# load_dotenv(dotenv_path=\"../../.env\", override=True)\n",
    "\n",
    "# AWS_ACCESS_KEY_ID=os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "# AWS_SECRET_ACCESS_KEY=os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "# AWS_REGION_NAME=os.getenv(\"AWS_REGION_NAME\")\n",
    "# AWS_MODEL_ARN=os.getenv(\"AWS_MODEL_ARN\")\n",
    "\n",
    "# model = ChatBedrockConverse(\n",
    "#     aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "#     aws_secret_access_key=AWS_SECRET_ACCESS_KEY, \n",
    "#     region_name=AWS_REGION_NAME,\n",
    "#     provider=\"anthropic\",\n",
    "#     model_id=AWS_MODEL_ARN\n",
    "# )\n",
    "\n",
    "\n",
    "# \"\"\"Google Vertex AI version\"\"\"\n",
    "# Make sure you have your vertex ai credentials setup and your GOOGLE_APPLICATION_CREDENTIALS are pointing to the JSON file. \n",
    "\n",
    "# import os\n",
    "# from pathlib import Path\n",
    "# from dotenv import load_dotenv\n",
    "# from langchain.chat_models import init_chat_model\n",
    "\n",
    "# # Find project root and load .env\n",
    "# # Use __file__ to get the location of this file, then go up two directories to project root\n",
    "# project_root = Path.cwd().parent.parent\n",
    "# load_dotenv(dotenv_path=project_root / \".env\", override=True)\n",
    "\n",
    "# # Fix credentials path to absolute\n",
    "# if \"GOOGLE_APPLICATION_CREDENTIALS\" in os.environ:\n",
    "#     cred_path = os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]\n",
    "#     if not os.path.isabs(cred_path):\n",
    "#         os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = str(project_root / cred_path.lstrip(\"./\"))\n",
    "\n",
    "# # Create model\n",
    "# model = init_chat_model(\"google_vertexai:gemini-2.5-flash\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å¸¸ç”¨æ–¹æ³•é…ç½®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¿½ç•¥ LangSmith ä½¿ç”¨ UUID v7 çš„è­¦å‘Šï¼ˆåœ¨ç®€å•çš„æ— çº¿ç¨‹ ID ç¤ºä¾‹ä¸­ï¼‰\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', message='LangSmith now uses UUID v7')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç¬¬ 1 éƒ¨åˆ†: ä½¿ç”¨ Interrupts å®ç°äººæœºäº¤äº’ (Human-in-the-Loop)\n",
    "\n",
    "### é—®é¢˜èƒŒæ™¯\n",
    "\n",
    "æƒ³è±¡ä¸€ä¸‹ï¼Œä½ æ­£åœ¨æ„å»ºä¸€ä¸ªå¯ä»¥å‘é€ç”µå­é‚®ä»¶æˆ–è¿›è¡Œç”µå­å•†åŸä¸‹å•è´­ä¹°çš„ Agentã€‚ä½ è‚¯å®šä¸å¸Œæœ›å®ƒè‡ªåŠ¨æ‰§è¡Œè¿™äº›æ“ä½œ â€”â€” ä½ å¸Œæœ›å…ˆç»è¿‡äººå·¥æ‰¹å‡†ï¼\n",
    "\n",
    "**Human-in-the-Loop** å…è®¸ä½ ï¼š\n",
    "- æš‚åœæ‰§è¡Œä»¥è¿›è¡Œå®¡æŸ¥\n",
    "- æ‰¹å‡†ã€æ‹’ç»æˆ–ç¼–è¾‘åŠ¨ä½œ\n",
    "- ä¸ºæ•æ„Ÿæ“ä½œæ·»åŠ å®‰å…¨æ§åˆ¶\n",
    "\n",
    "### å·¥ä½œåŸç† (LangGraph 1.0 æ–°ç‰¹æ€§)\n",
    "\n",
    "LangGraph 1.0 å¼•å…¥äº†åŠ¨æ€ `interrupt` å‡½æ•°ï¼Œæ›¿ä»£äº†æ—§ç‰ˆè¾ƒä¸ºé™æ€çš„é…ç½®æ–¹å¼ã€‚\n",
    "\n",
    "1. Agent é‡åˆ° `interrupt()` å‡½æ•° - æ‰§è¡Œæš‚åœ\n",
    "2. ç³»ç»Ÿå°†ä¿¡æ¯å±•ç¤ºç»™äººç±»\n",
    "3. äººç±»æä¾›è¾“å…¥ï¼ˆæ‰¹å‡†/æ‹’ç»/ç¼–è¾‘ï¼‰\n",
    "4. Agent ä½¿ç”¨ `Command(resume=...)` æ¢å¤æ‰§è¡Œï¼Œå¹¶å°†äººç±»è¾“å…¥ä½œä¸º `interrupt()` çš„è¿”å›å€¼ä¼ å›"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ç¤ºä¾‹ 1: ç®€å•çš„å®¡æ‰¹å·¥ä½œæµ\n",
    "\n",
    "è®©æˆ‘ä»¬ä»ä¸€ä¸ªç®€å•çš„ä¾‹å­å¼€å§‹â€”â€”åœ¨å‘é€ç”µå­é‚®ä»¶ä¹‹å‰è¯·æ±‚æ‰¹å‡†ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "#### ğŸ”„ ç‰ˆæœ¬å¯¹æ¯”ï¼š`interrupt()` çš„ä½¿ç”¨\n",
    "\n",
    "```python\n",
    "# âŒ æ—§ç‰ˆ (LangGraph 0.x) - éœ€è¦åœ¨ç¼–è¯‘æ—¶é…ç½®\n",
    "# 1. å®šä¹‰èŠ‚ç‚¹\n",
    "def send_email_node(state):\n",
    "    # ... å‘é€é‚®ä»¶é€»è¾‘\n",
    "    return state\n",
    "\n",
    "# 2. åœ¨ç¼–è¯‘æ—¶æŒ‡å®šä¸­æ–­ç‚¹\n",
    "builder.add_node(\"send_email\", send_email_node)\n",
    "graph = builder.compile(\n",
    "    interrupt_before=[\"send_email\"]  # é™æ€é…ç½®\n",
    ")\n",
    "\n",
    "# 3. è¿è¡Œæ—¶æ— æ³•åŠ¨æ€å†³å®šæ˜¯å¦ä¸­æ–­\n",
    "result = graph.invoke(input, config=config)\n",
    "\n",
    "# âœ… æ–°ç‰ˆ (LangGraph 1.0) - åœ¨å·¥å…·å†…éƒ¨åŠ¨æ€ä¸­æ–­\n",
    "@tool\n",
    "def send_email(to: str, subject: str, body: str) -> str:\n",
    "    # å¯ä»¥åŸºäºæ¡ä»¶åŠ¨æ€å†³å®šæ˜¯å¦éœ€è¦æ‰¹å‡†\n",
    "    if is_sensitive_content(body):  # æ¡ä»¶åˆ¤æ–­\n",
    "        approval = interrupt({\n",
    "            \"to\": to,\n",
    "            \"subject\": subject,\n",
    "            \"message\": \"æ£€æµ‹åˆ°æ•æ„Ÿå†…å®¹ï¼Œéœ€è¦æ‰¹å‡†\"\n",
    "        })\n",
    "        if not approval[\"approved\"]:\n",
    "            return \"é‚®ä»¶å·²å–æ¶ˆ\"\n",
    "    return f\"é‚®ä»¶å·²å‘é€è‡³ {to}\"\n",
    "```\n",
    "\n",
    "**æ–°ç‰ˆä¼˜åŠ¿**ï¼š\n",
    "- âœ… **æ¡ä»¶æ€§ä¸­æ–­**ï¼šåªåœ¨éœ€è¦æ—¶æ‰ä¸­æ–­ï¼ˆå¦‚\"æ•æ„Ÿå†…å®¹\"ã€\"é«˜é‡‘é¢\"ç­‰ï¼‰\n",
    "- âœ… **ä¸Šä¸‹æ–‡ä¼ é€’**ï¼šå¯ä»¥å‘å®¡æ‰¹è€…ä¼ é€’è¯¦ç»†ä¿¡æ¯\n",
    "- âœ… **æ— éœ€ä¿®æ”¹å›¾ç»“æ„**ï¼šé€»è¾‘å°è£…åœ¨å·¥å…·å†…éƒ¨\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å·¥å…·åˆ›å»ºæˆåŠŸï¼\n",
      "å·¥å…·åç§°: send_email\n",
      "å·¥å…·æè¿°: å‘é€é‚®ä»¶ç»™æ¥æ”¶è€…ã€‚\n"
     ]
    }
   ],
   "source": [
    "from langgraph.types import interrupt\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def send_email(to: str, subject: str, body: str) -> str:\n",
    "    \"\"\"å‘é€é‚®ä»¶ç»™æ¥æ”¶è€…ã€‚\"\"\"\n",
    "    \n",
    "    # æš‚åœä»¥ç­‰å¾…äººå·¥æ‰¹å‡†\n",
    "    # interrupt æ¥æ”¶çš„å‚æ•°ä¼šä½œä¸ºæš‚åœæ—¶çš„ä¿¡æ¯è¿”å›ç»™å‰ç«¯/ç”¨æˆ·\n",
    "    # ç¨‹åºä¼šåœ¨è¿™é‡ŒæŒ‚èµ·ï¼Œç›´åˆ°æ”¶åˆ° resume æŒ‡ä»¤\n",
    "    approval = interrupt({\n",
    "        \"action\": \"send_email\",\n",
    "        \"to\": to,\n",
    "        \"subject\": subject,\n",
    "        \"body\": body,\n",
    "        \"message\": \"æ‚¨ç¡®å®šè¦å‘é€è¿™å°é‚®ä»¶å—ï¼Ÿ\"\n",
    "    })\n",
    "    \n",
    "    # æ¢å¤æ‰§è¡Œåï¼Œapproval å˜é‡å°†åŒ…å« resume æ—¶ä¼ å…¥çš„æ•°æ®\n",
    "    if approval.get(\"approved\"): # å¦‚æœé€šè¿‡æ‰¹å‡†ï¼ˆæ ¹æ®æˆ‘ä»¬å®šä¹‰çš„åè®®ï¼‰\n",
    "        # åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œè¿™é‡Œä¼šå®é™…å‘é€é‚®ä»¶\n",
    "        return f\"é‚®ä»¶å·²å‘é€è‡³ {to}ï¼Œä¸»é¢˜ä¸º '{subject}'\"\n",
    "    else:\n",
    "        return \"ç”¨æˆ·å–æ¶ˆäº†é‚®ä»¶å‘é€\"\n",
    "\n",
    "# æµ‹è¯•å·¥å…·å®šä¹‰\n",
    "print(\"å·¥å…·åˆ›å»ºæˆåŠŸï¼\")\n",
    "print(f\"å·¥å…·åç§°: {send_email.name}\")\n",
    "print(f\"å·¥å…·æè¿°: {send_email.description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### åˆ›å»ºå¸¦æœ‰ Human-in-the-Loop çš„ Agent\n",
    "\n",
    "ç°åœ¨è®©æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªä½¿ç”¨æ­¤å·¥å…·çš„ Agentã€‚**åˆ‡è®°ï¼š** Interrupts å¿…é¡»é…åˆ Checkpointer ä½¿ç”¨ï¼Œå¦åˆ™æ— æ³•ä¿å­˜æš‚åœæ—¶çš„çŠ¶æ€ï¼\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”„ Checkpointer çš„å˜åŒ– (0.x vs 1.0)\n",
    "\n",
    "#### LangGraph 1.0 ç»Ÿä¸€äº† Checkpointer æ¥å£\n",
    "\n",
    "**æ—§ç‰ˆ (0.x) çš„é—®é¢˜**ï¼š\n",
    "- é…ç½®æ–¹å¼ä¸ç»Ÿä¸€\n",
    "- ä¸åŒçš„ checkpointer æœ‰ä¸åŒçš„åˆå§‹åŒ–å‚æ•°\n",
    "- æ–‡æ¡£åˆ†æ•£ï¼Œéš¾ä»¥é€‰æ‹©åˆé€‚çš„å®ç°\n",
    "\n",
    "**æ–°ç‰ˆ (1.0) çš„æ”¹è¿›**ï¼š\n",
    "\n",
    "```python\n",
    "# âœ… ç»Ÿä¸€çš„æ¥å£ï¼Œæ¸…æ™°çš„é€‰æ‹©\n",
    "\n",
    "# 1. å¼€å‘/æµ‹è¯•ç¯å¢ƒ - å†…å­˜å­˜å‚¨\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "checkpointer = MemorySaver()\n",
    "\n",
    "# 2. SQLite - æœ¬åœ°æŒä¹…åŒ–\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "checkpointer = SqliteSaver.from_conn_string(\"sqlite:///checkpoints.db\")\n",
    "\n",
    "# 3. PostgreSQL - ç”Ÿäº§ç¯å¢ƒæ¨è\n",
    "from langgraph.checkpoint.postgres import PostgresSaver\n",
    "checkpointer = PostgresSaver.from_conn_string(\"postgresql://...\")\n",
    "\n",
    "# 4. è‡ªå®šä¹‰ - å®ç° BaseCheckpointSaver æ¥å£\n",
    "from langgraph.checkpoint import BaseCheckpointSaver\n",
    "class MyCustomSaver(BaseCheckpointSaver):\n",
    "    # å®ç° get(), put(), list() æ–¹æ³•\n",
    "    pass\n",
    "```\n",
    "\n",
    "**é€‰æ‹©æŒ‡å—**ï¼š\n",
    "- **`MemorySaver`**ï¼šå¿«é€ŸåŸå‹ã€æµ‹è¯•ã€demo\n",
    "- **`SqliteSaver`**ï¼šå•æœºåº”ç”¨ã€å°è§„æ¨¡ç”Ÿäº§\n",
    "- **`PostgresSaver`**ï¼šå¤šç”¨æˆ·ã€é«˜å¹¶å‘ã€ç”Ÿäº§ç¯å¢ƒ\n",
    "\n",
    "**ä¸ºä»€ä¹ˆ Checkpointer æ˜¯å¿…é¡»çš„ï¼Ÿ**\n",
    "- **Interrupt æ¢å¤**ï¼šä¿å­˜æš‚åœæ—¶çš„å®Œæ•´çŠ¶æ€\n",
    "- **å¤šè½®å¯¹è¯**ï¼šä¿æŒä¼šè¯å†å²\n",
    "- **å®¹é”™èƒ½åŠ›**ï¼šæ•…éšœåå¯ä»¥ä»ä¸­æ–­ç‚¹ç»§ç»­\n",
    "- **æ—¶é—´æ—…è¡Œ**ï¼šå›é€€åˆ°å†å²çŠ¶æ€è¿›è¡Œè°ƒè¯•\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# åˆ›å»º Checkpointer ç”¨äºæŒä¹…åŒ–\n",
    "checkpointer = MemorySaver()\n",
    "\n",
    "# åˆ›å»ºå¸¦æœ‰é‚®ä»¶å·¥å…·çš„ Agent\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[send_email],\n",
    "    system_prompt=\"ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„é‚®ä»¶åŠ©æ‰‹ã€‚å½“è¢«è¦æ±‚å‘é€é‚®ä»¶æ—¶ï¼Œè¯·ä½¿ç”¨ send_email å·¥å…·ã€‚\",\n",
    "    checkpointer=checkpointer  # å¿…é¡»é¡¹ï¼šç”¨äº interrupts\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### è¿è¡Œç›´åˆ°ä¸­æ–­ (Running Until Interrupt)\n",
    "\n",
    "è®©æˆ‘ä»¬è¿è¡Œ Agentï¼Œçœ‹çœ‹å®ƒå¦‚ä½•æš‚åœä»¥ç­‰å¾…æ‰¹å‡†ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent å·²æš‚åœç­‰å¾…æ‰¹å‡†\n",
      "\n",
      "ä¸­æ–­è¯¦æƒ…ï¼š\n",
      "  æ”¶ä»¶äºº: alice@example.com\n",
      "  ä¸»é¢˜: æ˜å¤©å¼€ä¼š\n",
      "  å†…å®¹: æˆ‘ä»¬ä¸‹åˆ3ç‚¹è§é¢ã€‚\n",
      "  æ¶ˆæ¯: æ‚¨ç¡®å®šè¦å‘é€è¿™å°é‚®ä»¶å—ï¼Ÿ\n"
     ]
    }
   ],
   "source": [
    "from langchain.messages import HumanMessage\n",
    "from langsmith import uuid7\n",
    "\n",
    "# ä¸ºæ­¤å¯¹è¯åˆ›å»ºå”¯ä¸€çº¿ç¨‹\n",
    "config = {\"configurable\": {\"thread_id\": uuid7()}}\n",
    "\n",
    "# è¿è¡Œ Agent\n",
    "result = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(content=\"ç»™ alice@example.com å‘é€ä¸€å°é‚®ä»¶ï¼Œä¸»é¢˜æ˜¯ 'æ˜å¤©å¼€ä¼š'ï¼Œå†…å®¹æ˜¯ 'æˆ‘ä»¬ä¸‹åˆ3ç‚¹è§é¢ã€‚'\")]\n",
    "    },\n",
    "    config=config\n",
    ")\n",
    "\n",
    "# æ£€æŸ¥æ˜¯å¦è§¦å‘äº† interrupt\n",
    "# åœ¨ LangGraph 1.0 ä¸­ï¼Œå¦‚æœå›  interrupt æš‚åœï¼Œç»“æœä¸­ä¼šåŒ…å« __interrupt__ é”®\n",
    "if \"__interrupt__\" in result:\n",
    "    print(\"Agent å·²æš‚åœç­‰å¾…æ‰¹å‡†\\n\")\n",
    "\n",
    "    # è·å– interrupt çš„è¯¦ç»†ä¿¡æ¯\n",
    "    interrupt_info = result[\"__interrupt__\"][0]\n",
    "\n",
    "    print(\"ä¸­æ–­è¯¦æƒ…ï¼š\")\n",
    "    print(f\"  æ”¶ä»¶äºº: {interrupt_info.value['to']}\")\n",
    "    print(f\"  ä¸»é¢˜: {interrupt_info.value['subject']}\")\n",
    "    print(f\"  å†…å®¹: {interrupt_info.value['body']}\")\n",
    "    print(f\"  æ¶ˆæ¯: {interrupt_info.value['message']}\")\n",
    "else:\n",
    "    print(\"Agent æ‰§è¡Œå®Œæˆï¼Œæœªè§¦å‘ä¸­æ–­\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æ‰¹å‡†å¹¶æ¢å¤æ‰§è¡Œ (Resuming with Approval)\n",
    "\n",
    "ç°åœ¨è®©æˆ‘ä»¬æ‰¹å‡†è¿™å°é‚®ä»¶ï¼Œå¹¶è®© Agent ç»§ç»­è¿è¡Œã€‚\n",
    "æˆ‘ä»¬ä½¿ç”¨ `Command` å¯¹è±¡å¹¶ä¼ å…¥ `resume` å‚æ•°ã€‚è¿™ä¸ªå€¼ä¼šç›´æ¥æˆä¸º `interrupt()` å‡½æ•°åœ¨å·¥å…·å†…éƒ¨çš„è¿”å›å€¼ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "#### ğŸ”„ ç‰ˆæœ¬å¯¹æ¯”ï¼šæ¢å¤æ‰§è¡Œçš„æ–¹å¼\n",
    "\n",
    "```python\n",
    "# âŒ æ—§ç‰ˆ (LangGraph 0.x) - é‡æ–° invoke å®Œæ•´è¾“å…¥\n",
    "result = graph.invoke(input, config=config)\n",
    "# ä¸­æ–­åï¼Œéœ€è¦é‡æ–°ä¼ å…¥å®Œæ•´çš„ input\n",
    "result = graph.invoke(input, config=config)  # ä»ä¸­æ–­å¤„ç»§ç»­\n",
    "\n",
    "# âœ… æ–°ç‰ˆ (LangGraph 1.0) - ä½¿ç”¨ Command å¯¹è±¡\n",
    "from langgraph.types import Command\n",
    "\n",
    "# è¿è¡Œåˆ°ä¸­æ–­\n",
    "result = agent.invoke(input, config=config)\n",
    "\n",
    "# æ¢å¤ - åªéœ€ä¼ å…¥ Command å¯¹è±¡\n",
    "result = agent.invoke(\n",
    "    Command(resume={\"approved\": True}),  # ä¼ é€’å®¡æ‰¹ç»“æœ\n",
    "    config=config  # ç›¸åŒçš„ configï¼ˆthread_idï¼‰\n",
    ")\n",
    "```\n",
    "\n",
    "**`Command` å¯¹è±¡çš„å¼ºå¤§ä¹‹å¤„**ï¼š\n",
    "- âœ… **è¯­ä¹‰æ¸…æ™°**ï¼š`Command(resume=...)` æ˜ç¡®è¡¨è¾¾\"æ¢å¤ä¸­æ–­\"çš„æ„å›¾\n",
    "- âœ… **æ— éœ€é‡å¤è¾“å…¥**ï¼šä¸éœ€è¦å†æ¬¡ä¼ å…¥å®Œæ•´çš„åŸå§‹ input\n",
    "- âœ… **çµæ´»çš„æ•°æ®ä¼ é€’**ï¼šå¯ä»¥ä¼ é€’ä»»æ„ç»“æ„çš„å®¡æ‰¹æ•°æ®\n",
    "\n",
    "**`Command` çš„å…¶ä»–ç”¨æ³•**ï¼š\n",
    "```python\n",
    "# 1. çŠ¶æ€æ›´æ–° + è·¯ç”±\n",
    "Command(update={\"messages\": [...]}, goto=\"next_node\")\n",
    "\n",
    "# 2. æ¢å¤ä¸­æ–­ï¼ˆæœ¬ä¾‹ï¼‰\n",
    "Command(resume={\"approved\": True})\n",
    "\n",
    "# 3. å¤šç›®æ ‡è·¯ç”±ï¼ˆå¹¶è¡Œï¼‰\n",
    "Command(update={...}, goto=[\"node1\", \"node2\"])\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æœ€ç»ˆå“åº”ï¼š\n",
      "é‚®ä»¶å·²æˆåŠŸå‘é€ï¼\n"
     ]
    }
   ],
   "source": [
    "from langgraph.types import Command\n",
    "\n",
    "# æ¢å¤æ‰§è¡Œå¹¶ç»™äºˆæ‰¹å‡†\n",
    "# è¿™é‡Œçš„ {\"approved\": True} å°†ä¼šæ˜¯å·¥å…·ä¸­ approval å˜é‡çš„å€¼\n",
    "result = agent.invoke(\n",
    "    Command(resume={\"approved\": True}),\n",
    "    config=config\n",
    ")\n",
    "\n",
    "# æ‰“å°æœ€ç»ˆå“åº”\n",
    "print(\"æœ€ç»ˆå“åº”ï¼š\")\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ç»ƒä¹ ï¼šå°è¯•æ‹’ç»é‚®ä»¶\n",
    "\n",
    "å†æ¬¡è¿è¡Œä¸Šé¢çš„æ­¥éª¤ï¼Œä½†è¿™æ¬¡é€šè¿‡ä¼ å…¥ `{\"approved\": False}` æ¥æ‹’ç»é‚®ä»¶ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æœ€ç»ˆå“åº”ï¼š\n",
      "é‚®ä»¶å‘é€å·²å–æ¶ˆã€‚å¦‚éœ€é‡æ–°å‘é€ï¼Œè¯·å‘Šè¯‰æˆ‘ã€‚\n"
     ]
    }
   ],
   "source": [
    "# ä¸ºæ‹’ç»ç¤ºä¾‹åˆ›å»ºä¸€ä¸ªæ–°çº¿ç¨‹\n",
    "config_2 = {\"configurable\": {\"thread_id\": uuid7()}}\n",
    "\n",
    "# è¿è¡Œç›´åˆ°ä¸­æ–­\n",
    "result = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(content=\"ç»™ bob@example.com å‘é€ä¸€å°é‚®ä»¶ï¼Œå†…å®¹æ˜¯ 'ä½ å¥½ï¼'\")]\n",
    "    },\n",
    "    config=config_2\n",
    ")\n",
    "\n",
    "# æ¢å¤å¹¶æ‹’ç»\n",
    "result = agent.invoke(\n",
    "    Command(resume={\"approved\": False}),  # æ‹’ç»é‚®ä»¶\n",
    "    config=config_2\n",
    ")\n",
    "\n",
    "print(\"æœ€ç»ˆå“åº”ï¼š\")\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content=\"ç»™ bob@example.com å‘é€ä¸€å°é‚®ä»¶ï¼Œå†…å®¹æ˜¯ 'ä½ å¥½ï¼'\", additional_kwargs={}, response_metadata={}, id='744da160-072c-4938-b8e2-0081ecabec53'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 102, 'prompt_tokens': 94, 'total_tokens': 196, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 64, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'o3-mini-2025-01-31', 'system_fingerprint': 'fp_52e4403cb8', 'id': 'chatcmpl-Cw2DjJNp7VEx501j5qczL1Sf0UcBg', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019ba1e3-6e5a-7563-8139-dbdb3882f066-0', tool_calls=[{'name': 'send_email', 'args': {'body': 'ä½ å¥½ï¼', 'subject': 'é‚®ä»¶', 'to': 'bob@example.com'}, 'id': 'call_IXrReFPzuW0s04IapK3FSOuo', 'type': 'tool_call'}], usage_metadata={'input_tokens': 94, 'output_tokens': 102, 'total_tokens': 196, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 64}}), ToolMessage(content='ç”¨æˆ·å–æ¶ˆäº†é‚®ä»¶å‘é€', name='send_email', id='63087ed4-47f8-4853-95f0-3406e17d8220', tool_call_id='call_IXrReFPzuW0s04IapK3FSOuo'), AIMessage(content='é‚®ä»¶å‘é€å·²å–æ¶ˆã€‚å¦‚éœ€é‡æ–°å‘é€ï¼Œè¯·å‘Šè¯‰æˆ‘ã€‚', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 216, 'prompt_tokens': 134, 'total_tokens': 350, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 192, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'o3-mini-2025-01-31', 'system_fingerprint': 'fp_52e4403cb8', 'id': 'chatcmpl-Cw2DnC5QngfjOEtsssvH3LwvFTtvD', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019ba1e3-7bfa-7f72-8e25-0ac7055ef64a-0', usage_metadata={'input_tokens': 134, 'output_tokens': 216, 'total_tokens': 350, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 192}})]\n"
     ]
    }
   ],
   "source": [
    "print(result[\"messages\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç¬¬ 2 éƒ¨åˆ†: è¿›é˜¶æ¨¡å¼ - æ‰§è¡Œå‰å…ˆç¼–è¾‘ (Edit Before Execution)\n",
    "\n",
    "æœ‰æ—¶ä½ ä¸ä»…ä»…æƒ³æ‰¹å‡†æˆ–æ‹’ç»ï¼Œè¿˜æƒ³**ç¼–è¾‘**å·¥å…·è°ƒç”¨çš„å‚æ•°ã€‚è®©æˆ‘ä»¬å‡çº§æˆ‘ä»¬çš„å·¥å…·ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def send_email_v2(to: str, subject: str, body: str) -> str:\n",
    "    \"\"\"å‘é€é‚®ä»¶ç»™æ¥æ”¶è€…ã€‚\"\"\"\n",
    "    \n",
    "    # æš‚åœç­‰å¾…äººå·¥å®¡æŸ¥\n",
    "    response = interrupt({\n",
    "        \"action\": \"send_email\",\n",
    "        \"to\": to,\n",
    "        \"subject\": subject,\n",
    "        \"body\": body,\n",
    "        \"message\": \"è¯·å®¡æŸ¥è¿™å°é‚®ä»¶ã€‚æ‚¨å¯ä»¥æ‰¹å‡†ã€æ‹’ç»æˆ–ç¼–è¾‘å®ƒã€‚\"\n",
    "    })\n",
    "    \n",
    "    # å¤„ç†ä¸åŒçš„å“åº”ç±»å‹\n",
    "    if response[\"type\"] == \"approve\":\n",
    "        return f\"é‚®ä»¶å·²å‘é€è‡³ {to}ï¼Œä¸»é¢˜ä¸º '{subject}'\"\n",
    "\n",
    "    elif response[\"type\"] == \"reject\":\n",
    "        return \"é‚®ä»¶å·²å–æ¶ˆ\"\n",
    "\n",
    "    elif response[\"type\"] == \"edit\":\n",
    "        # æ›´æ–°ä¸ºç¼–è¾‘åçš„å€¼\n",
    "        to = response.get(\"to\", to)\n",
    "        subject = response.get(\"subject\", subject)\n",
    "        body = response.get(\"body\", body)\n",
    "        return f\"\"\"Email sent with edits:\n",
    "                To: {to}\n",
    "                Subject: {subject}\n",
    "                Body: {body}\"\"\"\n",
    "    \n",
    "    return \"æœªçŸ¥å“åº”\"\n",
    "\n",
    "# åˆ›å»ºä½¿ç”¨å¢å¼ºå·¥å…·çš„æ–° Agent\n",
    "agent_v2 = create_agent(\n",
    "    model=model,\n",
    "    tools=[send_email_v2],\n",
    "    system_prompt=\"ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„é‚®ä»¶åŠ©æ‰‹ã€‚\",\n",
    "    checkpointer=MemorySaver()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æš‚åœç­‰å¾…å®¡æŸ¥...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# è¿è¡Œå¹¶ç¼–è¾‘é‚®ä»¶\n",
    "config_3 = {\"configurable\": {\"thread_id\": uuid7()}}\n",
    "\n",
    "# è¿è¡Œç›´åˆ°ä¸­æ–­\n",
    "result = agent_v2.invoke(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(content=\"ç»™ team@example.com å‘é€ä¸€å°å…³äºä¼šè®®çš„é‚®ä»¶\")]\n",
    "    },\n",
    "    config=config_3\n",
    ")\n",
    "\n",
    "print(\"æš‚åœç­‰å¾…å®¡æŸ¥...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç°åœ¨ï¼Œè®©æˆ‘ä»¬ä¿®æ”¹é‚®ä»¶ä¸»é¢˜ï¼Œå°†å…¶æ ‡è®°ä¸º URGENT (ç´§æ€¥) ä¼šè®®ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æœ€ç»ˆå“åº”ï¼š\n",
      "é‚®ä»¶å·²ç»å‘é€ã€‚\n"
     ]
    }
   ],
   "source": [
    "# æ¢å¤å¹¶å¸¦å…¥ç¼–è¾‘åçš„å†…å®¹\n",
    "result = agent_v2.invoke(\n",
    "    Command(resume={\n",
    "        \"type\": \"edit\",\n",
    "        \"subject\": \"ç´§æ€¥ï¼šä»Šå¤©ä¸‹åˆ2ç‚¹å¼€ä¼š\",  # æˆ‘ä»¬ä¿®æ”¹äº†é‚®ä»¶ä¸»é¢˜\n",
    "        \"body\": \"è¿™æ˜¯ç¼–è¾‘åçš„é‚®ä»¶å†…å®¹ï¼ŒåŒ…å«æ›´å¤šç»†èŠ‚ã€‚\"\n",
    "    }),\n",
    "    config=config_3\n",
    ")\n",
    "\n",
    "print(\"æœ€ç»ˆå“åº”ï¼š\")\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='ç»™ team@example.com å‘é€ä¸€å°å…³äºä¼šè®®çš„é‚®ä»¶', additional_kwargs={}, response_metadata={}, id='a74697db-9f52-49fe-bfd3-2163453a0d26'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 361, 'prompt_tokens': 80, 'total_tokens': 441, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 256, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'o3-mini-2025-01-31', 'system_fingerprint': 'fp_52e4403cb8', 'id': 'chatcmpl-Cw2Ds69jr82kmOip2moqGZfubxcEs', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019ba1e3-8e19-73e0-a0c7-94f36459c6b2-0', tool_calls=[{'name': 'send_email_v2', 'args': {'body': 'å¤§å®¶å¥½ï¼Œ\\n\\nè¿™å°é‚®ä»¶æ˜¯å…³äºå³å°†å¬å¼€çš„ä¼šè®®çš„é€šçŸ¥ã€‚è¯·å„ä½å®‰æ’å¥½æ—¶é—´ï¼Œæˆ‘ä»¬å°†è®¨è®ºç›®å‰é¡¹ç›®çš„è¿›å±•ä»¥åŠæœªæ¥çš„è®¡åˆ’å®‰æ’ã€‚\\n\\nå¦‚æœ‰ä»»ä½•é—®é¢˜ï¼Œè¯·éšæ—¶ä¸æˆ‘è”ç³»ã€‚\\n\\nè°¢è°¢ï¼\\n\\næ­¤è‡´\\næ•¬ç¤¼', 'subject': 'å…³äºä¼šè®®çš„é€šçŸ¥', 'to': 'team@example.com'}, 'id': 'call_LFDcidzMkTjKvOo8ChaqS3EB', 'type': 'tool_call'}], usage_metadata={'input_tokens': 80, 'output_tokens': 361, 'total_tokens': 441, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 256}}), ToolMessage(content='Email sent with edits:\\n                To: team@example.com\\n                Subject: ç´§æ€¥ï¼šä»Šå¤©ä¸‹åˆ2ç‚¹å¼€ä¼š\\n                Body: è¿™æ˜¯ç¼–è¾‘åçš„é‚®ä»¶å†…å®¹ï¼ŒåŒ…å«æ›´å¤šç»†èŠ‚ã€‚', name='send_email_v2', id='9360c9f3-2806-460a-8dc9-db540af1e704', tool_call_id='call_LFDcidzMkTjKvOo8ChaqS3EB'), AIMessage(content='é‚®ä»¶å·²ç»å‘é€ã€‚', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 208, 'prompt_tokens': 225, 'total_tokens': 433, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 192, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'o3-mini-2025-01-31', 'system_fingerprint': 'fp_52e4403cb8', 'id': 'chatcmpl-Cw2DzkWPN5VTJGzUgGFJ1qbhyIuzP', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019ba1e3-aa23-7960-81ba-d13ac24c2e69-0', usage_metadata={'input_tokens': 225, 'output_tokens': 208, 'total_tokens': 433, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 192}})]\n"
     ]
    }
   ],
   "source": [
    "print(result[\"messages\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç¬¬ 3 éƒ¨åˆ†: ä¸­é—´ä»¶ (Middleware) ç®€ä»‹\n",
    "\n",
    "**Middleware (ä¸­é—´ä»¶)** æä¾›äº†å¯¹ Agent å¾ªç¯ (Loop) çš„ç»†ç²’åº¦æ§åˆ¶ã€‚å®ƒå¯ä»¥è®©ä½ ï¼š\n",
    "- åœ¨æ¨¡å‹è°ƒç”¨å‰åæ£€æŸ¥çŠ¶æ€\n",
    "- åŠ¨æ€ä¿®æ”¹æ¨¡å‹è¯·æ±‚\n",
    "- åœ¨æ‰§è¡Œçš„å…³é”®ç‚¹æ·»åŠ è‡ªå®šä¹‰é€»è¾‘\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ†• LangChain 1.0 çš„æ ¸å¿ƒæ–°ç‰¹æ€§ï¼šMiddleware\n",
    "\n",
    "**ä¸­é—´ä»¶æ˜¯ LangChain 1.0 å¼•å…¥çš„å…¨æ–°æœºåˆ¶ï¼Œ0.x ç‰ˆæœ¬ä¸å­˜åœ¨ï¼**\n",
    "\n",
    "#### æ—§ç‰ˆå¦‚ä½•å®ç°ç±»ä¼¼åŠŸèƒ½ï¼Ÿ\n",
    "\n",
    "```python\n",
    "# âŒ æ—§ç‰ˆ (0.x) - éœ€è¦æ‰‹åŠ¨åœ¨èŠ‚ç‚¹ä¸­å®ç°æ‰€æœ‰é€»è¾‘\n",
    "def agent_node(state):\n",
    "    # æ—¥å¿—è®°å½• - æ‰‹åŠ¨å®ç°\n",
    "    print(f\"å¤„ç† {len(state['messages'])} æ¡æ¶ˆæ¯\")\n",
    "    \n",
    "    # PII è¿‡æ»¤ - æ‰‹åŠ¨å®ç°\n",
    "    messages = []\n",
    "    for msg in state[\"messages\"]:\n",
    "        filtered_msg = redact_pii(msg)  # è‡ªå·±å†™è¿‡æ»¤é€»è¾‘\n",
    "        messages.append(filtered_msg)\n",
    "    \n",
    "    # è°ƒç”¨æ¨¡å‹\n",
    "    response = model.invoke(messages)\n",
    "    \n",
    "    # éªŒè¯è¾“å‡º - æ‰‹åŠ¨å®ç°\n",
    "    if not is_safe(response):\n",
    "        response = \"æˆ‘æ— æ³•å›ç­”è¿™ä¸ªé—®é¢˜\"\n",
    "    \n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# âœ… æ–°ç‰ˆ (1.0) - ä½¿ç”¨ä¸­é—´ä»¶ï¼Œé€»è¾‘è§£è€¦ä¸”å¯å¤ç”¨\n",
    "from langchain.agents.middleware import PIIMiddleware, before_model, after_model\n",
    "\n",
    "@before_model\n",
    "def log_middleware(state, runtime):\n",
    "    print(f\"å¤„ç† {len(state['messages'])} æ¡æ¶ˆæ¯\")\n",
    "    return None\n",
    "\n",
    "@after_model\n",
    "def safety_middleware(state, runtime):\n",
    "    last_msg = state[\"messages\"][-1]\n",
    "    if not is_safe(last_msg):\n",
    "        return {\"messages\": [AIMessage(\"æˆ‘æ— æ³•å›ç­”è¿™ä¸ªé—®é¢˜\")]}\n",
    "    return None\n",
    "\n",
    "agent = create_agent(\n",
    "    model,\n",
    "    tools,\n",
    "    middleware=[\n",
    "        log_middleware,\n",
    "        PIIMiddleware(\"email\", strategy=\"redact\"),\n",
    "        safety_middleware\n",
    "    ]\n",
    ")\n",
    "```\n",
    "\n",
    "**ä¸­é—´ä»¶çš„ä¼˜åŠ¿**ï¼š\n",
    "- ğŸ” **å¯å¤ç”¨**ï¼šä¸€æ¬¡ç¼–å†™ï¼Œå¤šä¸ª Agent å…±äº«\n",
    "- ğŸ§© **æ¨¡å—åŒ–**ï¼šæ¯ä¸ªä¸­é—´ä»¶è´Ÿè´£å•ä¸€èŒè´£\n",
    "- ğŸ”Œ **å¯æ’æ‹”**ï¼šè½»æ¾å¯ç”¨/ç¦ç”¨ç‰¹å®šåŠŸèƒ½\n",
    "- ğŸ§¹ **ä»£ç æ¸…æ™°**ï¼šæ¨ªåˆ‡å…³æ³¨ç‚¹ä»ä¸šåŠ¡é€»è¾‘ä¸­åˆ†ç¦»\n",
    "\n",
    "---\n",
    "\n",
    "### Agent å¾ªç¯ (The Agent Loop)\n",
    "\n",
    "```\n",
    "Input --> [before_model] --> [wrap_model_call] --> Model --> [after_model] --> Tools --> ...\n",
    "```\n",
    "\n",
    "Middleware ä¼šæŒ‚è½½åˆ°è¿™ä¸ªå¾ªç¯ä¸­ï¼š\n",
    "- **`before_model`** - åœ¨æ¨¡å‹æ‰§è¡Œå‰è¿è¡Œï¼Œå¯ä»¥æ›´æ–°çŠ¶æ€\n",
    "- **`wrap_model_call`** - åŒ…è£…æ¨¡å‹è°ƒç”¨ï¼Œæ§åˆ¶æ¨¡å‹ä½•æ—¶/å¦‚ä½•è¢«è°ƒç”¨ï¼ˆä¾‹å¦‚é‡è¯•ã€ç¼“å­˜ï¼‰\n",
    "- **`after_model`** - åœ¨æ¨¡å‹æ‰§è¡Œåï¼Œæ‰§è¡Œå·¥å…·å‰è¿è¡Œ\n",
    "\n",
    "### ä¸¤ç§ Hook é£æ ¼\n",
    "\n",
    "**Node-style hooks (èŠ‚ç‚¹å¼é’©å­)** æŒ‰é¡ºåºè¿è¡Œï¼š\n",
    "- `before_agent`, `before_model`, `after_model`, `after_agent`\n",
    "- é€‚åˆç”¨äºæ—¥å¿—è®°å½•ã€éªŒè¯ã€çŠ¶æ€æ›´æ–°\n",
    "\n",
    "**Wrap-style hooks (åŒ…è£…å¼é’©å­)** æ‹¦æˆªæ‰§è¡Œï¼š\n",
    "- `wrap_model_call`, `wrap_tool_call`\n",
    "- å®Œå…¨æ§åˆ¶å¤„ç†ç¨‹åºçš„è°ƒç”¨\n",
    "- é€‚åˆç”¨äºé‡è¯•é€»è¾‘ã€ç¼“å­˜ã€æ•°æ®è½¬æ¢"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“‹ LangChain 1.0 Middleware å®Œæ•´å‚è€ƒæŒ‡å—\n",
    "\n",
    "#### Middleware Hook çš„æ‰§è¡Œé¡ºåº\n",
    "\n",
    "```\n",
    "ç”¨æˆ·è¾“å…¥\n",
    "    â†“\n",
    "[before_agent]  â† æ•´ä¸ª Agent æ‰§è¡Œå‰ï¼ˆä¸€æ¬¡ï¼‰\n",
    "    â†“\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Agent å¾ªç¯ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                                                                   â”‚\n",
    "â”‚  [before_model]  â† æ¯æ¬¡ LLM è°ƒç”¨å‰                               â”‚\n",
    "â”‚      â†“                                                            â”‚\n",
    "â”‚  [wrap_model_call]  â† åŒ…è£¹ LLM è°ƒç”¨ï¼ˆå¯é‡è¯•ã€ç¼“å­˜ï¼‰              â”‚\n",
    "â”‚      â†“                                                            â”‚\n",
    "â”‚  LLM æ‰§è¡Œ                                                         â”‚\n",
    "â”‚      â†“                                                            â”‚\n",
    "â”‚  [after_model]  â† LLM å“åº”å                                      â”‚\n",
    "â”‚      â†“                                                            â”‚\n",
    "â”‚  å¦‚æœæœ‰å·¥å…·è°ƒç”¨:                                                  â”‚\n",
    "â”‚      [wrap_tool_call]  â† åŒ…è£¹æ¯ä¸ªå·¥å…·è°ƒç”¨                         â”‚\n",
    "â”‚      å·¥å…·æ‰§è¡Œ                                                     â”‚\n",
    "â”‚      è¿”å› before_modelï¼ˆç»§ç»­å¾ªç¯ï¼‰                                â”‚\n",
    "â”‚                                                                   â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "    â†“\n",
    "[after_agent]  â† æ•´ä¸ª Agent å®Œæˆåï¼ˆä¸€æ¬¡ï¼‰\n",
    "    â†“\n",
    "æœ€ç»ˆè¾“å‡º\n",
    "```\n",
    "\n",
    "#### Hook ç±»å‹è¯¦è§£\n",
    "\n",
    "##### 1. Node-Style Hooksï¼ˆèŠ‚ç‚¹å¼é’©å­ï¼‰\n",
    "\n",
    "æŒ‰é¡ºåºæ‰§è¡Œï¼Œå¯ä»¥ä¿®æ”¹çŠ¶æ€ï¼š\n",
    "\n",
    "| Hook | æ‰§è¡Œæ—¶æœº | è¿”å›å€¼ | å…¸å‹ç”¨é€” |\n",
    "|------|----------|--------|----------|\n",
    "| `before_agent` | Agent å¼€å§‹å‰ | `dict \\| None` | åŠ è½½ç”¨æˆ·ä¸Šä¸‹æ–‡ã€åˆå§‹åŒ–çŠ¶æ€ |\n",
    "| `before_model` | æ¯æ¬¡è°ƒç”¨ LLM å‰ | `dict \\| None` | åŠ¨æ€ä¿®æ”¹ promptã€è£å‰ªæ¶ˆæ¯å†å² |\n",
    "| `after_model` | LLM å“åº”å | `dict \\| None` | éªŒè¯è¾“å‡ºã€åº”ç”¨å†…å®¹è¿‡æ»¤ |\n",
    "| `after_agent` | Agent å®Œæˆå | `dict \\| None` | ä¿å­˜ç»“æœã€è®°å½•æ—¥å¿— |\n",
    "\n",
    "```python\n",
    "from langchain.agents.middleware import before_model\n",
    "\n",
    "@before_model\n",
    "def token_limit_middleware(state, runtime):\n",
    "    \"\"\"é™åˆ¶æ¶ˆæ¯æ•°é‡ï¼Œé˜²æ­¢è¶…è¿‡ token é™åˆ¶\"\"\"\n",
    "    messages = state.get(\"messages\", [])\n",
    "    if len(messages) > 10:\n",
    "        # ä¿ç•™æœ€è¿‘ 10 æ¡æ¶ˆæ¯\n",
    "        return {\"messages\": messages[-10:]}\n",
    "    return None\n",
    "```\n",
    "\n",
    "##### 2. Wrap-Style Hooksï¼ˆåŒ…è£…å¼é’©å­ï¼‰\n",
    "\n",
    "æ‹¦æˆªå¹¶æ§åˆ¶æ‰§è¡Œæµç¨‹ï¼š\n",
    "\n",
    "| Hook | æ‰§è¡Œæ—¶æœº | å‚æ•° | å…¸å‹ç”¨é€” |\n",
    "|------|----------|------|----------|\n",
    "| `wrap_model_call` | å›´ç»• LLM è°ƒç”¨ | `request`, `handler` | é‡è¯•é€»è¾‘ã€ç¼“å­˜ã€è¯·æ±‚ä¿®æ”¹ |\n",
    "| `wrap_tool_call` | å›´ç»•å·¥å…·è°ƒç”¨ | `request`, `handler` | æƒé™æ£€æŸ¥ã€å‚æ•°éªŒè¯ã€æ¨¡æ‹Ÿæ‰§è¡Œ |\n",
    "\n",
    "```python\n",
    "from langchain.agents.middleware import AgentMiddleware\n",
    "\n",
    "class RetryMiddleware(AgentMiddleware):\n",
    "    \"\"\"LLM è°ƒç”¨å¤±è´¥æ—¶è‡ªåŠ¨é‡è¯•\"\"\"\n",
    "    \n",
    "    def wrap_model_call(self, request, handler):\n",
    "        max_retries = 3\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                return handler(request)\n",
    "            except Exception as e:\n",
    "                if attempt == max_retries - 1:\n",
    "                    raise\n",
    "                print(f\"é‡è¯• {attempt + 1}/{max_retries}...\")\n",
    "                time.sleep(1)\n",
    "```\n",
    "\n",
    "#### å†…ç½® Middlewareï¼ˆLangChain 1.0ï¼‰\n",
    "\n",
    "LangChain 1.0 æä¾›äº†å¼€ç®±å³ç”¨çš„ä¸­é—´ä»¶ï¼š\n",
    "\n",
    "| ä¸­é—´ä»¶ | åŠŸèƒ½ | é…ç½®ç¤ºä¾‹ |\n",
    "|--------|------|----------|\n",
    "| `PIIMiddleware` | PII æ•°æ®è„±æ• | `PIIMiddleware(\"email\", strategy=\"redact\")` |\n",
    "| `SummarizationMiddleware` | å¯¹è¯å†å²æ‘˜è¦ | `SummarizationMiddleware(model, trigger={\"tokens\": 500})` |\n",
    "| `HumanInTheLoopMiddleware` | å·¥å…·è°ƒç”¨å®¡æ‰¹ | `HumanInTheLoopMiddleware(interrupt_on={\"tool_name\": {...}})` |\n",
    "\n",
    "```python\n",
    "from langchain.agents.middleware import (\n",
    "    PIIMiddleware,\n",
    "    SummarizationMiddleware\n",
    ")\n",
    "\n",
    "agent = create_agent(\n",
    "    model,\n",
    "    tools,\n",
    "    middleware=[\n",
    "        PIIMiddleware(\"email\", strategy=\"redact\", apply_to_input=True),\n",
    "        PIIMiddleware(\n",
    "            \"phone_number\",\n",
    "            detector=r\"\\\\+?\\\\d{1,3}[\\\\s.-]?\\\\d{2,4}[\\\\s.-]?\\\\d{3,4}\",\n",
    "            strategy=\"block\"\n",
    "        ),\n",
    "        SummarizationMiddleware(\n",
    "            model=\"openai:gpt-4o-mini\",\n",
    "            trigger={\"tokens\": 500}\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "```\n",
    "\n",
    "#### è‡ªå®šä¹‰ Middleware æœ€ä½³å®è·µ\n",
    "\n",
    "1. **å•ä¸€èŒè´£**ï¼šæ¯ä¸ªä¸­é—´ä»¶åªåšä¸€ä»¶äº‹\n",
    "2. **æ— çŠ¶æ€**ï¼šä¸­é—´ä»¶åº”è¯¥æ˜¯æ— çŠ¶æ€çš„ï¼ŒçŠ¶æ€ä¿å­˜åœ¨ Agent State ä¸­\n",
    "3. **å¿«é€Ÿå¤±è´¥**ï¼šé”™è¯¯å¤„ç†è¦æ˜ç¡®ï¼Œè¯¥æŠ›å‡ºå¼‚å¸¸æ—¶ä¸è¦é™é»˜\n",
    "4. **å¯é…ç½®**ï¼šé€šè¿‡æ„é€ å‡½æ•°æ¥å—é…ç½®å‚æ•°\n",
    "5. **æ–‡æ¡£åŒ–**ï¼šæ¸…æ¥šè¯´æ˜ä¸­é—´ä»¶çš„ä½œç”¨å’Œå‰¯ä½œç”¨\n",
    "\n",
    "```python\n",
    "class MyMiddleware(AgentMiddleware):\n",
    "    \"\"\"æ¸…æ™°çš„ docstring è¯´æ˜ç”¨é€”\n",
    "    \n",
    "    Args:\n",
    "        threshold: é˜ˆå€¼å‚æ•°\n",
    "        enabled: æ˜¯å¦å¯ç”¨\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, threshold: float, enabled: bool = True):\n",
    "        self.threshold = threshold\n",
    "        self.enabled = enabled\n",
    "    \n",
    "    def before_model(self, state, runtime):\n",
    "        if not self.enabled:\n",
    "            return None\n",
    "        # å®ç°é€»è¾‘...\n",
    "```\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ç¤ºä¾‹ 1: åŠ¨æ€ç³»ç»Ÿæç¤ºè¯ (Dynamic System Prompt)\n",
    "\n",
    "è®©æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªä¸­é—´ä»¶ï¼Œæ ¹æ®ç”¨æˆ·çš„è§’è‰²åŠ¨æ€æ›´æ”¹ç³»ç»Ÿæç¤ºè¯ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.middleware import dynamic_prompt, ModelRequest\n",
    "from typing import TypedDict\n",
    "\n",
    "# å®šä¹‰ä¸Šä¸‹æ–‡ Schema\n",
    "class Context(TypedDict):\n",
    "    user_role: str\n",
    "\n",
    "# ä½¿ç”¨è£…é¥°å™¨åˆ›å»ºä¸­é—´ä»¶\n",
    "@dynamic_prompt\n",
    "def dynamic_prompt_middleware(request: ModelRequest) -> str:\n",
    "    \"\"\"æ ¹æ®ç”¨æˆ·è§’è‰²è°ƒæ•´ç³»ç»Ÿæç¤ºè¯ã€‚\"\"\"\n",
    "    \n",
    "    # ä»è¿è¡Œæ—¶ä¸Šä¸‹æ–‡ä¸­è·å– user_role\n",
    "    user_role = request.runtime.context.get(\"user_role\", \"general\")\n",
    "    \n",
    "    if user_role == \"expert\":\n",
    "        return \"ä½ æ˜¯ä¸€åé¢å‘ä¸“å®¶çš„ AI åŠ©æ‰‹ã€‚è¯·æä¾›åŒ…å«ä»£ç ç¤ºä¾‹çš„è¯¦ç»†æŠ€æœ¯è§£ç­”ã€‚\"\n",
    "    elif user_role == \"beginner\":\n",
    "        return \"ä½ æ˜¯ä¸€åé¢å‘åˆå­¦è€…çš„ AI åŠ©æ‰‹ã€‚è¯·é€šä¿—æ˜“æ‡‚åœ°è§£é‡Šæ¦‚å¿µï¼Œé¿å…ä½¿ç”¨è¡Œè¯ã€‚\"\n",
    "    else:\n",
    "        return \"ä½ æ˜¯ä¸€åä¹äºåŠ©äººçš„ AI åŠ©æ‰‹ã€‚\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def explain_concept(concept: str) -> str:\n",
    "    \"\"\"è§£é‡Šä¸€ä¸ªç¼–ç¨‹æ¦‚å¿µã€‚\"\"\"\n",
    "    explanations = {\n",
    "        \"async\": \"å¼‚æ­¥ç¼–ç¨‹å…è®¸ä»£ç åœ¨ä¸é˜»å¡çš„æƒ…å†µä¸‹è¿è¡Œã€‚\",\n",
    "        \"recursion\": \"é€’å½’æ˜¯æŒ‡å‡½æ•°è°ƒç”¨è‡ªèº«çš„æƒ…å†µã€‚\"\n",
    "    }\n",
    "    return explanations.get(concept.lower(), \"æœªæ‰¾åˆ°è¯¥æ¦‚å¿µã€‚\")\n",
    "\n",
    "# åˆ›å»ºå¸¦æœ‰ä¸­é—´ä»¶çš„ Agent\n",
    "agent_with_middleware = create_agent(\n",
    "    model=model,\n",
    "    tools=[explain_concept],\n",
    "    middleware=[dynamic_prompt_middleware],\n",
    "    context_schema=Context\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æµ‹è¯•ä¸åŒçš„ç”¨æˆ·è§’è‰²\n",
    "\n",
    "è®©æˆ‘ä»¬çœ‹çœ‹ Agent å¦‚ä½•æ ¹æ®ç”¨æˆ·è§’è‰²åšå‡ºä¸åŒçš„ååº”ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "ä¸“å®¶ç”¨æˆ·\n",
      "==================================================\n",
      "å¼‚æ­¥ç¼–ç¨‹æ˜¯ä¸€ç§ç¼–ç¨‹æ¨¡å‹ï¼Œç”¨äºå¤„ç†è€—æ—¶ä»»åŠ¡è€Œä¸é˜»å¡ä¸»çº¿ç¨‹çš„æ‰§è¡Œã€‚ä¼ ç»Ÿçš„åŒæ­¥æ¨¡å‹ä¸­ï¼Œç¨‹åºå¿…é¡»ç­‰å¾…ä¸€ä¸ªæ“ä½œï¼ˆå¦‚ç½‘ç»œè¯·æ±‚ã€æ–‡ä»¶IOï¼‰å®Œæˆåæ‰èƒ½ç»§ç»­æ‰§è¡Œåç»­ä»£ç ï¼Œè€Œå¼‚æ­¥ç¼–ç¨‹åˆ™å…è®¸è¿™äº›æ“ä½œåœ¨åå°æ‰§è¡Œï¼Œè®©ä¸»ç¨‹åºå¯ä»¥ç»§ç»­å“åº”å…¶ä»–äº‹ä»¶ï¼Œä»è€Œæå‡æ•´ä½“æ€§èƒ½å’Œç”¨æˆ·ä½“éªŒã€‚\n",
      "\n",
      "ä»¥ä¸‹é€šè¿‡JavaScriptæ¥è¯¦ç»†è¯´æ˜å¼‚æ­¥ç¼–ç¨‹çš„å…³é”®æ¦‚å¿µå’Œå®ç°æ–¹å¼ï¼š\n",
      "\n",
      "1. Promise\n",
      "\n",
      "Promise æ˜¯ä¸€ç§ç”¨äºå°è£…å¼‚æ­¥æ“ä½œçš„å¯¹è±¡ï¼Œè¡¨ç¤ºä¸€ä¸ªå¯èƒ½è¿˜æœªå®Œæˆä½†å°†åœ¨æœªæ¥æŸä¸ªæ—¶é—´ç‚¹å®Œæˆçš„æ“ä½œã€‚Promise æä¾›äº† .then()ã€.catch() ç­‰æ–¹æ³•ï¼Œæ–¹ä¾¿æˆ‘ä»¬åœ¨å¼‚æ­¥æ“ä½œæˆåŠŸæˆ–å¤±è´¥åæ‰§è¡Œç›¸åº”çš„å¤„ç†é€»è¾‘ã€‚\n",
      "\n",
      "ç¤ºä¾‹ä»£ç ï¼š\n",
      "-------------------------------------------------\n",
      "function fetchData() {\n",
      "    return new Promise((resolve, reject) => {\n",
      "        // æ¨¡æ‹Ÿä¸€ä¸ªè€—æ—¶æ“ä½œï¼Œæ¯”å¦‚ç½‘ç»œè¯·æ±‚æˆ–å®šæ—¶ä»»åŠ¡\n",
      "        setTimeout(() => {\n",
      "            const data = { id: 1, name: 'Alice' };\n",
      "            resolve(data);  // æ“ä½œæˆåŠŸï¼Œè¿”å›æ•°æ®\n",
      "        }, 1000);\n",
      "    });\n",
      "}\n",
      "\n",
      "fetchData()\n",
      "    .then(data => {\n",
      "        console.log('Promiseè·å–åˆ°çš„æ•°æ®:', data);\n",
      "    })\n",
      "    .catch(error => {\n",
      "        console.error('å‘ç”Ÿé”™è¯¯:', error);\n",
      "    });\n",
      "-------------------------------------------------\n",
      "\n",
      "2. async/await\n",
      "\n",
      "async/await æ˜¯åŸºäº Promise å®ç°çš„ä¸€ç§æ›´ç›´è§‚çš„å¼‚æ­¥ç¼–ç¨‹æ–¹å¼ã€‚é€šè¿‡ async å£°æ˜ä¸€ä¸ªå‡½æ•°ä¸ºå¼‚æ­¥å‡½æ•°ï¼Œåœ¨è¯¥å‡½æ•°å†…éƒ¨å¯ä»¥ä½¿ç”¨ await ç­‰å¾… Promise å®Œæˆï¼Œä½¿å¾—å¼‚æ­¥ä»£ç é£æ ¼ç±»ä¼¼åŒæ­¥ä»£ç ï¼Œæå‡äº†ä»£ç çš„å¯è¯»æ€§å’Œæ˜“ç»´æŠ¤æ€§ã€‚\n",
      "\n",
      "ç¤ºä¾‹ä»£ç ï¼š\n",
      "-------------------------------------------------\n",
      "async function fetchDataAsync() {\n",
      "    try {\n",
      "        // await ç­‰å¾… fetchData çš„ Promise å®Œæˆ\n",
      "        const data = await fetchData();\n",
      "        console.log('async/awaitè·å–åˆ°çš„æ•°æ®:', data);\n",
      "    } catch (error) {\n",
      "        console.error('å‘ç”Ÿé”™è¯¯:', error);\n",
      "    }\n",
      "}\n",
      "\n",
      "fetchDataAsync();\n",
      "-------------------------------------------------\n",
      "\n",
      "3. äº‹ä»¶å¾ªç¯æœºåˆ¶\n",
      "\n",
      "å¼‚æ­¥ç¼–ç¨‹çš„å¹•åè‹±é›„æ˜¯äº‹ä»¶å¾ªç¯ï¼ˆEvent Loopï¼‰ã€‚åœ¨ JavaScript ä¸­ï¼Œå•çº¿ç¨‹çš„è¿è¡Œæ—¶ä¼šå°†æ‰€æœ‰åŒæ­¥ä»£ç æ”¾å…¥è°ƒç”¨æ ˆä¸­æ‰§è¡Œï¼Œè€Œå¼‚æ­¥ä»»åŠ¡ï¼ˆå¦‚setTimeoutã€ç½‘ç»œè¯·æ±‚ç­‰ï¼‰åˆ™ä¼šæ³¨å†Œåˆ°ä»»åŠ¡é˜Ÿåˆ—ä¸­ã€‚äº‹ä»¶å¾ªç¯è´Ÿè´£åœ¨è°ƒç”¨æ ˆç©ºé—²æ—¶ï¼Œå°†ä»»åŠ¡é˜Ÿåˆ—ä¸­çš„ä»»åŠ¡ä¾æ¬¡æ¨å…¥è°ƒç”¨æ ˆæ‰§è¡Œï¼Œä»è€Œå®ç°å¼‚æ­¥æ“ä½œè€Œä¸ä¼šé˜»å¡ä¸»çº¿ç¨‹ã€‚\n",
      "\n",
      "4. åº”ç”¨åœºæ™¯\n",
      "\n",
      "å¼‚æ­¥ç¼–ç¨‹å¸¸è§çš„åº”ç”¨åœºæ™¯åŒ…æ‹¬ä½†ä¸é™äºï¼š\n",
      "- ç½‘ç»œè¯·æ±‚ï¼šä¾‹å¦‚ AJAX è¯·æ±‚ã€APIè°ƒç”¨ç­‰ã€‚\n",
      "- æ–‡ä»¶ç³»ç»Ÿæ“ä½œï¼šåœ¨Node.jsä¸­ï¼Œè¯»å–æˆ–å†™å…¥æ–‡ä»¶é€šå¸¸é‡‡ç”¨å¼‚æ­¥æ–¹å¼ï¼Œé˜²æ­¢é˜»å¡å…¶ä»–è¯·æ±‚ã€‚\n",
      "- ç”¨æˆ·ç•Œé¢äº¤äº’ï¼šåœ¨Webåº”ç”¨ä¸­ï¼Œé˜²æ­¢UIå†»ç»“ï¼Œæé«˜å“åº”æ€§ã€‚\n",
      "\n",
      "æ€»è€Œè¨€ä¹‹ï¼Œå¼‚æ­¥ç¼–ç¨‹ä¸ºå¤„ç†è€—æ—¶æ“ä½œæä¾›äº†é«˜æ•ˆæ–¹æ¡ˆï¼Œä½¿å¾—åº”ç”¨ç¨‹åºèƒ½å¤Ÿåœ¨ç­‰å¾…åå°ä»»åŠ¡æ‰§è¡Œçš„åŒæ—¶ç»§ç»­å¤„ç†å…¶ä»–ä»»åŠ¡ï¼Œä»è€Œæé«˜ç”¨æˆ·ä½“éªŒå’Œèµ„æºåˆ©ç”¨ç‡ã€‚\n",
      "\n",
      "==================================================\n",
      "åˆå­¦è€…\n",
      "==================================================\n",
      "å¼‚æ­¥ç¼–ç¨‹æ˜¯ä¸€ç§è®©ç¨‹åºèƒ½å¤ŸåŒæ—¶å¤„ç†å¤šä¸ªä»»åŠ¡çš„ç¼–ç¨‹æ–¹å¼ã€‚é€šå¸¸ï¼Œåœ¨å¤„ç†ä¸€äº›è€—æ—¶æ“ä½œï¼ˆæ¯”å¦‚è¯»å–æ–‡ä»¶ã€è®¿é—®ç½‘ç»œã€æ•°æ®åº“æŸ¥è¯¢ç­‰ï¼‰æ—¶ï¼Œå¦‚æœä½¿ç”¨ä¼ ç»Ÿçš„åŒæ­¥ç¼–ç¨‹ï¼Œç¨‹åºå¿…é¡»ç­‰å¾…è¿™ä¸ªæ“ä½œå®Œæˆï¼Œå…¶ä»–ä»»åŠ¡å°±åªèƒ½â€œåœä¸‹æ¥â€ç­‰å¾…ã€‚è€Œå¼‚æ­¥ç¼–ç¨‹åˆ™å…è®¸ç¨‹åºåœ¨ç­‰å¾…è¿™äº›è€—æ—¶æ“ä½œçš„æ—¶å€™ï¼Œç»§ç»­æ‰§è¡Œå…¶ä»–ä»£ç ï¼Œå°±åƒæ˜¯åŒæ—¶è¿›è¡Œå¤šä»¶äº‹æƒ…ã€‚ä¾‹å¦‚ï¼Œå½“ä½ åœ¨ç½‘ä¸Šè´­ç‰©æ—¶ï¼Œç”µè„‘å¯ä»¥åŒæ—¶ä¸‹è½½ç½‘é¡µå†…å®¹ã€å“åº”ä½ çš„ç‚¹å‡»ã€æ˜¾ç¤ºåŠ¨ç”»ï¼Œè€Œä¸æ˜¯ç­‰æ‰€æœ‰å†…å®¹éƒ½åŠ è½½å®Œæˆåå†å“åº”ã€‚è¿™æ ·çš„ç¼–ç¨‹æ–¹å¼æœ‰åŠ©äºæé«˜åº”ç”¨çš„å“åº”é€Ÿåº¦å’Œæ•ˆç‡ã€‚\n"
     ]
    }
   ],
   "source": [
    "# ä¸“å®¶ç”¨æˆ·\n",
    "print(\"=\" * 50)\n",
    "print(\"ä¸“å®¶ç”¨æˆ·\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "result = agent_with_middleware.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"è§£é‡Šå¼‚æ­¥ç¼–ç¨‹\")]},\n",
    "    context={\"user_role\": \"expert\"}\n",
    ")\n",
    "print(result[\"messages\"][-1].content)\n",
    "print()\n",
    "\n",
    "# åˆå­¦è€…\n",
    "print(\"=\" * 50)\n",
    "print(\"åˆå­¦è€…\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "result = agent_with_middleware.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"è§£é‡Šå¼‚æ­¥ç¼–ç¨‹\")]},\n",
    "    context={\"user_role\": \"beginner\"}\n",
    ")\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ç¤ºä¾‹ 2: è‡ªå®šä¹‰ä¸­é—´ä»¶ - è¯·æ±‚æ—¥å¿—è®°å½•å™¨ (Request Logger)\n",
    "\n",
    "ä¸­é—´ä»¶å…è®¸ä½  hook è¿› Agent å¾ªç¯ï¼ŒæŸ¥çœ‹æ¯ä¸€æ­¥å‘ç”Ÿäº†ä»€ä¹ˆã€‚è¿™å¯¹äºè°ƒè¯•å’Œç†è§£ Agent çš„å·¥ä½œåŸç†éå¸¸æœ‰ç”¨ã€‚\n",
    "\n",
    "**Agent å¾ªç¯ï¼š**\n",
    "User Input --> [before_model] --> [wrap_model_call] --> Model --> [after_model] --> Tools --> ...\n",
    "\n",
    "**æˆ‘ä»¬å°†æ„å»ºä¸€ä¸ªæ—¥å¿—è®°å½•å™¨ï¼Œåœ¨ä»¥ä¸‹æ­¥éª¤æ‰“å°ä¿¡æ¯ï¼š**\n",
    "- **Before model** - å½“å‰å¯¹è¯ä¸­æœ‰å¤šå°‘æ¡æ¶ˆæ¯ï¼Ÿ\n",
    "- **Wrap model call** - æ­£åœ¨ä½¿ç”¨å“ªä¸ªæ¨¡å‹å’Œå·¥å…·ï¼Ÿ\n",
    "- **After model** - æ¨¡å‹æ˜¯è°ƒç”¨äº†å·¥å…·è¿˜æ˜¯ç»™å‡ºäº†æœ€ç»ˆç­”æ¡ˆï¼Ÿ\n",
    "\n",
    "è¿™å°±åƒæ˜¯æ·»åŠ äº†è°ƒè¯•ç”¨çš„ `print()` è¯­å¥ï¼Œä½†ä»¥ä¸€ç§å¹²å‡€ã€å¯é‡ç”¨çš„æ–¹å¼ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.middleware import AgentMiddleware, AgentState, ModelRequest, ModelResponse\n",
    "from typing import Any, Callable\n",
    "\n",
    "class RequestLoggerMiddleware(AgentMiddleware):\n",
    "    \"\"\"ç”¨äºè°ƒè¯•çš„æ¨¡å‹è¯·æ±‚æ—¥å¿—è®°å½•ä¸­é—´ä»¶ã€‚\"\"\"\n",
    "    \n",
    "    def before_model(self, state: AgentState, runtime) -> dict[str, Any] | None:\n",
    "        \"\"\"åœ¨æ¨¡å‹æ‰§è¡Œå‰è®°å½•æ—¥å¿—ã€‚\n",
    "        \n",
    "        Args:\n",
    "            state: å½“å‰ Agent çš„çŠ¶æ€ (åŒ…å«æ¶ˆæ¯å†å²ç­‰)\n",
    "            runtime: è¿è¡Œæ—¶ä¸Šä¸‹æ–‡\n",
    "        \"\"\"\n",
    "        message_count = len(state.get(\"messages\", []))\n",
    "        print(f\"[æ¨¡å‹å‰] æ­£åœ¨å¤„ç† {message_count} æ¡æ¶ˆæ¯\")\n",
    "        return None  # ä¸ä¿®æ”¹çŠ¶æ€\n",
    "    \n",
    "    def wrap_model_call(\n",
    "        self, \n",
    "        request: ModelRequest,\n",
    "        handler: Callable[[ModelRequest], ModelResponse]\n",
    "    ) -> ModelResponse:\n",
    "        \"\"\"åŒ…è£…æ¨¡å‹è°ƒç”¨ï¼Œè®°å½•è¯·æ±‚è¯¦æƒ…ã€‚\n",
    "        \n",
    "        Args:\n",
    "           request: å³å°†å‘é€ç»™æ¨¡å‹çš„è¯·æ±‚å¯¹è±¡\n",
    "           handler: æ‰§è¡Œå®é™…æ¨¡å‹è°ƒç”¨çš„å‡½æ•°\n",
    "        \"\"\"\n",
    "        print(f\"  [æ¨¡å‹è¯·æ±‚]\")\n",
    "        print(f\"   æ¨¡å‹: {request.model if hasattr(request, 'model') else 'é»˜è®¤'}\")\n",
    "        print(f\"   å¯ç”¨å·¥å…·: {len(request.tools) if request.tools else 0}\")\n",
    "        \n",
    "        # è°ƒç”¨å®é™…çš„æ¨¡å‹å¤„ç†ç¨‹åº\n",
    "        return handler(request)\n",
    "    \n",
    "    def after_model(self, state: AgentState, runtime) -> dict[str, Any] | None:\n",
    "        \"\"\"åœ¨æ¨¡å‹æ‰§è¡Œåè®°å½•æ—¥å¿—ã€‚\"\"\"\n",
    "        last_message = state[\"messages\"][-1]\n",
    "        if hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
    "            print(f\" [æ¨¡å‹å] æ¨¡å‹è¯·æ±‚äº† {len(last_message.tool_calls)} ä¸ªå·¥å…·è°ƒç”¨\")\n",
    "        else:\n",
    "            print(f\" [æ¨¡å‹å] æ¨¡å‹æä¾›äº†æœ€ç»ˆå“åº”\")\n",
    "        return None  # ä¸ä¿®æ”¹çŠ¶æ€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºå¸¦æœ‰æ—¥å¿—ä¸­é—´ä»¶çš„ Agent\n",
    "agent_with_logger = create_agent(\n",
    "    model=model,\n",
    "    tools=[explain_concept],\n",
    "    middleware=[RequestLoggerMiddleware()],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### é¢„æœŸç»“æœ\n",
    "\n",
    "å½“æˆ‘ä»¬è¿è¡Œå¸¦æ—¥å¿—è®°å½•å™¨çš„ Agent æ—¶ï¼Œä½ ä¼šå®æ—¶çœ‹åˆ°æ‰§è¡Œæµç¨‹ï¼š\n",
    "\n",
    "**ç¬¬ä¸€æ¬¡è¿­ä»£:**\n",
    "1. `[æ¨¡å‹å‰]` - æ˜¾ç¤ºæˆ‘ä»¬å¼€å§‹æ—¶çš„æ¶ˆæ¯æ•°é‡\n",
    "2. `[æ¨¡å‹è¯·æ±‚]` - æ˜¾ç¤ºå¯ç”¨æ¨¡å‹å’Œå·¥å…·\n",
    "3. `[æ¨¡å‹å]` - æ¨¡å‹å†³å®šè°ƒç”¨ `explain_concept` å·¥å…·\n",
    "\n",
    "**ç¬¬äºŒæ¬¡è¿­ä»£ (å·¥å…·æ‰§è¡Œå):**\n",
    "1. `[æ¨¡å‹å‰]` - ç°åœ¨æ¶ˆæ¯æ›´å¤šäº†ï¼ˆåŒ…å«å·¥å…·ç»“æœï¼‰\n",
    "2. `[æ¨¡å‹è¯·æ±‚]` -å†æ¬¡æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯\n",
    "3. `[æ¨¡å‹å]` - æ¨¡å‹ç»™å‡ºæœ€ç»ˆç­”æ¡ˆï¼ˆä¸å†éœ€è¦å·¥å…·ï¼‰\n",
    "\n",
    "è¿™è®©ä½ èƒ½å¤Ÿæ·±å…¥äº†è§£ Agent çš„å†³ç­–è¿‡ç¨‹ã€‚\n",
    "\n",
    "è®©æˆ‘ä»¬è¿è¡Œå®ƒï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "è¿è¡Œå¸¦æœ‰æ—¥å¿—è®°å½•å™¨çš„ Agent\n",
      "==================================================\n",
      "\n",
      "[æ¨¡å‹å‰] æ­£åœ¨å¤„ç† 1 æ¡æ¶ˆæ¯\n",
      "  [æ¨¡å‹è¯·æ±‚]\n",
      "   æ¨¡å‹: profile={'max_input_tokens': 200000, 'max_output_tokens': 100000, 'image_inputs': False, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': True, 'tool_calling': True, 'structured_output': True, 'image_url_inputs': True, 'pdf_inputs': True, 'pdf_tool_message': True, 'image_tool_message': True, 'tool_choice': True} client=<openai.resources.chat.completions.completions.Completions object at 0x7f6ee66a87c0> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7f6ee53f6920> root_client=<openai.OpenAI object at 0x7f6ee66a8970> root_async_client=<openai.AsyncOpenAI object at 0x7f6f2828cca0> model_name='o3-mini' model_kwargs={} openai_api_key=SecretStr('**********')\n",
      "   å¯ç”¨å·¥å…·: 1\n",
      " [æ¨¡å‹å] æ¨¡å‹è¯·æ±‚äº† 1 ä¸ªå·¥å…·è°ƒç”¨\n",
      "[æ¨¡å‹å‰] æ­£åœ¨å¤„ç† 3 æ¡æ¶ˆæ¯\n",
      "  [æ¨¡å‹è¯·æ±‚]\n",
      "   æ¨¡å‹: profile={'max_input_tokens': 200000, 'max_output_tokens': 100000, 'image_inputs': False, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': True, 'tool_calling': True, 'structured_output': True, 'image_url_inputs': True, 'pdf_inputs': True, 'pdf_tool_message': True, 'image_tool_message': True, 'tool_choice': True} client=<openai.resources.chat.completions.completions.Completions object at 0x7f6ee66a87c0> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7f6ee53f6920> root_client=<openai.OpenAI object at 0x7f6ee66a8970> root_async_client=<openai.AsyncOpenAI object at 0x7f6f2828cca0> model_name='o3-mini' model_kwargs={} openai_api_key=SecretStr('**********')\n",
      "   å¯ç”¨å·¥å…·: 1\n",
      " [æ¨¡å‹å] æ¨¡å‹æä¾›äº†æœ€ç»ˆå“åº”\n",
      "\n",
      "==================================================\n",
      "æœ€ç»ˆå“åº”\n",
      "==================================================\n",
      "é€’å½’æ˜¯ä¸€ç§åœ¨è§£å†³é—®é¢˜æ—¶é‡‡ç”¨çš„æ–¹æ³•ï¼Œå…¶åŸºæœ¬æ€æƒ³æ˜¯å°†ä¸€ä¸ªå¤§é—®é¢˜æ‹†è§£ä¸ºä¸€ä¸ªæˆ–å¤šä¸ªè§„æ¨¡æ›´å°çš„ã€ç±»ä¼¼çš„é—®é¢˜ï¼Œç›´åˆ°é—®é¢˜ç®€åŒ–åˆ°è¶³ä»¥ç›´æ¥æ±‚è§£ä¸ºæ­¢ã€‚é€’å½’é€šå¸¸åŒ…å«ä¸¤ä¸ªå…³é”®éƒ¨åˆ†ï¼š\n",
      "\n",
      "1. åŸºæœ¬æƒ…å†µï¼ˆç»ˆæ­¢æ¡ä»¶ï¼‰ï¼šè¿™æ˜¯é€’å½’åœæ­¢çš„æ¡ä»¶ï¼Œä¸€æ—¦è¾¾åˆ°è¿™ä¸ªæ¡ä»¶ï¼Œé€’å½’è¿‡ç¨‹å°±ä¼šåœæ­¢ï¼Œä»è€Œé¿å…æ— é™å¾ªç¯ã€‚\n",
      "2. é€’å½’æ­¥éª¤ï¼šè¿™æ˜¯å°†åŸé—®é¢˜æ‹†åˆ†ä¸ºè§„æ¨¡æ›´å°çš„å­é—®é¢˜ï¼Œå¹¶ç”¨ç›¸åŒçš„è§£å†³æ–¹æ³•æ¥å¤„ç†è¿™äº›å­é—®é¢˜çš„è¿‡ç¨‹ã€‚\n",
      "\n",
      "ä»¥è®¡ç®—é˜¶ä¹˜ï¼ˆn!ï¼‰ä¸ºä¾‹ï¼Œé€’å½’æ–¹æ³•å¯ä»¥æè¿°ä¸ºï¼š\n",
      "è‹¥ n ç­‰äº 0ï¼Œåˆ™é˜¶ä¹˜ä¸º 1ï¼›å¦åˆ™ n! = n Ã— (n-1)!ã€‚åœ¨è¿™é‡Œï¼Œé˜¶ä¹˜å‡½æ•°ä¸æ–­è°ƒç”¨è‡ªèº«ï¼Œç›´åˆ°é‡åˆ° n = 0 çš„åŸºæœ¬æƒ…å†µï¼Œä»è€Œè¿”å›æœ€ç»ˆç»“æœã€‚\n",
      "\n",
      "é€’å½’åœ¨å¤„ç†å…·æœ‰åˆ†å½¢æˆ–è‡ªç›¸ä¼¼ç»“æ„çš„é—®é¢˜æ—¶éå¸¸æœ‰ç”¨ï¼Œå¦‚æ ‘å½¢ç»“æ„éå†ã€å½’å¹¶æ’åºã€å¿«é€Ÿæ’åºç­‰ã€‚ä½†éœ€è¦æ³¨æ„ï¼Œç¡®ä¿é€’å½’è°ƒç”¨æœ‰æ˜ç¡®çš„ç»ˆæ­¢æ¡ä»¶éå¸¸é‡è¦ï¼Œå¦åˆ™å¯èƒ½ä¼šå¯¼è‡´æ— é™é€’å½’ï¼Œæœ€ç»ˆè€—å°½ç³»ç»Ÿèµ„æºã€‚\n"
     ]
    }
   ],
   "source": [
    "# è¿è¡Œå¹¶è§‚å¯Ÿæ—¥å¿—\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"è¿è¡Œå¸¦æœ‰æ—¥å¿—è®°å½•å™¨çš„ Agent\")\n",
    "print(\"=\" * 50 + \"\\n\")\n",
    "\n",
    "result = agent_with_logger.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"è§£é‡Šé€’å½’\"}]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"æœ€ç»ˆå“åº”\")\n",
    "print(\"=\" * 50)\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç¬¬ 4 éƒ¨åˆ†: ç»“åˆ Middleware å’Œ Human-in-the-loop\n",
    "\n",
    "è®©æˆ‘ä»¬ç»“åˆ Human-in-the-Loop å’Œ Middlewareï¼Œæ„å»ºä¸€ä¸ªç”Ÿäº§å°±ç»ªçš„ Agentï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# éœ€è¦æ‰¹å‡†çš„æ•æ„Ÿå·¥å…·\n",
    "@tool\n",
    "def delete_database(database_name: str) -> str:\n",
    "    \"\"\"åˆ é™¤æ•°æ®åº“ã€‚è¿™å¾ˆå±é™©ï¼\"\"\"\n",
    "    \n",
    "    response = interrupt({\n",
    "        \"action\": \"delete_database\",\n",
    "        \"database_name\": database_name,\n",
    "        \"warning\": \"è¿™å°†æ°¸ä¹…åˆ é™¤æ•°æ®åº“ï¼\",\n",
    "        \"message\": \"ä½ ç¡®å®šè¦è¿™æ ·åšå—ï¼Ÿ\"\n",
    "    })\n",
    "    \n",
    "    if response.get(\"confirmed\"):\n",
    "        return f\"æ•°æ®åº“ '{database_name}' å·²è¢«åˆ é™¤ï¼ˆæ¨¡æ‹Ÿï¼‰\"\n",
    "    else:\n",
    "        return \"æ•°æ®åº“åˆ é™¤å·²å–æ¶ˆ\"\n",
    "\n",
    "# ç”¨äºè·Ÿè¸ªå±é™©æ“ä½œçš„ä¸­é—´ä»¶\n",
    "class SafetyMiddleware(AgentMiddleware):\n",
    "    \"\"\"æ·»åŠ å®‰å…¨æ£€æŸ¥å’Œæ—¥å¿—è®°å½•çš„ä¸­é—´ä»¶ã€‚\"\"\"\n",
    "    \n",
    "    name = \"safety_checker\"\n",
    "    \n",
    "    def after_model(self, state: AgentState) -> dict[str, Any] | None:\n",
    "        \"\"\"æ£€æŸ¥å±é™©çš„å·¥å…·è°ƒç”¨ã€‚\"\"\"\n",
    "        last_message = state[\"messages\"][-1]\n",
    "        \n",
    "        if hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
    "            for tool_call in last_message.tool_calls:\n",
    "                if \"delete\" in tool_call[\"name\"].lower():\n",
    "                    print(\"   [å®‰å…¨] æ£€æµ‹åˆ°å±é™©æ“ä½œï¼\")\n",
    "                    print(f\"   å·¥å…·: {tool_call['name']}\")\n",
    "                    print(f\"   å‚æ•°: {tool_call['args']}\")\n",
    "        \n",
    "        return None\n",
    "\n",
    "# åˆ›å»ºç”Ÿäº§çº§ Agent\n",
    "production_agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[delete_database],\n",
    "    middleware=[SafetyMiddleware()],\n",
    "    checkpointer=MemorySaver()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### é¢„æœŸç»“æœï¼šå¤šå±‚å®‰å…¨æœºåˆ¶å®æˆ˜\n",
    "\n",
    "  å½“æˆ‘ä»¬å°è¯•ä¸€ä¸ªå±é™©æ“ä½œæ—¶ï¼Œä½ ä¼šçœ‹åˆ° **ä¸¤ç§** å®‰å…¨æœºåˆ¶è¢«æ¿€æ´»ï¼š\n",
    "\n",
    "  **ç¬¬ 1 å±‚ - Middleware æ£€æµ‹:**\n",
    "  - `[å®‰å…¨] æ£€æµ‹åˆ°å±é™©æ“ä½œï¼` - ä¸­é—´ä»¶å‘ç° delete æ“ä½œ\n",
    "  - è®°å½•å·¥å…·åç§°å’Œå‚æ•°ä»¥ç”¨äºå®¡è®¡è¿½è¸ª\n",
    "\n",
    "  **ç¬¬ 2 å±‚ - äººå·¥æ‰¹å‡† (Interrupt):**\n",
    "  - Agent æ‰§è¡Œåœ¨ `interrupt()` å¤„æš‚åœ\n",
    "  - å‘å®¡æ ¸äººå‘˜å±•ç¤ºè­¦å‘Šä¿¡æ¯\n",
    "  - é™¤éè·å¾—æ˜ç¡®æ‰¹å‡†ï¼Œå¦åˆ™æ‰§è¡Œä¸ä¼šç»§ç»­\n",
    "\n",
    "  **è¿™å°±æ˜¯çºµæ·±é˜²å¾¡ï¼š** Middleware ç›‘æ§æ‰€æœ‰æ“ä½œï¼Œè€Œ Interrupts å¼ºåˆ¶å¯¹å…³é”®è¡ŒåŠ¨è¿›è¡Œäººå·¥æ‰¹å‡†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "å°è¯•å±é™©æ“ä½œ\n",
      "==================================================\n",
      "\n",
      "   [å®‰å…¨] æ£€æµ‹åˆ°å±é™©æ“ä½œï¼\n",
      "   å·¥å…·: delete_database\n",
      "   å‚æ•°: {'database_name': 'production_db'}\n",
      "\n",
      "  éœ€è¦äººå·¥æ‰¹å‡†ï¼š\n",
      "   è¿™å°†æ°¸ä¹…åˆ é™¤æ•°æ®åº“ï¼\n",
      "   Database: production_db\n",
      "\n",
      "(åœ¨çœŸå®åº”ç”¨ä¸­ï¼Œäººç±»ä¼šåœ¨ç»§ç»­ä¹‹å‰å®¡æŸ¥æ­¤æ“ä½œ)\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•ç»„åˆæ¨¡å¼\n",
    "config_4 = {\"configurable\": {\"thread_id\": uuid7()}}\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"å°è¯•å±é™©æ“ä½œ\")\n",
    "print(\"=\" * 50 + \"\\n\")\n",
    "\n",
    "# è¿è¡Œç›´åˆ° interrupt\n",
    "result = production_agent.invoke(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(content=\"åˆ é™¤ production_db æ•°æ®åº“\")]\n",
    "    },\n",
    "    config=config_4\n",
    ")\n",
    "\n",
    "if \"__interrupt__\" in result:\n",
    "    interrupt_info = result[\"__interrupt__\"][0]\n",
    "    print(\"\\n  éœ€è¦äººå·¥æ‰¹å‡†ï¼š\")\n",
    "    print(f\"   {interrupt_info.value['warning']}\")\n",
    "    print(f\"   Database: {interrupt_info.value['database_name']}\")\n",
    "\n",
    "print(\"\\n(åœ¨çœŸå®åº”ç”¨ä¸­ï¼Œäººç±»ä¼šåœ¨ç»§ç»­ä¹‹å‰å®¡æŸ¥æ­¤æ“ä½œ)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ ¸å¿ƒè¦ç‚¹\n",
    "\n",
    "### Human-in-the-Loop (Interrupts)\n",
    "- ä½¿ç”¨ `interrupt()` æš‚åœæ‰§è¡Œ\n",
    "- å¿…é¡»é…åˆ `checkpointer` å®ç°æŒä¹…åŒ–\n",
    "- ä½¿ç”¨ `Command(resume=value)` æ¢å¤æ‰§è¡Œ\n",
    "- éå¸¸é€‚åˆå®¡æ‰¹å·¥ä½œæµå’Œæ•æ„Ÿæ“ä½œ\n",
    "\n",
    "### Middleware\n",
    "- **Node-style hooks**: `before_model`, `after_model` - é¡ºåºé€»è¾‘ã€éªŒè¯ã€æ—¥å¿—\n",
    "- **Wrap-style hooks**: `wrap_model_call`, `wrap_tool_call` - å®Œå…¨æ§åˆ¶ã€é‡è¯•ã€è½¬æ¢\n",
    "- **Decorators**: `@dynamic_prompt`, `@before_model`, `@wrap_model_call` ç”¨äºå¿«é€Ÿå®šä¹‰ä¸­é—´ä»¶\n",
    "- **Classes**: ç»§æ‰¿ `AgentMiddleware` ä»¥æ„å»ºå¤æ‚ã€å¯é‡ç”¨çš„ç»„ä»¶\n",
    "\n",
    "### ä½•æ—¶ä½¿ç”¨ä»€ä¹ˆï¼Ÿ\n",
    "\n",
    "**ä½¿ç”¨ Interrupts å½“ï¼š**\n",
    "- åŠ¨ä½œéœ€è¦äººå·¥æ‰¹å‡†\n",
    "- ä½ æƒ³å®¡æŸ¥/ç¼–è¾‘å·¥å…·è°ƒç”¨\n",
    "- éœ€è¦éªŒè¯ç”¨æˆ·è¾“å…¥\n",
    "\n",
    "**ä½¿ç”¨ Middleware å½“ï¼š**\n",
    "- éœ€è¦åŠ¨æ€ä¿®æ”¹ Agent è¡Œä¸º\n",
    "- æƒ³è¦æ·»åŠ æ—¥å¿—/ç›‘æ§\n",
    "- éœ€è¦æ‰§è¡Œç­–ç•¥ï¼ˆToken é™åˆ¶ã€å®‰å…¨æ£€æŸ¥ï¼‰\n",
    "- æƒ³è¦æ ¹æ®ä¸Šä¸‹æ–‡ä¸ªæ€§åŒ–å“åº”\n",
    "\n",
    "**Node-style vs Wrap-style:**\n",
    "- Node-style ç”¨äºé¡ºåºæ“ä½œï¼ˆæ—¥å¿—ã€éªŒè¯ï¼‰\n",
    "- Wrap-style ç”¨äºæ§åˆ¶æµï¼ˆé‡è¯•ã€å›é€€ã€ç¼“å­˜ï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç»ƒä¹  (å¯é€‰)\n",
    "\n",
    "å°è¯•æ„å»ºä¸€ä¸ª Agentï¼š\n",
    "1. æ‹¥æœ‰ä¸€ä¸ªè¿›è¡Œè´­ä¹°æ“ä½œçš„å·¥å…·\n",
    "2. ä½¿ç”¨ä¸­é—´ä»¶æ£€æŸ¥è´­ä¹°é‡‘é¢æ˜¯å¦è¶…è¿‡ `$1000`\n",
    "3. å¦‚æœè¶…è¿‡ `$1000`ï¼Œä½¿ç”¨ interrupt è¦æ±‚æ‰¹å‡†\n",
    "4. å¦‚æœä½äº `$1000`ï¼Œè‡ªåŠ¨å¤„ç†\n",
    "\n",
    "æç¤ºï¼šç»“åˆ `before_model` ä¸­é—´ä»¶å’Œæ¡ä»¶æ€§çš„ `interrupt()` é€»è¾‘ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä½ çš„ä»£ç ï¼\n",
    "# æŒ‘æˆ˜ï¼šæ„å»ºè´­ä¹°å®¡æ‰¹ Agent\n",
    "\n",
    "# @tool\n",
    "# def make_purchase(item: str, amount: float) -> str:\n",
    "#     ...\n",
    "#\n",
    "# class PurchaseLimitMiddleware(AgentMiddleware):\n",
    "#     ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“š LangChain & LangGraph 1.0 è¿ç§»æ€»ç»“\n",
    "\n",
    "### æ ¸å¿ƒå˜åŒ–å›é¡¾\n",
    "\n",
    "#### 1. LangChain 1.0 ä¸»è¦å˜åŒ–\n",
    "\n",
    "| ç‰¹æ€§ | 0.x | 1.0 | å½±å“ |\n",
    "|------|-----|-----|------|\n",
    "| Agent åˆ›å»º | `create_react_agent()` | `create_agent()` | ğŸ”´ å¿…é¡»è¿ç§» |\n",
    "| ä¸­é—´ä»¶ | âŒ ä¸å­˜åœ¨ | âœ… å®Œæ•´æ”¯æŒ | ğŸ†• æ–°åŠŸèƒ½ |\n",
    "| Content Blocks | æä¾›å•†ç‰¹å®š | ç»Ÿä¸€ API | ğŸŸ¡ æ¨èé‡‡ç”¨ |\n",
    "| å‘½åç©ºé—´ | æ··åˆ | æ ¸å¿ƒ + Classic | ğŸŸ¡ é€æ­¥è¿ç§» |\n",
    "| ç»“æ„åŒ–è¾“å‡º | é¢å¤– LLM è°ƒç”¨ | ä¸»å¾ªç¯é›†æˆ | ğŸŸ¢ æ€§èƒ½æå‡ |\n",
    "\n",
    "#### 2. LangGraph 1.0 ä¸»è¦å˜åŒ–\n",
    "\n",
    "| ç‰¹æ€§ | 0.x | 1.0 | å½±å“ |\n",
    "|------|-----|-----|------|\n",
    "| Interrupt | é™æ€ `interrupt_before` | åŠ¨æ€ `interrupt()` | ğŸ”´ å¿…é¡»è¿ç§» |\n",
    "| çŠ¶æ€æ›´æ–° | åˆ†ç¦»çš„è¿”å›å€¼å’Œè·¯ç”± | `Command` å¯¹è±¡ | ğŸŸ¡ æ¨èé‡‡ç”¨ |\n",
    "| Checkpointer | ä¸ç»Ÿä¸€ | ç»Ÿä¸€æ¥å£ | ğŸŸ¡ æ¨èé‡‡ç”¨ |\n",
    "| æ ¸å¿ƒ API | å®éªŒæ€§ | ç¨³å®šï¼ˆè¯­ä¹‰åŒ–ç‰ˆæœ¬ï¼‰ | ğŸŸ¢ ç¨³å®šæ€§æå‡ |\n",
    "\n",
    "#### 2. ğŸ“Š å®Œæ•´å¯¹æ¯”è¡¨\n",
    "\n",
    "| åŠŸèƒ½ | LangChain/LangGraph 0.x | LangChain/LangGraph 1.0 | è¿ç§»å¤æ‚åº¦ |\n",
    "|------|------------------------|------------------------|-----------|\n",
    "| **Agent åˆ›å»º** | `langgraph.prebuilt.create_react_agent` | `langchain.agents.create_agent` | ğŸŸ¢ ç®€å• |\n",
    "| **ä¸­é—´ä»¶** | âŒ ä¸æ”¯æŒ | âœ… å®Œæ•´æ”¯æŒ | ğŸŸ¡ ä¸­ç­‰ (æ–°åŠŸèƒ½) |\n",
    "| **äººæœºäº¤äº’** | é™æ€ `interrupt_before` | åŠ¨æ€ `interrupt()` | ğŸŸ¡ ä¸­ç­‰ |\n",
    "| **çŠ¶æ€ + è·¯ç”±** | åˆ†ç¦»çš„å‡½æ•° | `Command` å¯¹è±¡ | ğŸŸ¢ ç®€å• |\n",
    "| **Content Blocks** | æä¾›å•†ç‰¹å®š | ç»Ÿä¸€ `content_blocks` | ğŸŸ¢ ç®€å• |\n",
    "| **å‘½åç©ºé—´** | æ‰€æœ‰åŠŸèƒ½åœ¨ `langchain` | æ ¸å¿ƒåœ¨ `langchain`ï¼Œé—ç•™åœ¨ `langchain-classic` | ğŸŸ¢ ç®€å• |\n",
    "| **ç»“æ„åŒ–è¾“å‡º** | éœ€è¦é¢å¤– LLM è°ƒç”¨ | ä¸»å¾ªç¯å†…ç”Ÿæˆ | ğŸŸ¢ ç®€å• |\n",
    "| **Checkpointer** | é…ç½®æ–¹å¼ä¸ç»Ÿä¸€ | ç»Ÿä¸€æ¥å£ | ğŸŸ¢ ç®€å• |\n",
    "| **æ ¸å¿ƒ Graph API** | å®éªŒæ€§ | ç¨³å®š (è¯­ä¹‰åŒ–ç‰ˆæœ¬) | ğŸŸ¢ æ— éœ€è¿ç§» |\n",
    "\n",
    "**å¤æ‚åº¦è¯´æ˜**ï¼š\n",
    "- ğŸŸ¢ **ç®€å•**ï¼šç›´æ¥æ›¿æ¢å¯¼å…¥è·¯å¾„æˆ– API è°ƒç”¨\n",
    "- ğŸŸ¡ **ä¸­ç­‰**ï¼šéœ€è¦ç†è§£æ–°æ¦‚å¿µï¼Œé‡æ„éƒ¨åˆ†ä»£ç \n",
    "- ğŸ”´ **å¤æ‚**ï¼šéœ€è¦é‡æ–°è®¾è®¡æ¶æ„\n",
    "\n",
    "---\n",
    "\n",
    "### é¿å…çš„å¸¸è§é™·é˜±\n",
    "\n",
    "#### âŒ é™·é˜± 1ï¼šå¿˜è®°é…ç½® Checkpointer\n",
    "\n",
    "```python\n",
    "# é”™è¯¯ï¼šä½¿ç”¨ interrupt ä½†æ²¡æœ‰ checkpointer\n",
    "agent = create_agent(model, [tool_with_interrupt])\n",
    "result = agent.invoke(...)  # âš ï¸ è¿è¡Œæ—¶é”™è¯¯ï¼\n",
    "```\n",
    "\n",
    "**è§£å†³**ï¼šæ‰€æœ‰ä½¿ç”¨ `interrupt()` çš„ Agent å¿…é¡»é…ç½® `checkpointer`\n",
    "\n",
    "---\n",
    "\n",
    "#### âŒ é™·é˜± 2ï¼šæ··ç”¨æ—§ç‰ˆå’Œæ–°ç‰ˆ API\n",
    "\n",
    "```python\n",
    "# é”™è¯¯ï¼šå¯¼å…¥æ–°ç‰ˆä½†ä½¿ç”¨æ—§å‚æ•°å\n",
    "from langchain.agents import create_agent\n",
    "agent = create_agent(\n",
    "    model,\n",
    "    tools,\n",
    "    messages_modifier=SystemMessage(\"...\")  # âš ï¸ å‚æ•°åé”™è¯¯\n",
    ")\n",
    "```\n",
    "\n",
    "**è§£å†³**ï¼šä½¿ç”¨ `system_prompt=\"...\"` è€Œä¸æ˜¯ `messages_modifier`\n",
    "\n",
    "---\n",
    "\n",
    "#### âŒ é™·é˜± 3ï¼šMiddleware ä¿®æ”¹çŠ¶æ€ä½†è¿”å› None\n",
    "\n",
    "```python\n",
    "# é”™è¯¯ï¼šä¿®æ”¹äº† state ä½†æ²¡æœ‰è¿”å›\n",
    "def before_model(state, runtime):\n",
    "    state[\"messages\"].append(...)  # âš ï¸ ç›´æ¥ä¿®æ”¹æ— æ•ˆ\n",
    "    return None\n",
    "\n",
    "# æ­£ç¡®ï¼šè¿”å›è¦æ›´æ–°çš„çŠ¶æ€\n",
    "def before_model(state, runtime):\n",
    "    return {\"messages\": state[\"messages\"] + [...]}\n",
    "```\n",
    "\n",
    "**è§£å†³**ï¼šMiddleware å¿…é¡»**è¿”å›**çŠ¶æ€æ›´æ–°å­—å…¸\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… è¿ç§»æ£€æŸ¥æ¸…å•\n",
    "\n",
    "### 1. ä¾èµ–æ›´æ–°\n",
    "```bash\n",
    "# æ›´æ–°åˆ° 1.x ç‰ˆæœ¬\n",
    "pip install --upgrade langchain>=1.1.0 langgraph>=1.0.0\n",
    "\n",
    "# å¦‚æœä½¿ç”¨é—ç•™åŠŸèƒ½\n",
    "pip install langchain-classic\n",
    "```\n",
    "\n",
    "### 2. ä»£ç è¿ç§»æ­¥éª¤\n",
    "\n",
    "#### Step 1: æ›¿æ¢ Agent åˆ›å»º\n",
    "- [ ] å°† `from langgraph.prebuilt import create_react_agent` æ”¹ä¸º `from langchain.agents import create_agent`\n",
    "- [ ] æ·»åŠ  `system_prompt` å‚æ•°\n",
    "- [ ] ç§»é™¤ `messages_modifier`ï¼ˆåˆå¹¶åˆ° `system_prompt`ï¼‰\n",
    "\n",
    "#### Step 2: è¿ç§»é—ç•™åŠŸèƒ½\n",
    "- [ ] æ£€æŸ¥æ˜¯å¦ä½¿ç”¨ `langchain.chains`\n",
    "- [ ] æ£€æŸ¥æ˜¯å¦ä½¿ç”¨ `langchain.retrievers`\n",
    "- [ ] æ£€æŸ¥æ˜¯å¦ä½¿ç”¨ `langchain.hub`\n",
    "- [ ] å¦‚æœä½¿ç”¨ï¼Œå®‰è£… `langchain-classic` å¹¶æ›´æ–°å¯¼å…¥\n",
    "\n",
    "#### Step 3: å‡çº§ Human-in-the-Loop\n",
    "- [ ] å°†é™æ€ `interrupt_before` æ›¿æ¢ä¸ºåŠ¨æ€ `interrupt()`\n",
    "- [ ] æ›´æ–°æ¢å¤é€»è¾‘ä½¿ç”¨ `Command(resume=...)`\n",
    "\n",
    "#### Step 4: (å¯é€‰) æ·»åŠ ä¸­é—´ä»¶\n",
    "- [ ] è¯†åˆ«é‡å¤çš„æ¨ªåˆ‡é€»è¾‘ï¼ˆæ—¥å¿—ã€PII è¿‡æ»¤ç­‰ï¼‰\n",
    "- [ ] å®ç°æˆ–ä½¿ç”¨å†…ç½®ä¸­é—´ä»¶\n",
    "- [ ] åœ¨ `create_agent()` ä¸­æ·»åŠ  `middleware` å‚æ•°\n",
    "\n",
    "#### Step 5: æµ‹è¯•\n",
    "- [ ] è¿è¡Œç°æœ‰æµ‹è¯•å¥—ä»¶\n",
    "- [ ] éªŒè¯ checkpointer è¡Œä¸º\n",
    "- [ ] éªŒè¯å·¥å…·è°ƒç”¨\n",
    "- [ ] éªŒè¯æµå¼è¾“å‡º\n",
    "- [ ] éªŒè¯ interrupt/resume æµç¨‹\n",
    "\n",
    "### 3. æ€§èƒ½ä¼˜åŒ–å»ºè®®\n",
    "- [ ] ä½¿ç”¨ `ToolStrategy` ä¼˜åŒ–ç»“æ„åŒ–è¾“å‡º\n",
    "- [ ] è€ƒè™‘ä½¿ç”¨ `PostgresSaver` ä½œä¸ºç”Ÿäº§ checkpointer\n",
    "- [ ] å¯ç”¨ LangSmith è¿›è¡Œç›‘æ§å’Œè°ƒè¯•\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç»ƒä¹ å‚è€ƒç­”æ¡ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "æµ‹è¯•åœºæ™¯ 1: å°é¢è´­ä¹° ($300) -> åº”è‡ªåŠ¨é€šè¿‡\n",
      "==================================================\n",
      "Agent å›å¤: å·²ä¸ºæ‚¨æˆåŠŸè´­ä¹°æœºæ¢°é”®ç›˜ï¼å¦‚æœéœ€è¦å…¶ä»–å¸®åŠ©ï¼Œè¯·å‘Šè¯‰æˆ‘ã€‚\n",
      "\n",
      "==================================================\n",
      "æµ‹è¯•åœºæ™¯ 2: å¤§é¢è´­ä¹° ($2500) -> åº”æš‚åœç­‰å¾…æ‰¹å‡†\n",
      "==================================================\n",
      ">>> æ­¥éª¤ 1: å‘èµ·è¯·æ±‚\n",
      "\n",
      "[ä¸­é—´ä»¶] âš ï¸  é£æ§è§¦å‘ï¼š'æ–°çš„æœåŠ¡å™¨' é‡‘é¢ $2500 è¶…è¿‡è‡ªåŠ¨æ‰¹å‡†é™é¢ ($1000)ã€‚\n",
      "\n",
      "[ç³»ç»Ÿ] Agent å·²æš‚åœï¼Œç­‰å¾…äººå·¥æŒ‡ä»¤...\n",
      "è¯¦æƒ…: ç”³è¯·è´­ä¹° 'æ–°çš„æœåŠ¡å™¨'ï¼Œé‡‘é¢ $2500ã€‚æ˜¯å¦æ‰¹å‡†ï¼Ÿ\n",
      "\n",
      ">>> æ­¥éª¤ 2: æ¨¡æ‹Ÿäººå·¥æ‰¹å‡† (Resume)\n",
      "\n",
      "[ä¸­é—´ä»¶] âš ï¸  é£æ§è§¦å‘ï¼š'æ–°çš„æœåŠ¡å™¨' é‡‘é¢ $2500 è¶…è¿‡è‡ªåŠ¨æ‰¹å‡†é™é¢ ($1000)ã€‚\n",
      "[ä¸­é—´ä»¶] âœ… è´­ä¹°ç”³è¯·å·²è·æ‰¹å‡†ï¼Œç»§ç»­æ‰§è¡Œ...\n",
      "Agent æœ€ç»ˆå›å¤: æœåŠ¡å™¨é‡‡è´­å·²æˆåŠŸå®Œæˆï¼Œæ”¯ä»˜é‡‘é¢ä¸º 2500 ç¾å…ƒã€‚\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents.middleware import AgentMiddleware\n",
    "from typing import Any, Callable\n",
    "from langgraph.types import interrupt, Command\n",
    "from langchain_core.tools import tool\n",
    "from langchain.messages import HumanMessage\n",
    "from langsmith import uuid7\n",
    "\n",
    "# ==========================================\n",
    "# 1. å®šä¹‰è´­ä¹°å·¥å…·\n",
    "# ==========================================\n",
    "@tool\n",
    "def make_purchase(item: str, amount: float) -> str:\n",
    "    \"\"\"\n",
    "    æ‰§è¡Œè´­ä¹°æ“ä½œçš„å·¥å…·ã€‚\n",
    "    \"\"\"\n",
    "    return f\"æ”¯ä»˜æˆåŠŸï¼šå·²ä¸º '{item}' æ”¯ä»˜ ${amount}ã€‚\"\n",
    "\n",
    "# ==========================================\n",
    "# 2. å®šä¹‰è´­ä¹°é™åˆ¶ä¸­é—´ä»¶ (ä¿®æ­£ç‰ˆ)\n",
    "# ==========================================\n",
    "class PurchaseLimitMiddleware(AgentMiddleware):\n",
    "    \"\"\"\n",
    "    è´­ä¹°é£æ§ä¸­é—´ä»¶ã€‚\n",
    "    \"\"\"\n",
    "    \n",
    "    def wrap_tool_call(self, request: Any, handler: Callable[[Any], Any]) -> Any:\n",
    "        # ä¿®æ­£ç‚¹ï¼šä» request å¯¹è±¡ä¸­è§£æå·¥å…·è°ƒç”¨ä¿¡æ¯\n",
    "        # request.tool_call æ˜¯ä¸€ä¸ªåŒ…å« name, args ç­‰ä¿¡æ¯çš„å­—å…¸\n",
    "        tool_call = getattr(request, \"tool_call\", {})\n",
    "        tool_name = tool_call.get(\"name\")\n",
    "        tool_args = tool_call.get(\"args\", {})\n",
    "        \n",
    "        # æå–å‚æ•°\n",
    "        amount = tool_args.get(\"amount\", 0)\n",
    "        item = tool_args.get(\"item\", \"æœªçŸ¥å•†å“\")\n",
    "\n",
    "        # æ£€æŸ¥é€»è¾‘ï¼šå¿…é¡»æ˜¯ make_purchase å·¥å…·ï¼Œä¸”é‡‘é¢è¶…è¿‡ 1000\n",
    "        if tool_name == \"make_purchase\" and amount > 1000:\n",
    "            print(f\"\\n[ä¸­é—´ä»¶] âš ï¸  é£æ§è§¦å‘ï¼š'{item}' é‡‘é¢ ${amount} è¶…è¿‡è‡ªåŠ¨æ‰¹å‡†é™é¢ ($1000)ã€‚\")\n",
    "            \n",
    "            # è§¦å‘ä¸­æ–­\n",
    "            approval_result = interrupt({\n",
    "                \"type\": \"purchase_approval\",\n",
    "                \"item\": item,\n",
    "                \"amount\": amount,\n",
    "                \"reason\": \"é‡‘é¢è¶…é™\",\n",
    "                \"message\": f\"ç”³è¯·è´­ä¹° '{item}'ï¼Œé‡‘é¢ ${amount}ã€‚æ˜¯å¦æ‰¹å‡†ï¼Ÿ\"\n",
    "            })\n",
    "            \n",
    "            # æ£€æŸ¥äººå·¥å®¡æ ¸ç»“æœ\n",
    "            if not approval_result.get(\"approved\"):\n",
    "                print(\"[ä¸­é—´ä»¶] âŒ è´­ä¹°ç”³è¯·è¢«äººå·¥æ‹’ç»ã€‚\")\n",
    "                return f\"äº¤æ˜“å–æ¶ˆï¼šç®¡ç†å‘˜æ‹’ç»äº†å¯¹ '{item}' çš„ ${amount} è´­ä¹°ç”³è¯·ã€‚\"\n",
    "            \n",
    "            print(\"[ä¸­é—´ä»¶] âœ… è´­ä¹°ç”³è¯·å·²è·æ‰¹å‡†ï¼Œç»§ç»­æ‰§è¡Œ...\")\n",
    "        \n",
    "        # æ‰§è¡ŒåŸå§‹å·¥å…·è°ƒç”¨\n",
    "        return handler(request)\n",
    "\n",
    "# ==========================================\n",
    "# 3. åˆ›å»º Agent\n",
    "# ==========================================\n",
    "purchase_agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[make_purchase],\n",
    "    middleware=[PurchaseLimitMiddleware()],\n",
    "    checkpointer=MemorySaver(),\n",
    "    system_prompt=\"ä½ æ˜¯ä¸€ä¸ªé‡‡è´­åŠ©æ‰‹ã€‚æ”¶åˆ°è´­ä¹°è¯·æ±‚æ—¶ï¼Œè¯·è°ƒç”¨ make_purchase å·¥å…·ã€‚\"\n",
    ")\n",
    "\n",
    "# ==========================================\n",
    "# 4. éªŒè¯ä¸æµ‹è¯•\n",
    "# ==========================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"æµ‹è¯•åœºæ™¯ 1: å°é¢è´­ä¹° ($300) -> åº”è‡ªåŠ¨é€šè¿‡\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "thread_config_1 = {\"configurable\": {\"thread_id\": uuid7()}}\n",
    "\n",
    "response_1 = purchase_agent.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"æˆ‘è¦ä¹°ä¸€ä¸ªæœºæ¢°é”®ç›˜ï¼Œä»·æ ¼ 300 ç¾å…ƒ\")]},\n",
    "    config=thread_config_1\n",
    ")\n",
    "print(f\"Agent å›å¤: {response_1['messages'][-1].content}\")\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"æµ‹è¯•åœºæ™¯ 2: å¤§é¢è´­ä¹° ($2500) -> åº”æš‚åœç­‰å¾…æ‰¹å‡†\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "thread_config_2 = {\"configurable\": {\"thread_id\": uuid7()}}\n",
    "\n",
    "# ç¬¬ä¸€æ¬¡è¿è¡Œï¼šè§¦å‘ä¸­æ–­\n",
    "print(\">>> æ­¥éª¤ 1: å‘èµ·è¯·æ±‚\")\n",
    "response_2 = purchase_agent.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"å…¬å¸éœ€è¦é‡‡è´­ä¸€å°æ–°çš„æœåŠ¡å™¨ï¼Œä»·æ ¼ 2500 ç¾å…ƒ\")]},\n",
    "    config=thread_config_2\n",
    ")\n",
    "\n",
    "# æ£€æŸ¥æ˜¯å¦ä¸­æ–­\n",
    "if \"__interrupt__\" in response_2:\n",
    "    interrupt_info = response_2[\"__interrupt__\"][0].value\n",
    "    print(f\"\\n[ç³»ç»Ÿ] Agent å·²æš‚åœï¼Œç­‰å¾…äººå·¥æŒ‡ä»¤...\")\n",
    "    print(f\"è¯¦æƒ…: {interrupt_info['message']}\")\n",
    "    \n",
    "    print(\"\\n>>> æ­¥éª¤ 2: æ¨¡æ‹Ÿäººå·¥æ‰¹å‡† (Resume)\")\n",
    "    final_response = purchase_agent.invoke(\n",
    "        Command(resume={\"approved\": True}),\n",
    "        config=thread_config_2\n",
    "    )\n",
    "    print(f\"Agent æœ€ç»ˆå›å¤: {final_response['messages'][-1].content}\")\n",
    "else:\n",
    "    print(\"é”™è¯¯ï¼šå³é¢„æœŸåº”è¯¥æš‚åœï¼Œä½† Agent ç›´æ¥æ‰§è¡Œå®Œæˆäº†ã€‚\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## ğŸ“š å‚è€ƒèµ„æº\n",
    "\n",
    "### å®˜æ–¹æ–‡æ¡£\n",
    "- [LangChain 1.0 å‘å¸ƒè¯´æ˜](https://docs.langchain.com/oss/python/releases/langchain-v1)\n",
    "- [LangGraph 1.0 å‘å¸ƒè¯´æ˜](https://docs.langchain.com/oss/python/releases/langgraph-v1)\n",
    "- [LangChain 1.0 è¿ç§»æŒ‡å—](https://docs.langchain.com/oss/python/migrate/langchain-v1)\n",
    "- [LangGraph 1.0 è¿ç§»æŒ‡å—](https://docs.langchain.com/oss/python/migrate/langgraph-v1)\n",
    "\n",
    "### æ·±å…¥é˜…è¯»\n",
    "- [Middleware å®Œæ•´æŒ‡å—](https://docs.langchain.com/oss/python/langchain/middleware)\n",
    "- [Human-in-the-Loop æ¨¡å¼](https://docs.langchain.com/oss/python/langchain/human-in-the-loop)\n",
    "- [LangChain 1.0 vs LangGraph 1.0 å¯¹æ¯”](https://www.clickittech.com/ai/langchain-1-0-vs-langgraph-1-0/)\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (langchain1.x)",
   "language": "python",
   "name": "langchain1.x"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
