{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### ğŸ”§ ç¯å¢ƒé…ç½®å’Œæ£€æŸ¥\n",
    "\n",
    "#### æ¦‚è¿°\n",
    "\n",
    "æœ¬æ•™ç¨‹éœ€è¦ç‰¹å®šçš„ç¯å¢ƒé…ç½®ä»¥ç¡®ä¿æœ€ä½³å­¦ä¹ ä½“éªŒã€‚ä»¥ä¸‹é…ç½®å°†å¸®åŠ©ä½ ï¼š\n",
    "\n",
    "- ä½¿ç”¨ç»Ÿä¸€çš„condaç¯å¢ƒï¼šæ¿€æ´»ç»Ÿä¸€çš„å­¦ä¹ ç¯å¢ƒ\n",
    "- é€šè¿‡å›½å†…é•œåƒæºå¿«é€Ÿå®‰è£…ä¾èµ–ï¼šé…ç½®pipä½¿ç”¨æ¸…åé•œåƒæº\n",
    "- åŠ é€Ÿæ¨¡å‹ä¸‹è½½ï¼šè®¾ç½®HuggingFaceé•œåƒä»£ç†\n",
    "- æ£€æŸ¥ç³»ç»Ÿé…ç½®ï¼šæ£€æŸ¥ç¡¬ä»¶å’Œè½¯ä»¶é…ç½®\n",
    "\n",
    "#### é…ç½®\n",
    "\n",
    "- **æ‰€éœ€ç¯å¢ƒåŠå…¶ä¾èµ–å·²ç»éƒ¨ç½²å¥½**\n",
    "- åœ¨`Notebook`å³ä¸Šè§’é€‰æ‹©`jupyterå†…æ ¸`ä¸º`python(flyai_agent_in_action)`ï¼Œå³å¯æ‰§è¡Œä¸‹æ–¹ä»£ç "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================\n",
      "== Conda ç¯å¢ƒæ£€æŸ¥æŠ¥å‘Š (ä»…é’ˆå¯¹å½“å‰ Bash å­è¿›ï¿½ï¿½) ==\n",
      "=========================================\n",
      "âœ… å½“å‰å•å…ƒæ ¼å·²æˆåŠŸæ¿€æ´»åˆ° agent101 ç¯å¢ƒã€‚\n",
      "âœ… æ­£åœ¨ä½¿ç”¨çš„ç¯å¢ƒè·¯å¾„: /root/miniconda3/envs/agent101\n",
      "\n",
      "ğŸ’¡ æç¤º: åç»­çš„Pythonå•å…ƒæ ¼å°†ä½¿ç”¨Notebookå½“å‰é€‰æ‹©çš„Jupyterï¿½ï¿½æ ¸ã€‚\n",
      "   å¦‚æœéœ€è¦åç»­å•å…ƒæ ¼ä¹Ÿä½¿ç”¨æ­¤ç¯å¢ƒï¼Œè¯·æ‰§è¡Œä»¥ä¸‹æ“ä½œ:\n",
      "   1. æ£€æŸ¥ Notebook å³ä¸Šè§’æ˜¯å¦å·²é€‰æ‹© 'python(agent101)'ã€‚\n",
      "=========================================\n"
     ]
    }
   ],
   "source": [
    "%%script bash\n",
    "\n",
    "# 1. æ¿€æ´» conda ç¯å¢ƒ (ä»…å¯¹å½“å‰å•å…ƒæ ¼æœ‰æ•ˆ)\n",
    "eval \"$(conda shell.bash hook)\"\n",
    "conda activate agent101\n",
    "\n",
    "echo \"=========================================\"\n",
    "echo \"== Conda ç¯å¢ƒæ£€æŸ¥æŠ¥å‘Š (ä»…é’ˆå¯¹å½“å‰ Bash å­è¿›ç¨‹) ==\"\n",
    "echo \"=========================================\"\n",
    "\n",
    "# 2. æ£€æŸ¥å½“å‰æ¿€æ´»çš„ç¯å¢ƒ\n",
    "CURRENT_ENV_NAME=$(basename $CONDA_PREFIX)\n",
    "\n",
    "if [ \"$CURRENT_ENV_NAME\" = \"agent101\" ]; then\n",
    "    echo \"âœ… å½“å‰å•å…ƒæ ¼å·²æˆåŠŸæ¿€æ´»åˆ° agent101 ç¯å¢ƒã€‚\"\n",
    "    echo \"âœ… æ­£åœ¨ä½¿ç”¨çš„ç¯å¢ƒè·¯å¾„: $CONDA_PREFIX\"\n",
    "    echo \"\"\n",
    "    echo \"ğŸ’¡ æç¤º: åç»­çš„Pythonå•å…ƒæ ¼å°†ä½¿ç”¨Notebookå½“å‰é€‰æ‹©çš„Jupyterå†…æ ¸ã€‚\"\n",
    "    echo \"   å¦‚æœéœ€è¦åç»­å•å…ƒæ ¼ä¹Ÿä½¿ç”¨æ­¤ç¯å¢ƒï¼Œè¯·æ‰§è¡Œä»¥ä¸‹æ“ä½œ:\"\n",
    "    echo \"   1. æ£€æŸ¥ Notebook å³ä¸Šè§’æ˜¯å¦å·²é€‰æ‹© 'python(agent101)'ã€‚\"\n",
    "else\n",
    "    echo \"âŒ æ¿€æ´»å¤±è´¥æˆ–ç¯å¢ƒåç§°ä¸åŒ¹é…ã€‚å½“å‰ç¯å¢ƒ: $CURRENT_ENV_NAME\"\n",
    "    echo \"\"\n",
    "    echo \"âš ï¸ ä¸¥é‡æç¤º: å»ºè®®å°† Notebook çš„ Jupyter **å†…æ ¸ (Kernel)** åˆ‡æ¢ä¸º 'python(agent101)'ã€‚\"\n",
    "    echo \"   (é€šå¸¸ä½äº Notebook å³ä¸Šè§’æˆ– 'å†…æ ¸' èœå•ä¸­)\"\n",
    "    echo \"\"\n",
    "    echo \"ğŸ“š å¤‡ç”¨æ–¹æ³• (ä¸æ¨è): å¦‚æœæ— æ³•åˆ‡æ¢å†…æ ¸ï¼Œåˆ™å¿…é¡»åœ¨**æ¯ä¸ª**ä»£ç å•å…ƒæ ¼çš„å¤´éƒ¨é‡å¤ä»¥ä¸‹å‘½ä»¤:\"\n",
    "    echo \"\"\n",
    "    echo \"%%script bash\"\n",
    "    echo \"# å¿…é¡»åœ¨æ¯ä¸ªå•å…ƒæ ¼éƒ½æ‰§è¡Œ\"\n",
    "    echo \"eval \\\"\\$(conda shell.bash hook)\\\"\"\n",
    "    echo \"conda activate agent101\"\n",
    "fi\n",
    "\n",
    "echo \"=========================================\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For variant 'global', will try loading '/etc/xdg/pip/pip.conf'\n",
      "For variant 'global', will try loading '/etc/pip.conf'\n",
      "For variant 'user', will try loading '/root/.pip/pip.conf'\n",
      "For variant 'user', will try loading '/root/.config/pip/pip.conf'\n",
      "For variant 'site', will try loading '/root/miniconda3/envs/agent101/pip.conf'\n",
      "\u001b[31mERROR: Got unexpected number of arguments, expected 0. (example: \"/root/miniconda3/envs/agent101/bin/python -m pip config list\")\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "For variant 'global', will try loading '/etc/xdg/pip/pip.conf'\n",
      "For variant 'global', will try loading '/etc/pip.conf'\n",
      "For variant 'user', will try loading '/root/.pip/pip.conf'\n",
      "For variant 'user', will try loading '/root/.config/pip/pip.conf'\n",
      "For variant 'site', will try loading '/root/miniconda3/envs/agent101/pip.conf'\n",
      "\u001b[31mERROR: Got unexpected number of arguments, expected 0. (example: \"/root/miniconda3/envs/agent101/bin/python -m pip config list\")\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# 2. è®¾ç½®pip ä¸ºæ¸…åæº\n",
    "%pip config list -v set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "%pip config list -v list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: HF_ENDPOINT=https://hf-mirror.com\n",
      "https://hf-mirror.com\n"
     ]
    }
   ],
   "source": [
    "# 3. è®¾ç½®HuggingFaceä»£ç†\n",
    "%env HF_ENDPOINT=https://hf-mirror.com\n",
    "# éªŒè¯ï¼šä½¿ç”¨shellå‘½ä»¤æ£€æŸ¥\n",
    "!echo $HF_ENDPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: pandas==2.2.2 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: tabulate==0.9.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from pandas==2.2.2) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from pandas==2.2.2) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from pandas==2.2.2) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from pandas==2.2.2) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas==2.2.2) (1.17.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "### ç¯å¢ƒä¿¡æ¯\n",
      "| é¡¹ç›®         | ä¿¡æ¯                                                                               |\n",
      "|:-------------|:-----------------------------------------------------------------------------------|\n",
      "| æ“ä½œç³»ç»Ÿ     | Linux Ubuntu 22.04.4 LTS                                                           |\n",
      "| CPU ä¿¡æ¯     | 11th Gen Intel(R) Core(TM) i5-1135G7 @ 2.40GHz (1 physical cores, 4 logical cores) |\n",
      "| å†…å­˜ä¿¡æ¯     | 5.75 GB (Available: 2.50 GB)                                                       |\n",
      "| GPU ä¿¡æ¯     | No GPU found (nvidia-smi not found)                                                |\n",
      "| CUDA ä¿¡æ¯    | CUDA not found                                                                     |\n",
      "| Python ç‰ˆæœ¬  | 3.10.18                                                                            |\n",
      "| Conda ç‰ˆæœ¬   | conda 24.4.0                                                                       |\n",
      "| ç‰©ç†ç£ç›˜ç©ºé—´ | Total: 145.49 GB, Used: 50.19 GB, Free: 89.07 GB                                   |\n"
     ]
    }
   ],
   "source": [
    "# ğŸ” ç¯å¢ƒä¿¡æ¯æ£€æŸ¥è„šæœ¬\n",
    "#\n",
    "# æœ¬è„šæœ¬çš„ä½œç”¨ï¼š\n",
    "# 1. å®‰è£… pandas åº“ç”¨äºæ•°æ®è¡¨æ ¼å±•ç¤º\n",
    "# 2. æ£€æŸ¥ç³»ç»Ÿçš„å„é¡¹é…ç½®ä¿¡æ¯\n",
    "# 3. ç”Ÿæˆè¯¦ç»†çš„ç¯å¢ƒæŠ¥å‘Šè¡¨æ ¼\n",
    "#\n",
    "# å¯¹äºåˆå­¦è€…æ¥è¯´ï¼Œè¿™ä¸ªæ­¥éª¤å¸®åŠ©ä½ ï¼š\n",
    "# - äº†è§£å½“å‰è¿è¡Œç¯å¢ƒçš„ç¡¬ä»¶é…ç½®\n",
    "# - ç¡®è®¤æ˜¯å¦æ»¡è¶³æ¨¡å‹è¿è¡Œçš„æœ€ä½è¦æ±‚\n",
    "# - å­¦ä¹ å¦‚ä½•é€šè¿‡ä»£ç è·å–ç³»ç»Ÿä¿¡æ¯\n",
    "\n",
    "# å®‰è£… pandas åº“ - ç”¨äºåˆ›å»ºå’Œå±•ç¤ºæ•°æ®è¡¨æ ¼\n",
    "# pandas æ˜¯ Python ä¸­æœ€æµè¡Œçš„æ•°æ®å¤„ç†å’Œåˆ†æåº“\n",
    "%pip install pandas==2.2.2 tabulate==0.9.0\n",
    "\n",
    "import platform # å¯¼å…¥ platform æ¨¡å—ä»¥è·å–ç³»ç»Ÿä¿¡æ¯\n",
    "import os # å¯¼å…¥ os æ¨¡å—ä»¥ä¸æ“ä½œç³»ç»Ÿäº¤äº’\n",
    "import subprocess # å¯¼å…¥ subprocess æ¨¡å—ä»¥è¿è¡Œå¤–éƒ¨å‘½ä»¤\n",
    "import pandas as pd # å¯¼å…¥ pandas æ¨¡å—ï¼Œé€šå¸¸ç”¨äºæ•°æ®å¤„ç†ï¼Œè¿™é‡Œç”¨äºåˆ›å»ºè¡¨æ ¼\n",
    "import shutil # å¯¼å…¥ shutil æ¨¡å—ä»¥è·å–ç£ç›˜ç©ºé—´ä¿¡æ¯\n",
    "\n",
    "# è·å– CPU ä¿¡æ¯çš„å‡½æ•°ï¼ŒåŒ…æ‹¬æ ¸å¿ƒæ•°é‡\n",
    "def get_cpu_info():\n",
    "    cpu_info = \"\" # åˆå§‹åŒ– CPU ä¿¡æ¯å­—ç¬¦ä¸²\n",
    "    physical_cores = \"N/A\"\n",
    "    logical_cores = \"N/A\"\n",
    "\n",
    "    if platform.system() == \"Windows\": # å¦‚æœæ˜¯ Windows ç³»ç»Ÿ\n",
    "        cpu_info = platform.processor() # ä½¿ç”¨ platform.processor() è·å– CPU ä¿¡æ¯\n",
    "        try:\n",
    "            # è·å– Windows ä¸Šçš„æ ¸å¿ƒæ•°é‡ (éœ€è¦ WMI)\n",
    "            import wmi\n",
    "            c = wmi.WMI()\n",
    "            for proc in c.Win32_Processor():\n",
    "                physical_cores = proc.NumberOfCores\n",
    "                logical_cores = proc.NumberOfLogicalProcessors\n",
    "        except:\n",
    "            pass # å¦‚æœ WMI ä¸å¯ç”¨ï¼Œå¿½ç•¥é”™è¯¯\n",
    "\n",
    "    elif platform.system() == \"Darwin\": # å¦‚æœæ˜¯ macOS ç³»ç»Ÿ\n",
    "        # åœ¨ macOS ä¸Šä½¿ç”¨ sysctl å‘½ä»¤è·å– CPU ä¿¡æ¯å’Œæ ¸å¿ƒæ•°é‡\n",
    "        os.environ['PATH'] = os.environ['PATH'] + os.pathsep + '/usr/sbin' # æ›´æ–° PATH ç¯å¢ƒå˜é‡\n",
    "        try:\n",
    "            process_brand = subprocess.Popen(['sysctl', \"machdep.cpu.brand_string\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_brand, stderr_brand = process_brand.communicate()\n",
    "            cpu_info = stdout_brand.decode().split(': ')[1].strip() if stdout_brand else \"Could not retrieve CPU info\"\n",
    "\n",
    "            process_physical = subprocess.Popen(['sysctl', \"hw.physicalcpu\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_physical, stderr_physical = process_physical.communicate()\n",
    "            physical_cores = stdout_physical.decode().split(': ')[1].strip() if stdout_physical else \"N/A\"\n",
    "\n",
    "            process_logical = subprocess.Popen(['sysctl', \"hw.logicalcpu\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_logical, stderr_logical = process_logical.communicate()\n",
    "            logical_cores = stdout_logical.decode().split(': ')[1].strip() if stdout_logical else \"N/A\"\n",
    "\n",
    "        except:\n",
    "            cpu_info = \"Could not retrieve CPU info\"\n",
    "            physical_cores = \"N/A\"\n",
    "            logical_cores = \"N/A\"\n",
    "\n",
    "    else:  # Linux ç³»ç»Ÿ\n",
    "        try:\n",
    "            # åœ¨ Linux ä¸Šè¯»å– /proc/cpuinfo æ–‡ä»¶è·å– CPU ä¿¡æ¯å’Œæ ¸å¿ƒæ•°é‡\n",
    "            with open('/proc/cpuinfo') as f:\n",
    "                physical_cores_count = 0\n",
    "                logical_cores_count = 0\n",
    "                cpu_info_lines = []\n",
    "                for line in f:\n",
    "                    if line.startswith('model name'): # æŸ¥æ‰¾ä»¥ 'model name'å¼€å¤´çš„è¡Œ\n",
    "                        if not cpu_info: # åªè·å–ç¬¬ä¸€ä¸ª model name\n",
    "                            cpu_info = line.split(': ')[1].strip()\n",
    "                    elif line.startswith('cpu cores'): # æŸ¥æ‰¾ä»¥ 'cpu cores' å¼€å¤´çš„è¡Œ\n",
    "                        physical_cores_count = int(line.split(': ')[1].strip())\n",
    "                    elif line.startswith('processor'): # æŸ¥æ‰¾ä»¥ 'processor' å¼€å¤´çš„è¡Œ\n",
    "                        logical_cores_count += 1\n",
    "                physical_cores = str(physical_cores_count) if physical_cores_count > 0 else \"N/A\"\n",
    "                logical_cores = str(logical_cores_count) if logical_cores_count > 0 else \"N/A\"\n",
    "                if not cpu_info:\n",
    "                     cpu_info = \"Could not retrieve CPU info\"\n",
    "\n",
    "        except:\n",
    "            cpu_info = \"Could not retrieve CPU info\"\n",
    "            physical_cores = \"N/A\"\n",
    "            logical_cores = \"N/A\"\n",
    "\n",
    "    return f\"{cpu_info} ({physical_cores} physical cores, {logical_cores} logical cores)\" # è¿”å› CPU ä¿¡æ¯å’Œæ ¸å¿ƒæ•°é‡\n",
    "\n",
    "\n",
    "# è·å–å†…å­˜ä¿¡æ¯çš„å‡½æ•°\n",
    "def get_memory_info():\n",
    "    mem_info = \"\" # åˆå§‹åŒ–å†…å­˜ä¿¡æ¯å­—ç¬¦ä¸²\n",
    "    if platform.system() == \"Windows\":\n",
    "        # åœ¨ Windows ä¸Šä¸å®¹æ˜“é€šè¿‡æ ‡å‡†åº“è·å–ï¼Œéœ€è¦å¤–éƒ¨åº“æˆ– PowerShell\n",
    "        mem_info = \"Requires external tools on Windows\" # è®¾ç½®æç¤ºä¿¡æ¯\n",
    "    elif platform.system() == \"Darwin\": # å¦‚æœæ˜¯ macOS ç³»ç»Ÿ\n",
    "        # åœ¨ macOS ä¸Šä½¿ç”¨ sysctl å‘½ä»¤è·å–å†…å­˜å¤§å°\n",
    "        process = subprocess.Popen(['sysctl', \"hw.memsize\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE) # è¿è¡Œ sysctl å‘½ä»¤\n",
    "        stdout, stderr = process.communicate() # è·å–æ ‡å‡†è¾“å‡ºå’Œæ ‡å‡†é”™è¯¯\n",
    "        mem_bytes = int(stdout.decode().split(': ')[1].strip()) # è§£æè¾“å‡ºï¼Œè·å–å†…å­˜å¤§å°ï¼ˆå­—èŠ‚ï¼‰\n",
    "        mem_gb = mem_bytes / (1024**3) # è½¬æ¢ä¸º GB\n",
    "        mem_info = f\"{mem_gb:.2f} GB\" # æ ¼å¼åŒ–è¾“å‡º\n",
    "    else:  # Linux ç³»ç»Ÿ\n",
    "        try:\n",
    "            # åœ¨ Linux ä¸Šè¯»å– /proc/meminfo æ–‡ä»¶è·å–å†…å­˜ä¿¡æ¯\n",
    "            with open('/proc/meminfo') as f:\n",
    "                total_mem_kb = 0\n",
    "                available_mem_kb = 0\n",
    "                for line in f:\n",
    "                    if line.startswith('MemTotal'): # æŸ¥æ‰¾ä»¥ 'MemTotal' å¼€å¤´çš„è¡Œ\n",
    "                        total_mem_kb = int(line.split(':')[1].strip().split()[0]) # è§£æè¡Œï¼Œè·å–æ€»å†…å­˜ï¼ˆKBï¼‰\n",
    "                    elif line.startswith('MemAvailable'): # æŸ¥æ‰¾ä»¥ 'MemAvailable' å¼€å¤´çš„è¡Œ\n",
    "                         available_mem_kb = int(line.split(':')[1].strip().split()[0]) # è§£æè¡Œï¼Œè·å–å¯ç”¨å†…å­˜ï¼ˆKBï¼‰\n",
    "\n",
    "                if total_mem_kb > 0:\n",
    "                    total_mem_gb = total_mem_kb / (1024**2) # è½¬æ¢ä¸º GB\n",
    "                    mem_info = f\"{total_mem_gb:.2f} GB\" # æ ¼å¼åŒ–è¾“å‡ºæ€»å†…å­˜\n",
    "                    if available_mem_kb > 0:\n",
    "                        available_mem_gb = available_mem_kb / (1024**2)\n",
    "                        mem_info += f\" (Available: {available_mem_gb:.2f} GB)\" # æ·»åŠ å¯ç”¨å†…å­˜ä¿¡æ¯\n",
    "                else:\n",
    "                     mem_info = \"Could not retrieve memory info\" # å¦‚æœè¯»å–æ–‡ä»¶å‡ºé”™ï¼Œè®¾ç½®é”™è¯¯ä¿¡æ¯\n",
    "\n",
    "        except:\n",
    "            mem_info = \"Could not retrieve memory info\" # å¦‚æœè¯»å–æ–‡ä»¶å‡ºé”™ï¼Œè®¾ç½®é”™è¯¯ä¿¡æ¯\n",
    "    return mem_info # è¿”å›å†…å­˜ä¿¡æ¯\n",
    "\n",
    "# è·å– GPU ä¿¡æ¯çš„å‡½æ•°ï¼ŒåŒ…æ‹¬æ˜¾å­˜\n",
    "def get_gpu_info():\n",
    "    try:\n",
    "        # å°è¯•ä½¿ç”¨ nvidia-smi è·å– NVIDIA GPU ä¿¡æ¯å’Œæ˜¾å­˜\n",
    "        result = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total', '--format=csv,noheader'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # å¦‚æœå‘½ä»¤æˆåŠŸæ‰§è¡Œ\n",
    "            gpu_lines = result.stdout.strip().split('\\n') # è§£æè¾“å‡ºï¼Œè·å– GPU åç§°å’Œæ˜¾å­˜\n",
    "            gpu_info_list = []\n",
    "            for line in gpu_lines:\n",
    "                name, memory = line.split(', ')\n",
    "                gpu_info_list.append(f\"{name} ({memory})\") # æ ¼å¼åŒ– GPU ä¿¡æ¯\n",
    "            return \", \".join(gpu_info_list) if gpu_info_list else \"NVIDIA GPU found, but info not listed\" # è¿”å› GPU ä¿¡æ¯æˆ–æç¤ºä¿¡æ¯\n",
    "        else:\n",
    "             # å°è¯•ä½¿ç”¨ lshw è·å–å…¶ä»– GPU ä¿¡æ¯ (éœ€è¦å®‰è£… lshw)\n",
    "            try:\n",
    "                result_lshw = subprocess.run(['lshw', '-C', 'display'], capture_output=True, text=True)\n",
    "                if result_lshw.returncode == 0: # å¦‚æœå‘½ä»¤æˆåŠŸæ‰§è¡Œ\n",
    "                     # ç®€å•è§£æè¾“å‡ºä¸­çš„ product åç§°å’Œæ˜¾å­˜\n",
    "                    gpu_info_lines = []\n",
    "                    current_gpu = {}\n",
    "                    for line in result_lshw.stdout.splitlines():\n",
    "                        if 'product:' in line:\n",
    "                             if current_gpu:\n",
    "                                 gpu_info_lines.append(f\"{current_gpu.get('product', 'GPU')} ({current_gpu.get('memory', 'N/A')})\")\n",
    "                             current_gpu = {'product': line.split('product:')[1].strip()}\n",
    "                        elif 'size:' in line and 'memory' in line:\n",
    "                             current_gpu['memory'] = line.split('size:')[1].strip()\n",
    "\n",
    "                    if current_gpu: # æ·»åŠ æœ€åä¸€ä¸ª GPU çš„ä¿¡æ¯\n",
    "                        gpu_info_lines.append(f\"{current_gpu.get('product', 'GPU')} ({current_gpu.get('memory', 'N/A')})\")\n",
    "\n",
    "                    return \", \".join(gpu_info_lines) if gpu_info_lines else \"GPU found (via lshw), but info not parsed\" # å¦‚æœæ‰¾åˆ° GPU ä½†ä¿¡æ¯æ— æ³•è§£æï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "                else:\n",
    "                    return \"No GPU found (checked nvidia-smi and lshw)\" # å¦‚æœä¸¤ä¸ªå‘½ä»¤éƒ½æ‰¾ä¸åˆ° GPUï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "            except FileNotFoundError:\n",
    "                 return \"No GPU found (checked nvidia-smi, lshw not found)\" # å¦‚æœæ‰¾ä¸åˆ° lshw å‘½ä»¤ï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "    except FileNotFoundError:\n",
    "        return \"No GPU found (nvidia-smi not found)\" # å¦‚æœæ‰¾ä¸åˆ° nvidia-smi å‘½ä»¤ï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "\n",
    "\n",
    "# è·å– CUDA ç‰ˆæœ¬çš„å‡½æ•°\n",
    "def get_cuda_version():\n",
    "    try:\n",
    "        # å°è¯•ä½¿ç”¨ nvcc --version è·å– CUDA ç‰ˆæœ¬\n",
    "        result = subprocess.run(['nvcc', '--version'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # å¦‚æœå‘½ä»¤æˆåŠŸæ‰§è¡Œ\n",
    "            for line in result.stdout.splitlines():\n",
    "                if 'release' in line: # æŸ¥æ‰¾åŒ…å« 'release' çš„è¡Œ\n",
    "                    return line.split('release ')[1].split(',')[0] # è§£æè¡Œï¼Œæå–ç‰ˆæœ¬å·\n",
    "        return \"CUDA not found or version not parsed\" # å¦‚æœæ‰¾ä¸åˆ° CUDA æˆ–ç‰ˆæœ¬æ— æ³•è§£æï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "    except FileNotFoundError:\n",
    "        return \"CUDA not found\" # å¦‚æœæ‰¾ä¸åˆ° nvcc å‘½ä»¤ï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "\n",
    "# è·å– Python ç‰ˆæœ¬çš„å‡½æ•°\n",
    "def get_python_version():\n",
    "    return platform.python_version() # è·å– Python ç‰ˆæœ¬\n",
    "\n",
    "# è·å– Conda ç‰ˆæœ¬çš„å‡½æ•°\n",
    "def get_conda_version():\n",
    "    try:\n",
    "        # å°è¯•ä½¿ç”¨ conda --version è·å– Conda ç‰ˆæœ¬\n",
    "        result = subprocess.run(['conda', '--version'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # å¦‚æœå‘½ä»¤æˆåŠŸæ‰§è¡Œ\n",
    "            return result.stdout.strip() # è¿”å› Conda ç‰ˆæœ¬\n",
    "        return \"Conda not found or version not parsed\" # å¦‚æœæ‰¾ä¸åˆ° Conda æˆ–ç‰ˆæœ¬æ— æ³•è§£æï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "    except FileNotFoundError:\n",
    "        return \"Conda not found\" # å¦‚æœæ‰¾ä¸åˆ° conda å‘½ä»¤ï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "\n",
    "# è·å–ç‰©ç†ç£ç›˜ç©ºé—´ä¿¡æ¯çš„å‡½æ•°\n",
    "def get_disk_space():\n",
    "    try:\n",
    "        total, used, free = shutil.disk_usage(\"/\") # è·å–æ ¹ç›®å½•çš„ç£ç›˜ä½¿ç”¨æƒ…å†µ\n",
    "        total_gb = total / (1024**3) # è½¬æ¢ä¸º GB\n",
    "        used_gb = used / (1024**3) # è½¬æ¢ä¸º GB\n",
    "        free_gb = free / (1024**3) # è½¬æ¢ä¸º GB\n",
    "        return f\"Total: {total_gb:.2f} GB, Used: {used_gb:.2f} GB, Free: {free_gb:.2f} GB\" # æ ¼å¼åŒ–è¾“å‡º\n",
    "    except Exception as e:\n",
    "        return f\"Could not retrieve disk info: {e}\" # å¦‚æœè·å–ä¿¡æ¯å‡ºé”™ï¼Œè®¾ç½®é”™è¯¯ä¿¡æ¯\n",
    "\n",
    "# è·å–ç¯å¢ƒä¿¡æ¯\n",
    "os_name = platform.system() # è·å–æ“ä½œç³»ç»Ÿåç§°\n",
    "os_version = platform.release() # è·å–æ“ä½œç³»ç»Ÿç‰ˆæœ¬\n",
    "if os_name == \"Linux\":\n",
    "    try:\n",
    "        # åœ¨ Linux ä¸Šå°è¯•è·å–å‘è¡Œç‰ˆå’Œç‰ˆæœ¬\n",
    "        lsb_info = subprocess.run(['lsb_release', '-a'], capture_output=True, text=True)\n",
    "        if lsb_info.returncode == 0: # å¦‚æœå‘½ä»¤æˆåŠŸæ‰§è¡Œ\n",
    "            for line in lsb_info.stdout.splitlines():\n",
    "                if 'Description:' in line: # æŸ¥æ‰¾åŒ…å« 'Description:' çš„è¡Œ\n",
    "                    os_version = line.split('Description:')[1].strip() # æå–æè¿°ä¿¡æ¯ä½œä¸ºç‰ˆæœ¬\n",
    "                    break # æ‰¾åˆ°åé€€å‡ºå¾ªç¯\n",
    "                elif 'Release:' in line: # æŸ¥æ‰¾åŒ…å« 'Release:' çš„è¡Œ\n",
    "                     os_version = line.split('Release:')[1].strip() # æå–ç‰ˆæœ¬å·\n",
    "                     # å°è¯•è·å– codename\n",
    "                     try:\n",
    "                         codename_info = subprocess.run(['lsb_release', '-c'], capture_output=True, text=True)\n",
    "                         if codename_info.returncode == 0:\n",
    "                             os_version += f\" ({codename_info.stdout.split(':')[1].strip()})\" # å°† codename æ·»åŠ åˆ°ç‰ˆæœ¬ä¿¡æ¯ä¸­\n",
    "                     except:\n",
    "                         pass # å¦‚æœè·å– codename å¤±è´¥åˆ™å¿½ç•¥\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        pass # lsb_release å¯èƒ½æœªå®‰è£…ï¼Œå¿½ç•¥é”™è¯¯\n",
    "\n",
    "full_os_info = f\"{os_name} {os_version}\" # ç»„åˆå®Œæ•´çš„æ“ä½œç³»ç»Ÿä¿¡æ¯\n",
    "cpu_info = get_cpu_info() # è°ƒç”¨å‡½æ•°è·å– CPU ä¿¡æ¯å’Œæ ¸å¿ƒæ•°é‡\n",
    "memory_info = get_memory_info() # è°ƒç”¨å‡½æ•°è·å–å†…å­˜ä¿¡æ¯\n",
    "gpu_info = get_gpu_info() # è°ƒç”¨å‡½æ•°è·å– GPU ä¿¡æ¯å’Œæ˜¾å­˜\n",
    "cuda_version = get_cuda_version() # è°ƒç”¨å‡½æ•°è·å– CUDA ç‰ˆæœ¬\n",
    "python_version = get_python_version() # è°ƒç”¨å‡½æ•°è·å– Python ç‰ˆæœ¬\n",
    "conda_version = get_conda_version() # è°ƒç”¨å‡½æ•°è·å– Conda ç‰ˆæœ¬\n",
    "disk_info = get_disk_space() # è°ƒç”¨å‡½æ•°è·å–ç‰©ç†ç£ç›˜ç©ºé—´ä¿¡æ¯\n",
    "\n",
    "\n",
    "# åˆ›å»ºç”¨äºå­˜å‚¨æ•°æ®çš„å­—å…¸\n",
    "env_data = {\n",
    "    \"é¡¹ç›®\": [ # é¡¹ç›®åç§°åˆ—è¡¨\n",
    "        \"æ“ä½œç³»ç»Ÿ\",\n",
    "        \"CPU ä¿¡æ¯\",\n",
    "        \"å†…å­˜ä¿¡æ¯\",\n",
    "        \"GPU ä¿¡æ¯\",\n",
    "        \"CUDA ä¿¡æ¯\",\n",
    "        \"Python ç‰ˆæœ¬\",\n",
    "        \"Conda ç‰ˆæœ¬\",\n",
    "        \"ç‰©ç†ç£ç›˜ç©ºé—´\" # æ·»åŠ ç‰©ç†ç£ç›˜ç©ºé—´\n",
    "    ],\n",
    "    \"ä¿¡æ¯\": [ # å¯¹åº”çš„ä¿¡æ¯åˆ—è¡¨\n",
    "        full_os_info,\n",
    "        cpu_info,\n",
    "        memory_info,\n",
    "        gpu_info,\n",
    "        cuda_version,\n",
    "        python_version,\n",
    "        conda_version,\n",
    "        disk_info # æ·»åŠ ç‰©ç†ç£ç›˜ç©ºé—´ä¿¡æ¯\n",
    "    ]\n",
    "}\n",
    "\n",
    "# åˆ›å»ºä¸€ä¸ª pandas DataFrame\n",
    "df = pd.DataFrame(env_data)\n",
    "\n",
    "# æ‰“å°è¡¨æ ¼\n",
    "print(\"### ç¯å¢ƒä¿¡æ¯\") # æ‰“å°æ ‡é¢˜\n",
    "print(df.to_markdown(index=False)) # å°† DataFrame è½¬æ¢ä¸º Markdown æ ¼å¼å¹¶æ‰“å°ï¼Œä¸åŒ…å«ç´¢å¼•\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ki7E44X5ViQB"
   },
   "source": [
    "# OpenAI SDKé›†æˆLangfuseè·å¾—å®Œæ•´çš„å¯è§‚æµ‹æ€§\n",
    "---\n",
    "\n",
    "## ğŸ“š ä»€ä¹ˆæ˜¯å¤§æ¨¡å‹å¯è§‚æµ‹æ€§ï¼Ÿ\n",
    "\n",
    "**å¯è§‚æµ‹æ€§ï¼ˆObservabilityï¼‰** æ˜¯ç›‘æ§å’Œè°ƒè¯•å¤§è¯­è¨€æ¨¡å‹åº”ç”¨çš„å…³é”®æŠ€æœ¯ã€‚æƒ³è±¡ä¸€ä¸‹ï¼Œå½“ä½ çš„AIåº”ç”¨åœ¨ç”Ÿäº§ç¯å¢ƒä¸­è¿è¡Œæ—¶ï¼Œä½ éœ€è¦çŸ¥é“ï¼š\n",
    "\n",
    "- ğŸ¤” **æ¨¡å‹å›ç­”äº†ä»€ä¹ˆï¼Ÿ** - æŸ¥çœ‹æ¯æ¬¡å¯¹è¯çš„å®Œæ•´å†…å®¹\n",
    "- â±ï¸ **å“åº”é€Ÿåº¦å¦‚ä½•ï¼Ÿ** - ç›‘æ§å»¶è¿Ÿå’Œæ€§èƒ½æŒ‡æ ‡  \n",
    "- ğŸ’° **èŠ±è´¹äº†å¤šå°‘ï¼Ÿ** - è·Ÿè¸ªTokenä½¿ç”¨å’Œæˆæœ¬\n",
    "- ğŸ› **å“ªé‡Œå‡ºé”™äº†ï¼Ÿ** - å¿«é€Ÿå®šä½å’Œè§£å†³é—®é¢˜\n",
    "- ğŸ“Š **æ•ˆæœæ€ä¹ˆæ ·ï¼Ÿ** - è¯„ä¼°æ¨¡å‹å›ç­”è´¨é‡\n",
    "\n",
    "**Langfuse** å°±æ˜¯ä¸€ä¸ªä¸“é—¨ä¸ºå¤§æ¨¡å‹åº”ç”¨è®¾è®¡çš„å¯è§‚æµ‹æ€§å¹³å°ï¼Œå®ƒèƒ½å¤Ÿï¼š\n",
    "- è‡ªåŠ¨è®°å½•æ‰€æœ‰APIè°ƒç”¨\n",
    "- æä¾›ç›´è§‚çš„å¯è§†åŒ–ç•Œé¢\n",
    "- æ”¯æŒè¯„åˆ†å’Œè¯„ä¼°\n",
    "- å¸®åŠ©ä¼˜åŒ–æ¨¡å‹æ€§èƒ½\n",
    "\n",
    "## ğŸ¯ æœ¬æ•™ç¨‹å°†æ•™ä¼šä½ ä»€ä¹ˆï¼Ÿ\n",
    "\n",
    "1. **åŸºç¡€é›†æˆ** - å¦‚ä½•ç”¨å‡ è¡Œä»£ç é›†æˆLangfuse\n",
    "2. **å¤šç§è°ƒç”¨æ–¹å¼** - æ–‡æœ¬ã€å›¾åƒã€æµå¼ã€å¼‚æ­¥è°ƒç”¨\n",
    "3. **é«˜çº§åŠŸèƒ½** - å‡½æ•°è°ƒç”¨ã€è¯„åˆ†ç³»ç»Ÿã€é“¾è·¯è¿½è¸ª\n",
    "4. **ä¼˜ç§€åšæ³•** - ç”Ÿäº§ç¯å¢ƒä¸­çš„ä½¿ç”¨æŠ€å·§\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mfMAzJYcirtK"
   },
   "source": [
    "# ğŸš€ ç¤ºä¾‹æ‰‹å†Œï¼šOpenAI é›†æˆï¼ˆPythonï¼‰\n",
    "\n",
    "## ä¸ºä»€ä¹ˆéœ€è¦è¿™ä¸ªæ•™ç¨‹ï¼Ÿ\n",
    "\n",
    "ä½œä¸ºå¤§æ¨¡å‹æŠ€æœ¯åˆå­¦è€…ï¼Œä½ å¯èƒ½é‡åˆ°è¿‡è¿™äº›é—®é¢˜ï¼š\n",
    "- ä¸çŸ¥é“æ¨¡å‹åˆ°åº•è¾“å‡ºäº†ä»€ä¹ˆ\n",
    "- æ— æ³•è¿½è¸ªAPIè°ƒç”¨çš„æˆæœ¬\n",
    "- è°ƒè¯•é—®é¢˜æ—¶æ‰¾ä¸åˆ°å†å²è®°å½•\n",
    "- ä¸çŸ¥é“å¦‚ä½•è¯„ä¼°æ¨¡å‹æ•ˆæœ\n",
    "\n",
    "**è¿™ä¸ªæ•™ç¨‹å°†å½»åº•è§£å†³è¿™äº›é—®é¢˜ï¼** é€šè¿‡ç®€å•çš„ä»£ç ä¿®æ”¹ï¼Œä½ å°±èƒ½è·å¾—ä¼ä¸šçº§çš„å¯è§‚æµ‹æ€§èƒ½åŠ›ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B0A389k2irtK"
   },
   "source": [
    "## ğŸ“– æ•™ç¨‹æ¦‚è¿°\n",
    "\n",
    "è¿™æ˜¯ä¸€ä¸ª**é›¶åŸºç¡€å‹å¥½**çš„ç¤ºä¾‹æ‰‹å†Œï¼Œæ¼”ç¤ºå¦‚ä½•åœ¨ Python é¡¹ç›®ä¸­é›†æˆ Langfuse ä¸ OpenAIã€‚\n",
    "\n",
    "### ğŸ” Langfuse èƒ½ä¸ºä½ åšä»€ä¹ˆï¼Ÿ\n",
    "\n",
    "**Langfuse ä¼šè®°å½•æ¯æ¬¡æ¨¡å‹è°ƒç”¨çš„è¾“å…¥è¾“å‡º**ï¼Œå°±åƒç»™ä½ çš„AIåº”ç”¨è£…ä¸Šäº†\"é»‘åŒ£å­\"ï¼š\n",
    "\n",
    "1. **ğŸ“ å®Œæ•´è®°å½•** - ä¿å­˜æ¯æ¬¡å¯¹è¯çš„å®Œæ•´ä¸Šä¸‹æ–‡\n",
    "2. **ğŸ” é—®é¢˜æ’æŸ¥** - å¿«é€Ÿå®šä½é”™è¯¯å’Œå¼‚å¸¸\n",
    "3. **ğŸ“Š è´¨é‡è¯„ä¼°** - é€šè¿‡è¯„åˆ†ç³»ç»Ÿè¯„ä¼°æ¨¡å‹æ•ˆæœ\n",
    "4. **ğŸ’° æˆæœ¬æ§åˆ¶** - ç›‘æ§Tokenä½¿ç”¨å’ŒAPIè´¹ç”¨\n",
    "5. **ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–** - åˆ†æå“åº”æ—¶é—´å’Œååé‡\n",
    "\n",
    "### ğŸ¯ å­¦ä¹ ç›®æ ‡\n",
    "\n",
    "å®Œæˆæœ¬æ•™ç¨‹åï¼Œä½ å°†æŒæ¡ï¼š\n",
    "- âœ… å¦‚ä½•å®‰è£…å’Œé…ç½®Langfuse\n",
    "- âœ… å¦‚ä½•æ›¿æ¢OpenAI SDKå®ç°è‡ªåŠ¨è¿½è¸ª\n",
    "- âœ… å¦‚ä½•æŸ¥çœ‹å’Œåˆ†æè¿½è¸ªæ•°æ®\n",
    "- âœ… å¦‚ä½•æ·»åŠ è‡ªå®šä¹‰å…ƒæ•°æ®å’Œè¯„åˆ†\n",
    "- âœ… å¦‚ä½•åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ä½¿ç”¨\n",
    "\n",
    "æŒ‰ç…§ [é›†æˆæŒ‡å—](https://langfuse.com/integrations/model-providers/openai-py) å°†æœ¬é›†æˆæ·»åŠ åˆ°ä½ çš„ OpenAI é¡¹ç›®ä¸­ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uq04G_FSWjF-"
   },
   "source": [
    "## ğŸ› ï¸ ç¯å¢ƒå‡†å¤‡\n",
    "\n",
    "### å‰ç½®çŸ¥è¯†è¦æ±‚\n",
    "\n",
    "åœ¨å¼€å§‹ä¹‹å‰ï¼Œä½ éœ€è¦äº†è§£ä¸€äº›åŸºç¡€æ¦‚å¿µï¼š\n",
    "\n",
    "- **PythonåŸºç¡€** - å˜é‡ã€å‡½æ•°ã€ç±»çš„åŸºæœ¬ä½¿ç”¨\n",
    "- **APIè°ƒç”¨** - äº†è§£HTTPè¯·æ±‚å’Œå“åº”\n",
    "- **ç¯å¢ƒå˜é‡** - å¦‚ä½•å®‰å…¨åœ°å­˜å‚¨æ•æ„Ÿä¿¡æ¯\n",
    "- **Jupyter Notebook** - åŸºæœ¬çš„notebookæ“ä½œ\n",
    "\n",
    "### ç³»ç»Ÿè¦æ±‚\n",
    "\n",
    "- Python 3.10+\n",
    "- ç¨³å®šçš„ç½‘ç»œè¿æ¥\n",
    "- OpenAI APIå¯†é’¥\n",
    "- Langfuseè´¦æˆ·ï¼ˆå…è´¹æ³¨å†Œï¼‰\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XYoil3FcOIQt"
   },
   "source": [
    "### ğŸ“¦ ä¾èµ–åŒ…ç‰ˆæœ¬è¯´æ˜\n",
    "\n",
    "**é‡è¦ç‰ˆæœ¬è¦æ±‚ï¼š**\n",
    "- **OpenAI SDK** `>=0.27.8` - åŸºç¡€åŠŸèƒ½æ”¯æŒ\n",
    "- **OpenAI SDK** `>=1.0.0` - å¼‚æ­¥å‡½æ•°å’Œæµå¼è¾“å‡ºæ”¯æŒï¼ˆæ¨èï¼‰\n",
    "\n",
    "**ä¸ºä»€ä¹ˆéœ€è¦ç‰¹å®šç‰ˆæœ¬ï¼Ÿ**\n",
    "- æ—§ç‰ˆæœ¬å¯èƒ½ç¼ºå°‘æŸäº›åŠŸèƒ½\n",
    "- æ–°ç‰ˆæœ¬æœ‰æ›´å¥½çš„æ€§èƒ½å’Œç¨³å®šæ€§\n",
    "- æµå¼è¾“å‡ºéœ€è¦è¾ƒæ–°çš„SDKæ”¯æŒ\n",
    "\n",
    "**åˆå­¦è€…æç¤ºï¼š** å¦‚æœä½ ä¸ç¡®å®šå½“å‰ç‰ˆæœ¬ï¼Œç›´æ¥å®‰è£…æœ€æ–°ç‰ˆæœ¬å³å¯ï¼\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hVOOiBtUPtOO",
    "outputId": "2d9a4742-d70e-4cbf-c7fe-63a25dad2bcf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: langfuse==3.3.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (3.3.0)\n",
      "Requirement already satisfied: openai==1.107.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (1.107.0)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langfuse==3.3.0) (2.2.1)\n",
      "Requirement already satisfied: httpx<1.0,>=0.15.4 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langfuse==3.3.0) (0.28.1)\n",
      "Requirement already satisfied: opentelemetry-api<2.0.0,>=1.33.1 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langfuse==3.3.0) (1.38.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langfuse==3.3.0) (1.38.0)\n",
      "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.33.1 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langfuse==3.3.0) (1.38.0)\n",
      "Requirement already satisfied: packaging<26.0,>=23.2 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langfuse==3.3.0) (25.0)\n",
      "Requirement already satisfied: pydantic<3.0,>=1.10.7 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langfuse==3.3.0) (2.11.9)\n",
      "Requirement already satisfied: requests<3,>=2 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langfuse==3.3.0) (2.32.5)\n",
      "Requirement already satisfied: wrapt<2.0,>=1.14 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langfuse==3.3.0) (1.17.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from openai==1.107.0) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from openai==1.107.0) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from openai==1.107.0) (0.11.0)\n",
      "Requirement already satisfied: sniffio in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from openai==1.107.0) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from openai==1.107.0) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from openai==1.107.0) (4.14.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai==1.107.0) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai==1.107.0) (3.10)\n",
      "Requirement already satisfied: certifi in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from httpx<1.0,>=0.15.4->langfuse==3.3.0) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from httpx<1.0,>=0.15.4->langfuse==3.3.0) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from httpcore==1.*->httpx<1.0,>=0.15.4->langfuse==3.3.0) (0.16.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from opentelemetry-api<2.0.0,>=1.33.1->langfuse==3.3.0) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api<2.0.0,>=1.33.1->langfuse==3.3.0) (3.23.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0) (1.70.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.38.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0) (1.38.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.38.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0) (1.38.0)\n",
      "Requirement already satisfied: protobuf<7.0,>=5.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from opentelemetry-proto==1.38.0->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0) (5.29.5)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.59b0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from opentelemetry-sdk<2.0.0,>=1.33.1->langfuse==3.3.0) (0.59b0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from pydantic<3.0,>=1.10.7->langfuse==3.3.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from pydantic<3.0,>=1.10.7->langfuse==3.3.0) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from pydantic<3.0,>=1.10.7->langfuse==3.3.0) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from requests<3,>=2->langfuse==3.3.0) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from requests<3,>=2->langfuse==3.3.0) (2.5.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“¥ å®‰è£…å¿…è¦çš„ä¾èµ–åŒ…\n",
    "# è¿™ä¸ªå‘½ä»¤ä¼šå®‰è£…ä¸¤ä¸ªæ ¸å¿ƒåŒ…ï¼š\n",
    "# 1. langfuse - å¯è§‚æµ‹æ€§å¹³å°çš„æ ¸å¿ƒåº“\n",
    "# 2. openai - OpenAIå®˜æ–¹SDK\n",
    "\n",
    "%pip install langfuse==3.3.0 openai==1.107.0\n",
    "\n",
    "# ğŸ’¡ åˆå­¦è€…æç¤ºï¼š\n",
    "# - %pip æ˜¯Jupyter Notebookçš„é­”æ³•å‘½ä»¤ï¼Œç”¨äºå®‰è£…PythonåŒ…\n",
    "# - == æŒ‡å®šäº†ç¡®åˆ‡çš„ç‰ˆæœ¬å·ï¼Œç¡®ä¿ç¯å¢ƒä¸€è‡´æ€§\n",
    "# - å¦‚æœå®‰è£…å¤±è´¥ï¼Œæ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–å°è¯•ä½¿ç”¨å›½å†…é•œåƒæº"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K72KpSE2OiJY",
    "outputId": "e137b755-2a4e-4db8-fc97-d8da6754b1aa"
   },
   "outputs": [],
   "source": [
    "# ğŸ” ç¯å¢ƒå˜é‡é…ç½® - å®‰å…¨å­˜å‚¨æ•æ„Ÿä¿¡æ¯\n",
    "# ç¯å¢ƒå˜é‡æ˜¯å­˜å‚¨APIå¯†é’¥ç­‰æ•æ„Ÿä¿¡æ¯çš„ä¼˜ç§€åšæ³•\n",
    "# é¿å…åœ¨ä»£ç ä¸­ç¡¬ç¼–ç å¯†é’¥ï¼Œé˜²æ­¢æ³„éœ²\n",
    "\n",
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    \"\"\"\n",
    "    å®‰å…¨åœ°è®¾ç½®ç¯å¢ƒå˜é‡\n",
    "    å¦‚æœç¯å¢ƒå˜é‡ä¸å­˜åœ¨ï¼Œä¼šæç¤ºç”¨æˆ·è¾“å…¥\n",
    "    ä½¿ç”¨getpassæ¨¡å—éšè—è¾“å…¥å†…å®¹ï¼Œé˜²æ­¢å¯†ç æ³„éœ²\n",
    "    \"\"\"\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "# ğŸ¤– OpenAI API é…ç½®\n",
    "# OpenAI APIå¯†é’¥ï¼šä» https://platform.openai.com/api-keys è·å–\n",
    "# è¿™æ˜¯è°ƒç”¨GPTæ¨¡å‹å¿…éœ€çš„è®¤è¯ä¿¡æ¯\n",
    "_set_env(\"OPENAI_API_KEY\")\n",
    "\n",
    "# APIä»£ç†åœ°å€ï¼šå¦‚æœä½ ä½¿ç”¨ç¬¬ä¸‰æ–¹ä»£ç†æœåŠ¡ï¼ˆå¦‚å›½å†…ä»£ç†ï¼‰\n",
    "# ç¤ºä¾‹ï¼šhttps://api.apiyi.com/v1\n",
    "# å¦‚æœç›´æ¥ä½¿ç”¨OpenAIå®˜æ–¹APIï¼Œå¯ä»¥ç•™ç©º\n",
    "_set_env(\"OPENAI_BASE_URL\")\n",
    "\n",
    "# # ğŸŒ Langfuse é…ç½®\n",
    "# Langfuseæ˜¯ä¸€ä¸ªå¯è§‚æµ‹æ€§å¹³å°ï¼Œéœ€è¦æ³¨å†Œè´¦æˆ·è·å–å¯†é’¥\n",
    "# æ³¨å†Œåœ°å€ï¼šhttps://cloud.langfuse.com\n",
    "\n",
    "# å…¬å¼€å¯†é’¥ï¼šç”¨äºæ ‡è¯†ä½ çš„é¡¹ç›®\n",
    "_set_env(\"LANGFUSE_PUBLIC_KEY\")\n",
    "\n",
    "# ç§˜å¯†å¯†é’¥ï¼šç”¨äºè®¤è¯ï¼Œè¯·å¦¥å–„ä¿ç®¡\n",
    "_set_env(\"LANGFUSE_SECRET_KEY\")\n",
    "\n",
    "#  è®¾ç½®åŸºç¡€ URL\n",
    "# ğŸ‡ªğŸ‡º æ¬§ç›ŸåŒºåŸŸ(æ¨è) https://cloud.langfuse.com\n",
    "# ğŸ‡ºğŸ‡¸ ç¾å›½åŒºåŸŸ https://us.cloud.langfuse.com\n",
    "# æœ¬åœ°æµ‹è¯•åœ°å€ï¼šhttp://192.168.172.128:3000\n",
    "_set_env(\"LANGFUSE_BASE_URL\")\n",
    "# å…¼å®¹è€ç‰ˆæœ¬çš„åŸºç¡€ URL\n",
    "_set_env(\"LANGFUSE_HOST\")\n",
    "\n",
    "# ğŸ’¡ åˆå­¦è€…æç¤ºï¼š\n",
    "# 1. ç¯å¢ƒå˜é‡å­˜å‚¨åœ¨æ“ä½œç³»ç»Ÿä¸­ï¼Œé‡å¯åéœ€è¦é‡æ–°è®¾ç½®\n",
    "# 2. ç”Ÿäº§ç¯å¢ƒä¸­å»ºè®®ä½¿ç”¨.envæ–‡ä»¶æˆ–äº‘æœåŠ¡é…ç½®\n",
    "# 3. æ°¸è¿œä¸è¦åœ¨ä»£ç ä¸­ç¡¬ç¼–ç APIå¯†é’¥ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ldSEJ0bAP4sj"
   },
   "outputs": [],
   "source": [
    "# ğŸ¯ æ ¸å¿ƒé›†æˆï¼šæ›¿æ¢OpenAI SDK\n",
    "# è¿™æ˜¯æ•´ä¸ªæ•™ç¨‹çš„æ ¸å¿ƒï¼åªéœ€è¦ä¸€è¡Œä»£ç çš„ä¿®æ”¹\n",
    "# åªéœ€æ›¿æ¢ import è¯­å¥ï¼Œå°±èƒ½ç”¨ Langfuse ç‰ˆæœ¬çš„ OpenAI SDK è·å¾—å®Œæ•´çš„å¯è§‚æµ‹æ€§\n",
    "\n",
    "# åŸæ¥çš„å¯¼å…¥æ–¹å¼ï¼š\n",
    "# from openai import OpenAI\n",
    "\n",
    "# æ–°çš„å¯¼å…¥æ–¹å¼ï¼ˆè‡ªåŠ¨é›†æˆLangfuseï¼‰ï¼š\n",
    "from langfuse.openai import openai\n",
    "\n",
    "# ğŸš€ é­”æ³•å°±åœ¨è¿™é‡Œï¼\n",
    "# Langfuseæä¾›äº†å¯¹åŸç”ŸOpenAI SDKçš„å®Œå…¨å…¼å®¹å°è£…\n",
    "# è¿™æ„å‘³ç€ï¼š\n",
    "# 1. âœ… ä½ çš„ç°æœ‰ä»£ç æ— éœ€ä¿®æ”¹\n",
    "# 2. âœ… è‡ªåŠ¨è®°å½•æ‰€æœ‰APIè°ƒç”¨\n",
    "# 3. âœ… ä¿æŒå®Œå…¨ç›¸åŒçš„æ¥å£\n",
    "# 4. âœ… é›¶å­¦ä¹ æˆæœ¬\n",
    "\n",
    "# ğŸ’¡ åˆå­¦è€…ç†è§£ï¼š\n",
    "# æƒ³è±¡ä¸€ä¸‹ï¼ŒLangfuseå°±åƒä¸€ä¸ª\"é€æ˜çš„ä¸­é—´å±‚\"\n",
    "# å®ƒæ‹¦æˆªä½ çš„OpenAIè°ƒç”¨ï¼Œè®°å½•æ•°æ®ï¼Œç„¶åè½¬å‘ç»™çœŸæ­£çš„OpenAI API\n",
    "# å¯¹ä½ æ¥è¯´ï¼Œä½¿ç”¨æ–¹å¼å®Œå…¨ä¸€æ ·ï¼Œä½†è·å¾—äº†å¼ºå¤§çš„å¯è§‚æµ‹æ€§èƒ½åŠ›\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ovnAAdbaLmD"
   },
   "source": [
    "## ğŸ¯ å®æˆ˜ç¤ºä¾‹\n",
    "\n",
    "ç°åœ¨è®©æˆ‘ä»¬é€šè¿‡å…·ä½“çš„ä»£ç ç¤ºä¾‹æ¥å­¦ä¹ å¦‚ä½•ä½¿ç”¨Langfuseï¼\n",
    "\n",
    "### ğŸ“ ç¤ºä¾‹1ï¼šæ–‡æœ¬èŠå¤©è¡¥å…¨\n",
    "\n",
    "**ä»€ä¹ˆæ˜¯èŠå¤©è¡¥å…¨ï¼Ÿ**\n",
    "èŠå¤©è¡¥å…¨æ˜¯GPTæ¨¡å‹çš„æ ¸å¿ƒåŠŸèƒ½ï¼Œå®ƒæ ¹æ®ä½ æä¾›çš„å¯¹è¯å†å²ï¼Œç”Ÿæˆä¸‹ä¸€ä¸ªå›å¤ã€‚å°±åƒå’ŒçœŸäººèŠå¤©ä¸€æ ·ï¼\n",
    "\n",
    "**åº”ç”¨åœºæ™¯ï¼š**\n",
    "- æ™ºèƒ½å®¢æœ\n",
    "- å†™ä½œåŠ©æ‰‹  \n",
    "- ä»£ç ç”Ÿæˆ\n",
    "- é—®ç­”ç³»ç»Ÿ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "c8RhokKUP9I0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®¡ç®—ç»“æœ: 2\n"
     ]
    }
   ],
   "source": [
    "# ğŸ§® ç®€å•è®¡ç®—å™¨ç¤ºä¾‹\n",
    "# è¿™ä¸ªä¾‹å­å±•ç¤ºå¦‚ä½•è®©GPTæ‰®æ¼”ä¸€ä¸ªç²¾ç¡®çš„è®¡ç®—å™¨\n",
    "\n",
    "# å‘èµ·èŠå¤©è¡¥å…¨è¯·æ±‚\n",
    "completion = openai.chat.completions.create(\n",
    "  # ğŸ“ è¿½è¸ªä¿¡æ¯\n",
    "  name=\"calculator-demo\",  # ç»™è¿™æ¬¡è°ƒç”¨èµ·ä¸ªåå­—ï¼Œæ–¹ä¾¿åœ¨Langfuseä¸­æŸ¥æ‰¾\n",
    "\n",
    "  # ğŸ¤– æ¨¡å‹é€‰æ‹©\n",
    "  model=\"gpt-4o\",  # ä½¿ç”¨GPT-4oæ¨¡å‹ï¼Œä½ ä¹Ÿå¯ä»¥é€‰æ‹©gpt-3.5-turboç­‰\n",
    "\n",
    "  # ğŸ’¬ å¯¹è¯å†…å®¹\n",
    "  messages=[\n",
    "      # systemæ¶ˆæ¯ï¼šå®šä¹‰AIçš„è§’è‰²å’Œè¡Œä¸º\n",
    "      {\"role\": \"system\", \"content\": \"ä½ æ˜¯ä¸€ä¸ªéå¸¸ç²¾ç¡®çš„è®¡ç®—å™¨ã€‚ä½ åªè¾“å‡ºè®¡ç®—ç»“æœã€‚\"},\n",
    "\n",
    "      # useræ¶ˆæ¯ï¼šç”¨æˆ·çš„å®é™…é—®é¢˜\n",
    "      {\"role\": \"user\", \"content\": \"1 + 1 = \"}\n",
    "  ],\n",
    "\n",
    "  # ğŸŒ¡ï¸ æ¸©åº¦æ§åˆ¶\n",
    "  temperature=0,  # 0è¡¨ç¤ºæœ€ç¨³å®šï¼Œé€‚åˆæ•°å­¦è®¡ç®—ç­‰éœ€è¦å‡†ç¡®ç­”æ¡ˆçš„åœºæ™¯\n",
    "\n",
    "  # ğŸ·ï¸ è‡ªå®šä¹‰å…ƒæ•°æ®\n",
    "  metadata={\n",
    "      \"task_type\": \"calculator\",  # ä»»åŠ¡ç±»å‹\n",
    "      \"difficulty\": \"easy\",       # éš¾åº¦ç­‰çº§\n",
    "      \"user_id\": \"demo_user\"      # ç”¨æˆ·ID\n",
    "  }\n",
    ")\n",
    "\n",
    "# ğŸ“Š è·å–æ¨¡å‹å“åº”\n",
    "# completion.choices[0] è·å–ç¬¬ä¸€ä¸ªï¼ˆé€šå¸¸ä¹Ÿæ˜¯å”¯ä¸€çš„ï¼‰å›å¤\n",
    "# .message.content è·å–å›å¤çš„æ–‡æœ¬å†…å®¹\n",
    "result = completion.choices[0].message.content\n",
    "print(f\"è®¡ç®—ç»“æœ: {result}\")\n",
    "\n",
    "# ğŸ’¡ åˆå­¦è€…ç†è§£ï¼š\n",
    "# 1. messagesæ˜¯ä¸€ä¸ªå¯¹è¯å†å²åˆ—è¡¨ï¼ŒæŒ‰æ—¶é—´é¡ºåºæ’åˆ—\n",
    "# 2. systemæ¶ˆæ¯è®¾ç½®AIçš„è§’è‰²ï¼Œuseræ¶ˆæ¯æ˜¯ç”¨æˆ·è¾“å…¥\n",
    "# 3. temperatureæ§åˆ¶è¾“å‡ºçš„éšæœºæ€§ï¼ˆ0-2ï¼Œè¶Šé«˜è¶Šéšæœºï¼‰\n",
    "# 4. metadataå¯ä»¥å­˜å‚¨ä»»ä½•è‡ªå®šä¹‰ä¿¡æ¯ï¼Œç”¨äºåˆ†æå’Œè°ƒè¯•\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image-20251126153044528](https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202511261530111.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SAqxBgOqKTzO"
   },
   "source": [
    "### ğŸ–¼ï¸ ç¤ºä¾‹2ï¼šå›¾åƒèŠå¤©è¡¥å…¨\n",
    "\n",
    "**ä»€ä¹ˆæ˜¯å›¾åƒèŠå¤©è¡¥å…¨ï¼Ÿ**\n",
    "GPT-4oç­‰æ¨¡å‹ä¸ä»…èƒ½ç†è§£æ–‡å­—ï¼Œè¿˜èƒ½\"çœ‹æ‡‚\"å›¾ç‰‡ï¼è¿™è®©AIå¯ä»¥ï¼š\n",
    "- æè¿°å›¾ç‰‡å†…å®¹\n",
    "- å›ç­”å…³äºå›¾ç‰‡çš„é—®é¢˜\n",
    "- åˆ†æå›¾ç‰‡ä¸­çš„ä¿¡æ¯\n",
    "- è¿›è¡Œå›¾åƒç›¸å…³çš„åˆ›ä½œ\n",
    "\n",
    "**åº”ç”¨åœºæ™¯ï¼š**\n",
    "- å›¾åƒå†…å®¹å®¡æ ¸\n",
    "- è§†è§‰é—®ç­”ç³»ç»Ÿ\n",
    "- å›¾åƒæ ‡æ³¨å’Œæè¿°\n",
    "- å¤šæ¨¡æ€AIåŠ©æ‰‹\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "_sM_Pe0YIfTT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å›¾åƒåˆ†æç»“æœ: è¿™å¹…ç”»å‘ˆç°äº†ä¸€ä¸ªå……æ»¡æœªæ¥æ„Ÿå’Œç§‘æŠ€æ„Ÿçš„åœºæ™¯ã€‚ç”»é¢çš„ä¸»è‰²è°ƒæ˜¯æ·±ç»¿è‰²ï¼Œç»™äººä¸€ç§ç¥ç§˜å’Œè¶…ç°å®çš„æ„Ÿè§‰ã€‚ç”»é¢ä¸­å¤®æœ‰ä¸€ä¸ªæ˜äº®çš„å…‰æŸï¼Œç›´å†²å¤©é™…ï¼Œå½¢æˆäº†ä¸€ä¸ªå¼ºçƒˆçš„è§†è§‰ç„¦ç‚¹ã€‚è¿™ä¸ªå…‰æŸçš„é¡¶éƒ¨æœ‰ä¸€ä¸ªå‘å…‰çš„æ–‡å­—â€œLANGFUSEâ€ï¼Œå­—æ¯å‘ˆç°å‡ºä¸€ç§æ•°å­—åŒ–çš„æ•ˆæœï¼Œä¼¼ä¹åœ¨é—ªçƒæˆ–æµåŠ¨ã€‚\n",
      "\n",
      "åœ¨å…‰æŸçš„å‘¨å›´ï¼ŒèƒŒæ™¯ä¸­æœ‰è®¸å¤šå‚ç›´çš„çº¿æ¡å’Œç‚¹çŠ¶çš„å…ƒç´ ï¼Œä»¿ä½›æ˜¯æ•°æ®æµæˆ–ä»£ç åœ¨ä¸æ–­åœ°ä¸‹è½ï¼Œè¥é€ å‡ºä¸€ç§ä¿¡æ¯çˆ†ç‚¸çš„æ„Ÿè§‰ã€‚è¿™äº›çº¿æ¡å’Œç‚¹çš„æ’åˆ—æ–¹å¼ä½¿å¾—æ•´ä¸ªç”»é¢çœ‹èµ·æ¥åƒæ˜¯ä¸€ä¸ªè™šæ‹Ÿä¸–ç•Œæˆ–æ•°å­—ç©ºé—´ï¼Œç»™äººä¸€ç§èº«å¤„äºç½‘ç»œæˆ–è®¡ç®—æœºç³»ç»Ÿä¸­çš„é”™è§‰ã€‚\n",
      "\n",
      "ç”»é¢çš„åº•éƒ¨æœ‰ä¸€äº›æ¨¡ç³Šçš„è½®å»“ï¼Œå¯èƒ½æ˜¯åŸå¸‚çš„è½®å»“æˆ–å…¶ä»–ç»“æ„ï¼Œè¿›ä¸€æ­¥å¢å¼ºäº†æœªæ¥ç§‘æŠ€çš„æ°›å›´ã€‚æ•´ä½“è€Œè¨€ï¼Œè¿™å¹…ç”»é€šè¿‡å…¶è‰²å½©ã€å…‰çº¿å’Œæ„å›¾ï¼Œä¼ è¾¾äº†ä¸€ç§å¯¹ç§‘æŠ€å’Œæ•°å­—ä¸–ç•Œçš„æ¢ç´¢ä¸æ€è€ƒã€‚\n"
     ]
    }
   ],
   "source": [
    "# ğŸ–¼ï¸ å›¾åƒåˆ†æç¤ºä¾‹\n",
    "# è¿™ä¸ªä¾‹å­å±•ç¤ºå¦‚ä½•è®©GPTåˆ†æä¸€å¼ å›¾ç‰‡\n",
    "\n",
    "completion = openai.chat.completions.create(\n",
    "  # ğŸ“ è¿½è¸ªä¿¡æ¯\n",
    "  name=\"image-analysis-demo\",  # ç»™è¿™æ¬¡å›¾åƒåˆ†æèµ·ä¸ªåå­—\n",
    "\n",
    "  # ğŸ¤– æ¨¡å‹é€‰æ‹©ï¼ˆæ”¯æŒè§†è§‰çš„æ¨¡å‹ï¼‰\n",
    "  model=\"gpt-4o-mini\",  # æ”¯æŒè§†è§‰çš„æ¨¡å‹ï¼šGPT-4oã€GPT-4o miniã€GPT-4 Turbo\n",
    "\n",
    "  # ğŸ’¬ å¤šæ¨¡æ€å¯¹è¯å†…å®¹\n",
    "  messages=[\n",
    "      # systemæ¶ˆæ¯ï¼šå®šä¹‰AIåœ¨å›¾åƒåˆ†æä¸­çš„è§’è‰²\n",
    "      {\"role\": \"system\", \"content\": \"ä½ æ˜¯ä¸€ä¸ªè¢«è®­ç»ƒæ¥æè¿°å’Œè§£é‡Šå›¾åƒçš„AIã€‚æè¿°å›¾åƒä¸­çš„ä¸»è¦ç‰©ä½“å’ŒåŠ¨ä½œã€‚\"},\n",
    "\n",
    "      # useræ¶ˆæ¯ï¼šåŒ…å«æ–‡å­—å’Œå›¾ç‰‡çš„å¤åˆå†…å®¹\n",
    "      {\"role\": \"user\", \"content\": [\n",
    "        # æ–‡å­—éƒ¨åˆ†ï¼šç»™AIçš„æŒ‡ä»¤\n",
    "        {\"type\": \"text\", \"text\": \"è¿™å¹…ç”»æç»˜äº†ä»€ä¹ˆï¼Ÿè¯·è¯¦ç»†æè¿°ã€‚\"},\n",
    "\n",
    "        # å›¾ç‰‡éƒ¨åˆ†ï¼šè¦åˆ†æçš„å›¾ç‰‡\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\n",
    "            \"url\": \"https://static.langfuse.com/langfuse-dev/langfuse-example-image.jpeg\"\n",
    "          },\n",
    "        },\n",
    "      ]}\n",
    "  ],\n",
    "\n",
    "  # ğŸŒ¡ï¸ æ¸©åº¦æ§åˆ¶\n",
    "  temperature=0,  # å›¾åƒæè¿°éœ€è¦å‡†ç¡®æ€§ï¼Œä½¿ç”¨è¾ƒä½æ¸©åº¦\n",
    "\n",
    "  # ğŸ·ï¸ è‡ªå®šä¹‰å…ƒæ•°æ®\n",
    "  metadata={\n",
    "      \"task_type\": \"image_analysis\",\n",
    "      \"image_source\": \"langfuse_example\",\n",
    "      \"analysis_type\": \"description\"\n",
    "  }\n",
    ")\n",
    "\n",
    "# ğŸ“Š è·å–åˆ†æç»“æœ\n",
    "analysis_result = completion.choices[0].message.content\n",
    "print(f\"å›¾åƒåˆ†æç»“æœ: {analysis_result}\")\n",
    "\n",
    "# ğŸ’¡ åˆå­¦è€…ç†è§£ï¼š\n",
    "# 1. å¤šæ¨¡æ€æ¶ˆæ¯ï¼šuseræ¶ˆæ¯å¯ä»¥åŒæ—¶åŒ…å«æ–‡å­—å’Œå›¾ç‰‡\n",
    "# 2. å›¾ç‰‡æ ¼å¼ï¼šæ”¯æŒURLé“¾æ¥æˆ–base64ç¼–ç \n",
    "# 3. è§†è§‰æ¨¡å‹ï¼šåªæœ‰ç‰¹å®šæ¨¡å‹æ”¯æŒå›¾åƒç†è§£\n",
    "# 4. Langfuseè®°å½•ï¼šä¼šè‡ªåŠ¨ä¿å­˜å›¾ç‰‡URLï¼Œæ–¹ä¾¿åç»­æŸ¥çœ‹\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image-20251126153325118](https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202511261533566.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M4iJpqYQirtM"
   },
   "source": [
    "#### ğŸ” æŸ¥çœ‹è¿½è¸ªç»“æœ\n",
    "\n",
    "ç°åœ¨ä½ å¯ä»¥å‰å¾€ [Langfuseæ§åˆ¶å°](https://cloud.langfuse.com) æŸ¥çœ‹åˆšæ‰çš„APIè°ƒç”¨è®°å½•ï¼\n",
    "\n",
    "**åœ¨Langfuseä¸­ä½ å¯ä»¥çœ‹åˆ°ï¼š**\n",
    "- ğŸ“Š **å®Œæ•´çš„å¯¹è¯å†å²** - åŒ…æ‹¬systemå’Œuseræ¶ˆæ¯\n",
    "- â±ï¸ **å“åº”æ—¶é—´** - äº†è§£APIæ€§èƒ½\n",
    "- ğŸ’° **Tokenä½¿ç”¨é‡** - ç›‘æ§æˆæœ¬\n",
    "- ğŸ–¼ï¸ **å›¾ç‰‡é“¾æ¥** - æ–¹ä¾¿å¤ç°å›¾åƒåˆ†æ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jFYWEbD6IfTU"
   },
   "source": [
    "### ğŸŒŠ ç¤ºä¾‹3ï¼šæµå¼èŠå¤©è¡¥å…¨\n",
    "\n",
    "**ä»€ä¹ˆæ˜¯æµå¼è¾“å‡ºï¼Ÿ**\n",
    "æµå¼è¾“å‡ºè®©AIå¯ä»¥\"è¾¹æƒ³è¾¹è¯´\"ï¼Œå°±åƒçœŸäººå¯¹è¯ä¸€æ ·é€å­—é€å¥åœ°å›å¤ï¼Œè€Œä¸æ˜¯ç­‰å¾…å®Œæ•´ç­”æ¡ˆã€‚\n",
    "\n",
    "**æµå¼è¾“å‡ºçš„ä¼˜åŠ¿ï¼š**\n",
    "- âš¡ **æ›´å¿«çš„å“åº”æ„ŸçŸ¥** - ç”¨æˆ·ç«‹å³çœ‹åˆ°AIå¼€å§‹å›å¤\n",
    "- ğŸ¯ **æ›´å¥½çš„ç”¨æˆ·ä½“éªŒ** - é¿å…é•¿æ—¶é—´ç­‰å¾…\n",
    "- ğŸ”„ **å®æ—¶äº¤äº’** - å¯ä»¥ä¸­é€”åœæ­¢æˆ–ä¿®æ”¹\n",
    "- ğŸ“± **é€‚åˆç§»åŠ¨ç«¯** - å‡å°‘ç½‘ç»œè¶…æ—¶é£é™©\n",
    "\n",
    "**åº”ç”¨åœºæ™¯ï¼š**\n",
    "- èŠå¤©æœºå™¨äºº\n",
    "- é•¿æ–‡æœ¬ç”Ÿæˆ\n",
    "- å®æ—¶ç¿»è¯‘\n",
    "- ä»£ç ç”ŸæˆåŠ©æ‰‹\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b9gRlb2rKTaA",
    "outputId": "12be69ba-0f5b-46c7-afa0-b6390a9671c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– AIå¼€å§‹è®²ç¬‘è¯ï¼š\n",
      "----------------------------------------\n",
      "å½“ç„¶å•¦ï¼å¬å¥½äº†ï¼š\n",
      "\n",
      "ä¸ºä»€ä¹ˆç¨‹åºå‘˜å–œæ¬¢é»‘å’–å•¡ï¼Ÿ  \n",
      "å› ä¸ºå–å’–å•¡çš„æ—¶å€™ï¼Œä»–ä»¬ä¸éœ€è¦åŠ ä»»ä½•â€œç±»â€ï¼\n",
      "----------------------------------------\n",
      "âœ… ç¬‘è¯è®²å®Œäº†ï¼\n"
     ]
    }
   ],
   "source": [
    "# ğŸ­ æµå¼ç¬‘è¯ç”Ÿæˆç¤ºä¾‹\n",
    "# è¿™ä¸ªä¾‹å­å±•ç¤ºå¦‚ä½•å®æ—¶è·å–AIçš„å›å¤\n",
    "\n",
    "print(\"ğŸ¤– AIå¼€å§‹è®²ç¬‘è¯ï¼š\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# å‘èµ·æµå¼èŠå¤©è¡¥å…¨è¯·æ±‚\n",
    "completion = openai.chat.completions.create(\n",
    "  # ğŸ“ è¿½è¸ªä¿¡æ¯\n",
    "  name=\"streaming-joke-demo\",  # ç»™è¿™æ¬¡æµå¼è°ƒç”¨èµ·ä¸ªåå­—\n",
    "\n",
    "  # ğŸ¤– æ¨¡å‹é€‰æ‹©\n",
    "  model=\"gpt-4o\",\n",
    "\n",
    "  # ğŸ’¬ å¯¹è¯å†…å®¹\n",
    "  messages=[\n",
    "      {\"role\": \"system\", \"content\": \"ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å–œå‰§æ¼”å‘˜ï¼Œæ“…é•¿è®²æœ‰è¶£çš„ç¬‘è¯ã€‚\"},\n",
    "      {\"role\": \"user\", \"content\": \"è®²ä¸€ä¸ªå…³äºç¼–ç¨‹çš„ç¬‘è¯ç»™æˆ‘å¬ã€‚\"}\n",
    "  ],\n",
    "\n",
    "  # ğŸŒ¡ï¸ æ¸©åº¦æ§åˆ¶\n",
    "  temperature=0.7,  # ç¨å¾®æé«˜æ¸©åº¦ï¼Œè®©ç¬‘è¯æ›´æœ‰åˆ›æ„\n",
    "\n",
    "  # ğŸ·ï¸ è‡ªå®šä¹‰å…ƒæ•°æ®\n",
    "  metadata={\n",
    "      \"task_type\": \"joke_generation\",\n",
    "      \"style\": \"programming_humor\",\n",
    "      \"streaming\": True\n",
    "  },\n",
    "\n",
    "  # ğŸŒŠ å¼€å¯æµå¼æ¨¡å¼\n",
    "  stream=True  # è¿™æ˜¯å…³é”®ï¼å¼€å¯åAPIä¼šè¾¹ç”Ÿæˆè¾¹è¿”å›\n",
    ")\n",
    "\n",
    "# ğŸ“Š å¤„ç†æµå¼å“åº”\n",
    "# completionç°åœ¨æ˜¯ä¸€ä¸ªç”Ÿæˆå™¨ï¼Œä¼šé€æ­¥è¿”å›å†…å®¹\n",
    "for chunk in completion:\n",
    "    # æ£€æŸ¥chunkä¸­æ˜¯å¦æœ‰æ–°å†…å®¹\n",
    "    if chunk.choices[0].delta.content is not None:\n",
    "        # å®æ—¶æ‰“å°å†…å®¹ï¼Œend=\"\"è¡¨ç¤ºä¸æ¢è¡Œ\n",
    "        print(chunk.choices[0].delta.content, end=\"\", flush=True)\n",
    "\n",
    "print(\"\\n\" + \"-\" * 40)\n",
    "print(\"âœ… ç¬‘è¯è®²å®Œäº†ï¼\")\n",
    "\n",
    "# ğŸ’¡ åˆå­¦è€…ç†è§£ï¼š\n",
    "# 1. stream=True å¼€å¯æµå¼æ¨¡å¼\n",
    "# 2. è¿”å›çš„æ˜¯ç”Ÿæˆå™¨ï¼Œéœ€è¦ç”¨forå¾ªç¯å¤„ç†\n",
    "# 3. delta.content åŒ…å«æ–°å¢çš„å†…å®¹ç‰‡æ®µ\n",
    "# 4. flush=True ç¡®ä¿å†…å®¹ç«‹å³æ˜¾ç¤º\n",
    "# 5. Langfuseä¼šè‡ªåŠ¨è®°å½•æ•´ä¸ªæµå¼è¿‡ç¨‹\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image-20251126153933013](https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202511261539373.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F2pvm0qLKg7Q"
   },
   "source": [
    "### âš¡ ç¤ºä¾‹4ï¼šå¼‚æ­¥èŠå¤©è¡¥å…¨\n",
    "\n",
    "**ä»€ä¹ˆæ˜¯å¼‚æ­¥è°ƒç”¨ï¼Ÿ**\n",
    "å¼‚æ­¥è°ƒç”¨å…è®¸ç¨‹åºåœ¨ç­‰å¾…APIå“åº”æ—¶ç»§ç»­æ‰§è¡Œå…¶ä»–ä»»åŠ¡ï¼Œæé«˜ç¨‹åºçš„å¹¶å‘æ€§èƒ½ã€‚\n",
    "\n",
    "**å¼‚æ­¥çš„ä¼˜åŠ¿ï¼š**\n",
    "- ğŸš€ **æ›´é«˜çš„å¹¶å‘æ€§** - åŒæ—¶å¤„ç†å¤šä¸ªè¯·æ±‚\n",
    "- â±ï¸ **æ›´å¥½çš„èµ„æºåˆ©ç”¨** - é¿å…é˜»å¡ç­‰å¾…\n",
    "- ğŸ“ˆ **æ›´é«˜çš„ååé‡** - é€‚åˆé«˜å¹¶å‘åœºæ™¯\n",
    "- ğŸ”„ **éé˜»å¡æ“ä½œ** - ä¸ä¼šå¡ä½æ•´ä¸ªç¨‹åº\n",
    "\n",
    "**åº”ç”¨åœºæ™¯ï¼š**\n",
    "- æ‰¹é‡å¤„ç†å¤§é‡è¯·æ±‚\n",
    "- å¾®æœåŠ¡æ¶æ„\n",
    "- é«˜å¹¶å‘Webåº”ç”¨\n",
    "- å®æ—¶æ•°æ®å¤„ç†\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Hggwggv_MKpV"
   },
   "outputs": [],
   "source": [
    "# âš¡ å¼‚æ­¥å®¢æˆ·ç«¯åˆå§‹åŒ–\n",
    "# å¼‚æ­¥å®¢æˆ·ç«¯å…è®¸éé˜»å¡çš„APIè°ƒç”¨ï¼Œæé«˜ç¨‹åºæ€§èƒ½\n",
    "\n",
    "from langfuse.openai import AsyncOpenAI\n",
    "\n",
    "# åˆ›å»ºå¼‚æ­¥å®¢æˆ·ç«¯å®ä¾‹\n",
    "# è‡ªåŠ¨å¤ç”¨ç¯å¢ƒå˜é‡ä¸­çš„Langfuseé…ç½®\n",
    "async_client = AsyncOpenAI()\n",
    "\n",
    "# ğŸ’¡ åˆå­¦è€…ç†è§£ï¼š\n",
    "# 1. AsyncOpenAI æ˜¯å¼‚æ­¥ç‰ˆæœ¬çš„OpenAIå®¢æˆ·ç«¯\n",
    "# 2. ä½¿ç”¨æ–¹å¼ä¸åŒæ­¥å®¢æˆ·ç«¯åŸºæœ¬ç›¸åŒ\n",
    "# 3. ä¸»è¦åŒºåˆ«æ˜¯éœ€è¦ä½¿ç”¨ await å…³é”®å­—\n",
    "# 4. é€‚åˆéœ€è¦å¹¶å‘å¤„ç†å¤šä¸ªè¯·æ±‚çš„åœºæ™¯\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ZIUKD8Z3KmvQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å¼‚æ­¥è®¡ç®—ç»“æœ: 101\n"
     ]
    }
   ],
   "source": [
    "# ğŸ§® å¼‚æ­¥è®¡ç®—å™¨ç¤ºä¾‹\n",
    "# è¿™ä¸ªä¾‹å­å±•ç¤ºå¦‚ä½•ä½¿ç”¨å¼‚æ­¥å®¢æˆ·ç«¯è¿›è¡ŒAPIè°ƒç”¨\n",
    "\n",
    "# åœ¨å¼‚æ­¥å‡½æ•°å†…è°ƒç”¨èŠå¤©è¡¥å…¨æ¥å£\n",
    "completion = await async_client.chat.completions.create(\n",
    "  # ğŸ“ è¿½è¸ªä¿¡æ¯\n",
    "  name=\"async-calculator-demo\",  # ä¸ºæœ¬æ¬¡å¼‚æ­¥è°ƒç”¨å‘½å\n",
    "\n",
    "  # ğŸ¤– æ¨¡å‹é€‰æ‹©\n",
    "  model=\"gpt-4o\",\n",
    "\n",
    "  # ğŸ’¬ å¯¹è¯å†…å®¹\n",
    "  messages=[\n",
    "      {\"role\": \"system\", \"content\": \"ä½ æ˜¯ä¸€ä¸ªéå¸¸ç²¾ç¡®çš„è®¡ç®—å™¨ã€‚ä½ åªè¾“å‡ºè®¡ç®—ç»“æœã€‚\"},\n",
    "      {\"role\": \"user\", \"content\": \"1 + 100 = \"}\n",
    "  ],\n",
    "\n",
    "  # ğŸŒ¡ï¸ æ¸©åº¦æ§åˆ¶\n",
    "  temperature=0,\n",
    "\n",
    "  # ğŸ·ï¸ è‡ªå®šä¹‰å…ƒæ•°æ®\n",
    "  metadata={\n",
    "      \"task_type\": \"async_calculator\",\n",
    "      \"concurrency\": \"high\",\n",
    "      \"user_id\": \"async_demo_user\"\n",
    "  }\n",
    ")\n",
    "\n",
    "# ğŸ“Š è·å–å¼‚æ­¥å“åº”ç»“æœ\n",
    "result = completion.choices[0].message.content\n",
    "print(f\"å¼‚æ­¥è®¡ç®—ç»“æœ: {result}\")\n",
    "\n",
    "# ğŸ’¡ åˆå­¦è€…ç†è§£ï¼š\n",
    "# 1. await å…³é”®å­—ç”¨äºç­‰å¾…å¼‚æ­¥æ“ä½œå®Œæˆ\n",
    "# 2. å¼‚æ­¥è°ƒç”¨ä¸ä¼šé˜»å¡ç¨‹åºæ‰§è¡Œ\n",
    "# 3. Langfuseè‡ªåŠ¨å¤„ç†å¼‚æ­¥è°ƒç”¨çš„è¿½è¸ª\n",
    "# 4. é€‚åˆéœ€è¦åŒæ—¶å¤„ç†å¤šä¸ªè¯·æ±‚çš„åœºæ™¯\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HVbKbya4IfTX"
   },
   "source": [
    "![image-20251126154122496](https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202511261541951.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ky7CtCNzaSrn"
   },
   "source": [
    "### ğŸ”§ ç¤ºä¾‹5ï¼šå‡½æ•°è°ƒç”¨ï¼ˆFunction Callingï¼‰\n",
    "\n",
    "**ä»€ä¹ˆæ˜¯å‡½æ•°è°ƒç”¨ï¼Ÿ**\n",
    "å‡½æ•°è°ƒç”¨è®©AIå¯ä»¥è°ƒç”¨ä½ å®šä¹‰çš„å‡½æ•°ï¼Œå®ç°æ›´å¤æ‚çš„äº¤äº’å’Œç»“æ„åŒ–è¾“å‡ºã€‚\n",
    "\n",
    "**å‡½æ•°è°ƒç”¨çš„ä¼˜åŠ¿ï¼š**\n",
    "- ğŸ¯ **ç»“æ„åŒ–è¾“å‡º** - è·å¾—æ ¼å¼åŒ–çš„JSONæ•°æ®\n",
    "- ğŸ”— **å¤–éƒ¨é›†æˆ** - è°ƒç”¨æ•°æ®åº“ã€APIç­‰å¤–éƒ¨æœåŠ¡\n",
    "- ğŸ“Š **æ•°æ®éªŒè¯** - ä½¿ç”¨Pydanticç¡®ä¿æ•°æ®æ ¼å¼æ­£ç¡®\n",
    "- ğŸ¤– **æ™ºèƒ½å†³ç­–** - AIæ ¹æ®æƒ…å†µé€‰æ‹©è°ƒç”¨å“ªä¸ªå‡½æ•°\n",
    "\n",
    "**åº”ç”¨åœºæ™¯ï¼š**\n",
    "- æ™ºèƒ½åŠ©æ‰‹ï¼ˆæŸ¥è¯¢å¤©æ°”ã€å‘é€é‚®ä»¶ï¼‰\n",
    "- æ•°æ®æå–å’Œè½¬æ¢\n",
    "- å·¥ä½œæµè‡ªåŠ¨åŒ–\n",
    "- APIæ¥å£ç”Ÿæˆ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jJfBdHowaRgs",
    "outputId": "cda9d41d-9a70-40a2-9625-93714c1f253c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: pydantic==2.11.9 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (2.11.9)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from pydantic==2.11.9) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from pydantic==2.11.9) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from pydantic==2.11.9) (4.14.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from pydantic==2.11.9) (0.4.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“¦ å®‰è£…Pydanticä¾èµ–\n",
    "# Pydanticæ˜¯ä¸€ä¸ªå¼ºå¤§çš„æ•°æ®éªŒè¯åº“ï¼Œç”¨äºå®šä¹‰ç»“æ„åŒ–æ•°æ®æ¨¡å‹\n",
    "\n",
    "%pip install pydantic==2.11.9\n",
    "\n",
    "# ğŸ’¡ åˆå­¦è€…ç†è§£ï¼š\n",
    "# Pydanticå¸®åŠ©æˆ‘ä»¬ï¼š\n",
    "# 1. å®šä¹‰æ•°æ®ç»“æ„ï¼ˆç±»ä¼¼æ•°æ®åº“è¡¨ç»“æ„ï¼‰\n",
    "# 2. è‡ªåŠ¨éªŒè¯æ•°æ®æ ¼å¼\n",
    "# 3. ç”ŸæˆJSON Schemaä¾›AIä½¿ç”¨\n",
    "# 4. ç¡®ä¿AIè¿”å›çš„æ•°æ®ç¬¦åˆé¢„æœŸæ ¼å¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2gA-zGk7VYYp",
    "outputId": "10430c87-cf69-4679-ea68-0aabb687de75"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_216832/414262564.py:9: PydanticDeprecatedSince20: The `schema` method is deprecated; use `model_json_schema` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  schema = StepByStepAIResponse.schema()  # è¿”å› JSON Schemaï¼Œä¾› OpenAI å‡½æ•°è°ƒç”¨ä½¿ç”¨\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel\n",
    "\n",
    "# å®šä¹‰å‡½æ•°è°ƒç”¨è¿”å›å€¼çš„æ•°æ®ç»“æ„ï¼Œè®©æ¨¡å‹ç”Ÿæˆç»“æ„åŒ–çš„ JSON\n",
    "class StepByStepAIResponse(BaseModel):\n",
    "    title: str  # æ ‡é¢˜ï¼šä¾‹å¦‚â€œè£…æœºæ­¥éª¤â€\n",
    "    steps: List[str]  # æ­¥éª¤åˆ—è¡¨ï¼šæ¯ä¸ªå…ƒç´ æ˜¯ä¸€å¥æè¿°\n",
    "\n",
    "schema = StepByStepAIResponse.schema()  # è¿”å› JSON Schemaï¼Œä¾› OpenAI å‡½æ•°è°ƒç”¨ä½¿ç”¨\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ORtNcN4-afDC"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_216832/539520121.py:14: PydanticDeprecatedSince20: The `schema` method is deprecated; use `model_json_schema` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  \"parameters\": StepByStepAIResponse.schema()  # Pydantic è‡ªåŠ¨ç”Ÿæˆçš„å‚æ•°å®šä¹‰\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# ç¤ºä¾‹ï¼šå¼•å¯¼æ¨¡å‹è°ƒç”¨æˆ‘ä»¬å®šä¹‰çš„å‡½æ•°ï¼Œå¹¶è¿”å›ç»“æ„åŒ–ç»“æœ\n",
    "response = openai.chat.completions.create(\n",
    "    name=\"test-function\",\n",
    "    model=\"gpt-4o\",  # æ”¯æŒå‡½æ•°è°ƒç”¨çš„æ¨¡å‹ç‰ˆæœ¬(æœ‰äº›OpenAIä»£ç†ä¸æ”¯æŒå‡½æ•°è°ƒç”¨ï¼Œè¿™é‡Œå¯ä»¥æ›¿æ¢ä¸ºDeepSeek)\n",
    "    messages=[\n",
    "       {\"role\": \"user\", \"content\": \"å¦‚ä½•ç»„è£…ä¸€å°ç”µè„‘\"}\n",
    "    ],\n",
    "    functions=[\n",
    "        {\n",
    "          \"name\": \"get_answer_for_user_query\",  # å‡½æ•°åç§°ï¼Œéœ€è¦ä¸ä¸šåŠ¡ä»£ç ä¿æŒä¸€è‡´\n",
    "          \"description\": \"åˆ†æ­¥éª¤ä¸ºç”¨æˆ·æä¾›ç­”æ¡ˆ\",  # å‘Šè¯‰æ¨¡å‹å‡½æ•°çš„ç”¨é€”\n",
    "          \"parameters\": StepByStepAIResponse.schema()  # Pydantic è‡ªåŠ¨ç”Ÿæˆçš„å‚æ•°å®šä¹‰\n",
    "        }\n",
    "    ],\n",
    "    function_call={\"name\": \"get_answer_for_user_query\"}  # å¼ºåˆ¶æ¨¡å‹è°ƒç”¨æŒ‡å®šå‡½æ•°\n",
    ")\n",
    "\n",
    "# Langfuse ä¼šè®°å½•å‡½æ•°è°ƒç”¨çš„å…¥å‚ä¸å‡ºå‚ï¼Œä¾¿äºè¿½è¸ª\n",
    "output = json.loads(response.choices[0].message.function_call.arguments)  # å°†å­—ç¬¦ä¸²ååºåˆ—åŒ–ä¸º Python å­—å…¸\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qurrm-Ntp24O"
   },
   "source": [
    "å‰å¾€ https://cloud.langfuse.com æˆ–ä½ è‡ªå»ºçš„å®ä¾‹ï¼Œå¯ä»¥åœ¨ Langfuse ä¸­æŸ¥çœ‹ç”Ÿæˆè®°å½•ã€‚\n",
    "![image-20251126154233516](https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202511261542923.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0hMsPXFDIfTZ"
   },
   "source": [
    "## Langfuse åŠŸèƒ½ï¼ˆç”¨æˆ·ã€æ ‡ç­¾ã€å…ƒæ•°æ®ã€ä¼šè¯ï¼‰\n",
    "\n",
    "ä½ å¯ä»¥åœ¨ OpenAI è¯·æ±‚ä¸­åŠ å…¥é¢å¤–å±æ€§ï¼Œä»¥å¯ç”¨æ›´å¤š Langfuse åŠŸèƒ½ã€‚Langfuse é›†æˆä¼šè‡ªåŠ¨è§£æè¿™äº›å­—æ®µã€‚å®Œæ•´åŠŸèƒ½åˆ—è¡¨è§ [æ–‡æ¡£](https://langfuse.com/integrations/model-providers/openai-py#custom-trace-properties)ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "7srTKGjaIfTZ"
   },
   "outputs": [],
   "source": [
    "result = openai.chat.completions.create(\n",
    "    name=\"test-chat-with-attributes\",  # trace åç§°ï¼Œå¯¹åº” Langfuse ä¸­çš„ Trace.name\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"ä½ æ˜¯ä¸€ä¸ªéå¸¸ç²¾ç¡®çš„è®¡ç®—å™¨ã€‚ä½ åªè¾“å‡ºè®¡ç®—ç»“æœã€‚\"},\n",
    "        {\"role\": \"user\", \"content\": \"1 + 1 = \"}],\n",
    "    temperature=0,\n",
    "    metadata={\n",
    "        \"langfuse_session_id\": \"session_123\", # ä¼šè¯ IDï¼Œç”¨äºåŒºåˆ†ä¸åŒå¯¹è¯/è¯·æ±‚\n",
    "        \"langfuse_user_id\": \"user_456\", # ä¸šåŠ¡ç”¨æˆ· IDï¼Œè®©ä½ åœ¨ Langfuse ä¸­æŒ‰ç”¨æˆ·èšåˆ\n",
    "        \"langfuse_tags\": [\"calculator\"], # trace æ ‡ç­¾ï¼Œå¯ç”¨äº Langfuse æ§åˆ¶å°ç­›é€‰\n",
    "        \"someMetadataKey\": \"someValue\"  # trace å…ƒæ•°æ®ï¼Œé€‚åˆè®°å½•ä¸šåŠ¡ä¸Šä¸‹æ–‡\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WPfrmgbEIfTZ"
   },
   "source": [
    "ç¤ºä¾‹è¿½è¸ªï¼š\n",
    "![image-20251126154541203](https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202511261545581.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Su1OaQq3rPPh"
   },
   "source": [
    "## å°†å¤šæ¬¡ç”Ÿæˆå½’å¹¶ä¸ºå•ä¸ª Trace\n",
    "\n",
    "åœ¨å®é™…åº”ç”¨ä¸­ï¼Œå¾€å¾€éœ€è¦å¤šæ¬¡è°ƒç”¨ OpenAIã€‚å€ŸåŠ© `@observe()` è£…é¥°å™¨ï¼Œå¯ä»¥æŠŠä¸€æ¬¡ API è°ƒç”¨ä¸­çš„æ‰€æœ‰ LLM è¯·æ±‚å½’å…¥ Langfuse ä¸­åŒä¸€ä¸ª `trace`ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zMDVxzS1ltWU",
    "outputId": "ce14c152-20f5-48f9-ffb4-60f934e8b85c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### åŸå¸‚ä¹‹é­‚\n",
      "\n",
      "é«˜æ¥¼ç©¿äº‘ï¼Œè‹ç©¹ä½å¤´ï¼Œ  \n",
      "äººæ½®ä¼¼æµ·ï¼Œå–§åš£å¦‚æµã€‚  \n",
      "éœ“è™¹é—ªçƒæ˜ å¿ƒæ¢¦ï¼Œ  \n",
      "è¡—å··æ·±å¤„æ•…äº‹æ‚ ã€‚\n",
      "\n",
      "å¤å¢™ä¾æ—§é•Œåˆ»å²æœˆï¼Œ  \n",
      "æ–°æ¡¥æ¨ªæ¶æ—¶ä»£æ´ªæµã€‚  \n",
      "å°è´©å†å–ï¼Œå¸‚åœºå–§é—¹ï¼Œ  \n",
      "æ‘©å¤©å¤§å¦èµ·èˆé£æŸ”ã€‚\n",
      "\n",
      "èµ¤è‰²æ™¨å…‰æŠ«é»„åœŸåœ°ï¼Œ  \n",
      "æ±Ÿæ²³å¥”è…¾è½½ä¸‡ç‰©èˆŸã€‚  \n",
      "è½¦è½®æ»šæ»šç©¿æ¢­ç–¾é€Ÿï¼Œ  \n",
      "ç”µå…‰äº¤æ±‡ç»‡æ¢¦æ— ä¼‘ã€‚\n",
      "\n",
      "æ­¤é—´æœ‰è¯—ï¼Œå¤éŸµæ‚ æ‚ ï¼Œ  \n",
      "çº¸å¢¨é“ºé™ˆåƒè½½é•¿è½´ï¼›  \n",
      "æ­¤é—´æœ‰å¿ƒï¼Œé“éª¨æŸ”è‚ ï¼Œ  \n",
      "ä¸€åŸä¸€é­‚ä¸€å›½æ˜‚é¦–ã€‚\n",
      "\n",
      "åŸå¸‚ä¸çœ ï¼ŒçƒŸç«å¸¸åœ¨ï¼Œ  \n",
      "ç¹åæ·±å¤„æœ‰ä¹¡æ„å¾˜å¾Šã€‚  \n",
      "è¿™æ˜¯ä¸­å›½\n"
     ]
    }
   ],
   "source": [
    "from langfuse.openai import openai\n",
    "from langfuse import observe\n",
    "\n",
    "# ã€@observe è£…é¥°å™¨ã€‘ä¼šè‡ªåŠ¨ï¼š\n",
    "# 1. ä¸º main å‡½æ•°åˆ›å»ºä¸€ä¸ªé¡¶å±‚ trace\n",
    "# 2. æ•è·å‡½æ•°å†…éƒ¨çš„æ‰€æœ‰ Langfuse/OpenAI è°ƒç”¨ï¼Œå¹¶å°†å®ƒä»¬ä¸²è”ä¸ºä¸€ä¸ªå®Œæ•´é“¾è·¯\n",
    "@observe()  # è£…é¥°å™¨ä¼šè‡ªåŠ¨åˆ›å»º trace å¹¶åµŒå¥—å„æ¬¡ç”Ÿæˆ\n",
    "def main(country: str, user_id: str, **kwargs) -> str:\n",
    "    # åµŒå¥—è°ƒç”¨ 1ï¼šè¯¢é—®å›½å®¶é¦–éƒ½\n",
    "    capital = openai.chat.completions.create(\n",
    "      name=\"geography-teacher\",\n",
    "      model=\"gpt-4o\",\n",
    "      messages=[\n",
    "          {\"role\": \"system\", \"content\": \"ä½ æ˜¯ä¸€ä½åœ°ç†è€å¸ˆï¼Œå¸®åŠ©å­¦ç”Ÿå­¦ä¹ å›½å®¶çš„é¦–éƒ½ã€‚å½“è¢«é—®åŠæ—¶ï¼Œåªè¾“å‡ºé¦–éƒ½ã€‚\"},\n",
    "          {\"role\": \"user\", \"content\": country}],\n",
    "      temperature=0,\n",
    "    ).choices[0].message.content  # è¯»å–æ¨¡å‹å›å¤\n",
    "\n",
    "    # åµŒå¥—è°ƒç”¨ 2ï¼šè¯·æ¨¡å‹å†™ä¸€é¦–å…³äºé¦–éƒ½çš„è¯—\n",
    "    poem = openai.chat.completions.create(\n",
    "      name=\"poet\",\n",
    "      model=\"gpt-4o\",\n",
    "      messages=[\n",
    "          {\"role\": \"system\", \"content\": \"ä½ æ˜¯ä¸€ä½è¯—äººã€‚åˆ›ä½œä¸€é¦–å…³äºåŸå¸‚çš„è¯—ã€‚\"},\n",
    "          {\"role\": \"user\", \"content\": capital}],\n",
    "      temperature=1,  # æé«˜æ¸©åº¦ï¼Œè®©è¯—æ­Œæ›´æœ‰åˆ›æ„\n",
    "      max_tokens=200,  # æ§åˆ¶è¾“å‡ºé•¿åº¦\n",
    "    ).choices[0].message.content\n",
    "\n",
    "    return poem\n",
    "\n",
    "# ç›´æ¥è°ƒç”¨ main å‡½æ•°ï¼ŒLangfuse ä¼šè‡ªåŠ¨ç”Ÿæˆ trace å¹¶å¯åœ¨æ§åˆ¶å°æŸ¥çœ‹é“¾è·¯\n",
    "print(main(\"åŒ—äº¬\", \"FLY\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ehx2NZuIrPPh"
   },
   "source": [
    "å‰å¾€ https://cloud.langfuse.com æˆ–ä½ è‡ªå»ºçš„å®ä¾‹ï¼Œå¯ä»¥åœ¨ Langfuse ä¸­æŸ¥çœ‹å®Œæ•´é“¾è·¯ã€‚\n",
    "\n",
    "![å¤šæ¬¡ OpenAI è°ƒç”¨çš„è¿½è¸ªå›¾](https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202511261546555.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-HeMqTWgK4xL"
   },
   "source": [
    "## å®Œæ•´æ–¹æ¡ˆï¼šä¸ Langfuse SDK ååŒ\n",
    "\n",
    "`trace` æ˜¯ Langfuse çš„æ ¸å¿ƒå¯¹è±¡ï¼Œä½ å¯ä»¥ä¸ºå®ƒé™„åŠ ä¸°å¯Œçš„å…ƒæ•°æ®ã€‚è¯¦è§ [Python SDK æ–‡æ¡£](https://langfuse.com/docs/sdk/python#traces-1)ã€‚\n",
    "\n",
    "è‡ªå®šä¹‰ trace åå¯ä»¥å®ç°ä»¥ä¸‹èƒ½åŠ›ï¼š\n",
    "- è‡ªå®šä¹‰åç§°ï¼Œç”¨æ¥åŒºåˆ†ä¸åŒç±»å‹çš„é“¾è·¯\n",
    "- ä»¥ç”¨æˆ·ä¸ºç²’åº¦çš„è¿½è¸ª\n",
    "- é€šè¿‡ç‰ˆæœ¬ä¸å‘å¸ƒä¿¡æ¯è¿›è¡Œå®éªŒç®¡ç†\n",
    "- ä¿å­˜è‡ªå®šä¹‰å…ƒæ•°æ®\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "28to65wpK4xL",
    "outputId": "6eec4e7c-b210-4690-a50d-ed9909f46e3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**åŸå¸‚æ¢¦å¢ƒ**  \n",
      "\n",
      "éœ“è™¹é—ªçƒï¼Œè¡—é“å¦‚æ²³ï¼Œ  \n",
      "äººç¾¤æ±‡èšï¼ŒåŒ–ä½œå¥”æµçš„æ­Œã€‚  \n",
      "é«˜æ¥¼ç›´ç«‹ï¼Œæ¥å¤©æ¬²é«˜ï¼Œ  \n",
      "é’¢ç­‹æ°´æ³¥ï¼Œå¦‚ç”»èˆ¬çš„è£è€€ã€‚  \n",
      "\n",
      "åŸä¸­çš„å··å¼„ï¼Œæ‰¿è½½å¤è€çš„å›å£°ï¼Œ  \n",
      "ç«¹å½±å©†å¨‘ï¼Œä»è®°åƒå¹´çš„æ¸…é£ã€‚  \n",
      "å°æ‘ŠçƒŸç«ï¼Œé£˜æ•£è®°å¿†çš„é¦™å‘³ï¼Œ  \n",
      "ç¹åæ·±å¤„ï¼Œæœ‰ç”Ÿæ´»çš„å®‰æ…°ã€‚  \n",
      "\n",
      "ç™½æ˜¼å–§åš£ï¼Œå·¥å‚çš„è„‰æè·³åŠ¨ï¼Œ  \n",
      "å¤œæ™šé™è°§ï¼Œç¹æ˜Ÿè—åœ¨å¿ƒä¸­ã€‚  \n",
      "åŸå¸‚çš„å¿ƒï¼Œæ˜¯åƒä¸‡æ­¥ä¼äº¤ç»‡ï¼Œ  \n",
      "äººäººå‘å‰ï¼Œè¿½é€ä¸å°½çš„æ•…äº‹ã€‚  \n",
      "\n",
      "é«˜é“å‘¼å•¸ï¼Œè¿é€šå››æ–¹çš„æ¢¦å¢ƒï¼Œ  \n",
      "åŸå¸‚çš„è„‰ç»œå¦‚ç››å¼€çš„é”¦å±ã€‚  \n",
      "æ¸¸äººè¸è¿‡å¤åŸé—¨ï¼Œ\n"
     ]
    }
   ],
   "source": [
    "from langfuse.openai import openai\n",
    "from langfuse import observe, get_client\n",
    "\n",
    "langfuse = get_client()  # è·å–åº•å±‚ Langfuse å®¢æˆ·ç«¯ï¼Œå¯åœ¨è£…é¥°å™¨ä¹‹å¤–æ‰‹åŠ¨æ“ä½œ trace\n",
    "\n",
    "@observe()  # è£…é¥°å™¨ä¼šè‡ªåŠ¨åˆ›å»º trace å¹¶åµŒå¥—å„æ¬¡ç”Ÿæˆ\n",
    "def main(country: str, user_id: str, **kwargs) -> str:\n",
    "    # åµŒå¥—è°ƒç”¨ 1ï¼šè·å–å›½å®¶é¦–éƒ½\n",
    "    capital = openai.chat.completions.create(\n",
    "      name=\"geography-teacher\",\n",
    "      model=\"gpt-4o\",\n",
    "      messages=[\n",
    "          {\"role\": \"system\", \"content\": \"ä½ æ˜¯ä¸€ä½åœ°ç†è€å¸ˆï¼Œå¸®åŠ©å­¦ç”Ÿå­¦ä¹ å›½å®¶çš„é¦–éƒ½ã€‚å½“è¢«é—®åŠæ—¶ï¼Œåªè¾“å‡ºé¦–éƒ½ã€‚\"},\n",
    "          {\"role\": \"user\", \"content\": country}],\n",
    "      temperature=0,\n",
    "    ).choices[0].message.content\n",
    "\n",
    "    # åµŒå¥—è°ƒç”¨ 2ï¼šæ ¹æ®é¦–éƒ½ç”Ÿæˆè¯—æ­Œ\n",
    "    poem = openai.chat.completions.create(\n",
    "      name=\"poet\",\n",
    "      model=\"gpt-4o\",\n",
    "      messages=[\n",
    "          {\"role\": \"system\", \"content\": \"ä½ æ˜¯ä¸€ä½è¯—äººã€‚åˆ›ä½œä¸€é¦–å…³äºåŸå¸‚çš„è¯—ã€‚\"},\n",
    "          {\"role\": \"user\", \"content\": capital}],\n",
    "      temperature=1,\n",
    "      max_tokens=200,\n",
    "    ).choices[0].message.content\n",
    "\n",
    "    # æ‰‹åŠ¨æ›´æ–°å½“å‰ trace çš„å±æ€§ï¼Œè®©ä»ªè¡¨ç›˜ä¿¡æ¯æ›´å®Œæ•´\n",
    "    langfuse.update_current_trace(\n",
    "        name=\"City poem generator\",  # è‡ªå®šä¹‰ trace åç§°\n",
    "        session_id=\"1234\",  # ä¸šåŠ¡ä¼šè¯ ID\n",
    "        user_id=user_id,  # ä¸šåŠ¡ç”¨æˆ· ID\n",
    "        tags=[\"tag1\", \"tag2\"],  # æ ‡ç­¾ï¼Œæ”¯æŒåœ¨ Langfuse ä¸­æœç´¢\n",
    "        public=True,  # æ˜¯å¦å…è®¸åˆ†äº« Trace é“¾æ¥\n",
    "        metadata = {\"env\": \"development\"}  # è‡ªå®šä¹‰å…ƒæ•°æ®ï¼Œä¾‹å¦‚ç¯å¢ƒæ ‡è®°\n",
    "    )\n",
    "\n",
    "    return poem\n",
    "\n",
    "# create_trace_id() ä¼šç”Ÿæˆä¸€ä¸ªå¯å¤ç”¨çš„è¿½è¸ª IDï¼Œä½ ä¹Ÿå¯ä»¥æ”¹ä¸ºè‡ªå·±çš„ä¸šåŠ¡ ID\n",
    "trace_id = langfuse.create_trace_id()\n",
    "\n",
    "# é€šè¿‡å…³é”®å­—å‚æ•° `langfuse_observation_id` å°† trace_id ä¼ é€’ç»™è£…é¥°å™¨ï¼Œæ–¹ä¾¿ä¸²è”ä¸Šä¸‹æ¸¸è°ƒç”¨\n",
    "print(main(\"åŒ—äº¬\", \"admin\", langfuse_observation_id=trace_id))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2u5n_RUic4nb"
   },
   "source": [
    "ç¤ºä¾‹ï¼š\n",
    "![image-20251126154814338](https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202511261548627.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O3jxed-VrPPi"
   },
   "source": [
    "## ä»¥ç¼–ç¨‹æ–¹å¼æ·»åŠ è¯„åˆ†\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uMO6tn53rPPi"
   },
   "source": [
    "ä½ å¯ä»¥å‘ trace æ·»åŠ  [è¯„åˆ†](https://langfuse.com/docs/scores)ï¼Œè®°å½•ç”¨æˆ·åé¦ˆæˆ–è‡ªåŠ¨åŒ–è¯„ä¼°ç»“æœã€‚è¯„åˆ†å¯ç”¨äºåœ¨ Langfuse ä¸­ç­›é€‰è¿½è¸ªï¼Œå¹¶ä¼šæ˜¾ç¤ºåœ¨æ§åˆ¶å°ä¸­ã€‚è¯¦è§è¯„åˆ†æ–‡æ¡£ã€‚\n",
    "\n",
    "è¯„åˆ†é€šè¿‡ `trace_id` ä¸å¯¹åº”çš„ trace å…³è”ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "J0argbJhrPPi"
   },
   "outputs": [],
   "source": [
    "from langfuse import observe, get_client\n",
    "\n",
    "langfuse = get_client()  # è·å–åº•å±‚å®¢æˆ·ç«¯ï¼Œç”¨äºä¸»æµç¨‹ä¹‹å¤–çš„æ“ä½œ\n",
    "\n",
    "@observe()  # è£…é¥°å™¨ä¼šè‡ªåŠ¨åˆ›å»º trace å¹¶åµŒå¥—å„æ¬¡ç”Ÿæˆ\n",
    "def main():\n",
    "    # åœ¨è£…é¥°å™¨å†…éƒ¨ï¼Œå¯éšæ—¶è·å–å½“å‰ trace çš„ ID\n",
    "    trace_id = langfuse.get_current_trace_id()\n",
    "\n",
    "    # TODO: åœ¨æ­¤å¤„ç¼–å†™ä½ çš„ä¸šåŠ¡é€»è¾‘ï¼Œä¾‹å¦‚ç»§ç»­è°ƒç”¨å…¶ä»– APIã€å¤„ç†ç”¨æˆ·è¾“å…¥ç­‰\n",
    "\n",
    "    return \"res\", trace_id\n",
    "\n",
    "# æ‰§è¡Œè¢«è£…é¥°çš„å‡½æ•°ï¼ŒLangfuse ä¼šç”Ÿæˆ trace\n",
    "_, trace_id = main()\n",
    "\n",
    "# åœ¨ trace ä¸Šä¸‹æ–‡å¤–éƒ¨ä¹Ÿå¯ä»¥ç»§ç»­æ“ä½œï¼Œä¾‹å¦‚å‘è¿™æ¬¡ trace æ·»åŠ è¯„åˆ†\n",
    "langfuse.create_score(\n",
    "    trace_id=trace_id,  # æŒ‡å®šè¦æ‰“åˆ†çš„ trace\n",
    "    name=\"my-score-name\",  # è¯„åˆ†åç§°ï¼Œç”¨äºåŒºåˆ†ä¸åŒæŒ‡æ ‡\n",
    "    value=1  # åˆ†å€¼ï¼Œå¯ä»¥æ˜¯å¸ƒå°”ã€æ•´æ•°ã€æµ®ç‚¹æ•°ï¼Œè§†ä¸šåŠ¡åœºæ™¯è€Œå®š\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zp899q3edni6"
   },
   "source": [
    "ç¤ºä¾‹ï¼š![image-20251126154926071](https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202511261549411.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bHVuMzDl2RWG"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (agent101)",
   "language": "python",
   "name": "agent101"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
