{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### ğŸ”§ ç¯å¢ƒé…ç½®å’Œæ£€æŸ¥\n",
    "\n",
    "#### æ¦‚è¿°\n",
    "\n",
    "æœ¬æ•™ç¨‹éœ€è¦ç‰¹å®šçš„ç¯å¢ƒé…ç½®ä»¥ç¡®ä¿æœ€ä½³å­¦ä¹ ä½“éªŒã€‚ä»¥ä¸‹é…ç½®å°†å¸®åŠ©ä½ ï¼š\n",
    "\n",
    "- ä½¿ç”¨ç»Ÿä¸€çš„condaç¯å¢ƒï¼šæ¿€æ´»ç»Ÿä¸€çš„å­¦ä¹ ç¯å¢ƒ\n",
    "- é€šè¿‡å›½å†…é•œåƒæºå¿«é€Ÿå®‰è£…ä¾èµ–ï¼šé…ç½®pipä½¿ç”¨æ¸…åé•œåƒæº\n",
    "- åŠ é€Ÿæ¨¡å‹ä¸‹è½½ï¼šè®¾ç½®HuggingFaceé•œåƒä»£ç†\n",
    "- æ£€æŸ¥ç³»ç»Ÿé…ç½®ï¼šæ£€æŸ¥ç¡¬ä»¶å’Œè½¯ä»¶é…ç½®\n",
    "\n",
    "#### é…ç½®\n",
    "\n",
    "- **æ‰€éœ€ç¯å¢ƒåŠå…¶ä¾èµ–å·²ç»éƒ¨ç½²å¥½**\n",
    "- åœ¨`Notebook`å³ä¸Šè§’é€‰æ‹©`jupyterå†…æ ¸`ä¸º`python(agent101)`ï¼Œå³å¯æ‰§è¡Œä¸‹æ–¹ä»£ç "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================\n",
      "== Conda ç¯å¢ƒæ£€æŸ¥æŠ¥å‘Š (ä»…é’ˆå¯¹å½“å‰ Bash å­è¿›ï¿½ï¿½) ==\n",
      "=========================================\n",
      "âœ… å½“å‰å•å…ƒæ ¼å·²æˆåŠŸæ¿€æ´»åˆ° agent101 ç¯ï¿½ï¿½ã€‚\n",
      "âœ… æ­£åœ¨ä½¿ç”¨çš„ç¯å¢ƒè·¯å¾„: /root/miniconda3/envs/agent101\n",
      "\n",
      "ğŸ’¡ æç¤º: åç»­çš„Pythonï¿½ï¿½å…ƒæ ¼å°†ä½¿ç”¨Notebookå½“å‰é€‰æ‹©çš„Jupyterå†…æ ¸ã€‚\n",
      "   å¦‚æœéœ€è¦åç»­å•å…ƒæ ¼ä¹Ÿä½¿ç”¨æ­¤ï¿½ï¿½å¢ƒï¼Œè¯·æ‰§è¡Œä»¥ä¸‹æ“ä½œ:\n",
      "   1. æ£€æŸ¥ Notebook å³ä¸Šè§’æ˜¯å¦å·²é€‰æ‹© 'python(agent101)'ã€‚\n",
      "=========================================\n"
     ]
    }
   ],
   "source": [
    "%%script bash\n",
    "\n",
    "# 1. æ¿€æ´» conda ç¯å¢ƒ (ä»…å¯¹å½“å‰å•å…ƒæ ¼æœ‰æ•ˆ)\n",
    "eval \"$(conda shell.bash hook)\"\n",
    "conda activate agent101\n",
    "\n",
    "echo \"=========================================\"\n",
    "echo \"== Conda ç¯å¢ƒæ£€æŸ¥æŠ¥å‘Š (ä»…é’ˆå¯¹å½“å‰ Bash å­è¿›ç¨‹) ==\"\n",
    "echo \"=========================================\"\n",
    "\n",
    "# 2. æ£€æŸ¥å½“å‰æ¿€æ´»çš„ç¯å¢ƒ\n",
    "CURRENT_ENV_NAME=$(basename $CONDA_PREFIX)\n",
    "\n",
    "if [ \"$CURRENT_ENV_NAME\" = \"agent101\" ]; then\n",
    "    echo \"âœ… å½“å‰å•å…ƒæ ¼å·²æˆåŠŸæ¿€æ´»åˆ° agent101 ç¯å¢ƒã€‚\"\n",
    "    echo \"âœ… æ­£åœ¨ä½¿ç”¨çš„ç¯å¢ƒè·¯å¾„: $CONDA_PREFIX\"\n",
    "    echo \"\"\n",
    "    echo \"ğŸ’¡ æç¤º: åç»­çš„Pythonå•å…ƒæ ¼å°†ä½¿ç”¨Notebookå½“å‰é€‰æ‹©çš„Jupyterå†…æ ¸ã€‚\"\n",
    "    echo \"   å¦‚æœéœ€è¦åç»­å•å…ƒæ ¼ä¹Ÿä½¿ç”¨æ­¤ç¯å¢ƒï¼Œè¯·æ‰§è¡Œä»¥ä¸‹æ“ä½œ:\"\n",
    "    echo \"   1. æ£€æŸ¥ Notebook å³ä¸Šè§’æ˜¯å¦å·²é€‰æ‹© 'python(agent101)'ã€‚\"\n",
    "else\n",
    "    echo \"âŒ æ¿€æ´»å¤±è´¥æˆ–ç¯å¢ƒåç§°ä¸åŒ¹é…ã€‚å½“å‰ç¯å¢ƒ: $CURRENT_ENV_NAME\"\n",
    "    echo \"\"\n",
    "    echo \"âš ï¸ ä¸¥é‡æç¤º: å»ºè®®å°† Notebook çš„ Jupyter **å†…æ ¸ (Kernel)** åˆ‡æ¢ä¸º 'python(agent101)'ã€‚\"\n",
    "    echo \"   (é€šå¸¸ä½äº Notebook å³ä¸Šè§’æˆ– 'å†…æ ¸' èœå•ä¸­)\"\n",
    "    echo \"\"\n",
    "    echo \"ğŸ“š å¤‡ç”¨æ–¹æ³• (ä¸æ¨è): å¦‚æœæ— æ³•åˆ‡æ¢å†…æ ¸ï¼Œåˆ™å¿…é¡»åœ¨**æ¯ä¸ª**ä»£ç å•å…ƒæ ¼çš„å¤´éƒ¨é‡å¤ä»¥ä¸‹å‘½ä»¤:\"\n",
    "    echo \"\"\n",
    "    echo \"%%script bash\"\n",
    "    echo \"# å¿…é¡»åœ¨æ¯ä¸ªå•å…ƒæ ¼éƒ½æ‰§è¡Œ\"\n",
    "    echo \"eval \\\"\\$(conda shell.bash hook)\\\"\"\n",
    "    echo \"conda activate agent101\"\n",
    "fi\n",
    "\n",
    "echo \"=========================================\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For variant 'global', will try loading '/etc/xdg/pip/pip.conf'\n",
      "For variant 'global', will try loading '/etc/pip.conf'\n",
      "For variant 'user', will try loading '/root/.pip/pip.conf'\n",
      "For variant 'user', will try loading '/root/.config/pip/pip.conf'\n",
      "For variant 'site', will try loading '/root/miniconda3/envs/agent101/pip.conf'\n",
      "\u001b[31mERROR: Got unexpected number of arguments, expected 0. (example: \"/root/miniconda3/envs/agent101/bin/python -m pip config list\")\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "For variant 'global', will try loading '/etc/xdg/pip/pip.conf'\n",
      "For variant 'global', will try loading '/etc/pip.conf'\n",
      "For variant 'user', will try loading '/root/.pip/pip.conf'\n",
      "For variant 'user', will try loading '/root/.config/pip/pip.conf'\n",
      "For variant 'site', will try loading '/root/miniconda3/envs/agent101/pip.conf'\n",
      "\u001b[31mERROR: Got unexpected number of arguments, expected 0. (example: \"/root/miniconda3/envs/agent101/bin/python -m pip config list\")\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# 2. è®¾ç½®pip ä¸ºæ¸…åæº\n",
    "%pip config list -v set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "%pip config list -v list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: HF_ENDPOINT=https://hf-mirror.com\n",
      "https://hf-mirror.com\n"
     ]
    }
   ],
   "source": [
    "# 3. è®¾ç½®HuggingFaceAgent\n",
    "%env HF_ENDPOINT=https://hf-mirror.com\n",
    "# éªŒè¯ï¼šä½¿ç”¨shellå‘½ä»¤æ£€æŸ¥\n",
    "!echo $HF_ENDPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: pandas==2.2.2 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: tabulate==0.9.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from pandas==2.2.2) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from pandas==2.2.2) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from pandas==2.2.2) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from pandas==2.2.2) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas==2.2.2) (1.17.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "### ç¯å¢ƒä¿¡æ¯\n",
      "| é¡¹ç›®         | ä¿¡æ¯                                                                               |\n",
      "|:-------------|:-----------------------------------------------------------------------------------|\n",
      "| æ“ä½œç³»ç»Ÿ     | Linux Ubuntu 22.04.4 LTS                                                           |\n",
      "| CPU ä¿¡æ¯     | 11th Gen Intel(R) Core(TM) i5-1135G7 @ 2.40GHz (1 physical cores, 4 logical cores) |\n",
      "| å†…å­˜ä¿¡æ¯     | 5.75 GB (Available: 1.55 GB)                                                       |\n",
      "| GPU ä¿¡æ¯     | No GPU found (nvidia-smi not found)                                                |\n",
      "| CUDA ä¿¡æ¯    | CUDA not found                                                                     |\n",
      "| Python ç‰ˆæœ¬  | 3.10.18                                                                            |\n",
      "| Conda ç‰ˆæœ¬   | conda 24.4.0                                                                       |\n",
      "| ç‰©ç†ç£ç›˜ç©ºé—´ | Total: 145.49 GB, Used: 45.30 GB, Free: 93.96 GB                                   |\n"
     ]
    }
   ],
   "source": [
    "# ğŸ” ç¯å¢ƒä¿¡æ¯æ£€æŸ¥è„šæœ¬\n",
    "#\n",
    "# æœ¬è„šæœ¬çš„ä½œç”¨ï¼š\n",
    "# 1. å®‰è£… pandas åº“ç”¨äºæ•°æ®è¡¨æ ¼å±•ç¤º\n",
    "# 2. æ£€æŸ¥ç³»ç»Ÿçš„å„é¡¹é…ç½®ä¿¡æ¯\n",
    "# 3. ç”Ÿæˆè¯¦ç»†çš„ç¯å¢ƒæŠ¥å‘Šè¡¨æ ¼\n",
    "#\n",
    "# å¯¹äºåˆå­¦è€…æ¥è¯´ï¼Œè¿™ä¸ªæ­¥éª¤å¸®åŠ©ä½ ï¼š\n",
    "# - äº†è§£å½“å‰è¿è¡Œç¯å¢ƒçš„ç¡¬ä»¶é…ç½®\n",
    "# - ç¡®è®¤æ˜¯å¦æ»¡è¶³æ¨¡å‹è¿è¡Œçš„æœ€ä½è¦æ±‚\n",
    "# - å­¦ä¹ å¦‚ä½•é€šè¿‡ä»£ç è·å–ç³»ç»Ÿä¿¡æ¯\n",
    "\n",
    "# å®‰è£… pandas åº“ - ç”¨äºåˆ›å»ºå’Œå±•ç¤ºæ•°æ®è¡¨æ ¼\n",
    "# pandas æ˜¯ Python ä¸­æœ€æµè¡Œçš„æ•°æ®å¤„ç†å’Œåˆ†æåº“\n",
    "%pip install pandas==2.2.2 tabulate==0.9.0\n",
    "\n",
    "import platform # å¯¼å…¥ platform æ¨¡å—ä»¥è·å–ç³»ç»Ÿä¿¡æ¯\n",
    "import os # å¯¼å…¥ os æ¨¡å—ä»¥ä¸æ“ä½œç³»ç»Ÿäº¤äº’\n",
    "import subprocess # å¯¼å…¥ subprocess æ¨¡å—ä»¥è¿è¡Œå¤–éƒ¨å‘½ä»¤\n",
    "import pandas as pd # å¯¼å…¥ pandas æ¨¡å—ï¼Œé€šå¸¸ç”¨äºæ•°æ®å¤„ç†ï¼Œè¿™é‡Œç”¨äºåˆ›å»ºè¡¨æ ¼\n",
    "import shutil # å¯¼å…¥ shutil æ¨¡å—ä»¥è·å–ç£ç›˜ç©ºé—´ä¿¡æ¯\n",
    "\n",
    "# è·å– CPU ä¿¡æ¯çš„å‡½æ•°ï¼ŒåŒ…æ‹¬æ ¸å¿ƒæ•°é‡\n",
    "def get_cpu_info():\n",
    "    cpu_info = \"\" # åˆå§‹åŒ– CPU ä¿¡æ¯å­—ç¬¦ä¸²\n",
    "    physical_cores = \"N/A\"\n",
    "    logical_cores = \"N/A\"\n",
    "\n",
    "    if platform.system() == \"Windows\": # å¦‚æœæ˜¯ Windows ç³»ç»Ÿ\n",
    "        cpu_info = platform.processor() # ä½¿ç”¨ platform.processor() è·å– CPU ä¿¡æ¯\n",
    "        try:\n",
    "            # è·å– Windows ä¸Šçš„æ ¸å¿ƒæ•°é‡ (éœ€è¦ WMI)\n",
    "            import wmi\n",
    "            c = wmi.WMI()\n",
    "            for proc in c.Win32_Processor():\n",
    "                physical_cores = proc.NumberOfCores\n",
    "                logical_cores = proc.NumberOfLogicalProcessors\n",
    "        except:\n",
    "            pass # å¦‚æœ WMI ä¸å¯ç”¨ï¼Œå¿½ç•¥é”™è¯¯\n",
    "\n",
    "    elif platform.system() == \"Darwin\": # å¦‚æœæ˜¯ macOS ç³»ç»Ÿ\n",
    "        # åœ¨ macOS ä¸Šä½¿ç”¨ sysctl å‘½ä»¤è·å– CPU ä¿¡æ¯å’Œæ ¸å¿ƒæ•°é‡\n",
    "        os.environ['PATH'] = os.environ['PATH'] + os.pathsep + '/usr/sbin' # æ›´æ–° PATH ç¯å¢ƒå˜é‡\n",
    "        try:\n",
    "            process_brand = subprocess.Popen(['sysctl', \"machdep.cpu.brand_string\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_brand, stderr_brand = process_brand.communicate()\n",
    "            cpu_info = stdout_brand.decode().split(': ')[1].strip() if stdout_brand else \"Could not retrieve CPU info\"\n",
    "\n",
    "            process_physical = subprocess.Popen(['sysctl', \"hw.physicalcpu\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_physical, stderr_physical = process_physical.communicate()\n",
    "            physical_cores = stdout_physical.decode().split(': ')[1].strip() if stdout_physical else \"N/A\"\n",
    "\n",
    "            process_logical = subprocess.Popen(['sysctl', \"hw.logicalcpu\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_logical, stderr_logical = process_logical.communicate()\n",
    "            logical_cores = stdout_logical.decode().split(': ')[1].strip() if stdout_logical else \"N/A\"\n",
    "\n",
    "        except:\n",
    "            cpu_info = \"Could not retrieve CPU info\"\n",
    "            physical_cores = \"N/A\"\n",
    "            logical_cores = \"N/A\"\n",
    "\n",
    "    else:  # Linux ç³»ç»Ÿ\n",
    "        try:\n",
    "            # åœ¨ Linux ä¸Šè¯»å– /proc/cpuinfo æ–‡ä»¶è·å– CPU ä¿¡æ¯å’Œæ ¸å¿ƒæ•°é‡\n",
    "            with open('/proc/cpuinfo') as f:\n",
    "                physical_cores_count = 0\n",
    "                logical_cores_count = 0\n",
    "                cpu_info_lines = []\n",
    "                for line in f:\n",
    "                    if line.startswith('model name'): # æŸ¥æ‰¾ä»¥ 'model name'å¼€å¤´çš„è¡Œ\n",
    "                        if not cpu_info: # åªè·å–ç¬¬ä¸€ä¸ª model name\n",
    "                            cpu_info = line.split(': ')[1].strip()\n",
    "                    elif line.startswith('cpu cores'): # æŸ¥æ‰¾ä»¥ 'cpu cores' å¼€å¤´çš„è¡Œ\n",
    "                        physical_cores_count = int(line.split(': ')[1].strip())\n",
    "                    elif line.startswith('processor'): # æŸ¥æ‰¾ä»¥ 'processor' å¼€å¤´çš„è¡Œ\n",
    "                        logical_cores_count += 1\n",
    "                physical_cores = str(physical_cores_count) if physical_cores_count > 0 else \"N/A\"\n",
    "                logical_cores = str(logical_cores_count) if logical_cores_count > 0 else \"N/A\"\n",
    "                if not cpu_info:\n",
    "                     cpu_info = \"Could not retrieve CPU info\"\n",
    "\n",
    "        except:\n",
    "            cpu_info = \"Could not retrieve CPU info\"\n",
    "            physical_cores = \"N/A\"\n",
    "            logical_cores = \"N/A\"\n",
    "\n",
    "    return f\"{cpu_info} ({physical_cores} physical cores, {logical_cores} logical cores)\" # è¿”å› CPU ä¿¡æ¯å’Œæ ¸å¿ƒæ•°é‡\n",
    "\n",
    "\n",
    "# è·å–å†…å­˜ä¿¡æ¯çš„å‡½æ•°\n",
    "def get_memory_info():\n",
    "    mem_info = \"\" # åˆå§‹åŒ–å†…å­˜ä¿¡æ¯å­—ç¬¦ä¸²\n",
    "    if platform.system() == \"Windows\":\n",
    "        # åœ¨ Windows ä¸Šä¸å®¹æ˜“é€šè¿‡æ ‡å‡†åº“è·å–ï¼Œéœ€è¦å¤–éƒ¨åº“æˆ– PowerShell\n",
    "        mem_info = \"Requires external tools on Windows\" # è®¾ç½®æç¤ºä¿¡æ¯\n",
    "    elif platform.system() == \"Darwin\": # å¦‚æœæ˜¯ macOS ç³»ç»Ÿ\n",
    "        # åœ¨ macOS ä¸Šä½¿ç”¨ sysctl å‘½ä»¤è·å–å†…å­˜å¤§å°\n",
    "        process = subprocess.Popen(['sysctl', \"hw.memsize\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE) # è¿è¡Œ sysctl å‘½ä»¤\n",
    "        stdout, stderr = process.communicate() # è·å–æ ‡å‡†è¾“å‡ºå’Œæ ‡å‡†é”™è¯¯\n",
    "        mem_bytes = int(stdout.decode().split(': ')[1].strip()) # è§£æè¾“å‡ºï¼Œè·å–å†…å­˜å¤§å°ï¼ˆå­—èŠ‚ï¼‰\n",
    "        mem_gb = mem_bytes / (1024**3) # è½¬æ¢ä¸º GB\n",
    "        mem_info = f\"{mem_gb:.2f} GB\" # æ ¼å¼åŒ–è¾“å‡º\n",
    "    else:  # Linux ç³»ç»Ÿ\n",
    "        try:\n",
    "            # åœ¨ Linux ä¸Šè¯»å– /proc/meminfo æ–‡ä»¶è·å–å†…å­˜ä¿¡æ¯\n",
    "            with open('/proc/meminfo') as f:\n",
    "                total_mem_kb = 0\n",
    "                available_mem_kb = 0\n",
    "                for line in f:\n",
    "                    if line.startswith('MemTotal'): # æŸ¥æ‰¾ä»¥ 'MemTotal' å¼€å¤´çš„è¡Œ\n",
    "                        total_mem_kb = int(line.split(':')[1].strip().split()[0]) # è§£æè¡Œï¼Œè·å–æ€»å†…å­˜ï¼ˆKBï¼‰\n",
    "                    elif line.startswith('MemAvailable'): # æŸ¥æ‰¾ä»¥ 'MemAvailable' å¼€å¤´çš„è¡Œ\n",
    "                         available_mem_kb = int(line.split(':')[1].strip().split()[0]) # è§£æè¡Œï¼Œè·å–å¯ç”¨å†…å­˜ï¼ˆKBï¼‰\n",
    "\n",
    "                if total_mem_kb > 0:\n",
    "                    total_mem_gb = total_mem_kb / (1024**2) # è½¬æ¢ä¸º GB\n",
    "                    mem_info = f\"{total_mem_gb:.2f} GB\" # æ ¼å¼åŒ–è¾“å‡ºæ€»å†…å­˜\n",
    "                    if available_mem_kb > 0:\n",
    "                        available_mem_gb = available_mem_kb / (1024**2)\n",
    "                        mem_info += f\" (Available: {available_mem_gb:.2f} GB)\" # æ·»åŠ å¯ç”¨å†…å­˜ä¿¡æ¯\n",
    "                else:\n",
    "                     mem_info = \"Could not retrieve memory info\" # å¦‚æœè¯»å–æ–‡ä»¶å‡ºé”™ï¼Œè®¾ç½®é”™è¯¯ä¿¡æ¯\n",
    "\n",
    "        except:\n",
    "            mem_info = \"Could not retrieve memory info\" # å¦‚æœè¯»å–æ–‡ä»¶å‡ºé”™ï¼Œè®¾ç½®é”™è¯¯ä¿¡æ¯\n",
    "    return mem_info # è¿”å›å†…å­˜ä¿¡æ¯\n",
    "\n",
    "# è·å– GPU ä¿¡æ¯çš„å‡½æ•°ï¼ŒåŒ…æ‹¬æ˜¾å­˜\n",
    "def get_gpu_info():\n",
    "    try:\n",
    "        # å°è¯•ä½¿ç”¨ nvidia-smi è·å– NVIDIA GPU ä¿¡æ¯å’Œæ˜¾å­˜\n",
    "        result = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total', '--format=csv,noheader'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # å¦‚æœå‘½ä»¤æˆåŠŸæ‰§è¡Œ\n",
    "            gpu_lines = result.stdout.strip().split('\\n') # è§£æè¾“å‡ºï¼Œè·å– GPU åç§°å’Œæ˜¾å­˜\n",
    "            gpu_info_list = []\n",
    "            for line in gpu_lines:\n",
    "                name, memory = line.split(', ')\n",
    "                gpu_info_list.append(f\"{name} ({memory})\") # æ ¼å¼åŒ– GPU ä¿¡æ¯\n",
    "            return \", \".join(gpu_info_list) if gpu_info_list else \"NVIDIA GPU found, but info not listed\" # è¿”å› GPU ä¿¡æ¯æˆ–æç¤ºä¿¡æ¯\n",
    "        else:\n",
    "             # å°è¯•ä½¿ç”¨ lshw è·å–å…¶ä»– GPU ä¿¡æ¯ (éœ€è¦å®‰è£… lshw)\n",
    "            try:\n",
    "                result_lshw = subprocess.run(['lshw', '-C', 'display'], capture_output=True, text=True)\n",
    "                if result_lshw.returncode == 0: # å¦‚æœå‘½ä»¤æˆåŠŸæ‰§è¡Œ\n",
    "                     # ç®€å•è§£æè¾“å‡ºä¸­çš„ product åç§°å’Œæ˜¾å­˜\n",
    "                    gpu_info_lines = []\n",
    "                    current_gpu = {}\n",
    "                    for line in result_lshw.stdout.splitlines():\n",
    "                        if 'product:' in line:\n",
    "                             if current_gpu:\n",
    "                                 gpu_info_lines.append(f\"{current_gpu.get('product', 'GPU')} ({current_gpu.get('memory', 'N/A')})\")\n",
    "                             current_gpu = {'product': line.split('product:')[1].strip()}\n",
    "                        elif 'size:' in line and 'memory' in line:\n",
    "                             current_gpu['memory'] = line.split('size:')[1].strip()\n",
    "\n",
    "                    if current_gpu: # æ·»åŠ æœ€åä¸€ä¸ª GPU çš„ä¿¡æ¯\n",
    "                        gpu_info_lines.append(f\"{current_gpu.get('product', 'GPU')} ({current_gpu.get('memory', 'N/A')})\")\n",
    "\n",
    "                    return \", \".join(gpu_info_lines) if gpu_info_lines else \"GPU found (via lshw), but info not parsed\" # å¦‚æœæ‰¾åˆ° GPU ä½†ä¿¡æ¯æ— æ³•è§£æï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "                else:\n",
    "                    return \"No GPU found (checked nvidia-smi and lshw)\" # å¦‚æœä¸¤ä¸ªå‘½ä»¤éƒ½æ‰¾ä¸åˆ° GPUï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "            except FileNotFoundError:\n",
    "                 return \"No GPU found (checked nvidia-smi, lshw not found)\" # å¦‚æœæ‰¾ä¸åˆ° lshw å‘½ä»¤ï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "    except FileNotFoundError:\n",
    "        return \"No GPU found (nvidia-smi not found)\" # å¦‚æœæ‰¾ä¸åˆ° nvidia-smi å‘½ä»¤ï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "\n",
    "\n",
    "# è·å– CUDA ç‰ˆæœ¬çš„å‡½æ•°\n",
    "def get_cuda_version():\n",
    "    try:\n",
    "        # å°è¯•ä½¿ç”¨ nvcc --version è·å– CUDA ç‰ˆæœ¬\n",
    "        result = subprocess.run(['nvcc', '--version'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # å¦‚æœå‘½ä»¤æˆåŠŸæ‰§è¡Œ\n",
    "            for line in result.stdout.splitlines():\n",
    "                if 'release' in line: # æŸ¥æ‰¾åŒ…å« 'release' çš„è¡Œ\n",
    "                    return line.split('release ')[1].split(',')[0] # è§£æè¡Œï¼Œæå–ç‰ˆæœ¬å·\n",
    "        return \"CUDA not found or version not parsed\" # å¦‚æœæ‰¾ä¸åˆ° CUDA æˆ–ç‰ˆæœ¬æ— æ³•è§£æï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "    except FileNotFoundError:\n",
    "        return \"CUDA not found\" # å¦‚æœæ‰¾ä¸åˆ° nvcc å‘½ä»¤ï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "\n",
    "# è·å– Python ç‰ˆæœ¬çš„å‡½æ•°\n",
    "def get_python_version():\n",
    "    return platform.python_version() # è·å– Python ç‰ˆæœ¬\n",
    "\n",
    "# è·å– Conda ç‰ˆæœ¬çš„å‡½æ•°\n",
    "def get_conda_version():\n",
    "    try:\n",
    "        # å°è¯•ä½¿ç”¨ conda --version è·å– Conda ç‰ˆæœ¬\n",
    "        result = subprocess.run(['conda', '--version'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # å¦‚æœå‘½ä»¤æˆåŠŸæ‰§è¡Œ\n",
    "            return result.stdout.strip() # è¿”å› Conda ç‰ˆæœ¬\n",
    "        return \"Conda not found or version not parsed\" # å¦‚æœæ‰¾ä¸åˆ° Conda æˆ–ç‰ˆæœ¬æ— æ³•è§£æï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "    except FileNotFoundError:\n",
    "        return \"Conda not found\" # å¦‚æœæ‰¾ä¸åˆ° conda å‘½ä»¤ï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "\n",
    "# è·å–ç‰©ç†ç£ç›˜ç©ºé—´ä¿¡æ¯çš„å‡½æ•°\n",
    "def get_disk_space():\n",
    "    try:\n",
    "        total, used, free = shutil.disk_usage(\"/\") # è·å–æ ¹ç›®å½•çš„ç£ç›˜ä½¿ç”¨æƒ…å†µ\n",
    "        total_gb = total / (1024**3) # è½¬æ¢ä¸º GB\n",
    "        used_gb = used / (1024**3) # è½¬æ¢ä¸º GB\n",
    "        free_gb = free / (1024**3) # è½¬æ¢ä¸º GB\n",
    "        return f\"Total: {total_gb:.2f} GB, Used: {used_gb:.2f} GB, Free: {free_gb:.2f} GB\" # æ ¼å¼åŒ–è¾“å‡º\n",
    "    except Exception as e:\n",
    "        return f\"Could not retrieve disk info: {e}\" # å¦‚æœè·å–ä¿¡æ¯å‡ºé”™ï¼Œè®¾ç½®é”™è¯¯ä¿¡æ¯\n",
    "\n",
    "# è·å–ç¯å¢ƒä¿¡æ¯\n",
    "os_name = platform.system() # è·å–æ“ä½œç³»ç»Ÿåç§°\n",
    "os_version = platform.release() # è·å–æ“ä½œç³»ç»Ÿç‰ˆæœ¬\n",
    "if os_name == \"Linux\":\n",
    "    try:\n",
    "        # åœ¨ Linux ä¸Šå°è¯•è·å–å‘è¡Œç‰ˆå’Œç‰ˆæœ¬\n",
    "        lsb_info = subprocess.run(['lsb_release', '-a'], capture_output=True, text=True)\n",
    "        if lsb_info.returncode == 0: # å¦‚æœå‘½ä»¤æˆåŠŸæ‰§è¡Œ\n",
    "            for line in lsb_info.stdout.splitlines():\n",
    "                if 'Description:' in line: # æŸ¥æ‰¾åŒ…å« 'Description:' çš„è¡Œ\n",
    "                    os_version = line.split('Description:')[1].strip() # æå–æè¿°ä¿¡æ¯ä½œä¸ºç‰ˆæœ¬\n",
    "                    break # æ‰¾åˆ°åé€€å‡ºå¾ªç¯\n",
    "                elif 'Release:' in line: # æŸ¥æ‰¾åŒ…å« 'Release:' çš„è¡Œ\n",
    "                     os_version = line.split('Release:')[1].strip() # æå–ç‰ˆæœ¬å·\n",
    "                     # å°è¯•è·å– codename\n",
    "                     try:\n",
    "                         codename_info = subprocess.run(['lsb_release', '-c'], capture_output=True, text=True)\n",
    "                         if codename_info.returncode == 0:\n",
    "                             os_version += f\" ({codename_info.stdout.split(':')[1].strip()})\" # å°† codename æ·»åŠ åˆ°ç‰ˆæœ¬ä¿¡æ¯ä¸­\n",
    "                     except:\n",
    "                         pass # å¦‚æœè·å– codename å¤±è´¥åˆ™å¿½ç•¥\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        pass # lsb_release å¯èƒ½æœªå®‰è£…ï¼Œå¿½ç•¥é”™è¯¯\n",
    "\n",
    "full_os_info = f\"{os_name} {os_version}\" # ç»„åˆå®Œæ•´çš„æ“ä½œç³»ç»Ÿä¿¡æ¯\n",
    "cpu_info = get_cpu_info() # è°ƒç”¨å‡½æ•°è·å– CPU ä¿¡æ¯å’Œæ ¸å¿ƒæ•°é‡\n",
    "memory_info = get_memory_info() # è°ƒç”¨å‡½æ•°è·å–å†…å­˜ä¿¡æ¯\n",
    "gpu_info = get_gpu_info() # è°ƒç”¨å‡½æ•°è·å– GPU ä¿¡æ¯å’Œæ˜¾å­˜\n",
    "cuda_version = get_cuda_version() # è°ƒç”¨å‡½æ•°è·å– CUDA ç‰ˆæœ¬\n",
    "python_version = get_python_version() # è°ƒç”¨å‡½æ•°è·å– Python ç‰ˆæœ¬\n",
    "conda_version = get_conda_version() # è°ƒç”¨å‡½æ•°è·å– Conda ç‰ˆæœ¬\n",
    "disk_info = get_disk_space() # è°ƒç”¨å‡½æ•°è·å–ç‰©ç†ç£ç›˜ç©ºé—´ä¿¡æ¯\n",
    "\n",
    "\n",
    "# åˆ›å»ºç”¨äºå­˜å‚¨æ•°æ®çš„å­—å…¸\n",
    "env_data = {\n",
    "    \"é¡¹ç›®\": [ # é¡¹ç›®åç§°åˆ—è¡¨\n",
    "        \"æ“ä½œç³»ç»Ÿ\",\n",
    "        \"CPU ä¿¡æ¯\",\n",
    "        \"å†…å­˜ä¿¡æ¯\",\n",
    "        \"GPU ä¿¡æ¯\",\n",
    "        \"CUDA ä¿¡æ¯\",\n",
    "        \"Python ç‰ˆæœ¬\",\n",
    "        \"Conda ç‰ˆæœ¬\",\n",
    "        \"ç‰©ç†ç£ç›˜ç©ºé—´\" # æ·»åŠ ç‰©ç†ç£ç›˜ç©ºé—´\n",
    "    ],\n",
    "    \"ä¿¡æ¯\": [ # å¯¹åº”çš„ä¿¡æ¯åˆ—è¡¨\n",
    "        full_os_info,\n",
    "        cpu_info,\n",
    "        memory_info,\n",
    "        gpu_info,\n",
    "        cuda_version,\n",
    "        python_version,\n",
    "        conda_version,\n",
    "        disk_info # æ·»åŠ ç‰©ç†ç£ç›˜ç©ºé—´ä¿¡æ¯\n",
    "    ]\n",
    "}\n",
    "\n",
    "# åˆ›å»ºä¸€ä¸ª pandas DataFrame\n",
    "df = pd.DataFrame(env_data)\n",
    "\n",
    "# æ‰“å°è¡¨æ ¼\n",
    "print(\"### ç¯å¢ƒä¿¡æ¯\") # æ‰“å°æ ‡é¢˜\n",
    "print(df.to_markdown(index=False)) # å°† DataFrame è½¬æ¢ä¸º Markdown æ ¼å¼å¹¶æ‰“å°ï¼Œä¸åŒ…å«ç´¢å¼•\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G2_SkHQMwIsZ"
   },
   "source": [
    "<!-- NOTEBOOK_METADATA source: \"Jupyter Notebook\" title: \"Example - Trace and Evaluate LangGraph Agents\" description: \"This guide shows how to evaluate LangGraph Agents with Langfuse using online and offline evaluation methods.\" category: \"Integrations\" -->\n",
    "\n",
    "# LangGraph Agentè¿½è¸ªä¸è¯„ä¼°å®Œæ•´æŒ‡å—\n",
    "\n",
    "## ğŸ“– æ•™ç¨‹æ¦‚è¿°\n",
    "\n",
    "åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†æ·±å…¥å­¦ä¹ å¦‚ä½•ä½¿ç”¨ [Langfuse](https://langfuse.com)ï¼ˆä¸€ä¸ªå¼ºå¤§çš„å¤§æ¨¡å‹å¯è§‚æµ‹æ€§å¹³å°ï¼‰ä¸ [Hugging Face Datasets](https://huggingface.co/datasets)ï¼Œæ¥**å…¨é¢ç›‘æ§ [LangGraph Agent](https://github.com/langchain-ai/langgraph) çš„æ‰§è¡Œè¿‡ç¨‹ï¼ˆtracesï¼‰**å¹¶**ç§‘å­¦è¯„ä¼°å…¶æ€§èƒ½è¡¨ç°**ã€‚\n",
    "\n",
    "## ğŸ¯ å­¦ä¹ ç›®æ ‡\n",
    "\n",
    "æœ¬æŒ‡å—å°†å¸®åŠ©ä½ æŒæ¡å°† AI Agentå¿«é€Ÿä¸”å¯é åœ°éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒæ‰€éœ€çš„æ ¸å¿ƒæŠ€èƒ½ï¼š\n",
    "- **åœ¨çº¿è¯„ä¼°**ï¼šå®æ—¶ç›‘æ§ç”Ÿäº§ç¯å¢ƒä¸­çš„Agentè¡¨ç°\n",
    "- **ç¦»çº¿è¯„ä¼°**ï¼šä½¿ç”¨åŸºå‡†æ•°æ®é›†è¿›è¡Œç³»ç»Ÿæ€§æµ‹è¯•\n",
    "\n",
    "\n",
    "## ğŸ” ä¸ºä»€ä¹ˆ AI Agentè¯„ä¼°å¦‚æ­¤é‡è¦ï¼Ÿ\n",
    "\n",
    "åœ¨ AI Agentå¼€å‘è¿‡ç¨‹ä¸­ï¼Œè¯„ä¼°æ˜¯ç¡®ä¿ç³»ç»Ÿè´¨é‡çš„å…³é”®ç¯èŠ‚ï¼š\n",
    "\n",
    "- **ğŸ› é—®é¢˜è¯Šæ–­**ï¼šå½“Agentä»»åŠ¡æ‰§è¡Œå¤±è´¥æˆ–ç»“æœä¸ç†æƒ³æ—¶ï¼Œèƒ½å¤Ÿå¿«é€Ÿå®šä½é—®é¢˜æ ¹æº\n",
    "- **ğŸ“Š æ€§èƒ½ç›‘æ§**ï¼šå®æ—¶è¿½è¸ªç³»ç»Ÿçš„æˆæœ¬æ¶ˆè€—ã€å“åº”å»¶è¿Ÿç­‰å…³é”®æŒ‡æ ‡\n",
    "- **ğŸ”„ æŒç»­æ”¹è¿›**ï¼šé€šè¿‡ç”¨æˆ·åé¦ˆå’Œè¯„ä¼°æ•°æ®ï¼Œä¸æ–­æå‡Agentçš„å¯é æ€§ä¸å®‰å…¨æ€§\n",
    "- **ğŸš€ ç”Ÿäº§å°±ç»ª**ï¼šç¡®ä¿Agentåœ¨çœŸå®ç¯å¢ƒä¸­èƒ½å¤Ÿç¨³å®šè¿è¡Œ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZzPbsmLrfoSN"
   },
   "source": [
    "## ğŸ› ï¸ æ­¥éª¤ 0ï¼šç¯å¢ƒå‡†å¤‡ä¸ä¾èµ–å®‰è£…\n",
    "\n",
    "### ğŸ“¦ å®‰è£…æ ¸å¿ƒä¾èµ–åº“\n",
    "\n",
    "åœ¨å¼€å§‹æœ¬æ•™ç¨‹ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦å®‰è£…ä»¥ä¸‹æ ¸å¿ƒåº“ï¼š\n",
    "\n",
    "- **`langgraph`**ï¼šç”¨äºæ„å»ºå¤šèŠ‚ç‚¹ã€çŠ¶æ€é©±åŠ¨çš„ AI Agentå·¥ä½œæµ\n",
    "- **`langfuse`**ï¼šæä¾›å¤§æ¨¡å‹åº”ç”¨çš„å¯è§‚æµ‹æ€§å’Œè¯„ä¼°åŠŸèƒ½  \n",
    "- **`langchain`** ç³»åˆ—ï¼šç”¨äº LLM åº”ç”¨å¼€å‘çš„æ ¸å¿ƒæ¡†æ¶\n",
    "- **`datasets`**ï¼šHugging Face çš„æ•°æ®é›†å¤„ç†åº“\n",
    "\n",
    "\n",
    "<!-- CALLOUT_START type: \"info\" emoji: \"âš ï¸\" -->\n",
    "**ğŸ“Œ é‡è¦æç¤ºï¼š**\n",
    "- æœ¬æ•™ç¨‹ä½¿ç”¨ **Langfuse Python SDK v3**ï¼Œå®ƒæä¾›äº†æ›´å¥½çš„æ€§èƒ½å’Œæ–°ç‰¹æ€§\n",
    "- å»ºè®®åœ¨è™šæ‹Ÿç¯å¢ƒä¸­è¿è¡Œæœ¬æ•™ç¨‹ä»¥é¿å…ä¾èµ–å†²çª\n",
    "<!-- CALLOUT_END -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_EI_0ZfzfoSO",
    "outputId": "d4418732-c65a-41cd-a7b3-931838ea85d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: langfuse==3.3.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (3.3.0)\n",
      "Requirement already satisfied: langchain==0.3.27 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (0.3.27)\n",
      "Requirement already satisfied: langgraph==0.6.7 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (0.6.7)\n",
      "Requirement already satisfied: langchain-openai==0.3.31 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (0.3.31)\n",
      "Requirement already satisfied: langchain_community==0.3.27 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (0.3.27)\n",
      "Requirement already satisfied: langchain_huggingface==0.3.1 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (0.3.1)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langfuse==3.3.0) (2.2.1)\n",
      "Requirement already satisfied: httpx<1.0,>=0.15.4 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langfuse==3.3.0) (0.28.1)\n",
      "Requirement already satisfied: opentelemetry-api<2.0.0,>=1.33.1 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langfuse==3.3.0) (1.38.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langfuse==3.3.0) (1.38.0)\n",
      "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.33.1 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langfuse==3.3.0) (1.38.0)\n",
      "Requirement already satisfied: packaging<26.0,>=23.2 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langfuse==3.3.0) (25.0)\n",
      "Requirement already satisfied: pydantic<3.0,>=1.10.7 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langfuse==3.3.0) (2.11.9)\n",
      "Requirement already satisfied: requests<3,>=2 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langfuse==3.3.0) (2.32.5)\n",
      "Requirement already satisfied: wrapt<2.0,>=1.14 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langfuse==3.3.0) (1.17.3)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langchain==0.3.27) (0.3.75)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langchain==0.3.27) (0.3.9)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langchain==0.3.27) (0.4.34)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langchain==0.3.27) (2.0.44)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langchain==0.3.27) (6.0.3)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langchain==0.3.27) (4.0.3)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.1.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langgraph==0.6.7) (2.1.2)\n",
      "Requirement already satisfied: langgraph-prebuilt<0.7.0,>=0.6.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langgraph==0.6.7) (0.6.4)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langgraph==0.6.7) (0.2.6)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langgraph==0.6.7) (3.6.0)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.99.9 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langchain-openai==0.3.31) (1.107.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langchain-openai==0.3.31) (0.11.0)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langchain_community==0.3.27) (3.13.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langchain_community==0.3.27) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langchain_community==0.3.27) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langchain_community==0.3.27) (2.11.0)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langchain_community==0.3.27) (0.4.2)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langchain_community==0.3.27) (2.2.6)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langchain_huggingface==0.3.1) (0.21.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.33.4 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langchain_huggingface==0.3.1) (0.36.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27) (1.22.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community==0.3.27) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community==0.3.27) (0.9.0)\n",
      "Requirement already satisfied: anyio in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from httpx<1.0,>=0.15.4->langfuse==3.3.0) (4.11.0)\n",
      "Requirement already satisfied: certifi in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from httpx<1.0,>=0.15.4->langfuse==3.3.0) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from httpx<1.0,>=0.15.4->langfuse==3.3.0) (1.0.9)\n",
      "Requirement already satisfied: idna in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from httpx<1.0,>=0.15.4->langfuse==3.3.0) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from httpcore==1.*->httpx<1.0,>=0.15.4->langfuse==3.3.0) (0.16.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain==0.3.27) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain==0.3.27) (4.14.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain==0.3.27) (3.0.0)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph==0.6.7) (1.11.0)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph==0.6.7) (3.11.3)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from openai<2.0.0,>=1.99.9->langchain-openai==0.3.31) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from openai<2.0.0,>=1.99.9->langchain-openai==0.3.31) (0.11.0)\n",
      "Requirement already satisfied: sniffio in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from openai<2.0.0,>=1.99.9->langchain-openai==0.3.31) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from openai<2.0.0,>=1.99.9->langchain-openai==0.3.31) (4.67.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from anyio->httpx<1.0,>=0.15.4->langfuse==3.3.0) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from opentelemetry-api<2.0.0,>=1.33.1->langfuse==3.3.0) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api<2.0.0,>=1.33.1->langfuse==3.3.0) (3.23.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0) (1.70.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.38.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0) (1.38.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.38.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0) (1.38.0)\n",
      "Requirement already satisfied: protobuf<7.0,>=5.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from opentelemetry-proto==1.38.0->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0) (5.29.5)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.59b0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from opentelemetry-sdk<2.0.0,>=1.33.1->langfuse==3.3.0) (0.59b0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from pydantic<3.0,>=1.10.7->langfuse==3.3.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from pydantic<3.0,>=1.10.7->langfuse==3.3.0) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from pydantic<3.0,>=1.10.7->langfuse==3.3.0) (0.4.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community==0.3.27) (1.1.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from requests<3,>=2->langfuse==3.3.0) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from requests<3,>=2->langfuse==3.3.0) (2.5.0)\n",
      "Requirement already satisfied: greenlet>=1 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.27) (3.2.4)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from tiktoken<1,>=0.7->langchain-openai==0.3.31) (2024.11.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community==0.3.27) (1.1.0)\n",
      "Requirement already satisfied: filelock in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from huggingface-hub>=0.33.4->langchain_huggingface==0.3.1) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from huggingface-hub>=0.33.4->langchain_huggingface==0.3.1) (2025.9.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from huggingface-hub>=0.33.4->langchain_huggingface==0.3.1) (1.1.10)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langsmith>=0.1.17->langchain==0.3.27) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langsmith>=0.1.17->langchain==0.3.27) (0.25.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“¦ å®‰è£…æ‰€éœ€çš„PythonåŒ…\n",
    "# ä½¿ç”¨é­”æ³•å‘½ä»¤ %pip åœ¨Jupyterç¯å¢ƒä¸­å®‰è£…ä¾èµ–åº“\n",
    "%pip install langfuse==3.3.0 langchain==0.3.27 langgraph==0.6.7 langchain-openai==0.3.31 langchain_community==0.3.27 langchain_huggingface==0.3.1\n",
    "\n",
    "# å„åº“åŠŸèƒ½è¯´æ˜ï¼š\n",
    "# - langfuse: LLMåº”ç”¨çš„å¯è§‚æµ‹æ€§å’Œè¯„ä¼°å¹³å°\n",
    "# - langchain: å¤§è¯­è¨€æ¨¡å‹åº”ç”¨å¼€å‘æ¡†æ¶\n",
    "# - langgraph: åŸºäºlangchainçš„å›¾å½¢åŒ–å·¥ä½œæµæ„å»ºå·¥å…·\n",
    "# - langchain_openai: OpenAIæ¨¡å‹çš„langchainé›†æˆ\n",
    "# - langchain_community: ç¤¾åŒºè´¡çŒ®çš„langchainæ‰©å±•\n",
    "# - langchain_huggingface: Hugging Faceæ¨¡å‹çš„langchainé›†æˆ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FHRsxz1VfoSP"
   },
   "source": [
    "## ğŸ”‘ 1ï¼šé…ç½® API å¯†é’¥å’Œç¯å¢ƒå˜é‡\n",
    "\n",
    "### è·å– Langfuse API å¯†é’¥\n",
    "\n",
    "åœ¨å¼€å§‹ä½¿ç”¨ Langfuse ä¹‹å‰ï¼Œä½ éœ€è¦è·å– API è®¿é—®å‡­è¯ï¼š\n",
    "\n",
    "#### æ–¹æ¡ˆä¸€ï¼šä½¿ç”¨ Langfuse Cloudï¼ˆæ¨èï¼‰\n",
    "1. è®¿é—® [Langfuse Cloud](https://cloud.langfuse.com) å¹¶æ³¨å†Œè´¦æˆ·\n",
    "2. åˆ›å»ºæ–°é¡¹ç›®æˆ–é€‰æ‹©ç°æœ‰é¡¹ç›®\n",
    "3. åœ¨é¡¹ç›®è®¾ç½®é¡µé¢è·å–ä»¥ä¸‹å¯†é’¥ï¼š\n",
    "   - `LANGFUSE_PUBLIC_KEY`ï¼šä»¥ `pk-lf-` å¼€å¤´çš„å…¬é’¥\n",
    "   - `LANGFUSE_SECRET_KEY`ï¼šä»¥ `sk-lf-` å¼€å¤´çš„ç§é’¥\n",
    "\n",
    "#### æ–¹æ¡ˆäºŒï¼šè‡ªæ‰˜ç®¡ Langfuse\n",
    "å¦‚æœä½ é€‰æ‹©è‡ªæ‰˜ç®¡éƒ¨ç½²ï¼Œè¯·æŒ‰ç…§ [Langfuse è‡ªæ‰˜ç®¡æ–‡æ¡£](https://langfuse.com/docs/deployment/self-host) è¿›è¡Œé…ç½®ã€‚\n",
    "\n",
    "### è·å– OpenAI API å¯†é’¥\n",
    "\n",
    "1. è®¿é—® [OpenAI å¹³å°](https://platform.openai.com/)\n",
    "2. æ³¨å†Œè´¦æˆ·å¹¶å®Œæˆèº«ä»½éªŒè¯\n",
    "3. åœ¨ API å¯†é’¥é¡µé¢åˆ›å»ºæ–°çš„ API å¯†é’¥\n",
    "4. ç¡®ä¿è´¦æˆ·æœ‰è¶³å¤Ÿçš„ä½™é¢ç”¨äº API è°ƒç”¨\n",
    "\n",
    "### ğŸ” å®‰å…¨æé†’\n",
    "\n",
    "- **è¯·å‹¿å°† API å¯†é’¥ç¡¬ç¼–ç åœ¨ä»£ç ä¸­**\n",
    "- **ç”Ÿäº§ç¯å¢ƒå»ºè®®ä½¿ç”¨ç¯å¢ƒå˜é‡æˆ–å¯†é’¥ç®¡ç†ç³»ç»Ÿ**\n",
    "- **å®šæœŸè½®æ¢å¯†é’¥ä»¥æé«˜å®‰å…¨æ€§**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mZnxtWx9foSP",
    "outputId": "cbabe0f0-49e2-4500-8b9a-b43baaa5cc17"
   },
   "outputs": [],
   "source": [
    "# ğŸ” ç¯å¢ƒå˜é‡é…ç½® - å®‰å…¨å­˜å‚¨æ•æ„Ÿä¿¡æ¯\n",
    "# ç¯å¢ƒå˜é‡æ˜¯å­˜å‚¨APIå¯†é’¥ç­‰æ•æ„Ÿä¿¡æ¯çš„ä¼˜ç§€åšæ³•\n",
    "# é¿å…åœ¨ä»£ç ä¸­ç¡¬ç¼–ç å¯†é’¥ï¼Œé˜²æ­¢æ³„éœ²\n",
    "\n",
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    \"\"\"\n",
    "    å®‰å…¨åœ°è®¾ç½®ç¯å¢ƒå˜é‡\n",
    "    å¦‚æœç¯å¢ƒå˜é‡ä¸å­˜åœ¨ï¼Œä¼šæç¤ºç”¨æˆ·è¾“å…¥\n",
    "    ä½¿ç”¨getpassæ¨¡å—éšè—è¾“å…¥å†…å®¹ï¼Œé˜²æ­¢å¯†ç æ³„éœ²\n",
    "    \"\"\"\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "# ğŸ¤– OpenAI API é…ç½®\n",
    "# OpenAI APIå¯†é’¥ï¼šä» https://platform.openai.com/api-keys è·å–\n",
    "# è¿™æ˜¯è°ƒç”¨GPTæ¨¡å‹å¿…éœ€çš„è®¤è¯ä¿¡æ¯\n",
    "_set_env(\"OPENAI_API_KEY\")\n",
    "\n",
    "# APIAgentåœ°å€ï¼šå¦‚æœä½ ä½¿ç”¨ç¬¬ä¸‰æ–¹AgentæœåŠ¡ï¼ˆå¦‚å›½å†…Agentï¼‰\n",
    "# ç¤ºä¾‹ï¼šhttps://api.apiyi.com/v1\n",
    "# å¦‚æœç›´æ¥ä½¿ç”¨OpenAIå®˜æ–¹APIï¼Œå¯ä»¥ç•™ç©º\n",
    "_set_env(\"OPENAI_BASE_URL\")\n",
    "\n",
    "# ğŸŒ Langfuse é…ç½®\n",
    "# Langfuseæ˜¯ä¸€ä¸ªå¯è§‚æµ‹æ€§å¹³å°ï¼Œéœ€è¦æ³¨å†Œè´¦æˆ·è·å–å¯†é’¥\n",
    "# æ³¨å†Œåœ°å€ï¼šhttps://cloud.langfuse.com\n",
    "\n",
    "# å…¬å¼€å¯†é’¥ï¼šç”¨äºæ ‡è¯†ä½ çš„é¡¹ç›®\n",
    "_set_env(\"LANGFUSE_PUBLIC_KEY\")\n",
    "\n",
    "# ç§˜å¯†å¯†é’¥ï¼šç”¨äºè®¤è¯ï¼Œè¯·å¦¥å–„ä¿ç®¡\n",
    "_set_env(\"LANGFUSE_SECRET_KEY\")\n",
    "\n",
    "# æœåŠ¡å™¨åœ°å€ï¼šé€‰æ‹©ç¦»ä½ æœ€è¿‘çš„åŒºåŸŸ\n",
    "# ğŸ‡ªğŸ‡º æ¬§ç›ŸåŒºåŸŸ(æ¨è) https://cloud.langfuse.com\n",
    "# ğŸ‡ºğŸ‡¸ ç¾å›½åŒºåŸŸ https://us.cloud.langfuse.com\n",
    "_set_env(\"LANGFUSE_HOST\")\n",
    "\n",
    "# ğŸ’¡ åˆå­¦è€…æç¤ºï¼š\n",
    "# 1. ç¯å¢ƒå˜é‡å­˜å‚¨åœ¨æ“ä½œç³»ç»Ÿä¸­ï¼Œé‡å¯åéœ€è¦é‡æ–°è®¾ç½®\n",
    "# 2. ç”Ÿäº§ç¯å¢ƒä¸­å»ºè®®ä½¿ç”¨.envæ–‡ä»¶æˆ–äº‘æœåŠ¡é…ç½®\n",
    "# 3. æ°¸è¿œä¸è¦åœ¨ä»£ç ä¸­ç¡¬ç¼–ç APIå¯†é’¥ï¼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OJjyA41_wIsi"
   },
   "source": [
    "### ğŸ”— è¿æ¥éªŒè¯ä¸å®¢æˆ·ç«¯åˆå§‹åŒ–\n",
    "\n",
    "è®¾ç½®å®Œç¯å¢ƒå˜é‡åï¼Œæˆ‘ä»¬éœ€è¦åˆå§‹åŒ– Langfuse å®¢æˆ·ç«¯å¹¶éªŒè¯è¿æ¥ã€‚\n",
    "\n",
    "**æ ¸å¿ƒæ¦‚å¿µè§£é‡Šï¼š**\n",
    "- **`get_client()`**ï¼šLangfuse æä¾›çš„ä¾¿æ·å‡½æ•°ï¼Œä¼šè‡ªåŠ¨è¯»å–ç¯å¢ƒå˜é‡ä¸­çš„å‡­è¯\n",
    "- **å®¢æˆ·ç«¯å®ä¾‹**ï¼šç”¨äºä¸ Langfuse æœåŠ¡å™¨é€šä¿¡çš„å¯¹è±¡\n",
    "- **è¿æ¥éªŒè¯**ï¼šç¡®ä¿ API å¯†é’¥æ­£ç¡®ä¸”ç½‘ç»œè¿æ¥æ­£å¸¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gvQRomm-wIsi",
    "outputId": "0fb60071-bc52-4d90-a487-5cb0bf3ff3c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Langfuse å®¢æˆ·ç«¯è¿æ¥æˆåŠŸï¼API è®¤è¯é€šè¿‡\n",
      "ğŸ¯ ç°åœ¨å¯ä»¥å¼€å§‹è¿½è¸ªå’Œè¯„ä¼° LLM åº”ç”¨äº†\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“¡ å¯¼å…¥ Langfuse å®¢æˆ·ç«¯å¹¶å»ºç«‹è¿æ¥\n",
    "from langfuse import get_client\n",
    "\n",
    "# ğŸ”§ åˆå§‹åŒ– Langfuse å®¢æˆ·ç«¯\n",
    "# get_client() ä¼šè‡ªåŠ¨ä»ç¯å¢ƒå˜é‡ä¸­è¯»å– API å‡­è¯\n",
    "langfuse = get_client()\n",
    "\n",
    "# âœ… éªŒè¯ API è¿æ¥å’Œèº«ä»½è®¤è¯\n",
    "# auth_check() æ–¹æ³•ä¼šæµ‹è¯•ä¸ Langfuse æœåŠ¡å™¨çš„è¿æ¥\n",
    "if langfuse.auth_check():\n",
    "    print(\"âœ… Langfuse å®¢æˆ·ç«¯è¿æ¥æˆåŠŸï¼API è®¤è¯é€šè¿‡\")\n",
    "    print(\"ğŸ¯ ç°åœ¨å¯ä»¥å¼€å§‹è¿½è¸ªå’Œè¯„ä¼° LLM åº”ç”¨äº†\")\n",
    "else:\n",
    "    print(\"âŒ è®¤è¯å¤±è´¥ï¼è¯·æ£€æŸ¥ä»¥ä¸‹é¡¹ç›®ï¼š\")\n",
    "    print(\"   1. API å¯†é’¥æ˜¯å¦æ­£ç¡®è®¾ç½®\")\n",
    "    print(\"   2. æœåŠ¡å™¨åœ°å€æ˜¯å¦æ­£ç¡®\")\n",
    "    print(\"   3. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "onjMD-ZJfoSQ"
   },
   "source": [
    "## ğŸ”¬ 2ï¼šæ„å»ºå¹¶è§‚æµ‹å¤æ‚çš„é‚®ä»¶å¤„ç†Agent\n",
    "\n",
    "### ğŸ¯ è¿›é˜¶å®æˆ˜ï¼šçœŸå®ä¸šåŠ¡åœºæ™¯æ¨¡æ‹Ÿ\n",
    "\n",
    "ç°åœ¨æˆ‘ä»¬æ¥æ„å»ºä¸€ä¸ªæ›´åŠ å¤æ‚ä¸”è´´è¿‘å®é™…ä¸šåŠ¡åœºæ™¯çš„Agentç³»ç»Ÿã€‚\n",
    "\n",
    "### ğŸ“§ ä¸šåŠ¡åœºæ™¯ï¼šæ™ºèƒ½é‚®ä»¶ç®¡ç†åŠ©æ‰‹\n",
    "\n",
    "æˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ª**é‚®ä»¶å¤„ç†Agent**ï¼Œå…·å¤‡ä»¥ä¸‹åŠŸèƒ½ï¼š\n",
    "\n",
    "#### ğŸ”§ æ ¸å¿ƒåŠŸèƒ½æ¨¡å—\n",
    "- **ğŸ“¬ é‚®ä»¶æ¥æ”¶**ï¼šè¯»å–å’Œè§£æé‚®ä»¶å†…å®¹\n",
    "- **ğŸ” åƒåœ¾é‚®ä»¶è¯†åˆ«**ï¼šæ™ºèƒ½åˆ¤æ–­é‚®ä»¶æ˜¯å¦ä¸ºåƒåœ¾é‚®ä»¶\n",
    "- **ğŸ—‚ï¸ è‡ªåŠ¨åˆ†ç±»**ï¼šå¯¹åˆæ³•é‚®ä»¶è¿›è¡Œåˆ†ç±»å¤„ç†\n",
    "- **âœï¸ å›å¤èµ·è‰**ï¼šä¸ºé‡è¦é‚®ä»¶ç”Ÿæˆå›å¤è‰ç¨¿\n",
    "- **ğŸ“¢ é€šçŸ¥ä¸»äºº**ï¼šå‘éŸ¦æ©å…ˆç”Ÿæ±‡æŠ¥é‡è¦é‚®ä»¶\n",
    "\n",
    "#### ğŸ“Š è¿½è¸ªçš„é«˜çº§æŒ‡æ ‡\n",
    "\n",
    "é€šè¿‡è¿™ä¸ªå¤æ‚Agentï¼Œæˆ‘ä»¬å°†è§‚å¯Ÿä»¥ä¸‹å…³é”®æŒ‡æ ‡ï¼š\n",
    "- **ğŸ’° æˆæœ¬è¿½è¸ª**ï¼šè¯¦ç»†çš„ä»¤ç‰Œæ¶ˆè€—å’Œ API è´¹ç”¨\n",
    "- **â±ï¸ æ€§èƒ½åˆ†æ**ï¼šæ¯ä¸ªå¤„ç†æ­¥éª¤çš„è€—æ—¶åˆ†å¸ƒ\n",
    "- **ğŸ”„ å·¥ä½œæµè·¯å¾„**ï¼šAgentçš„å†³ç­–é€»è¾‘å’Œæ‰§è¡Œè·¯å¾„\n",
    "- **âŒ é”™è¯¯ç›‘æ§**ï¼šå¼‚å¸¸æƒ…å†µçš„æ•è·å’Œåˆ†æ\n",
    "\n",
    "### ğŸ—ï¸ æŠ€æœ¯æ¶æ„ç‰¹ç‚¹\n",
    "\n",
    "- **çŠ¶æ€é©±åŠ¨**ï¼šä½¿ç”¨ LangGraph çš„çŠ¶æ€ç®¡ç†æœºåˆ¶\n",
    "- **æ¡ä»¶åˆ†æ”¯**ï¼šæ ¹æ®é‚®ä»¶ç±»å‹æ‰§è¡Œä¸åŒçš„å¤„ç†é€»è¾‘\n",
    "- **å¤šèŠ‚ç‚¹åä½œ**ï¼šæ¨¡æ‹ŸçœŸå®çš„ä¸šåŠ¡å¤„ç†æµç¨‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VhZyuiZNwIsj",
    "outputId": "66f2befe-309e-4f09-d675-405a64dcebbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“š åº“å¯¼å…¥å®Œæˆï¼Œå‡†å¤‡æ„å»ºé‚®ä»¶å¤„ç†Agent...\n",
      "ğŸ”§ å³å°†ä½¿ç”¨çš„æ ¸å¿ƒç»„ä»¶ï¼š\n",
      "   - StateGraph: æ„å»ºçŠ¶æ€é©±åŠ¨çš„å·¥ä½œæµ\n",
      "   - ChatOpenAI: è°ƒç”¨ GPT æ¨¡å‹è¿›è¡Œæ™ºèƒ½å¤„ç†\n",
      "   - TypedDict: å®šä¹‰ä¸¥æ ¼çš„æ•°æ®ç»“æ„\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“¦ å¯¼å…¥æ„å»ºå¤æ‚Agentæ‰€éœ€çš„åº“\n",
    "\n",
    "import os  # æ“ä½œç³»ç»Ÿæ¥å£ï¼Œç”¨äºç¯å¢ƒå˜é‡ç®¡ç†\n",
    "from typing import TypedDict, List, Dict, Any, Optional  # ç±»å‹æ³¨è§£ï¼Œæé«˜ä»£ç å¯è¯»æ€§å’ŒIDEæ”¯æŒ\n",
    "from langgraph.graph import StateGraph, START, END  # LangGraphæ ¸å¿ƒç»„ä»¶ï¼šçŠ¶æ€å›¾ã€å¼€å§‹èŠ‚ç‚¹ã€ç»“æŸèŠ‚ç‚¹\n",
    "from langchain_openai import ChatOpenAI  # OpenAIæ¨¡å‹çš„LangChainé›†æˆ\n",
    "from langchain_core.messages import HumanMessage  # LangChainæ¶ˆæ¯ç±»å‹\n",
    "\n",
    "print(\"ğŸ“š åº“å¯¼å…¥å®Œæˆï¼Œå‡†å¤‡æ„å»ºé‚®ä»¶å¤„ç†Agent...\")\n",
    "print(\"ğŸ”§ å³å°†ä½¿ç”¨çš„æ ¸å¿ƒç»„ä»¶ï¼š\")\n",
    "print(\"   - StateGraph: æ„å»ºçŠ¶æ€é©±åŠ¨çš„å·¥ä½œæµ\")\n",
    "print(\"   - ChatOpenAI: è°ƒç”¨ GPT æ¨¡å‹è¿›è¡Œæ™ºèƒ½å¤„ç†\")\n",
    "print(\"   - TypedDict: å®šä¹‰ä¸¥æ ¼çš„æ•°æ®ç»“æ„\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KbdEGxUQwIsj",
    "outputId": "f37e46ee-8c8e-467e-8fe9-7953eeb071b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… é‚®ä»¶çŠ¶æ€ç»“æ„å®šä¹‰å®Œæˆ\n",
      "ğŸ“‹ çŠ¶æ€å­—æ®µè¯´æ˜ï¼š\n",
      "   - email: åŸå§‹é‚®ä»¶æ•°æ®\n",
      "   - is_spam: åƒåœ¾é‚®ä»¶åˆ¤å®šç»“æœ\n",
      "   - draft_response: å›å¤è‰ç¨¿\n",
      "   - messages: LLMå¯¹è¯å†å²\n"
     ]
    }
   ],
   "source": [
    "# ğŸ—ï¸ å®šä¹‰é‚®ä»¶å¤„ç†Agentçš„çŠ¶æ€ç»“æ„\n",
    "\n",
    "class EmailState(TypedDict):\n",
    "    \"\"\"\n",
    "    é‚®ä»¶å¤„ç†Agentçš„çŠ¶æ€æ•°æ®ç»“æ„\n",
    "\n",
    "    è¿™ä¸ªç±»å®šä¹‰äº†Agentåœ¨å¤„ç†é‚®ä»¶è¿‡ç¨‹ä¸­éœ€è¦ç»´æŠ¤çš„æ‰€æœ‰çŠ¶æ€ä¿¡æ¯\n",
    "    \"\"\"\n",
    "    # ğŸ“§ åŸå§‹é‚®ä»¶ä¿¡æ¯\n",
    "    email: Dict[str, Any]  # åŒ…å«å‘ä»¶äººã€ä¸»é¢˜ã€æ­£æ–‡ç­‰é‚®ä»¶å®Œæ•´ä¿¡æ¯\n",
    "\n",
    "    # ğŸ” åƒåœ¾é‚®ä»¶æ£€æµ‹ç»“æœ\n",
    "    is_spam: Optional[bool]  # æ˜¯å¦ä¸ºåƒåœ¾é‚®ä»¶ï¼ˆTrue/False/Noneï¼‰\n",
    "\n",
    "    # âœï¸ å›å¤è‰ç¨¿\n",
    "    draft_response: Optional[str]  # ä¸ºä¸»äººå‡†å¤‡çš„å›å¤è‰ç¨¿\n",
    "\n",
    "    # ğŸ’¬ å¯¹è¯å†å²è®°å½•\n",
    "    messages: List[Dict[str, Any]]  # å­˜å‚¨å¤„ç†è¿‡ç¨‹ä¸­çš„LLMå¯¹è¯è®°å½•\n",
    "\n",
    "print(\"âœ… é‚®ä»¶çŠ¶æ€ç»“æ„å®šä¹‰å®Œæˆ\")\n",
    "print(\"ğŸ“‹ çŠ¶æ€å­—æ®µè¯´æ˜ï¼š\")\n",
    "print(\"   - email: åŸå§‹é‚®ä»¶æ•°æ®\")\n",
    "print(\"   - is_spam: åƒåœ¾é‚®ä»¶åˆ¤å®šç»“æœ\")\n",
    "print(\"   - draft_response: å›å¤è‰ç¨¿\")\n",
    "print(\"   - messages: LLMå¯¹è¯å†å²\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sdo7y_0mwIsj",
    "outputId": "08199035-52cb-4553-cbbb-738aa5b2e4c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7f78d64e7be0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# âœ… åˆå§‹åŒ–å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ï¼Œåç»­æ‰€æœ‰èŠ‚ç‚¹éƒ½ä¼šå¤ç”¨å®ƒè¿›è¡Œæ¨ç†\n",
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "# ğŸ” å®šä¹‰å·¥ä½œæµä¸­çš„æ¯ä¸ªèŠ‚ç‚¹å‡½æ•°\n",
    "def read_email(state: EmailState):\n",
    "    \"\"\"\n",
    "    å…¥å£èŠ‚ç‚¹ï¼šå±•ç¤ºé‚®ä»¶åŸºç¡€ä¿¡æ¯ï¼Œå¸®åŠ©æˆ‘ä»¬åœ¨å‘½ä»¤è¡Œä¸­è§‚å¯Ÿæµç¨‹ã€‚\n",
    "    \"\"\"\n",
    "    email = state[\"email\"]  # ä»çŠ¶æ€ä¸­å–å‡ºå½“å‰é‚®ä»¶\n",
    "    print(f\"é˜¿å°”å¼—é›·å¾·æ­£åœ¨å¤„ç†æ¥è‡ª {email['sender']} çš„é‚®ä»¶ï¼Œä¸»é¢˜ä¸ºï¼š{email['subject']}\")\n",
    "    return {}  # èŠ‚ç‚¹åªåšå±•ç¤ºï¼Œä¸ä¿®æ”¹çŠ¶æ€\n",
    "\n",
    "def classify_email(state: EmailState):\n",
    "    \"\"\"\n",
    "    ä½¿ç”¨ LLM åˆ¤æ–­å½“å‰é‚®ä»¶æ˜¯å¦ä¸ºåƒåœ¾é‚®ä»¶ã€‚\n",
    "    å¦‚æœæ˜¯åƒåœ¾é‚®ä»¶å°±ä¸è®°å½•æ¨¡å‹å¯¹è¯ï¼Œé¿å…æ±¡æŸ“å†å²ã€‚\n",
    "    \"\"\"\n",
    "    email = state[\"email\"]\n",
    "\n",
    "    # æ„é€ æç¤ºè¯ï¼Œå‘ LLM ä¼ å…¥é‚®ä»¶çš„æ‰€æœ‰å…³é”®ä¿¡æ¯ï¼ˆä¸­æ–‡åˆå­¦è€…å‹å¥½ç‰ˆæœ¬ï¼‰\n",
    "    prompt = f\"\"\"\n",
    "è¯·ä»¥é˜¿å°”å¼—é›·å¾·ï¼ˆAlfredï¼ŒéŸ¦æ©å…ˆç”Ÿçš„ç®¡å®¶ï¼ŒåŒæ—¶çŸ¥æ™“å…¶â€œè™è ä¾ â€èº«ä»½ï¼‰çš„è§†è§’ï¼Œåˆ†æä¸‹é¢è¿™å°é‚®ä»¶ï¼Œåˆ¤æ–­å…¶æ˜¯åƒåœ¾é‚®ä»¶ï¼ˆSPAMï¼‰è¿˜æ˜¯æ­£å¸¸é‚®ä»¶ï¼ˆHAMï¼‰ï¼Œå¹¶è¯´æ˜æ˜¯å¦éœ€è¦æé†’éŸ¦æ©å…ˆç”Ÿæ³¨æ„ã€‚\n",
    "\n",
    "é‚®ä»¶å†…å®¹ï¼š\n",
    "å‘ä»¶äººï¼ˆFromï¼‰ï¼š{email['sender']}\n",
    "ä¸»é¢˜ï¼ˆSubjectï¼‰ï¼š{email['subject']}\n",
    "æ­£æ–‡ï¼ˆBodyï¼‰ï¼š{email['body']}\n",
    "\n",
    "è¯·å…ˆåˆ¤æ–­è¿™å°é‚®ä»¶æ˜¯å¦ä¸ºåƒåœ¾é‚®ä»¶ã€‚\n",
    "åªè¿”å›ä¸€ä¸ªè‹±æ–‡å•è¯ä½œä¸ºæœ€ç»ˆç­”æ¡ˆï¼šè‹¥æ˜¯åƒåœ¾é‚®ä»¶ï¼Œè¿”å›â€œSPAMâ€ï¼›è‹¥æ˜¯æ­£å¸¸é‚®ä»¶ï¼Œè¿”å›â€œHAMâ€ã€‚ä¸è¦è¾“å‡ºå¤šä½™æ–‡å­—ã€‚\n",
    "ç­”æ¡ˆï¼š\n",
    "    \"\"\"\n",
    "    messages = [HumanMessage(content=prompt)]  # LangChain è¦æ±‚ä¼ å…¥ HumanMessage å¯¹è±¡\n",
    "    response = model.invoke(messages)  # è°ƒç”¨ LLM è·å¾—åˆ¤å®šç»“æœ\n",
    "\n",
    "    response_text = response.content.lower()  # ç»Ÿä¸€è½¬å°å†™ï¼Œä¾¿äºå…³é”®è¯åŒ¹é…\n",
    "    print(response_text)  # åœ¨æ§åˆ¶å°è¾“å‡ºï¼Œæ–¹ä¾¿æˆ‘ä»¬è°ƒè¯•å’Œè§‚å¯Ÿ\n",
    "    is_spam = \"spam\" in response_text and \"ham\" not in response_text  # åŒæ—¶æ’é™¤åŒæ—¶å‡ºç° spam/ham çš„æƒ…å†µ\n",
    "\n",
    "    if not is_spam:\n",
    "        # å¦‚æœä¸æ˜¯åƒåœ¾é‚®ä»¶ï¼Œå°±å°†æœ¬æ¬¡é—®ç­”è¿½åŠ åˆ°å¯¹è¯å†å²ä¸­ï¼Œä¾›åç»­èŠ‚ç‚¹ä½¿ç”¨\n",
    "        new_messages = state.get(\"messages\", []) + [\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "            {\"role\": \"assistant\", \"content\": response.content}\n",
    "        ]\n",
    "    else:\n",
    "        # åƒåœ¾é‚®ä»¶æ— éœ€è®°å½•ä¸Šä¸‹æ–‡ï¼Œä¿æŒåŸæœ‰çš„æ¶ˆæ¯è®°å½•\n",
    "        new_messages = state.get(\"messages\", [])\n",
    "\n",
    "    return {\n",
    "        \"is_spam\": is_spam,       # æŠŠåƒåœ¾é‚®ä»¶åˆ¤å®šç»“æœå†™å›çŠ¶æ€\n",
    "        \"messages\": new_messages  # åŒæ­¥å¯¹è¯å†å²\n",
    "    }\n",
    "\n",
    "def handle_spam(state: EmailState):\n",
    "    \"\"\"\n",
    "    åƒåœ¾é‚®ä»¶åˆ†æ”¯ï¼šè¿™é‡Œåªæ¼”ç¤ºæ‰“å°æç¤ºè¯­ï¼ŒçœŸå®é¡¹ç›®å¯ä»¥å†™å…¥æ•°æ®åº“æˆ–æŠ¥è­¦ã€‚\n",
    "    \"\"\"\n",
    "    print(\"é˜¿å°”å¼—é›·å¾·å·²ç»å°†é‚®ä»¶æ ‡è®°ä¸ºåƒåœ¾é‚®ä»¶ã€‚\")\n",
    "    print(\"è¯¥ç”µå­é‚®ä»¶å·²è¢«ç§»è‡³åƒåœ¾é‚®ä»¶æ–‡ä»¶å¤¹ã€‚\")\n",
    "    return {}  # è¿”å›ç©ºå­—å…¸è¡¨ç¤ºä¸ä¿®æ”¹çŠ¶æ€å­—æ®µ\n",
    "\n",
    "def drafting_response(state: EmailState):\n",
    "    \"\"\"\n",
    "    åˆæ³•é‚®ä»¶åˆ†æ”¯ï¼šè®© LLM å¸®å¿™æ’°å†™ä¸€ä»½ç¤¼è²Œçš„å›å¤è‰ç¨¿ã€‚\n",
    "    \"\"\"\n",
    "    email = state[\"email\"]\n",
    "\n",
    "    # ç»´æŒæç¤ºè¯ï¼Œæ˜ç¡®è¾“å‡ºè¯­æ°”å’Œéœ€è¦è¦†ç›–çš„å…³é”®å†…å®¹ï¼ˆä¸­æ–‡åˆå­¦è€…å‹å¥½ç‰ˆæœ¬ï¼‰\n",
    "    prompt = f\"\"\"\n",
    "è¯·ä»¥é˜¿å°”å¼—é›·å¾·ï¼ˆAlfredï¼ŒéŸ¦æ©å…ˆç”Ÿçš„ç®¡å®¶ï¼‰çš„å£å»ï¼Œä¸ºä¸‹é¢è¿™å°é‚®ä»¶èµ·è‰ä¸€ä»½ç¤¼è²Œã€ç®€æ´ä¸”ä¸“ä¸šçš„åˆç¨¿å›å¤ã€‚\n",
    "\n",
    "é‚®ä»¶å†…å®¹ï¼š\n",
    "å‘ä»¶äººï¼ˆFromï¼‰ï¼š{email['sender']}\n",
    "ä¸»é¢˜ï¼ˆSubjectï¼‰ï¼š{email['subject']}\n",
    "æ­£æ–‡ï¼ˆBodyï¼‰ï¼š{email['body']}\n",
    "\n",
    "è¯·ç”Ÿæˆä¸€æ®µç®€çŸ­ã€ä¸“ä¸šã€è¯­æ°”å‹å–„çš„ä¸­æ–‡å›å¤è‰ç¨¿ï¼Œä¾›éŸ¦æ©å…ˆç”Ÿå®¡é˜…å¹¶åœ¨å‘é€å‰ä¸ªæ€§åŒ–æ¶¦è‰²ã€‚\n",
    "    \"\"\"\n",
    "\n",
    "    messages = [HumanMessage(content=prompt)]\n",
    "    response = model.invoke(messages)\n",
    "\n",
    "    # å°†æœ€æ–°çš„é—®ç­”è¿½åŠ åˆ°å¯¹è¯å†å²é‡Œï¼Œä¿æŒä¸Šä¸‹æ–‡å®Œæ•´\n",
    "    new_messages = state.get(\"messages\", []) + [\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "        {\"role\": \"assistant\", \"content\": response.content}\n",
    "    ]\n",
    "\n",
    "    return {\n",
    "        \"draft_response\": response.content,  # ä¿å­˜ç”Ÿæˆçš„é‚®ä»¶è‰ç¨¿\n",
    "        \"messages\": new_messages\n",
    "    }\n",
    "\n",
    "def notify_mr_wayne(state: EmailState):\n",
    "    \"\"\"\n",
    "    æ”¶å°¾èŠ‚ç‚¹ï¼šæ¨¡æ‹Ÿå‘å¸ƒé²æ–¯Â·éŸ¦æ©æ±‡æŠ¥é‚®ä»¶å¤„ç†ç»“æœã€‚\n",
    "    \"\"\"\n",
    "    email = state[\"email\"]\n",
    "\n",
    "    print(\"\" + \"=\"*50)\n",
    "    print(f\"Sir, you've received an email from {email['sender']}.\")\n",
    "    print(f\"Subject: {email['subject']}\")\n",
    "    print(\"I've prepared a draft response for your review:\")\n",
    "    print(\"-\"*50)\n",
    "    print(state[\"draft_response\"])\n",
    "    print(\"=\"*50 + \"\")\n",
    "\n",
    "    return {}\n",
    "\n",
    "# ğŸ§­ è·¯ç”±é€»è¾‘ï¼šæ ¹æ®åƒåœ¾é‚®ä»¶åˆ¤å®šé€‰æ‹©ä¸‹ä¸€æ­¥çš„åˆ†æ”¯\n",
    "def route_email(state: EmailState) -> str:\n",
    "    if state[\"is_spam\"]:\n",
    "        return \"spam\"\n",
    "    else:\n",
    "        return \"legitimate\"\n",
    "\n",
    "# ğŸ› ï¸ åˆ›å»ºçŠ¶æ€å›¾ï¼Œå°†ä¸Šé¢å®šä¹‰çš„èŠ‚ç‚¹ä¸²è”æˆä¸€ä¸ª LangGraph å·¥ä½œæµ\n",
    "email_graph = StateGraph(EmailState)\n",
    "\n",
    "# ğŸ“Œ æ³¨å†ŒèŠ‚ç‚¹â€”â€”æ¯ä¸€è¡Œéƒ½ä¼šæŠŠå‡½æ•°å˜æˆå›¾é‡Œçš„ä¸€ä¸ªæ‰§è¡ŒèŠ‚ç‚¹\n",
    "email_graph.add_node(\"read_email\", read_email)  # é¦–å…ˆè¯»å–å¹¶å±•ç¤ºé‚®ä»¶ä¿¡æ¯\n",
    "email_graph.add_node(\"classify_email\", classify_email)  # ç„¶åè¯· LLM åˆ¤å®šåƒåœ¾é‚®ä»¶\n",
    "email_graph.add_node(\"handle_spam\", handle_spam)  # åƒåœ¾é‚®ä»¶èµ°å•ç‹¬çš„å¤„ç†åˆ†æ”¯\n",
    "email_graph.add_node(\"drafting_response\", drafting_response)  # åˆæ³•é‚®ä»¶ç”Ÿæˆå›å¤è‰ç¨¿\n",
    "email_graph.add_node(\"notify_mr_wayne\", notify_mr_wayne)  # æœ€åå‘ä¸»äººæ±‡æŠ¥ç»“æœ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1I6C2-0jwIsj",
    "outputId": "abd06b5b-3165-4cf7-996b-6fc9864059ce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7f78d64e7be0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# â• é…ç½®èŠ‚ç‚¹ä¹‹é—´çš„æµè½¬é¡ºåº\n",
    "email_graph.add_edge(START, \"read_email\")  # å›¾çš„èµ·ç‚¹å…ˆè¿›å…¥ read_email èŠ‚ç‚¹\n",
    "\n",
    "# ğŸ§  åˆ¤å®šä¹‹åæ ¹æ®ç»“æœæµå‘ä¸åŒåˆ†æ”¯\n",
    "email_graph.add_edge(\"read_email\", \"classify_email\")  # å±•ç¤ºå®Œé‚®ä»¶åè°ƒç”¨åˆ†ç±»é€»è¾‘\n",
    "\n",
    "# ğŸ”€ æ·»åŠ æ¡ä»¶åˆ†æ”¯ï¼šroute_email è¿”å›å­—ç¬¦ä¸²å†³å®šä¸‹ä¸€æ¡è¾¹\n",
    "email_graph.add_conditional_edges(\n",
    "    \"classify_email\",  # æ ¹æ®åƒåœ¾é‚®ä»¶åˆ¤å®šç»“æœæ¥å†³å®šå»å‘\n",
    "    route_email,\n",
    "    {\n",
    "        \"spam\": \"handle_spam\",          # åˆ¤å®šä¸ºåƒåœ¾é‚®ä»¶åˆ™ç›´æ¥èµ° handle_spam èŠ‚ç‚¹\n",
    "        \"legitimate\": \"drafting_response\"  # åˆæ³•é‚®ä»¶åˆ™ç»§ç»­æ’°å†™å›å¤\n",
    "    }\n",
    ")\n",
    "\n",
    "# âœ… æ”¶å°¾ï¼šæ— è®ºå“ªä¸ªåˆ†æ”¯èµ°å®Œéƒ½å›åˆ° END èŠ‚ç‚¹\n",
    "email_graph.add_edge(\"handle_spam\", END)  # åƒåœ¾é‚®ä»¶å¤„ç†å®Œæ¯•å³ç»“æŸ\n",
    "email_graph.add_edge(\"drafting_response\", \"notify_mr_wayne\")  # å›å¤è‰ç¨¿åé€šçŸ¥ä¸»äºº\n",
    "email_graph.add_edge(\"notify_mr_wayne\", END)  # æ±‡æŠ¥ç»“æŸåæ•´ä¸ªæµç¨‹æ”¶å°¾\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "haTVi7UmwIsj"
   },
   "outputs": [],
   "source": [
    "# ğŸ§® å°†å›¾ç»“æ„ç¼–è¯‘æˆå¯æ‰§è¡Œçš„ LangGraph Agentå¯¹è±¡\n",
    "compiled_graph = email_graph.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "GlJYoVUbwIsj"
   },
   "outputs": [],
   "source": [
    "# ğŸ“¨ å‡†å¤‡ä¸¤å°ç¤ºä¾‹é‚®ä»¶ï¼Œå¸®åŠ©æˆ‘ä»¬è§‚å¯Ÿä¸åŒåˆ†æ”¯çš„æ‰§è¡Œæ•ˆæœ\n",
    "legitimate_email = {\n",
    "    \"sender\": \"äº¬ä¸œå®¢æœ\",  # å‘ä»¶äºº\n",
    "    \"subject\": \"å…³äºä½ è¿‘æœŸè®¢å•çš„å‘ç¥¨å¼€å…·è¯´æ˜\",  # é‚®ä»¶ä¸»é¢˜\n",
    "    \"body\": \"å°Šæ•¬çš„éŸ¦æ©å…ˆç”Ÿï¼Œä½ å¥½ï¼å…³äºä½ åœ¨äº¬ä¸œçš„è¿‘æœŸè®¢å•ï¼Œå¢å€¼ç¨ç”µå­æ™®é€šå‘ç¥¨å·²å¼€å…·å¹¶æ¨é€è‡³ä½ çš„é‚®ç®±ã€‚å¦‚éœ€çº¸è´¨å‘ç¥¨æˆ–æŠ¬å¤´å˜æ›´ï¼Œè¯·åœ¨7æ—¥å†…é€šè¿‡â€œæˆ‘çš„è®¢å•-ç”³è¯·å¼€ç¥¨â€å‘èµ·ï¼Œæˆ‘ä»¬å°†å°½å¿«å¤„ç†ã€‚ç»™ä½ å¸¦æ¥ä¸ä¾¿ï¼Œæ•¬è¯·è°…è§£ã€‚\"  # é‚®ä»¶æ­£æ–‡\n",
    "}\n",
    "\n",
    "spam_email = {\n",
    "    \"sender\": \"æŸæ•°å­—è´§å¸é¡¹ç›®æ–¹\",  # åƒåœ¾é‚®ä»¶å¸¸è§çš„æ¨é”€è€…\n",
    "    \"subject\": \"é™æ—¶æš´æ¶¨100å€ï¼Œç«‹å³ä¸Šè½¦ï¼\",  # è¯±å¯¼æ€§æ ‡é¢˜\n",
    "    \"body\": \"éŸ¦æ©å…ˆç”Ÿï¼Œæˆ‘ä»¬æ–°ä¸Šçº¿äº†ä¸€æ¬¾æ•°å­—è´§å¸ï¼Œæ‰¿è¯ºç¨³ç¨³èµšã€ç¨³èµšä¸èµ”ï¼æ‰«ç åŠ ç¾¤ï¼Œå‰100åèµ é€ç©ºæŠ•åé¢ï¼Œé”™è¿‡ä»Šå¤©å†ç­‰ä¸€å¹´ï¼\"  # æ˜æ˜¾çš„åƒåœ¾æ¨å¹¿/è¯ˆéª—æ–‡æ¡ˆ\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "é˜¿å°”å¼—é›·å¾·æ­£åœ¨å¤„ç†æ¥è‡ª äº¬ä¸œå®¢æœ çš„é‚®ä»¶ï¼Œä¸»é¢˜ä¸ºï¼šå…³äºä½ è¿‘æœŸè®¢å•çš„å‘ç¥¨å¼€å…·è¯´æ˜\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'items'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 751, in on_llm_end\n",
      "    llm_usage = _parse_usage(response)\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 1027, in _parse_usage\n",
      "    llm_usage = _parse_usage_model(response.llm_output[key])\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 946, in _parse_usage_model\n",
      "    for key, value in input_token_details.items():\n",
      "AttributeError: 'NoneType' object has no attribute 'items'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'items'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 751, in on_llm_end\n",
      "    llm_usage = _parse_usage(response)\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 1027, in _parse_usage\n",
      "    llm_usage = _parse_usage_model(response.llm_output[key])\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 946, in _parse_usage_model\n",
      "    for key, value in input_token_details.items():\n",
      "AttributeError: 'NoneType' object has no attribute 'items'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Sir, you've received an email from äº¬ä¸œå®¢æœ.\n",
      "Subject: å…³äºä½ è¿‘æœŸè®¢å•çš„å‘ç¥¨å¼€å…·è¯´æ˜\n",
      "I've prepared a draft response for your review:\n",
      "--------------------------------------------------\n",
      "å°Šæ•¬çš„äº¬ä¸œå®¢æœå›¢é˜Ÿï¼š\n",
      "\n",
      "æ‚¨å¥½ï¼æ„Ÿè°¢æ‚¨åŠæ—¶é€šçŸ¥æˆ‘å…³äºè¿‘æœŸè®¢å•å‘ç¥¨çš„ç›¸å…³ä¿¡æ¯ã€‚æˆ‘å·²æ”¶åˆ°ç”µå­å‘ç¥¨ï¼Œè‹¥æœ‰è¿›ä¸€æ­¥éœ€æ±‚ï¼Œæˆ‘ä¼šåœ¨è§„å®šæ—¶é—´å†…é€šè¿‡â€œæˆ‘çš„è®¢å•-ç”³è¯·å¼€ç¥¨â€åŠŸèƒ½æäº¤ç”³è¯·ã€‚\n",
      "\n",
      "æ„Ÿè°¢æ‚¨æä¾›çš„ä¼˜è´¨æœåŠ¡ï¼Œç¥å·¥ä½œé¡ºåˆ©ï¼\n",
      "\n",
      "æ­¤è‡´  \n",
      "æ•¬ç¤¼  \n",
      "éŸ¦æ©\n",
      "==================================================\n",
      "é˜¿å°”å¼—é›·å¾·æ­£åœ¨å¤„ç†æ¥è‡ª æŸæ•°å­—è´§å¸é¡¹ç›®æ–¹ çš„é‚®ä»¶ï¼Œä¸»é¢˜ä¸ºï¼šé™æ—¶æš´æ¶¨100å€ï¼Œç«‹å³ä¸Šè½¦ï¼\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'items'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 751, in on_llm_end\n",
      "    llm_usage = _parse_usage(response)\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 1027, in _parse_usage\n",
      "    llm_usage = _parse_usage_model(response.llm_output[key])\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 946, in _parse_usage_model\n",
      "    for key, value in input_token_details.items():\n",
      "AttributeError: 'NoneType' object has no attribute 'items'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n",
      "é˜¿å°”å¼—é›·å¾·å·²ç»å°†é‚®ä»¶æ ‡è®°ä¸ºåƒåœ¾é‚®ä»¶ã€‚\n",
      "è¯¥ç”µå­é‚®ä»¶å·²è¢«ç§»è‡³åƒåœ¾é‚®ä»¶æ–‡ä»¶å¤¹ã€‚\n"
     ]
    }
   ],
   "source": [
    "from langfuse import observe, get_client\n",
    "from langfuse.langchain import CallbackHandler\n",
    "\n",
    "@observe()\n",
    "def process_email_with_langgraph(email_data):\n",
    "    langfuse = get_client()\n",
    "    \n",
    "    # è®¾ç½® trace name\n",
    "    langfuse.update_current_trace(\n",
    "        name=\"email-processing-workflow\",  # è‡ªå®šä¹‰ trace åç§°\n",
    "        input={\"email\": email_data}\n",
    "    )\n",
    "    \n",
    "    # åˆå§‹åŒ– CallbackHandler\n",
    "    langfuse_handler = CallbackHandler()\n",
    "    \n",
    "    # æ‰§è¡Œ LangGraph\n",
    "    result = compiled_graph.invoke(\n",
    "        input={\n",
    "            \"email\": email_data,\n",
    "            \"is_spam\": None,\n",
    "            \"draft_response\": None,\n",
    "            \"messages\": []\n",
    "        },\n",
    "        config={\"callbacks\": [langfuse_handler]}\n",
    "    )\n",
    "    \n",
    "    # æ›´æ–° trace è¾“å‡º\n",
    "    langfuse.update_current_trace(output=result)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# âœ… è¿è¡Œåˆæ³•é‚®ä»¶ç¤ºä¾‹ï¼Œæ¼”ç¤ºå®Œæ•´å·¥ä½œæµ\n",
    "result = process_email_with_langgraph(legitimate_email)\n",
    "# ğŸš¨ å†è¿è¡Œåƒåœ¾é‚®ä»¶ç¤ºä¾‹ï¼Œè§‚å¯Ÿåˆ†æ”¯å·®å¼‚\n",
    "result = process_email_with_langgraph(spam_email)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### å¤‡æ³¨\n",
    "```\n",
    "'NoneType' object has no attribute 'items'\n",
    "Traceback (most recent call last):\n",
    "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 751, in on_llm_end\n",
    "    llm_usage = _parse_usage(response)\n",
    "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 1027, in _parse_usage\n",
    "    llm_usage = _parse_usage_model(response.llm_output[key])\n",
    "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 946, in _parse_usage_model\n",
    "    for key, value in input_token_details.items():\n",
    "AttributeError: 'NoneType' object has no attribute 'items'\n",
    "```\n",
    "è¿™ä¸ªé”™è¯¯æ˜¯ Langfuse LangChain å›è°ƒå¤„ç†å™¨åœ¨è§£æ LLM å“åº”çš„ token ä½¿ç”¨è¯¦æƒ…æ—¶é‡åˆ°çš„é—®é¢˜ã€‚è™½ç„¶é”™è¯¯ä¸å½±å“ç¨‹åºè¿è¡Œ(é‚®ä»¶å¤„ç†æµç¨‹æ­£å¸¸å®Œæˆ),ä½†ä¼šåœ¨æ—¥å¿—ä¸­äº§ç”Ÿå¹²æ‰°ä¿¡æ¯ã€‚\n",
    "è¿™é‡Œå¯èƒ½å’Œæˆ‘ä½¿ç”¨OpenAIå›½å†…ä»£ç†APIæœ‰å…³ç³»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fjkhTgLWfoSQ"
   },
   "source": [
    "### è¿½è¸ªç»“æ„\n",
    "\n",
    "Langfuse ä¼šè®°å½•åŒ…å«è‹¥å¹² **spanï¼ˆè·¨åº¦ï¼‰** çš„**traceï¼ˆè¿½è¸ªï¼‰**ï¼Œæ¯ä¸ª span ä»£è¡¨Agenté€»è¾‘ä¸­çš„ä¸€ä¸ªæ­¥éª¤ã€‚æœ¬ä¾‹ä¸­çš„è¿½è¸ªåŒ…å«æ•´ä½“è¿è¡Œä»¥åŠå¦‚ä¸‹å­è·¨åº¦ï¼š\n",
    "- å·¥å…·è°ƒç”¨ï¼ˆ\n",
    "- LLM è°ƒç”¨ï¼ˆä½¿ç”¨ 'gpt-4o' çš„ Responses APIï¼‰\n",
    "\n",
    "ä½ å¯ä»¥æ£€æŸ¥è¿™äº›è®°å½•ä»¥ç²¾ç¡®äº†è§£æ—¶é—´æ¶ˆè€—ã€ä»¤ç‰Œä½¿ç”¨é‡ç­‰ï¼š\n",
    "\n",
    "![Langfuse ä¸­çš„è¿½è¸ªæ ‘](https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202509251730026.png)\n",
    "\n",
    "_[å‰å¾€è¯¥è¿½è¸ª](https://cloud.langfuse.com/project/cmequpe0j00euad07w6wrvkzg/traces?peek=2d1f23b960fb1ff0bdaf7623fda4936c&timestamp=2025-09-25T09%3A06%3A06.476Z)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JHZAkQuefoSQ"
   },
   "source": [
    "## ğŸ”¬ 3ï¼šåœ¨çº¿è¯„ä¼°\n",
    "\n",
    "åœ¨çº¿è¯„ä¼°æŒ‡åœ¨çœŸå®çº¿ä¸Šç¯å¢ƒï¼ˆç”Ÿäº§ç¯å¢ƒçš„å®é™…ä½¿ç”¨ä¸­ï¼‰å¯¹Agentè¿›è¡Œè¯„ä¼°ã€‚è¿™éœ€è¦å¯¹çœŸå®ç”¨æˆ·äº¤äº’è¿›è¡ŒæŒç»­ç›‘æ§ä¸ç»“æœåˆ†æã€‚\n",
    "\n",
    "æˆ‘ä»¬åœ¨æ­¤æ€»ç»“äº†å¤šç§è¯„ä¼°æŠ€æœ¯çš„æŒ‡å—ï¼š[é“¾æ¥](https://langfuse.com/blog/2025-03-04-llm-evaluation-101-best-practices-and-challenges)ã€‚\n",
    "\n",
    "### ç”Ÿäº§ç¯å¢ƒå¸¸è§ç›‘æ§æŒ‡æ ‡\n",
    "\n",
    "1. **æˆæœ¬ï¼ˆCostsï¼‰**ï¼šåŸ‹ç‚¹ä¼šè®°å½•ä»¤ç‰Œç”¨é‡ï¼Œä½ å¯æŒ‰æ¯ä¸ªä»¤ç‰Œçš„ä»·æ ¼ä¼°ç®—æˆæœ¬ã€‚\n",
    "2. **å»¶è¿Ÿï¼ˆLatencyï¼‰**ï¼šè§‚å¯Ÿå®Œæˆæ¯ä¸ªæ­¥éª¤æˆ–æ•´æ¬¡è¿è¡Œæ‰€éœ€çš„æ—¶é—´ã€‚\n",
    "3. **ç”¨æˆ·åé¦ˆï¼ˆUser Feedbackï¼‰**ï¼šç”¨æˆ·å¯ç›´æ¥æä¾›åé¦ˆï¼ˆå¦‚ç‚¹èµ/ç‚¹è¸©ï¼‰ä»¥å¸®åŠ©è¿­ä»£ä¸ä¿®æ­£Agentã€‚\n",
    "4. **LLM è¯„å®¡ï¼ˆLLM-as-a-Judgeï¼‰**ï¼šä½¿ç”¨é¢å¤–çš„ LLM è¿‘å®æ—¶è¯„ä¼°Agentè¾“å‡ºï¼ˆå¦‚æ£€æµ‹æ¯’æ€§æˆ–æ­£ç¡®æ€§ï¼‰ã€‚\n",
    "\n",
    "ä¸‹é¢å±•ç¤ºè¿™äº›æŒ‡æ ‡çš„ç¤ºä¾‹ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QHMvJ1QlfoSQ",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 1. æˆæœ¬ï¼ˆCostsï¼‰\n",
    "\n",
    "ä¸‹å›¾å±•ç¤ºäº† `gpt-4o` è°ƒç”¨çš„ç”¨é‡ï¼Œå¯æ®æ­¤è¯†åˆ«é«˜æˆæœ¬æ­¥éª¤å¹¶ä¼˜åŒ–Agentã€‚\n",
    "\n",
    "![æˆæœ¬](https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202509251732570.png)\n",
    "\n",
    "_[å‰å¾€è¯¥è¿½è¸ª](https://cloud.langfuse.com/project/cmequpe0j00euad07w6wrvkzg/traces?peek=2d1f23b960fb1ff0bdaf7623fda4936c&timestamp=2025-09-25T09%3A06%3A06.476Z)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yz0y9mn7foSQ",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 2. å»¶è¿Ÿï¼ˆLatencyï¼‰\n",
    "\n",
    "è¿˜å¯ä»¥æŸ¥çœ‹å®Œæˆæ¯ä¸ªæ­¥éª¤æ‰€éœ€çš„æ—¶é—´ã€‚å¦‚ä¸‹ä¾‹æ‰€ç¤ºï¼Œæ•´ä¸ªè¿è¡Œçº¦ 3 ç§’ï¼Œä½ å¯ä»¥ç»†åˆ†åˆ°å„æ­¥éª¤ã€‚æ­¤ä¸¾æœ‰åŠ©äºè¯†åˆ«ç“¶é¢ˆå¹¶ä¼˜åŒ–Agentã€‚\n",
    "\n",
    "![å»¶è¿Ÿ](https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202509251735069.png)\n",
    "\n",
    "_[å‰å¾€è¯¥è¿½è¸ª](https://cloud.langfuse.com/project/cmequpe0j00euad07w6wrvkzg/traces?peek=2d1f23b960fb1ff0bdaf7623fda4936c&timestamp=2025-09-25T09%3A06%3A06.476Z&display=timeline)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XtKiK62HfoSR"
   },
   "source": [
    "#### 3. ç”¨æˆ·åé¦ˆï¼ˆUser Feedbackï¼‰\n",
    "\n",
    "å¦‚æœä½ çš„AgentåµŒå…¥åœ¨ç”¨æˆ·ç•Œé¢ä¸­ï¼Œå¯ä»¥é‡‡é›†ç”¨æˆ·çš„ç›´æ¥åé¦ˆï¼ˆä¾‹å¦‚åœ¨èŠå¤©ç•Œé¢ä¸­çš„ç‚¹èµ/ç‚¹è¸©ï¼‰ã€‚\n",
    "\n",
    "ç”¨æˆ·åé¦ˆé€šå¸¸å€ŸåŠ©ï¼š**ä¸ºè¿½è¸ªæ·»åŠ è¯„åˆ†** æ–¹å¼\n",
    "\n",
    "[è¯„åˆ†ï¼ˆScoreï¼‰](https://langfuse.com/docs/scores/overview) ç”¨äºè¯„ä»·å•ä¸ªè§‚æµ‹ï¼ˆobservationï¼‰æˆ–æ•´æ¡è¿½è¸ªï¼ˆtraceï¼‰ï¼Œå¯å¸®åŠ©ä½ åœ¨è¿è¡Œæ—¶æ‰§è¡Œè‡ªå®šä¹‰è´¨é‡æ£€æŸ¥ï¼Œæˆ–é…åˆäººå·¥å®¡æ ¸æµç¨‹ã€‚\n",
    "\n",
    "ä¸‹é¢çš„ç¤ºä¾‹æ¼”ç¤ºå¦‚ä½•ï¼š\n",
    "\n",
    "- ä¸ºæŸä¸ª span è®°å½•ä¸€ä¸ªæ•°å€¼å‹è¯„åˆ†ï¼ˆå¦‚ `relevance`ï¼‰\n",
    "- ä¸ºæ•´æ¡è¿½è¸ªè®°å½•ä¸€ä¸ªåˆ†ç±»å‹è¯„åˆ†ï¼ˆå¦‚ `feedback`ï¼‰\n",
    "\n",
    "è¿™æœ‰åŠ©äºç³»ç»ŸåŒ–åœ°è¯„ä¼°ä¸æ”¹è¿›åº”ç”¨è´¨é‡ã€‚\n",
    "\n",
    "**â†’ æƒ³æ·±å…¥äº†è§£ï¼Ÿè¯·å‚é˜… [Langfuse è‡ªå®šä¹‰è¯„åˆ†æŒ‡å—](https://langfuse.com/docs/scores/custom)ã€‚**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "YI9siKKKfoSR"
   },
   "outputs": [],
   "source": [
    "from langfuse import get_client\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ“Š Langfuse è¯„åˆ†ç³»ç»Ÿè¯¦è§£\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# \n",
    "# è¯„åˆ†ï¼ˆScoreï¼‰æ˜¯ä¸€ç§å¯¹ Traceï¼ˆè¿½è¸ªï¼‰è¿›è¡Œè´¨é‡è¯„ä¼°å’Œåé¦ˆçš„æœºåˆ¶\n",
    "# \n",
    "# ğŸ’¡ è¯„åˆ†çš„ä¸»è¦åº”ç”¨åœºæ™¯ï¼š\n",
    "# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "# â”‚ 1. ã€åœ¨çº¿å®æ—¶åé¦ˆã€‘                                                        â”‚\n",
    "# â”‚    - ç”¨æˆ·æ»¡æ„åº¦è¯„åˆ†ï¼ˆğŸ‘/ğŸ‘ï¼‰                                              â”‚\n",
    "# â”‚    - ç­”æ¡ˆæ˜¯å¦æœ‰å¸®åŠ©ï¼ˆhelpful/not helpfulï¼‰                                â”‚\n",
    "# â”‚    - ç”¨æˆ·ç‚¹å‡»\"å¥½è¯„\"æˆ–\"å·®è¯„\"æŒ‰é’®çš„å³æ—¶åé¦ˆ                                   â”‚\n",
    "# â”‚                                                                          â”‚\n",
    "# â”‚ 2. ã€ç¦»çº¿è´¨é‡åº¦é‡ã€‘                                                        â”‚\n",
    "# â”‚    - AI å›ç­”çš„å‡†ç¡®æ€§ï¼ˆaccuracyï¼‰è¯„åˆ†                                       â”‚\n",
    "# â”‚    - å†…å®¹ç›¸å…³æ€§ï¼ˆrelevanceï¼‰è¯„åˆ†                                          â”‚\n",
    "# â”‚    - å®‰å…¨æ€§æ£€æµ‹ï¼ˆsafety checkï¼‰è¯„åˆ†                                       â”‚\n",
    "# â”‚    - äº‹å®æ ¸æŸ¥ï¼ˆfact-checkingï¼‰ç»“æœ                                        â”‚\n",
    "# â”‚                                                                          â”‚\n",
    "# â”‚ 3. ã€A/B æµ‹è¯•ä¸å¯¹æ¯”å®éªŒã€‘                                                  â”‚\n",
    "# â”‚    - ä¸åŒæ¨¡å‹ç‰ˆæœ¬çš„æ•ˆæœå¯¹æ¯”                                                â”‚\n",
    "# â”‚    - ä¸åŒæç¤ºè¯ï¼ˆpromptï¼‰çš„æ€§èƒ½è¯„ä¼°                                        â”‚\n",
    "# â”‚    - å¤šç§ç­–ç•¥çš„æ¨ªå‘æ¯”è¾ƒ                                                    â”‚\n",
    "# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "#\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "langfuse = get_client()\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ¯ æ–¹æ¡ˆä¸€ï¼šä½¿ç”¨ span å¯¹è±¡çš„ score_trace() æ–¹æ³•ï¼ˆâ˜… æ¨èæ–¹æ¡ˆï¼Œæœ€ç›´è§‚ï¼‰\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "#\n",
    "# ğŸ“Œ æ ¸å¿ƒç‰¹ç‚¹ï¼š\n",
    "#    - åœ¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼ˆwithï¼‰å†…éƒ¨ä½¿ç”¨\n",
    "#    - ç›´æ¥é€šè¿‡ span å¯¹è±¡è°ƒç”¨ score_trace() æ–¹æ³•\n",
    "#    - ä»£ç æ¸…æ™°ï¼Œä½œç”¨åŸŸæ˜ç¡®ï¼Œæœ€å®¹æ˜“ç†è§£å’Œç»´æŠ¤\n",
    "#\n",
    "# âœ… é€‚ç”¨åœºæ™¯ï¼š\n",
    "#    1. åŒæ­¥æ‰§è¡Œæµç¨‹ä¸­ï¼Œéœ€è¦ç«‹å³å¯¹å½“å‰ trace è¿›è¡Œè¯„åˆ†\n",
    "#    2. è¯„åˆ†é€»è¾‘å°±åœ¨ LangGraph æ‰§è¡Œä»£ç é™„è¿‘\n",
    "#    3. éœ€è¦åœ¨ä¸€ä¸ªæ˜ç¡®çš„ä»£ç å—å†…å®Œæˆè¯„åˆ†ï¼ˆæ¨èç”¨äºå¤§å¤šæ•°åœºæ™¯ï¼‰\n",
    "#\n",
    "# ğŸ’¡ ä½¿ç”¨æ—¶æœºï¼š\n",
    "#    - LangGraph æ‰§è¡Œå®Œæˆåï¼Œç«‹å³è·å–ç»“æœå¹¶è¯„åˆ†\n",
    "#    - åœ¨åŒä¸€ä¸ªå‡½æ•°æˆ–ä»£ç å—ä¸­å¤„ç†æ‰§è¡Œå’Œè¯„åˆ†é€»è¾‘\n",
    "#    - é€‚åˆåŒæ­¥åœºæ™¯ï¼Œè¯„åˆ†å‘ç”Ÿåœ¨ä¸šåŠ¡é€»è¾‘æ‰§è¡Œçš„åŒä¸€ä¸Šä¸‹æ–‡ä¸­\n",
    "#\n",
    "# ğŸ”§ æŠ€æœ¯ç»†èŠ‚ï¼š\n",
    "#    - span æ˜¯ä¸Šä¸‹æ–‡ç®¡ç†å™¨è¿”å›çš„å¯¹è±¡ï¼Œä»£è¡¨å½“å‰çš„è¿½è¸ªèŒƒå›´\n",
    "#    - score_trace() ä¼šè‡ªåŠ¨å…³è”åˆ°å½“å‰ span æ‰€å±çš„ trace\n",
    "#    - æ— éœ€æ‰‹åŠ¨ç®¡ç† trace_idï¼Œæ¡†æ¶è‡ªåŠ¨å¤„ç†å…³è”å…³ç³»\n",
    "with langfuse.start_as_current_span(name=\"email-processing-workflow\") as span:\n",
    "    # ... æ­¤å¤„æ‰§è¡Œ LangGraph çš„ä¸šåŠ¡é€»è¾‘ ...\n",
    "    # ä¾‹å¦‚ï¼šè°ƒç”¨ LLMã€æ‰§è¡Œå·¥å…·å‡½æ•°ã€å¤„ç†ç”¨æˆ·è¾“å…¥ç­‰\n",
    "    \n",
    "    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "    # ğŸ“ ç›´æ¥é€šè¿‡ span å¯¹è±¡è®°å½•è¯„åˆ†\n",
    "    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "    span.score_trace(\n",
    "        name=\"user-feedback-test-01\",        # è¯„åˆ†é¡¹åç§°ï¼ˆå¯è‡ªå®šä¹‰ï¼Œå¦‚ï¼šaccuracyã€relevanceã€safetyï¼‰\n",
    "        value=1,                            # è¯„åˆ†å€¼ï¼ˆNUMERIC ç±»å‹æ—¶ä¸ºæ•°å­—ï¼›TEXT/CATEGORICAL æ—¶ä¸ºå­—ç¬¦ä¸²ï¼‰\n",
    "        data_type=\"NUMERIC\",                # æ•°æ®ç±»å‹ï¼šNUMERICï¼ˆæ•°å€¼ï¼‰/ TEXTï¼ˆæ–‡æœ¬ï¼‰/ CATEGORICALï¼ˆåˆ†ç±»ï¼‰\n",
    "        comment=\"This was correct, thank you\"  # å¯é€‰ï¼šè¯„åˆ†å¤‡æ³¨æˆ–ç”¨æˆ·è¯„è®º\n",
    "    )\n",
    "    # \n",
    "    # ğŸ“Š å‚æ•°è¯´æ˜ï¼š\n",
    "    # â”œâ”€ name: è¯„åˆ†ç»´åº¦çš„åç§°æ ‡è¯†ï¼ˆå¦‚ï¼šuser-feedbackã€accuracyã€relevanceï¼‰\n",
    "    # â”œâ”€ value: è¯„åˆ†çš„å…·ä½“å€¼\n",
    "    # â”‚         â€¢ NUMERIC: å¯ä»¥æ˜¯æ•´æ•°æˆ–å°æ•°ï¼ˆå¦‚ï¼š1, 0.95, 5.0ï¼‰\n",
    "    # â”‚         â€¢ TEXT: æ–‡æœ¬è¯„è®ºï¼ˆå¦‚ï¼š\"ç­”æ¡ˆå‡†ç¡®ä¸”è¯¦ç»†\"ï¼‰\n",
    "    # â”‚         â€¢ CATEGORICAL: åˆ†ç±»æ ‡ç­¾ï¼ˆå¦‚ï¼š\"excellent\"ã€\"good\"ã€\"poor\"ï¼‰\n",
    "    # â”œâ”€ data_type: è¯„åˆ†å€¼çš„æ•°æ®ç±»å‹ï¼Œå½±å“ Langfuse å¹³å°çš„å±•ç¤ºå’Œèšåˆæ–¹å¼\n",
    "    # â””â”€ comment: é™„åŠ è¯´æ˜ï¼Œä¾¿äºåç»­åˆ†ææ—¶ç†è§£è¯„åˆ†èƒŒæ™¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ¯ æ–¹æ¡ˆäºŒï¼šä½¿ç”¨å…¨å±€æ–¹æ³• score_current_trace()ï¼ˆé€‚ç”¨äºæ·±å±‚å‡½æ•°è°ƒç”¨ï¼‰\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "#\n",
    "# ğŸ“Œ æ ¸å¿ƒç‰¹ç‚¹ï¼š\n",
    "#    - ä»ç„¶åœ¨ with ä¸Šä¸‹æ–‡å†…éƒ¨ï¼Œä½†ä¸éœ€è¦ç›´æ¥æŒæœ‰ span å¯¹è±¡\n",
    "#    - é€šè¿‡ langfuse.score_current_trace() è‡ªåŠ¨æ‰¾åˆ°å½“å‰æ´»è·ƒçš„ trace\n",
    "#    - é€‚åˆåœ¨æ·±å±‚åµŒå¥—çš„å‡½æ•°ä¸­è°ƒç”¨ï¼Œæ— éœ€å±‚å±‚ä¼ é€’ span å‚æ•°\n",
    "#\n",
    "# âœ… é€‚ç”¨åœºæ™¯ï¼š\n",
    "#    1. åœ¨æ·±å±‚å‡½æ•°ä¸­è¿›è¡Œè¯„åˆ†ï¼Œä¸æ–¹ä¾¿ä¼ é€’ span å¯¹è±¡\n",
    "#    2. å›è°ƒå‡½æ•°æˆ–é’©å­å‡½æ•°ä¸­éœ€è¦è¯„åˆ†\n",
    "#    3. ä»£ç ç»“æ„ä¸­ span å¯¹è±¡ä¸åœ¨å½“å‰ä½œç”¨åŸŸï¼Œä½†ä»åœ¨åŒä¸€ä¸ªä¸Šä¸‹æ–‡ä¸­\n",
    "#\n",
    "# ğŸ’¡ ä½¿ç”¨æ—¶æœºï¼š\n",
    "#    - è¯„åˆ†é€»è¾‘åœ¨å­å‡½æ•°ã€å·¥å…·å‡½æ•°æˆ–å›è°ƒä¸­å®ç°\n",
    "#    - ä¸æƒ³æ±¡æŸ“å‡½æ•°ç­¾åï¼ˆä¸æƒ³æ·»åŠ  span å‚æ•°ï¼‰\n",
    "#    - å¤šå±‚å‡½æ•°è°ƒç”¨ï¼Œä½†éƒ½åœ¨åŒä¸€ä¸ª trace ä¸Šä¸‹æ–‡ä¸­\n",
    "#\n",
    "# ğŸ”§ æŠ€æœ¯ç»†èŠ‚ï¼š\n",
    "#    - ä¾èµ– Langfuse çš„ä¸Šä¸‹æ–‡ç®¡ç†æœºåˆ¶ï¼ˆç±»ä¼¼ threading.localï¼‰\n",
    "#    - è‡ªåŠ¨æ£€æµ‹å½“å‰æ‰§è¡Œæ ˆä¸­æœ€è¿‘çš„æ´»è·ƒ trace\n",
    "#    - å¿…é¡»åœ¨ with è¯­å¥çš„ä½œç”¨åŸŸå†…è°ƒç”¨ï¼Œå¦åˆ™ä¼šæ‰¾ä¸åˆ°å½“å‰ trace\n",
    "#\n",
    "# ğŸ†š ä¸æ–¹æ¡ˆä¸€çš„åŒºåˆ«ï¼š\n",
    "#    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "#    â”‚              â”‚ æ–¹æ¡ˆä¸€ (span.score) â”‚ æ–¹æ¡ˆäºŒ (score_current)â”‚\n",
    "#    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "#    â”‚ span å¯¹è±¡    â”‚ å¿…é¡»æŒæœ‰            â”‚ ä¸éœ€è¦æŒæœ‰          â”‚\n",
    "#    â”‚ ä»£ç ä½ç½®     â”‚ é€šå¸¸åœ¨ with å—å†…éƒ¨  â”‚ å¯ä»¥åœ¨æ·±å±‚å‡½æ•°ä¸­    â”‚\n",
    "#    â”‚ å‚æ•°ä¼ é€’     â”‚ éœ€è¦ä¼ é€’ span       â”‚ æ— éœ€ä¼ é€’å‚æ•°        â”‚\n",
    "#    â”‚ ä»£ç è€¦åˆåº¦   â”‚ ä½ï¼ˆæ˜¾å¼å¼•ç”¨ï¼‰      â”‚ æ›´ä½ï¼ˆéšå¼æŸ¥æ‰¾ï¼‰    â”‚\n",
    "#    â”‚ é€‚ç”¨åœºæ™¯     â”‚ ç®€å•ç›´æ¥çš„è¯„åˆ†      â”‚ å¤æ‚åµŒå¥—çš„è¯„åˆ†      â”‚\n",
    "#    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "#\n",
    "with langfuse.start_as_current_span(name=\"email-processing-workflow\") as span:\n",
    "    # ... æ­¤å¤„æ‰§è¡Œ LangGraph çš„ä¸šåŠ¡é€»è¾‘ ...\n",
    "    \n",
    "    # å‡è®¾åœ¨æŸä¸ªæ·±å±‚å‡½æ•°ä¸­éœ€è¦è¯„åˆ†ï¼Œä½† span å¯¹è±¡ä¸æ–¹ä¾¿ä¼ é€’\n",
    "    # è¿™æ—¶å¯ä»¥ç›´æ¥è°ƒç”¨ langfuse.score_current_trace()\n",
    "    langfuse.score_current_trace(\n",
    "        name=\"user-feedback-test-02\",\n",
    "        value=1,\n",
    "        data_type=\"NUMERIC\"\n",
    "    )\n",
    "    # \n",
    "    # ğŸ” å†…éƒ¨æœºåˆ¶ï¼š\n",
    "    # Langfuse ç»´æŠ¤äº†ä¸€ä¸ªçº¿ç¨‹å±€éƒ¨å­˜å‚¨ï¼ˆthread-local storageï¼‰ï¼Œè®°å½•å½“å‰æ´»è·ƒçš„ trace\n",
    "    # score_current_trace() ä¼šæŸ¥æ‰¾å½“å‰çº¿ç¨‹ä¸­æœ€è¿‘æ¿€æ´»çš„ trace å¹¶è¿›è¡Œè¯„åˆ†\n",
    "    # è¿™ç§æ–¹å¼é¿å…äº†æ‰‹åŠ¨ä¼ é€’ span å¯¹è±¡ï¼Œä»£ç æ›´ç®€æ´\n",
    "    #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ¯ æ–¹æ¡ˆä¸‰ï¼šä½¿ç”¨ trace_id ç›´æ¥åˆ›å»ºè¯„åˆ†ï¼ˆâ˜… é€‚åˆå¼‚æ­¥/åå°æ‰¹å¤„ç†ï¼‰\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "#\n",
    "# ğŸ“Œ æ ¸å¿ƒç‰¹ç‚¹ï¼š\n",
    "#    - å®Œå…¨è„±ç¦»ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼ˆwith è¯­å¥ï¼‰\n",
    "#    - éœ€è¦æ˜ç¡®æä¾› trace_id æ¥å…³è”è¯„åˆ†\n",
    "#    - æœ€çµæ´»ï¼Œæ”¯æŒè·¨è¯·æ±‚ã€è·¨æœåŠ¡ã€è·¨æ—¶é—´çš„è¯„åˆ†\n",
    "#\n",
    "# âœ… é€‚ç”¨åœºæ™¯ï¼š\n",
    "#    1. å¼‚æ­¥è¯„åˆ†ï¼šLangGraph æ‰§è¡Œå®Œæˆåï¼Œç”¨æˆ·ç¨åæ‰ç»™å‡ºåé¦ˆ\n",
    "#    2. æ‰¹é‡è¯„åˆ†ï¼šä»æ•°æ®åº“è¯»å–å†å² trace_idï¼Œæ‰¹é‡æ·»åŠ è¯„åˆ†\n",
    "#    3. ç¦»çº¿åˆ†æï¼šå®šæœŸè¿è¡Œè„šæœ¬å¯¹å†å²æ•°æ®è¿›è¡Œè´¨é‡è¯„ä¼°\n",
    "#    4. è·¨æœåŠ¡è¯„åˆ†ï¼šå‰ç«¯æ”¶é›†åé¦ˆåï¼Œé€šè¿‡ API æäº¤åˆ°åç«¯è¿›è¡Œè¯„åˆ†\n",
    "#    5. äººå·¥æ ‡æ³¨ï¼šäººå·¥å®¡æ ¸å›¢é˜Ÿå¯¹å†å²å¯¹è¯è¿›è¡Œæ‰“åˆ†\n",
    "#\n",
    "# ğŸ’¡ ä½¿ç”¨æ—¶æœºï¼š\n",
    "#    - è¯„åˆ†ä¸æ‰§è¡Œä¸åœ¨åŒä¸€æ—¶é—´ï¼ˆæ—¶é—´è§£è€¦ï¼‰\n",
    "#    - è¯„åˆ†ä¸æ‰§è¡Œä¸åœ¨åŒä¸€è¿›ç¨‹ï¼ˆç©ºé—´è§£è€¦ï¼‰\n",
    "#    - éœ€è¦å¯¹å†å²æ•°æ®è¿›è¡Œå›æº¯è¯„åˆ†\n",
    "#    - å®ç°ç”¨æˆ·åé¦ˆç³»ç»Ÿï¼ˆç”¨æˆ·ç‚¹å‡»\"æœ‰å¸®åŠ©\"æŒ‰é’®æ—¶ï¼‰\n",
    "#\n",
    "# ğŸ”§ æŠ€æœ¯ç»†èŠ‚ï¼š\n",
    "#    - trace_id å¿…é¡»æå‰ä¿å­˜ï¼ˆå¯é€šè¿‡ Langfuse.create_trace_id() ç”Ÿæˆæˆ–ä»å›è°ƒä¸­è·å–ï¼‰\n",
    "#    - å®Œå…¨ç‹¬ç«‹çš„ API è°ƒç”¨ï¼Œä¸ä¾èµ–ä»»ä½•ä¸Šä¸‹æ–‡\n",
    "#    - å¯ä»¥åœ¨ä»»ä½•æ—¶é—´ã€ä»»ä½•åœ°æ–¹è°ƒç”¨ï¼Œåªè¦æœ‰æ­£ç¡®çš„ trace_id\n",
    "#\n",
    "# ğŸ†š ä¸å‰ä¸¤ç§æ–¹æ¡ˆçš„åŒºåˆ«ï¼š\n",
    "#    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "#    â”‚             â”‚ æ–¹æ¡ˆä¸€      â”‚ æ–¹æ¡ˆäºŒ      â”‚ æ–¹æ¡ˆä¸‰         â”‚\n",
    "#    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "#    â”‚ ä¸Šä¸‹æ–‡ä¾èµ–  â”‚ éœ€è¦        â”‚ éœ€è¦        â”‚ ä¸éœ€è¦         â”‚\n",
    "#    â”‚ trace_id    â”‚ è‡ªåŠ¨è·å–    â”‚ è‡ªåŠ¨è·å–    â”‚ æ‰‹åŠ¨æä¾›       â”‚\n",
    "#    â”‚ æ—¶é—´è€¦åˆ    â”‚ åŒæ­¥        â”‚ åŒæ­¥        â”‚ å®Œå…¨è§£è€¦       â”‚\n",
    "#    â”‚ æ‰§è¡Œæ—¶æœº    â”‚ æ‰§è¡ŒæœŸé—´    â”‚ æ‰§è¡ŒæœŸé—´    â”‚ ä»»ä½•æ—¶å€™       â”‚\n",
    "#    â”‚ å…¸å‹åœºæ™¯    â”‚ å³æ—¶è¯„åˆ†    â”‚ æ·±å±‚è¯„åˆ†    â”‚ å¼‚æ­¥/æ‰¹é‡è¯„åˆ†  â”‚\n",
    "#    â”‚ çµæ´»æ€§      â”‚ ä½          â”‚ ä¸­          â”‚ é«˜             â”‚\n",
    "#    â”‚ å¤æ‚åº¦      â”‚ ä½          â”‚ ä½          â”‚ ä¸­ï¼ˆéœ€ç®¡ç†IDï¼‰ â”‚\n",
    "#    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "#\n",
    "# ğŸ“ å…¸å‹ä½¿ç”¨æµç¨‹ï¼š\n",
    "# 1ï¸âƒ£ åœ¨ LangGraph æ‰§è¡Œæ—¶ä¿å­˜ trace_id\n",
    "# 2ï¸âƒ£ å°† trace_id ä¸ä¸šåŠ¡æ•°æ®å…³è”ï¼ˆå¦‚ï¼šå­˜å…¥æ•°æ®åº“ï¼‰\n",
    "# 3ï¸âƒ£ åœ¨åˆé€‚çš„æ—¶æœºï¼ˆå¦‚ç”¨æˆ·åé¦ˆã€å®šæ—¶ä»»åŠ¡ï¼‰ä½¿ç”¨ trace_id è¿›è¡Œè¯„åˆ†\n",
    "#\n",
    "langfuse.create_score(\n",
    "    trace_id=\"f4122db2c96eb4752585c3706cf802f2\",  # âš ï¸ è¿™é‡Œéœ€è¦æ›¿æ¢æˆçœŸå®çš„ trace_id\n",
    "    name=\"user-feedback\",                   # è¯„åˆ†é¡¹åç§°\n",
    "    value=1,                                # è¯„åˆ†å€¼\n",
    "    data_type=\"NUMERIC\",                    # æ•°æ®ç±»å‹\n",
    "    comment=\"This was correct, thank you\"   # å¯é€‰ï¼šè¯„åˆ†è¯´æ˜\n",
    ")\n",
    "# \n",
    "# ğŸŒŸ å®é™…åº”ç”¨ç¤ºä¾‹ï¼š\n",
    "# \n",
    "# ã€åœºæ™¯ 1ï¼šç”¨æˆ·å»¶è¿Ÿåé¦ˆã€‘\n",
    "# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "# 1. ç”¨æˆ·æé—® â†’ LangGraph æ‰§è¡Œ â†’ è¿”å›ç­”æ¡ˆï¼ˆä¿å­˜ trace_id åˆ°æ•°æ®åº“ï¼‰\n",
    "# 2. ç”¨æˆ·é˜…è¯»ç­”æ¡ˆåç‚¹å‡»\"ğŸ‘ æœ‰å¸®åŠ©\"æŒ‰é’®ï¼ˆå¯èƒ½æ˜¯å‡ åˆ†é’Ÿåï¼‰\n",
    "# 3. å‰ç«¯å‘é€ trace_id åˆ°åç«¯ API\n",
    "# 4. åç«¯è°ƒç”¨ create_score() è®°å½•ç”¨æˆ·åé¦ˆ\n",
    "#\n",
    "# ã€åœºæ™¯ 2ï¼šæ‰¹é‡è´¨é‡è¯„ä¼°ã€‘\n",
    "# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "# 1. æ¯å¤©å®šæ—¶ä»»åŠ¡ä»æ•°æ®åº“è¯»å–æ˜¨å¤©çš„æ‰€æœ‰ trace_id\n",
    "# 2. å¯¹æ¯ä¸ª trace è¿è¡Œè‡ªåŠ¨åŒ–è¯„ä¼°è„šæœ¬ï¼ˆå¦‚ï¼šäº‹å®æ ¸æŸ¥ã€å®‰å…¨æ£€æµ‹ï¼‰\n",
    "# 3. ä½¿ç”¨ create_score() æ‰¹é‡æ·»åŠ è¯„åˆ†ç»“æœ\n",
    "#\n",
    "# ã€åœºæ™¯ 3ï¼šäººå·¥æ ‡æ³¨ã€‘\n",
    "# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "# 1. æ ‡æ³¨å›¢é˜Ÿä½¿ç”¨å†…éƒ¨å·¥å…·æŸ¥çœ‹å†å²å¯¹è¯\n",
    "# 2. äººå·¥è¯„ä¼°æ¯ä¸ªå¯¹è¯çš„è´¨é‡ï¼ˆå‡†ç¡®æ€§ã€ç›¸å…³æ€§ã€å‹å¥½æ€§ç­‰ï¼‰\n",
    "# 3. æ ‡æ³¨å·¥å…·è°ƒç”¨ create_score() å°†è¯„åˆ†å†™å…¥ Langfuse\n",
    "#\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ’¡ ä¼˜ç§€åšæ³•å»ºè®®\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "#\n",
    "# 1. ã€é»˜è®¤é€‰æ‹©ã€‘å¤§å¤šæ•°æƒ…å†µä¸‹ä½¿ç”¨æ–¹æ¡ˆä¸€ï¼ˆspan.score_traceï¼‰\n",
    "#    â”œâ”€ ä»£ç æ¸…æ™°ï¼Œæ˜“äºç†è§£å’Œç»´æŠ¤\n",
    "#    â””â”€ é€‚åˆ 80% çš„åŒæ­¥è¯„åˆ†åœºæ™¯\n",
    "#\n",
    "# 2. ã€æ·±å±‚è°ƒç”¨ã€‘éœ€è¦åœ¨å­å‡½æ•°ä¸­è¯„åˆ†æ—¶ä½¿ç”¨æ–¹æ¡ˆäºŒï¼ˆscore_current_traceï¼‰\n",
    "#    â”œâ”€ é¿å…å±‚å±‚ä¼ é€’ span å¯¹è±¡\n",
    "#    â””â”€ ä¿æŒå‡½æ•°ç­¾åç®€æ´\n",
    "#\n",
    "# 3. ã€å¼‚æ­¥åœºæ™¯ã€‘éœ€è¦å»¶è¿Ÿè¯„åˆ†æˆ–æ‰¹é‡å¤„ç†æ—¶ä½¿ç”¨æ–¹æ¡ˆä¸‰ï¼ˆcreate_scoreï¼‰\n",
    "#    â”œâ”€ å®ç°ç”¨æˆ·åé¦ˆç³»ç»Ÿ\n",
    "#    â”œâ”€ å®šæœŸæ‰¹é‡è¯„ä¼°\n",
    "#    â””â”€ è·¨æœåŠ¡è¯„åˆ†\n",
    "#\n",
    "# 4. ã€ç»„åˆä½¿ç”¨ã€‘å¯ä»¥åŒæ—¶ä½¿ç”¨å¤šç§æ–¹æ¡ˆ\n",
    "#    â”œâ”€ æ–¹æ¡ˆä¸€ï¼šå³æ—¶è¯„åˆ†ï¼ˆå¦‚ï¼šAI è‡ªåŠ¨è¯„ä¼°ï¼‰\n",
    "#    â””â”€ æ–¹æ¡ˆä¸‰ï¼šå»¶è¿Ÿè¯„åˆ†ï¼ˆå¦‚ï¼šç”¨æˆ·åé¦ˆï¼‰\n",
    "#\n",
    "# 5. ã€æ•°æ®ç±»å‹é€‰æ‹©ã€‘\n",
    "#    â”œâ”€ NUMERIC: ç”¨äºå¯é‡åŒ–çš„æŒ‡æ ‡ï¼ˆå‡†ç¡®ç‡ã€æ»¡æ„åº¦åˆ†æ•°ï¼‰\n",
    "#    â”œâ”€ TEXT: ç”¨äºæ–‡æœ¬è¯„è®ºå’Œè¯¦ç»†åé¦ˆ\n",
    "#    â””â”€ CATEGORICAL: ç”¨äºåˆ†ç±»æ ‡ç­¾ï¼ˆexcellent/good/poorï¼‰\n",
    "#\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iiemuS7YfoSR"
   },
   "source": [
    "ç”¨æˆ·åé¦ˆéšåä¼šè¢« Langfuse æ•è·ï¼š\n",
    "\n",
    "![Langfuse ä¸­æ•è·çš„ç”¨æˆ·åé¦ˆ](https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202511251751419.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "29KsI9xcfoSR"
   },
   "source": [
    "#### 4. è‡ªåŠ¨åŒ–çš„ LLM è¯„å®¡æ‰“åˆ†ï¼ˆLLM-as-a-Judgeï¼‰\n",
    "\n",
    "LLM-as-a-Judge æä¾›äº†ä¸€ç§è‡ªåŠ¨è¯„ä¼°Agentè¾“å‡ºçš„æ–¹æ³•ã€‚ä½ å¯ä»¥**é…ç½®ä¸€ä¸ªç‹¬ç«‹çš„ LLM è°ƒç”¨**ï¼Œç”¨äºè¯„ä¼°è¾“å‡ºçš„æ­£ç¡®æ€§ã€æ¯’æ€§ã€é£æ ¼æˆ–å…¶ä»–ä½ å…³å¿ƒçš„æŒ‡æ ‡ã€‚\n",
    "\n",
    "**å·¥ä½œæµç¨‹ï¼š**\n",
    "1. å®šä¹‰ä¸€ä¸ª**è¯„ä¼°æ¨¡æ¿**ï¼Œä¾‹å¦‚â€œæ£€æŸ¥æ–‡æœ¬æ˜¯å¦å«æœ‰æ¯’æ€§â€ã€‚\n",
    "2. æŒ‡å®šç”¨äºè¯„å®¡çš„æ¨¡å‹ï¼ˆjudge-modelï¼‰ï¼Œä¾‹å¦‚ `gpt-4o-mini`ã€‚\n",
    "2. æ¯å½“Agentç”Ÿæˆè¾“å‡ºæ—¶ï¼Œå°†å…¶ä¸æ¨¡æ¿ä¸€èµ·ä¼ ç»™â€œè¯„å®¡â€LLMã€‚\n",
    "3. è¯„å®¡ LLM ç»™å‡ºè¯„åˆ†æˆ–æ ‡ç­¾ï¼Œå¹¶å°†ç»“æœè®°å½•åˆ°å¯è§‚æµ‹æ€§å¹³å°ã€‚\n",
    "\n",
    "Langfuse ç¤ºä¾‹ï¼š\n",
    "\n",
    "![LLM è¯„å®¡æ¨¡æ¿](https://langfuse.com/images/cookbook/integration_openai-agents/evaluator-template.png)\n",
    "![LLM è¯„å®¡å™¨](https://langfuse.com/images/cookbook/integration_openai-agents/evaluator.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g7fN0UTkfoSR"
   },
   "source": [
    "#### 5. å¯è§‚æµ‹æ€§æŒ‡æ ‡æ€»è§ˆ\n",
    "\n",
    "æ‰€æœ‰ä¸Šè¿°æŒ‡æ ‡éƒ½å¯ä»¥åœ¨ç»Ÿä¸€çš„ä»ªè¡¨ç›˜ä¸­å¯è§†åŒ–ã€‚è¿™æ ·ä½ å¯ä»¥å¿«é€ŸæŸ¥çœ‹Agentåœ¨å¤šæ¬¡ä¼šè¯ä¸­çš„è¡¨ç°ï¼Œå¹¶éšæ—¶é—´è·Ÿè¸ªè´¨é‡æŒ‡æ ‡ã€‚\n",
    "\n",
    "![å¯è§‚æµ‹æ€§æŒ‡æ ‡æ€»è§ˆ](https://langfuse.com/images/cookbook/integration_openai-agents/dashboard-dark.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zlwltgEkfoSR"
   },
   "source": [
    "## ğŸ”¬ 4ï¼š ç¦»çº¿è¯„ä¼°ï¼ˆOffline Evaluationï¼‰\n",
    "\n",
    "åœ¨çº¿è¯„ä¼°å¯ç”¨äºè·å–å®æ—¶åé¦ˆï¼Œä½†åŒæ ·éœ€è¦è¿›è¡Œ**ç¦»çº¿è¯„ä¼°ï¼ˆoffline evaluationï¼‰**â€”â€”å³åœ¨å¼€å‘å‰æˆ–å¼€å‘è¿‡ç¨‹ä¸­è¿›è¡Œç³»ç»Ÿæ€§çš„æ£€æŸ¥ã€‚è¿™æ ·å¯ä»¥åœ¨å‘å¸ƒå˜æ›´åˆ°ç”Ÿäº§ç¯å¢ƒä¹‹å‰ï¼Œä¿éšœè´¨é‡ä¸å¯é æ€§ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p5R8eNQxfoSR"
   },
   "source": [
    "### æ•°æ®é›†è¯„ä¼°ï¼ˆDataset Evaluationï¼‰\n",
    "\n",
    "åœ¨ç¦»çº¿è¯„ä¼°ä¸­ï¼Œé€šå¸¸ä¼šï¼š\n",
    "1. å‡†å¤‡ä¸€ä¸ªåŸºå‡†æ•°æ®é›†ï¼ˆåŒ…å«æç¤ºè¯ä¸æœŸæœ›è¾“å‡ºçš„æˆå¯¹æ ·æœ¬ï¼‰\n",
    "2. ä½¿ç”¨è¯¥æ•°æ®é›†æ‰¹é‡è¿è¡Œä½ çš„ Agent\n",
    "3. å°†æ¨¡å‹è¾“å‡ºä¸æœŸæœ›ç»“æœè¿›è¡Œæ¯”è¾ƒï¼Œæˆ–é‡‡ç”¨é¢å¤–çš„è‡ªåŠ¨æ‰“åˆ†æœºåˆ¶\n",
    "\n",
    "ä¸‹é¢æˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªé—®ç­”æ•°æ®é›†ç¤ºä¾‹ï¼š[q&a-dataset](https://huggingface.co/datasets/junzhang1207/search-dataset)ï¼Œå…¶ä¸­åŒ…å«é—®é¢˜ä¸æœŸæœ›ç­”æ¡ˆã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: datasets==4.3.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (4.3.0)\n",
      "Requirement already satisfied: filelock in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from datasets==4.3.0) (3.20.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from datasets==4.3.0) (2.2.6)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from datasets==4.3.0) (21.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from datasets==4.3.0) (0.4.0)\n",
      "Requirement already satisfied: pandas in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from datasets==4.3.0) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from datasets==4.3.0) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from datasets==4.3.0) (0.28.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from datasets==4.3.0) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from datasets==4.3.0) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from datasets==4.3.0) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets==4.3.0) (2025.9.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from datasets==4.3.0) (0.36.0)\n",
      "Requirement already satisfied: packaging in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from datasets==4.3.0) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from datasets==4.3.0) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets==4.3.0) (3.13.0)\n",
      "Requirement already satisfied: anyio in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from httpx<1.0.0->datasets==4.3.0) (4.11.0)\n",
      "Requirement already satisfied: certifi in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from httpx<1.0.0->datasets==4.3.0) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from httpx<1.0.0->datasets==4.3.0) (1.0.9)\n",
      "Requirement already satisfied: idna in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from httpx<1.0.0->datasets==4.3.0) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from httpcore==1.*->httpx<1.0.0->datasets==4.3.0) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets==4.3.0) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets==4.3.0) (1.1.10)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets==4.3.0) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets==4.3.0) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets==4.3.0) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets==4.3.0) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets==4.3.0) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets==4.3.0) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets==4.3.0) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets==4.3.0) (1.22.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from requests>=2.32.2->datasets==4.3.0) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from requests>=2.32.2->datasets==4.3.0) (2.5.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from anyio->httpx<1.0.0->datasets==4.3.0) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from anyio->httpx<1.0.0->datasets==4.3.0) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from pandas->datasets==4.3.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from pandas->datasets==4.3.0) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from pandas->datasets==4.3.0) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets==4.3.0) (1.17.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install datasets==4.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zOAP8e45wIsp",
    "outputId": "b2807d06-e184-43b7-cb94-e2e2ef8e40af"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/agent101/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: HF_ENDPOINT=https://hf-mirror.com\n",
      "First few rows of search-dataset:\n",
      "                                     id  \\\n",
      "0  20caf138-0c81-4ef9-be60-fe919e0d68d4   \n",
      "1  1f37d9fd-1bcc-4f79-b004-bc0e1e944033   \n",
      "2  76173a7f-d645-4e3e-8e0d-cca139e00ebe   \n",
      "3  5f5ef4ca-91fe-4610-a8a9-e15b12e3c803   \n",
      "4  64dbed0d-d91b-4acd-9a9c-0a7aa83115ec   \n",
      "\n",
      "                                            question  \\\n",
      "0                 steve jobs statue location budapst   \n",
      "1  Why is the Battle of Stalingrad considered a t...   \n",
      "2  In what year did 'The Birth of a Nation' surpa...   \n",
      "3  How many Russian soldiers surrendered to AFU i...   \n",
      "4   What event led to the creation of Google Images?   \n",
      "\n",
      "                                     expected_answer       category       area  \n",
      "0  The Steve Jobs statue is located in Budapest, ...           Arts  Knowledge  \n",
      "1  The Battle of Stalingrad is considered a turni...   General News       News  \n",
      "2  This question is based on a false premise. 'Th...  Entertainment       News  \n",
      "3  About 300 Russian soldiers surrendered to the ...   General News       News  \n",
      "4  Jennifer Lopez's appearance in a green Versace...     Technology       News  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "# è®¾ç½®HuggingFaceAgent\n",
    "%env HF_ENDPOINT=https://hf-mirror.com\n",
    "\n",
    "# ğŸ“¥ ä» Hugging Face ä¸‹è½½ç¤ºä¾‹æ•°æ®é›†ï¼Œè¿™é‡ŒåŒ…å«é—®ç­”å½¢å¼çš„æ¡ç›®\n",
    "dataset = load_dataset(\"junzhang1207/search-dataset\", split=\"train\")\n",
    "df = pd.DataFrame(dataset)  # è½¬æˆ DataFrame æ–¹ä¾¿ç­›é€‰ä¸éå†\n",
    "print(\"First few rows of search-dataset:\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æˆåŠŸè¯»å–æœ¬åœ° JSONL æ–‡ä»¶: ../dataset/data.jsonl\n",
      "\n",
      "æ•°æ®é›†å‰5è¡Œ:\n",
      "                                     id  \\\n",
      "0  20caf138-0c81-4ef9-be60-fe919e0d68d4   \n",
      "1  1f37d9fd-1bcc-4f79-b004-bc0e1e944033   \n",
      "2  76173a7f-d645-4e3e-8e0d-cca139e00ebe   \n",
      "3  5f5ef4ca-91fe-4610-a8a9-e15b12e3c803   \n",
      "4  64dbed0d-d91b-4acd-9a9c-0a7aa83115ec   \n",
      "\n",
      "                                            question  \\\n",
      "0                 steve jobs statue location budapst   \n",
      "1  Why is the Battle of Stalingrad considered a t...   \n",
      "2  In what year did 'The Birth of a Nation' surpa...   \n",
      "3  How many Russian soldiers surrendered to AFU i...   \n",
      "4   What event led to the creation of Google Images?   \n",
      "\n",
      "                                     expected_answer       category       area  \n",
      "0  The Steve Jobs statue is located in Budapest, ...           Arts  Knowledge  \n",
      "1  The Battle of Stalingrad is considered a turni...   General News       News  \n",
      "2  This question is based on a false premise. 'Th...  Entertainment       News  \n",
      "3  About 300 Russian soldiers surrendered to the ...   General News       News  \n",
      "4  Jennifer Lopez's appearance in a green Versace...     Technology       News  \n",
      "\n",
      "æ•°æ®é›†å½¢çŠ¶: (929, 5)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# ğŸ“Œ æ›¿æ¢ä¸ºä½ æœ¬åœ°æ–‡ä»¶çš„å®é™…è·¯å¾„ï¼Œä¾‹å¦‚ï¼š'dataset/data.jsonl '\n",
    "local_jsonl_path = '../dataset/data.jsonl'\n",
    "\n",
    "if os.path.exists(local_jsonl_path):\n",
    "    try:\n",
    "        # ä½¿ç”¨ pd.read_json å¹¶æŒ‡å®š lines=True æ¥è¯»å– JSON Lines æ ¼å¼\n",
    "        local_df = pd.read_json(local_jsonl_path, lines=True)\n",
    "        \n",
    "        print(f\"âœ… æˆåŠŸè¯»å–æœ¬åœ° JSONL æ–‡ä»¶: {local_jsonl_path}\")\n",
    "        print(\"\\næ•°æ®é›†å‰5è¡Œ:\")\n",
    "        print(local_df.head())\n",
    "        print(f\"\\næ•°æ®é›†å½¢çŠ¶: {local_df.shape}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ è¯»å–æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}\")\n",
    "else:\n",
    "    print(f\"æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·æ£€æŸ¥è·¯å¾„æ˜¯å¦æ­£ç¡®: {local_jsonl_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rlgYY3VmwIsp"
   },
   "source": [
    "æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬åœ¨ Langfuse ä¸­åˆ›å»ºä¸€ä¸ªæ•°æ®é›†å®ä½“ä»¥è¿½è¸ªè¿è¡Œï¼›éšåå°†æ•°æ®é›†ä¸­çš„æ¯æ¡è®°å½•æ·»åŠ åˆ°ç³»ç»Ÿä¸­ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cdn2qSCwwIsp",
    "outputId": "ef3bb5d3-21bc-416a-aef3-5dccfedd2b05"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset(id='cmicvzreq000spl07o8xsvpcq', name='qa-dataset_langgraph-agent', description='ä»Hugging Faceä¸Šä¼ çš„é—®ç­”æ•°æ®é›†', metadata={'date': '2025-11-04', 'type': 'benchmark'}, project_id='cmicm34hk0006pl07fhwb5ezk', created_at=datetime.datetime(2025, 11, 24, 8, 30, 22, 842000, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 11, 25, 2, 52, 43, 779000, tzinfo=datetime.timezone.utc), inputSchema=None, expectedOutputSchema=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langfuse import Langfuse\n",
    "langfuse = Langfuse()\n",
    "\n",
    "langfuse_dataset_name = \"qa-dataset_langgraph-agent\"\n",
    "\n",
    "# ğŸ—‚ï¸ åœ¨ Langfuse ä¸­åˆ›å»ºä¸€ä¸ªæ–°çš„æ•°æ®é›†ï¼Œç”¨äºå­˜å‚¨è¯„æµ‹æ ·æœ¬\n",
    "langfuse.create_dataset(\n",
    "    name=langfuse_dataset_name,\n",
    "    description=\"ä»Hugging Faceä¸Šä¼ çš„é—®ç­”æ•°æ®é›†\",\n",
    "    metadata={\n",
    "        \"date\": \"2025-11-04\",\n",
    "        \"type\": \"benchmark\"\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "_BkN1d1QwIsq"
   },
   "outputs": [],
   "source": [
    "# ğŸ¯ ä»…é€‰å– 30 æ¡ç¤ºä¾‹æ•°æ®ä¸Šä¼ ï¼Œå®é™…é¡¹ç›®å¯æ ¹æ®éœ€æ±‚è°ƒæ•´\n",
    "df_30 = local_df.sample(30)\n",
    "\n",
    "for idx, row in df_30.iterrows():\n",
    "    langfuse.create_dataset_item(\n",
    "        dataset_name=langfuse_dataset_name,\n",
    "        input={\"text\": row[\"question\"]},            # Langfuse éœ€è¦æ˜ç¡®çš„è¾“å…¥å­—æ®µ\n",
    "        expected_output={\"text\": row[\"expected_answer\"]}  # æä¾›æ ‡å‡†ç­”æ¡ˆä¾¿äºåç»­è¯„ä¼°\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x3yJVaBnwIsq"
   },
   "source": [
    "![Langfuse ä¸­çš„æ•°æ®é›†æ¡ç›®](https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202509261143566.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z7NHQ4XowIsq"
   },
   "source": [
    "#### åœ¨æ•°æ®é›†ä¸Šè¿è¡ŒAgent\n",
    "\n",
    "é¦–å…ˆï¼Œæ„å»ºä¸€ä¸ªä½¿ç”¨ OpenAI æ¨¡å‹å›ç­”é—®é¢˜çš„ç®€æ˜“ LangGraph Agentã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "ACoBDVzbwIsq"
   },
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage  # å¦‚éœ€è‡ªå®šä¹‰è¾“å…¥æ¶ˆæ¯å¯ä»¥ä½¿ç”¨è¯¥ç±»å‹\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "# ğŸ§± å®šä¹‰çŠ¶æ€ç»“æ„ï¼šmessages å­—æ®µä¼šè‡ªåŠ¨ç´¯ç§¯å¯¹è¯å†å²\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# ğŸ—ï¸ åˆå§‹åŒ–ä¸€ä¸ªæ–°çš„çŠ¶æ€å›¾æ„å»ºå™¨\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# ğŸ¤– å‡†å¤‡è¦è°ƒç”¨çš„ OpenAI èŠå¤©æ¨¡å‹\n",
    "llm = ChatOpenAI(model=\"gpt-4.5-preview\")\n",
    "\n",
    "def chatbot(state: State):\n",
    "    \"\"\"\n",
    "    å•èŠ‚ç‚¹èŠå¤©æœºå™¨äººï¼š\n",
    "    - å°†å½“å‰æ‰€æœ‰æ¶ˆæ¯ä¼ ç»™ LLM\n",
    "    - è¿”å›æ¨¡å‹çš„å›å¤ï¼ŒLangGraph ä¼šè‡ªåŠ¨æŠŠå®ƒè¿½åŠ åˆ°çŠ¶æ€é‡Œ\n",
    "    \"\"\"\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "# ğŸ”— æ³¨å†ŒèŠ‚ç‚¹ä¸å…¥å£ã€å‡ºå£\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "graph_builder.set_finish_point(\"chatbot\")\n",
    "\n",
    "# âš™ï¸ compile() ä¼šè¿”å›å¯ç›´æ¥è°ƒç”¨çš„å›¾å®ä¾‹\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MXSe2ScIwIsq"
   },
   "source": [
    "æ¥ç€ï¼Œæˆ‘ä»¬å®šä¹‰ä¸€ä¸ªè¾…åŠ©å‡½æ•° `my_agent()`ï¼Œå…¶èŒè´£æ˜¯ï¼š\n",
    "1. åˆ›å»ºä¸€ä¸ª Langfuse è¿½è¸ªï¼ˆtraceï¼‰\n",
    "2. è·å– `langfuse_handler_trace`ï¼Œç”¨äºä¸º LangGraph çš„æ‰§è¡Œè¿‡ç¨‹æ‰“ç‚¹\n",
    "3. è¿è¡Œæˆ‘ä»¬çš„ Agentï¼Œå¹¶åœ¨è°ƒç”¨æ—¶ä¼ å…¥ `langfuse_handler_trace` ä»¥è®°å½•æ‰§è¡Œç»†èŠ‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "ZQTQKusMwIsq"
   },
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langfuse import get_client\n",
    "from langfuse.langchain import CallbackHandler\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate  # å¯ç”¨äºè‡ªå®šä¹‰æç¤ºæ¨¡æ¿ï¼ˆæœ¬ç¤ºä¾‹æš‚æœªä½¿ç”¨ï¼‰\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# ğŸ—ï¸ æ„å»ºä¸€ä¸ªå¸¦ Langfuse è¿½è¸ªèƒ½åŠ›çš„ LangGraph Agent\n",
    "graph_builder = StateGraph(State)\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")  # é€‰æ‹©å¯¹è¯æ¨¡å‹  ï¼›ä½¿ç”¨å…¶ä»–æ¨¡å‹æµ‹è¯•ï¼Œæ³¨æ„ä¿®æ”¹\n",
    "langfuse = get_client()  # å¤ç”¨å‰é¢é…ç½®å¥½çš„ Langfuse å®¢æˆ·ç«¯\n",
    "\n",
    "def chatbot(state: State):\n",
    "    \"\"\"\n",
    "    æ ¸å¿ƒèŠ‚ç‚¹ï¼šå°†å¯¹è¯å†å²äº¤ç»™ LLMï¼Œå¹¶æŠŠç”Ÿæˆç»“æœåŒ…è£…æˆ LangGraph éœ€è¦çš„æ ¼å¼ã€‚\n",
    "    \"\"\"\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "graph_builder.set_finish_point(\"chatbot\")\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "def my_agent(question, langfuse_handler):\n",
    "    \"\"\"\n",
    "    å¯¹å¤–æš´éœ²çš„ä¾¿æ·å‡½æ•°ï¼š\n",
    "    1. æ‰“å¼€ä¸€ä¸ª Langfuse span ä»¥ä¾¿è§‚æµ‹è¿™æ¬¡è¯·æ±‚ï¼›\n",
    "    2. è°ƒç”¨ LangGraph Agentè·å–å›ç­”ï¼›\n",
    "    3. å°†è¾“å…¥è¾“å‡ºå†™å› Langfuseï¼Œæ–¹ä¾¿åç»­è¯„ä¼°ã€‚\n",
    "    \"\"\"\n",
    "\n",
    "    # åˆ›å»ºä¸€ä¸ªé¡¶å±‚è¿½è¸ª spanï¼Œæ‰€æœ‰ä¸Šä¸‹æ–‡éƒ½ä¼šè®°å½•åœ¨è¿™é‡Œ\n",
    "    with langfuse.start_as_current_span(name=\"my-langgraph-agent\") as root_span:\n",
    "\n",
    "        # Step 2: LangChain processing\n",
    "        response = graph.invoke(\n",
    "            input={\"messages\": [HumanMessage(content=question)]},\n",
    "            config={\"callbacks\": [langfuse_handler]}\n",
    "        )\n",
    "\n",
    "        # å°†åŸå§‹é—®é¢˜å’Œæ¨¡å‹å›ç­”åŒæ­¥åˆ° Langfuse ä»ªè¡¨ç›˜\n",
    "        root_span.update_trace(\n",
    "            input=question,\n",
    "            output=response[\"messages\"][1].content)\n",
    "\n",
    "        print(question)\n",
    "        print(response[\"messages\"][1].content)\n",
    "\n",
    "    return response[\"messages\"][1].content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1iri3PYQwIsq"
   },
   "source": [
    "æœ€åï¼Œæˆ‘ä»¬éå†æ•°æ®é›†ä¸­çš„æ¯ä¸€æ¡æ ·æœ¬ï¼Œè¿è¡ŒAgentï¼Œå¹¶å°†ç”Ÿæˆçš„è¿½è¸ªä¸è¯¥æ•°æ®é›†æ¡ç›®è¿›è¡Œå…³è”ã€‚å¦‚æœ‰éœ€è¦ï¼Œè¿˜å¯ä»¥é™„åŠ ä¸€ä¸ªå¿«é€Ÿçš„è¯„ä¼°åˆ†æ•°ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æµ‹è¯•ï¼š ä½¿ç”¨gpt-4oæ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MJyw6m61wIsq",
    "outputId": "7115f780-5ce4-49c2-c281-40cd7bcd76bb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'items'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 751, in on_llm_end\n",
      "    llm_usage = _parse_usage(response)\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 1027, in _parse_usage\n",
      "    llm_usage = _parse_usage_model(response.llm_output[key])\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 946, in _parse_usage_model\n",
      "    for key, value in input_token_details.items():\n",
      "AttributeError: 'NoneType' object has no attribute 'items'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'How much did Microsoft pay to acquire Mojang, the creator of Minecraft?'}\n",
      "Microsoft paid **$2.5 billion** to acquire Mojang, the developer of Minecraft, in September 2014.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'items'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 751, in on_llm_end\n",
      "    llm_usage = _parse_usage(response)\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 1027, in _parse_usage\n",
      "    llm_usage = _parse_usage_model(response.llm_output[key])\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 946, in _parse_usage_model\n",
      "    for key, value in input_token_details.items():\n",
      "AttributeError: 'NoneType' object has no attribute 'items'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'Which video game is set in 1899 and 1907?'}\n",
      "The video game set in 1899 and 1907 is *Red Dead Redemption 2*. Developed by Rockstar Games, it is an action-adventure game that follows the story of Arthur Morgan, a member of the Van der Linde gang, as they navigate challenges during the decline of the Wild West era.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'items'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 751, in on_llm_end\n",
      "    llm_usage = _parse_usage(response)\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 1027, in _parse_usage\n",
      "    llm_usage = _parse_usage_model(response.llm_output[key])\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 946, in _parse_usage_model\n",
      "    for key, value in input_token_details.items():\n",
      "AttributeError: 'NoneType' object has no attribute 'items'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'in which episode does omar little become mayor of baltimore'}\n",
      "Omar Little never becomes the mayor of Baltimore in the TV series *The Wire*. Omar is a renowned stick-up man who robs drug dealers and operates according to his own code, but his character never pursues or achieves any political position. If this question refers to a metaphorical or symbolic interpretation, feel free to clarify!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'items'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 751, in on_llm_end\n",
      "    llm_usage = _parse_usage(response)\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 1027, in _parse_usage\n",
      "    llm_usage = _parse_usage_model(response.llm_output[key])\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 946, in _parse_usage_model\n",
      "    for key, value in input_token_details.items():\n",
      "AttributeError: 'NoneType' object has no attribute 'items'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'What was the outcome of the Battle of Stalingrad and its significance in World War II?'}\n",
      "The Battle of Stalingrad, fought between August 23, 1942, and February 2, 1943, was a critical turning point in World War II. It was a brutal and devastating engagement between Nazi Germany and its allies against the Soviet Union.\n",
      "\n",
      "### **Outcome:**\n",
      "The Soviet Army successfully defended Stalingrad and defeated the German 6th Army, marking one of Adolf Hitler's most significant military defeats. The battle resulted in catastrophic losses for both sides, with an estimated total of over two million casualties, including soldiers and civilians. The Germans were forced to surrender, with approximately 91,000 troops taken prisoner by the Soviets.\n",
      "\n",
      "### **Significance:**\n",
      "1. **Turning Point in the Eastern Front:** The battle marked the beginning of the Soviet Union's transition from defense to offense. Following their victory, the Red Army launched counteroffensives that pushed German forces steadily westward.\n",
      "\n",
      "2. **Symbolic and Psychological Impact:** Stalingrad became a symbol of Soviet resilience and determination. The victory boosted morale among the Allies and dealt a severe blow to German confidence.\n",
      "\n",
      "3. **Strategic Consequences:** With the loss of the 6th Army and critical supplies, the Germans were unable to maintain their campaign in the East at the same intensity. This defeat began the gradual retreat of German forces from Soviet territory.\n",
      "\n",
      "4. **Shift in Global Perception:** The battle demonstrated the Soviet Unionâ€™s strength and its crucial role in defeating the Axis powers, contributing to its emergence as a major global power during and after the war.\n",
      "\n",
      "In summary, the Battle of Stalingrad was a pivotal event that shifted the tide of World War II, paving the way for the Allied victories that would follow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'items'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 751, in on_llm_end\n",
      "    llm_usage = _parse_usage(response)\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 1027, in _parse_usage\n",
      "    llm_usage = _parse_usage_model(response.llm_output[key])\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 946, in _parse_usage_model\n",
      "    for key, value in input_token_details.items():\n",
      "AttributeError: 'NoneType' object has no attribute 'items'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'causes of rotator cuff tear'}\n",
      "A rotator cuff tear occurs when the tendons that connect the muscles of the rotator cuff to the upper arm bone (humerus) are damaged or torn. Common causes include:\n",
      "\n",
      "### **1. Overuse or Repetitive Movements**\n",
      "   - Repetitive motions, such as those involved in sports (e.g., baseball, tennis) or occupations (e.g., painting or carpentry), can strain the rotator cuff over time.\n",
      "   - Activities that require frequent or forceful overhead movements tend to have a higher risk.\n",
      "\n",
      "### **2. Age-Related Degeneration**\n",
      "   - Wear and tear of the tendons becomes more common with aging, often leading to rotator cuff injuries in individuals over 40 years old.\n",
      "   - Blood supply to the tendons diminishes as people age, which can hinder the repair process.\n",
      "\n",
      "### **3. Acute Injury or Trauma**\n",
      "   - Sudden injuries, such as a fall onto an outstretched hand, heavy lifting, or accidents, can result in a rotator cuff tear.\n",
      "   - Dislocations of the shoulder or fractures of the collarbone can also affect the rotator cuff.\n",
      "\n",
      "### **4. Sports or Athletic Activities**\n",
      "   - Athletes who engage in overhead sports, such as swimming, tennis, baseball, or volleyball, are prone to developing tears due to repetitive stress on the rotator cuff.\n",
      "\n",
      "### **5. Impingement Syndrome**\n",
      "   - Impingement occurs when the rotator cuff rubs against the shoulder blade (acromion), leading to fraying or tearing over time.\n",
      "   - Chronic impingement can eventually result in a tear if untreated.\n",
      "\n",
      "### **6. Poor Posture or Mechanics**\n",
      "   - Poor posture, including forward-slumping shoulders, can place strain on the muscles and tendons over time.\n",
      "   - Incorrect lifting techniques can also cause excessive stress on the rotator cuff.\n",
      "\n",
      "### **7. Bone Spurs**\n",
      "   - Bony growths on the underside of the acromion can rub against the rotator cuff tendons, increasing the risk of tearing.\n",
      "\n",
      "### **8. Weak Muscles or Imbalances**\n",
      "   - Weakness in other shoulder or upper back muscles can transfer excess strain to the rotator cuff, increasing the likelihood of a tear.\n",
      "\n",
      "### **9. Genetic Factors**\n",
      "   - Some individuals might have a genetic predisposition to tendon weakness, increasing susceptibility to rotator cuff injuries.\n",
      "\n",
      "Preventive strategies include strengthening the shoulder muscles, improving posture, using proper techniques during physical activities, and addressing any chronic shoulder pain early to avoid progression to a tear.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'items'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 751, in on_llm_end\n",
      "    llm_usage = _parse_usage(response)\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 1027, in _parse_usage\n",
      "    llm_usage = _parse_usage_model(response.llm_output[key])\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 946, in _parse_usage_model\n",
      "    for key, value in input_token_details.items():\n",
      "AttributeError: 'NoneType' object has no attribute 'items'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \"Who is set to return as a series regular in the fifth and final season of 'The Boys'?\"}\n",
      "As of my last update in October 2023, there hasn't been any official information about who is set to return as a series regular in the fifth and final season of *The Boys*. For the most up-to-date information, I recommend checking announcements from Amazon Prime Video or updates from official sources related to the show.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'items'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 751, in on_llm_end\n",
      "    llm_usage = _parse_usage(response)\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 1027, in _parse_usage\n",
      "    llm_usage = _parse_usage_model(response.llm_output[key])\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 946, in _parse_usage_model\n",
      "    for key, value in input_token_details.items():\n",
      "AttributeError: 'NoneType' object has no attribute 'items'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'How many times was Mahatma Gandhi nominated for the Nobel Peace Prize?'}\n",
      "Mahatma Gandhi was nominated for the Nobel Peace Prize **five times**: in 1937, 1938, 1939, 1947, and 1948. Although widely regarded as a symbol of peace and nonviolence, he never received the prize. The Nobel Committee has acknowledged this omission as one of its significant historical oversights, especially considering Gandhi's profound impact on movements for justice and independence.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'items'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 751, in on_llm_end\n",
      "    llm_usage = _parse_usage(response)\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 1027, in _parse_usage\n",
      "    llm_usage = _parse_usage_model(response.llm_output[key])\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 946, in _parse_usage_model\n",
      "    for key, value in input_token_details.items():\n",
      "AttributeError: 'NoneType' object has no attribute 'items'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \"What was the primary purpose of Hadrian's Wall?\"}\n",
      "The primary purpose of Hadrian's Wall was to serve as a defensive fortification for the northern frontier of Roman Britain. Built during the reign of Emperor Hadrian around AD 122, the wall helped to secure the empire's borders, control movement of people, and prevent raids from tribes to the north, particularly the Picts in what is now Scotland. It also acted as a symbol of Roman power and authority, marking the edge of the empire in Britain. Additionally, the wall facilitated trade and taxation by regulating cross-border movement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'items'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 751, in on_llm_end\n",
      "    llm_usage = _parse_usage(response)\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 1027, in _parse_usage\n",
      "    llm_usage = _parse_usage_model(response.llm_output[key])\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 946, in _parse_usage_model\n",
      "    for key, value in input_token_details.items():\n",
      "AttributeError: 'NoneType' object has no attribute 'items'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'What topics does the Comprehensive Rust course cover?'}\n",
      "The **Comprehensive Rust course** typically covers a wide range of topics to provide a strong foundation and practical skills in Rust programming. While specific course contents may vary, here are some commonly included topics:\n",
      "\n",
      "### 1. **Introduction to Rust**\n",
      "   - Overview of the Rust programming language\n",
      "   - Comparing Rust with other languages (e.g., C++ or Python)\n",
      "   - Setting up the development environment (Rust compiler, Cargo)\n",
      "\n",
      "### 2. **Fundamental Rust Concepts**\n",
      "   - Variables and data types\n",
      "   - Ownership, borrowing, and lifetimes (Rustâ€™s memory management model)\n",
      "   - References and smart pointers\n",
      "   - Error handling (Result and Option types)\n",
      "\n",
      "### 3. **Control Flow and Functions**\n",
      "   - Conditionals and loops (`if`, `match`, `while`, `for`)\n",
      "   - Function definitions and parameters\n",
      "   - Closures and higher-order functions\n",
      "\n",
      "### 4. **Data Structures**\n",
      "   - Strings, arrays, tuples, and slices\n",
      "   - Collections (Vectors, HashMaps, Sets, etc.)\n",
      "   - Enums and pattern matching\n",
      "\n",
      "### 5. **Advanced Concepts**\n",
      "   - Traits and generics\n",
      "   - Macros and procedural macros\n",
      "   - Concurrency and parallelism (using threads and async/await)\n",
      "   - Error handling and custom error types\n",
      "\n",
      "### 6. **Rust Ecosystem**\n",
      "   - Package management with Cargo\n",
      "   - Debugging and testing (Unit testing with `#[test]`, integration testing)\n",
      "   - Using third-party crates from `crates.io`\n",
      "\n",
      "### 7. **Memory Safety and Performance**\n",
      "   - How Rust ensures safety and prevents data races\n",
      "   - Profiling and optimization techniques\n",
      "\n",
      "### 8. **Practical Projects**\n",
      "   - Building real-world applications (e.g., CLI tools, web servers, etc.)\n",
      "   - Using Rust frameworks (e.g., Actix or Rocket for web development)\n",
      "   - Networking and file I/O\n",
      "\n",
      "### 9. **Interfacing with Other Languages**\n",
      "   - Interoperability with C/C++ using `FFI`\n",
      "   - Writing safe bindings for external libraries\n",
      "\n",
      "### 10. **Deploying Rust Applications**\n",
      "   - Cross-platform compilation\n",
      "   - Distribution and deployment strategies\n",
      "\n",
      "### 11. **Community and Further Learning**\n",
      "   - Participating in the Rust community (forums, GitHub, etc.)\n",
      "   - Keeping up with the Rust roadmap and advancements\n",
      "\n",
      "If you're asking about a **specific course**, you may need to check the official curriculum or syllabus for that course, as it might focus on a subset or a specific approach to these topics. Would you like advice on learning Rust or recommendations for courses?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'items'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 751, in on_llm_end\n",
      "    llm_usage = _parse_usage(response)\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 1027, in _parse_usage\n",
      "    llm_usage = _parse_usage_model(response.llm_output[key])\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 946, in _parse_usage_model\n",
      "    for key, value in input_token_details.items():\n",
      "AttributeError: 'NoneType' object has no attribute 'items'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \"brand name of $14,000 talking toilet in bob's burgers episode o.t.: the outside toilet\"}\n",
      "In the *Bob's Burgers* episode \"O.T.: The Outside Toilet,\" the brand name of the $14,000 talking toilet is **\"Singing Butt\"**. This fancy, high-tech toilet becomes a major character in the episode and plays a central comedic role in the plot.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'items'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 751, in on_llm_end\n",
      "    llm_usage = _parse_usage(response)\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 1027, in _parse_usage\n",
      "    llm_usage = _parse_usage_model(response.llm_output[key])\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 946, in _parse_usage_model\n",
      "    for key, value in input_token_details.items():\n",
      "AttributeError: 'NoneType' object has no attribute 'items'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'when did russia invad ukraine 2022?'}\n",
      "Russia invaded Ukraine on **February 24, 2022**. This marked the beginning of a large-scale military conflict, escalating tensions that had been building for years. The invasion has had significant geopolitical, humanitarian, and economic repercussions globally.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'items'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 751, in on_llm_end\n",
      "    llm_usage = _parse_usage(response)\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 1027, in _parse_usage\n",
      "    llm_usage = _parse_usage_model(response.llm_output[key])\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 946, in _parse_usage_model\n",
      "    for key, value in input_token_details.items():\n",
      "AttributeError: 'NoneType' object has no attribute 'items'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'boeing 797 flagship model features'}\n",
      "As of October 2023, Boeing has not announced or released a model called the \"797.\" However, there has been significant speculation over the years about Boeing potentially developing a new aircraft to fill the gap between the 737 narrow-body and the 787 Dreamliner wide-body jets. Industry experts and rumors have referred to this hypothetical aircraft as the \"797,\" speculating that it may serve as a \"New Mid-Market Airplane\" (NMA).\n",
      "\n",
      "If Boeing were to develop a 797, it might combine advanced fuel efficiency, medium-haul capabilities, and seating capacities suited for routes that require more range than the 737 can provide but less passenger capacity than the 787 offers.\n",
      "\n",
      "For now, there are no confirmed details or features of a Boeing 797, as it remains speculative. Keep an eye on Boeing's announcements for future updates!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'items'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 751, in on_llm_end\n",
      "    llm_usage = _parse_usage(response)\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 1027, in _parse_usage\n",
      "    llm_usage = _parse_usage_model(response.llm_output[key])\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 946, in _parse_usage_model\n",
      "    for key, value in input_token_details.items():\n",
      "AttributeError: 'NoneType' object has no attribute 'items'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'When did Singapore become an independent sovereign country?'}\n",
      "Singapore became an independent sovereign country on **August 9, 1965**. This followed its separation from Malaysia, which marked its transformation into a fully independent nation. Independence was declared amidst political and social tensions, and Singapore embarked on its journey as a standalone republic.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'items'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 751, in on_llm_end\n",
      "    llm_usage = _parse_usage(response)\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 1027, in _parse_usage\n",
      "    llm_usage = _parse_usage_model(response.llm_output[key])\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 946, in _parse_usage_model\n",
      "    for key, value in input_token_details.items():\n",
      "AttributeError: 'NoneType' object has no attribute 'items'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \"dr smith's theory on humerus realignment for preventing tendonitis\"}\n",
      "Dr. Smith's theory on humerus realignment for preventing tendonitis may involve approaches that focus on improving the alignment and positioning of the humerus bone in the upper arm to reduce strain on tendons and associated muscles. By addressing misalignment or biomechanical imbalances in the shoulder joint, the goal might be to reduce stress and irritation in tissues, thereby minimizing the risk of tendonitis. It would be helpful to analyze the specifics of Dr. Smith's proposed methods, such as surgical intervention, targeted physical therapy, or other non-invasive techniques, to fully understand the scope and applicability of the theory.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'items'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 751, in on_llm_end\n",
      "    llm_usage = _parse_usage(response)\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 1027, in _parse_usage\n",
      "    llm_usage = _parse_usage_model(response.llm_output[key])\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 946, in _parse_usage_model\n",
      "    for key, value in input_token_details.items():\n",
      "AttributeError: 'NoneType' object has no attribute 'items'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \"ford's largest manufacturing facility outside us located in nigeria\"}\n",
      "Ford does not currently have a manufacturing facility in Nigeria that is its largest outside the U.S. Ford's largest manufacturing facilities outside the U.S. are typically located in regions such as Europe, South America, and Asia. For example, Ford's largest plant outside North America is considered to be the Ford Silverton Assembly Plant in South Africa, which plays a key role in producing vehicles for the African market.\n",
      "\n",
      "However, Nigeria is an important market for the automobile industry in Africa, and there have been assemblers and distributors active in the country, including Ford. If you're looking for specific information about Nigeria's connection to Ford, it would help to clarify or confirm with current reports or news from Ford's press releases.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'items'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 751, in on_llm_end\n",
      "    llm_usage = _parse_usage(response)\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 1027, in _parse_usage\n",
      "    llm_usage = _parse_usage_model(response.llm_output[key])\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 946, in _parse_usage_model\n",
      "    for key, value in input_token_details.items():\n",
      "AttributeError: 'NoneType' object has no attribute 'items'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \"Which episodes of House of the Dragon's first season did George R.R. Martin personally write the scripts for?\"}\n",
      "George R.R. Martin did not personally write any of the scripts for the first season of *House of the Dragon*. While he is credited as one of the creators and an executive producer, the writing duties for the show were primarily handled by Ryan Condal, Miguel Sapochnik, and their team of writers. Martin's involvement focused more on providing creative input and ensuring the show stayed true to the source material, particularly his book *Fire & Blood*, which serves as the foundation for the series.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'items'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 751, in on_llm_end\n",
      "    llm_usage = _parse_usage(response)\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 1027, in _parse_usage\n",
      "    llm_usage = _parse_usage_model(response.llm_output[key])\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 946, in _parse_usage_model\n",
      "    for key, value in input_token_details.items():\n",
      "AttributeError: 'NoneType' object has no attribute 'items'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'number of combat missions elizabeth ii flew as raf pilot ww2'}\n",
      "Elizabeth II, the late Queen of the United Kingdom, did not fly combat missions as an RAF pilot during World War II. During the war, she served in the Auxiliary Territorial Service (ATS), the women's branch of the British Army, where she trained as a mechanic and driver. Her service was more focused on logistical support rather than combat roles. \n",
      "\n",
      "This is a common misconceptionâ€”while she contributed to the war effort, she did not serve as a combat pilot.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'items'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 751, in on_llm_end\n",
      "    llm_usage = _parse_usage(response)\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 1027, in _parse_usage\n",
      "    llm_usage = _parse_usage_model(response.llm_output[key])\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 946, in _parse_usage_model\n",
      "    for key, value in input_token_details.items():\n",
      "AttributeError: 'NoneType' object has no attribute 'items'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'Who constructed the Colossus of Rhodes?'}\n",
      "The Colossus of Rhodes was constructed by Chares of Lindos, a Greek sculptor and engineer from the island of Rhodes. The massive statue, built between 292 and 280 BCE, was erected to commemorate the successful defense of Rhodes against a siege led by Demetrius I of Macedon. The Colossus was considered one of the Seven Wonders of the Ancient World and symbolized the island's triumph and independence.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'items'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 751, in on_llm_end\n",
      "    llm_usage = _parse_usage(response)\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 1027, in _parse_usage\n",
      "    llm_usage = _parse_usage_model(response.llm_output[key])\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 946, in _parse_usage_model\n",
      "    for key, value in input_token_details.items():\n",
      "AttributeError: 'NoneType' object has no attribute 'items'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'how to enable js and disable ad blockr'}\n",
      "### Enable JavaScript:\n",
      "To enable JavaScript in your browser, follow these steps:\n",
      "\n",
      "**Google Chrome**:  \n",
      "1. Click the three-dot menu **â‹® (Settings)** in the top-right corner.  \n",
      "2. Navigate to **Privacy and Security > Site Settings > JavaScript**.  \n",
      "3. Ensure the toggle is set to **Enabled**.\n",
      "\n",
      "**Mozilla Firefox**:  \n",
      "1. Type `about:config` in the address bar and press Enter.  \n",
      "2. Search for `javascript.enabled`.  \n",
      "3. If it's set to **false**, double-click to change it to **true**.\n",
      "\n",
      "**Microsoft Edge**:  \n",
      "1. Click the three-dot menu **â‹® (Settings)** in the top-right corner.  \n",
      "2. Navigate to **Cookies and site permissions > JavaScript**.  \n",
      "3. Ensure JavaScript is turned **On**.\n",
      "\n",
      "**Safari (Mac)**:  \n",
      "1. Go to **Safari > Preferences > Security**.  \n",
      "2. Check the box labeled **Enable JavaScript**.\n",
      "\n",
      "---\n",
      "\n",
      "### Disable Ad Blocker:\n",
      "To disable an ad blocker, follow these steps:\n",
      "\n",
      "**Google Chrome**:  \n",
      "1. Click the ad blocker icon in the browser toolbar (usually looks like a shield or stop sign).  \n",
      "2. Select **Pause on this site** or disable it altogether.  \n",
      "3. You can also check extensions via **Settings > Extensions** and toggle the ad blocker off.\n",
      "\n",
      "**Mozilla Firefox**:  \n",
      "1. Click the ad blocker icon in the browser toolbar.  \n",
      "2. Select **Disable on this site** or turn off the ad blocker entirely.  \n",
      "3. Go to `about:addons` to manage and disable extensions.\n",
      "\n",
      "**Microsoft Edge**:  \n",
      "1. Click the ad blocker icon on the toolbar.  \n",
      "2. Choose **Allow ads on this site**, or access **Settings > Extensions** for managing them.\n",
      "\n",
      "**Safari (Mac)**:  \n",
      "1. Select **Safari > Preferences > Extensions**.  \n",
      "2. Uncheck or disable the ad blocker.\n",
      "\n",
      "Let me know if you need further assistance!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'items'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 751, in on_llm_end\n",
      "    llm_usage = _parse_usage(response)\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 1027, in _parse_usage\n",
      "    llm_usage = _parse_usage_model(response.llm_output[key])\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 946, in _parse_usage_model\n",
      "    for key, value in input_token_details.items():\n",
      "AttributeError: 'NoneType' object has no attribute 'items'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'when did zayn malik leave one direction?'}\n",
      "Zayn Malik left One Direction on **March 25, 2015**. He stated in his announcement that he wanted to live as a normal 22-year-old and have some private time out of the spotlight.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'items'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 751, in on_llm_end\n",
      "    llm_usage = _parse_usage(response)\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 1027, in _parse_usage\n",
      "    llm_usage = _parse_usage_model(response.llm_output[key])\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 946, in _parse_usage_model\n",
      "    for key, value in input_token_details.items():\n",
      "AttributeError: 'NoneType' object has no attribute 'items'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'smallest patogen known'}\n",
      "The smallest known pathogen is a **viroid**. Viroids are simpler than viruses and consist entirely of a small circular RNA molecule without a protein coat. They infect plants, causing diseases, but do not infect animals or humans. \n",
      "\n",
      "If considering pathogens that affect humans, **prions** may be regarded as the smallest infectious agents. Prions are abnormal, infectious proteins that cause neurodegenerative diseases, such as Creutzfeldt-Jakob disease, by inducing misfolding in normal proteins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'items'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 751, in on_llm_end\n",
      "    llm_usage = _parse_usage(response)\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 1027, in _parse_usage\n",
      "    llm_usage = _parse_usage_model(response.llm_output[key])\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 946, in _parse_usage_model\n",
      "    for key, value in input_token_details.items():\n",
      "AttributeError: 'NoneType' object has no attribute 'items'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'House of the Dragon season finale leak response'}\n",
      "The leak of the season finale of *House of the Dragon* was a significant incident that drew intense attention from fans and media outlets alike. HBO addressed the situation promptly, expressing disappointment over the unauthorized distribution and vowing to track down the source of the leak. The network emphasized its commitment to protecting its intellectual property and preventing future leaks. Despite the leak, fans were encouraged to watch the episode legally on official platforms to fully appreciate the high-quality production.\n",
      "\n",
      "Leaks of major TV episodes often create controversy, as they can affect viewership, undermine marketing efforts, and spoil key moments for fans. HBO likely took additional steps to mitigate the impact, including increasing security measures to protect upcoming episodes and urging fans to refrain from sharing leaked content. This incident is another stark reminder of the challenges faced by entertainment companies in the digital age.\n",
      "{'text': \"How did Adam McKay's experience directing the first film in The Boys trilogy influence his approach to developing the TV series for Amazon?\"}\n",
      "It seems there might be some confusion in your question, as Adam McKay was not involved in directing *The Boys* trilogy or its TV adaptation for Amazon. *The Boys* is a television series based on the comic book by Garth Ennis and Darick Robertson, developed by Eric Kripke for Amazon Prime Video. Adam McKay, while a prominent filmmaker involved in projects like *The Big Short* and *Vice*, does not have a direct connection to *The Boys*. If you'd like, feel free to clarify or ask about other individuals involved in *The Boys*!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'items'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 751, in on_llm_end\n",
      "    llm_usage = _parse_usage(response)\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 1027, in _parse_usage\n",
      "    llm_usage = _parse_usage_model(response.llm_output[key])\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 946, in _parse_usage_model\n",
      "    for key, value in input_token_details.items():\n",
      "AttributeError: 'NoneType' object has no attribute 'items'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'What title did Marc Benioff earn at Oracle when he was 23 years old?'}\n",
      "Marc Benioff earned the title of **Vice President** at Oracle when he was 23 years old, making him one of the youngest individuals to achieve that position in the company's history.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'items'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 751, in on_llm_end\n",
      "    llm_usage = _parse_usage(response)\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 1027, in _parse_usage\n",
      "    llm_usage = _parse_usage_model(response.llm_output[key])\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 946, in _parse_usage_model\n",
      "    for key, value in input_token_details.items():\n",
      "AttributeError: 'NoneType' object has no attribute 'items'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'Steve Jobs garage historical significance'}\n",
      "Steve Jobs' garage holds immense historical significance as the birthplace of Apple Inc., one of the most influential technology companies in the world. Located at 2066 Crist Drive in Los Altos, California, this unassuming garage was where Jobs, along with Steve Wozniak, assembled and built the first Apple computers in 1976. The work done in this modest setting marked the beginning of the personal computer revolution.\n",
      "\n",
      "The garage has since become a symbol of innovation, entrepreneurship, and the idea that transformative companies can begin with small, humble beginnings. In 2013, the garage was officially designated a historic site in recognition of its role in shaping the modern tech industry. It represents the spirit of creativity and risk-taking that Apple embodied from its earliest days.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'items'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 751, in on_llm_end\n",
      "    llm_usage = _parse_usage(response)\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 1027, in _parse_usage\n",
      "    llm_usage = _parse_usage_model(response.llm_output[key])\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 946, in _parse_usage_model\n",
      "    for key, value in input_token_details.items():\n",
      "AttributeError: 'NoneType' object has no attribute 'items'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'how many times larger is pm2.5 than human hair'}\n",
      "PM2.5 refers to particulate matter with a size of 2.5 microns (micrometers) or smaller in diameter. Human hair typically has a diameter of about **50 to 70 microns**, depending on the individual and hair type.\n",
      "\n",
      "To calculate how many times larger human hair is than PM2.5:\n",
      "\n",
      "- Take the average diameter of human hair (letâ€™s say **60 microns** for simplicity) and divide it by the size of PM2.5 (2.5 microns).\n",
      "\n",
      "**60 Ã· 2.5 = 24**\n",
      "\n",
      "This means **human hair is approximately 24 times larger in diameter than PM2.5 particles**.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'items'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 751, in on_llm_end\n",
      "    llm_usage = _parse_usage(response)\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 1027, in _parse_usage\n",
      "    llm_usage = _parse_usage_model(response.llm_output[key])\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 946, in _parse_usage_model\n",
      "    for key, value in input_token_details.items():\n",
      "AttributeError: 'NoneType' object has no attribute 'items'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \"What is The Greek's relationship with Proposition Joe in 'The Wire'?\"}\n",
      "In *The Wire*, The Greek, a powerful and enigmatic figure in Baltimore's organized crime network, has a business partnership with Proposition Joe. Proposition Joe, a savvy and resourceful drug kingpin, buys high-quality heroin supplied by The Greek's network and then distributes it through his connections. This partnership allows Proposition Joe to maintain his share of the drug trade in Baltimore, while The Greek benefits from tapping into Joe's market and distribution network. Their relationship is largely transactional, built on mutual benefit and trust in their business dealings, but it is not portrayed as personal or overly close.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'items'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 751, in on_llm_end\n",
      "    llm_usage = _parse_usage(response)\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 1027, in _parse_usage\n",
      "    llm_usage = _parse_usage_model(response.llm_output[key])\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 946, in _parse_usage_model\n",
      "    for key, value in input_token_details.items():\n",
      "AttributeError: 'NoneType' object has no attribute 'items'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'what is the karman line definition?'}\n",
      "The KÃ¡rmÃ¡n line is defined as the boundary between Earth's atmosphere and outer space. It is located at an altitude of 100 kilometers (62 miles) above sea level. This definition is widely accepted by organizations such as the FÃ©dÃ©ration AÃ©ronautique Internationale (FAI), which governs aerospace records and standards. \n",
      "\n",
      "The line is named after Theodore von KÃ¡rmÃ¡n, a Hungarian-American physicist and engineer, who calculated that at this altitude, the atmosphere becomes too thin for conventional aircraft to generate sufficient lift to stay aloft. While the KÃ¡rmÃ¡n line serves as a practical and legal boundary, some countries and organizations, like NASA and the U.S. Air Force, define the edge of space differently, typically using an altitude of 50 miles (approximately 80 kilometers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'items'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 751, in on_llm_end\n",
      "    llm_usage = _parse_usage(response)\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 1027, in _parse_usage\n",
      "    llm_usage = _parse_usage_model(response.llm_output[key])\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 946, in _parse_usage_model\n",
      "    for key, value in input_token_details.items():\n",
      "AttributeError: 'NoneType' object has no attribute 'items'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'why is numpy fast'}\n",
      "NumPy is fast primarily because it's implemented in **optimized C and C++ code** under the hood, enabling it to perform numerical computations more efficiently than pure Python. The key reasons for NumPy's speed include:\n",
      "\n",
      "### 1. **Optimized Array Operations**\n",
      "NumPy's core functionalities are built on **highly optimized C and Fortran libraries** (like BLAS, LAPACK), which operate directly on contiguous memory blocks. This avoids the overhead associated with Python's native data structures and loops.\n",
      "\n",
      "### 2. **Efficient Memory Management**\n",
      "NumPy uses **contiguous arrays** stored in memory, which requires fewer memory operations during computations. This is much faster than Python's generic list handling, as it avoids frequent memory allocations.\n",
      "\n",
      "### 3. **Vectorization**\n",
      "Instead of running Python loops explicitly, which are slow due to Python's overhead, NumPy utilizes **vectorized operations** to perform operations on entire arrays without iterating element-by-element. This allows for substantial performance improvements.\n",
      "\n",
      "For example:\n",
      "```python\n",
      "import numpy as np\n",
      "\n",
      "# Add two arrays element-wise using NumPy (fast)\n",
      "a = np.array([1, 2, 3])\n",
      "b = np.array([4, 5, 6])\n",
      "result = a + b\n",
      "\n",
      "# Python equivalent would require a loop (slow)\n",
      "result = [x + y for x, y in zip([1, 2, 3], [4, 5, 6])]\n",
      "```\n",
      "\n",
      "### 4. **Low-Level Optimizations**\n",
      "NumPy uses low-level hardware optimizations, such as:\n",
      "   - SIMD (Single Instruction, Multiple Data) for parallel processing.\n",
      "   - Multi-threading in certain operations (like linear algebra).\n",
      "   - Specialized routines for fast computation.\n",
      "\n",
      "### 5. **Avoiding Python Overhead**\n",
      "Python loops, function calls, and dynamic typing introduce significant computational overhead. NumPy operates outside Python's standard runtime for core computations, bypassing these inefficiencies.\n",
      "\n",
      "---\n",
      "\n",
      "Ultimately, NumPy is fast because it effectively bridges the gap between the flexibility of Python and the raw performance of lower-level languages. Its ability to handle large datasets and execute computations efficiently makes it ideal for numerical tasks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'items'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 751, in on_llm_end\n",
      "    llm_usage = _parse_usage(response)\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 1027, in _parse_usage\n",
      "    llm_usage = _parse_usage_model(response.llm_output[key])\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 946, in _parse_usage_model\n",
      "    for key, value in input_token_details.items():\n",
      "AttributeError: 'NoneType' object has no attribute 'items'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'zuffa antitrust lawsuit ninth circut court decision'}\n",
      "The \"Zuffa antitrust lawsuit\" refers to ongoing legal proceedings against Zuffa LLC, the parent company of the UFC (Ultimate Fighting Championship). The lawsuit, first filed in 2014, alleges that Zuffa engaged in monopolistic and anti-competitive practices in violation of antitrust laws, including suppressing fighter wages and limiting opportunities for competitors in the MMA industry. \n",
      "\n",
      "The Ninth Circuit Court decision typically refers to any ruling or judgment made by the United States Court of Appeals for the Ninth Circuit in relation to the case. If you're seeking specific updates or outcomes on the Ninth Circuit's decision, I don't have details beyond October 2023, so you may need to verify the latest court rulings or case updates. Let me know if you'd like a deeper analysis of the lawsuit or the legal claims involved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'items'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 751, in on_llm_end\n",
      "    llm_usage = _parse_usage(response)\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 1027, in _parse_usage\n",
      "    llm_usage = _parse_usage_model(response.llm_output[key])\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 946, in _parse_usage_model\n",
      "    for key, value in input_token_details.items():\n",
      "AttributeError: 'NoneType' object has no attribute 'items'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'In which fields are the original Nobel Prizes awarded?'}\n",
      "The original Nobel Prizes, established by Alfred Nobel's will in 1895, are awarded in the following fields:\n",
      "\n",
      "1. **Physics**\n",
      "2. **Chemistry**\n",
      "3. **Physiology or Medicine**\n",
      "4. **Literature**\n",
      "5. **Peace** (formally known as the Nobel Peace Prize)\n",
      "\n",
      "These categories reflect Nobel's vision of honoring those whose work most benefits humanity.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'items'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 751, in on_llm_end\n",
      "    llm_usage = _parse_usage(response)\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 1027, in _parse_usage\n",
      "    llm_usage = _parse_usage_model(response.llm_output[key])\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 946, in _parse_usage_model\n",
      "    for key, value in input_token_details.items():\n",
      "AttributeError: 'NoneType' object has no attribute 'items'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \"What is Salesforce's largest acquisition?\"}\n",
      "Salesforce's largest acquisition is **Slack Technologies**, which it announced in December 2020 and completed in July 2021. Salesforce acquired Slack, the workplace communication platform, for **$27.7 billion**, making it the companyâ€™s most expensive acquisition to date. This was a strategic move to enhance Salesforce's offerings in enterprise software and collaboration tools.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'items'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 751, in on_llm_end\n",
      "    llm_usage = _parse_usage(response)\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 1027, in _parse_usage\n",
      "    llm_usage = _parse_usage_model(response.llm_output[key])\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 946, in _parse_usage_model\n",
      "    for key, value in input_token_details.items():\n",
      "AttributeError: 'NoneType' object has no attribute 'items'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'red dead redemption 2 development time and 1 billion dollar budget'}\n",
      "The development time and budget for *Red Dead Redemption 2* are certainly notable. Rockstar Games worked on the game for approximately **8 years**, beginning development in 2010 following the release of the original *Red Dead Redemption*.\n",
      "\n",
      "The budget for *Red Dead Redemption 2*, including development, marketing, and other associated costs, is estimated to have been **around $540 million to $1 billion dollars**, which makes it one of the most expensive video games ever made. The game required contributions from multiple Rockstar studios globally and involved over 1,000 developers at various stages of production.\n",
      "\n",
      "This extensive development cycle and high budget are reflected in the gameâ€™s incredible attention to detail, expansive open world, and complex narrativeâ€”earning it critical and commercial success.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'items'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 751, in on_llm_end\n",
      "    llm_usage = _parse_usage(response)\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 1027, in _parse_usage\n",
      "    llm_usage = _parse_usage_model(response.llm_output[key])\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 946, in _parse_usage_model\n",
      "    for key, value in input_token_details.items():\n",
      "AttributeError: 'NoneType' object has no attribute 'items'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'red-crowned parakeet conservaton status'}\n",
      "The **red-crowned parakeet** (*Cyanoramphus novaezelandiae*), commonly known as the **kÄkÄriki**, is native to New Zealand and is classified as **Least Concern** on the IUCN Red List globally. However, its conservation status can vary in certain regions due to habitat loss, predation by introduced species (like rats, stoats, and cats), and competition.\n",
      "\n",
      "In New Zealand, the species is considered to be in decline, especially on the mainland, where they are rare due to introduced predators. Conservation efforts are primarily focused on predator control, translocations, and the establishment of populations on predator-free offshore islands or sanctuaries.\n",
      "\n",
      "Restoration programs in predator-free areas, such as Zealandia or other island sanctuaries, have led to stable or recovering populations of the bird in those areas. Continued conservation measures are essential for ensuring the survival of this species in the long term.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'items'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 751, in on_llm_end\n",
      "    llm_usage = _parse_usage(response)\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 1027, in _parse_usage\n",
      "    llm_usage = _parse_usage_model(response.llm_output[key])\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 946, in _parse_usage_model\n",
      "    for key, value in input_token_details.items():\n",
      "AttributeError: 'NoneType' object has no attribute 'items'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'When did breaking debut in the Summer Olympics?'}\n",
      "Breaking (also known as breakdancing) will debut in the Summer Olympics at the **2024 Paris Games**. It was officially added to the Olympic program by the International Olympic Committee (IOC) in December 2020, following its successful showcase at the 2018 Youth Olympic Games in Buenos Aires.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'items'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 751, in on_llm_end\n",
      "    llm_usage = _parse_usage(response)\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 1027, in _parse_usage\n",
      "    llm_usage = _parse_usage_model(response.llm_output[key])\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 946, in _parse_usage_model\n",
      "    for key, value in input_token_details.items():\n",
      "AttributeError: 'NoneType' object has no attribute 'items'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'How many Russian soldiers surrendered to AFU in Kursk region?'}\n",
      "As of my last update in October 2023, I don't have real-time information on military developments, including the number of soldiers surrendering in specific regions such as Kursk. For accurate and up-to-date information regarding this matter, I suggest consulting reliable news sources or official government/military statements related to the conflict.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'items'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 751, in on_llm_end\n",
      "    llm_usage = _parse_usage(response)\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 1027, in _parse_usage\n",
      "    llm_usage = _parse_usage_model(response.llm_output[key])\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 946, in _parse_usage_model\n",
      "    for key, value in input_token_details.items():\n",
      "AttributeError: 'NoneType' object has no attribute 'items'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'kelly buchberger nhl draft year'}\n",
      "Kelly Buchberger was drafted into the NHL in the **1985 NHL Entry Draft**. He was selected by the Edmonton Oilers in the **9th round, 188th overall**. Buchberger went on to have a lengthy and successful career as a hard-working, physical forward, winning two Stanley Cups with the Oilers in 1987 and 1990.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'items'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 751, in on_llm_end\n",
      "    llm_usage = _parse_usage(response)\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 1027, in _parse_usage\n",
      "    llm_usage = _parse_usage_model(response.llm_output[key])\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 946, in _parse_usage_model\n",
      "    for key, value in input_token_details.items():\n",
      "AttributeError: 'NoneType' object has no attribute 'items'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'How many consecutive weeks did Roger Federer hold the ATP No. 1 ranking?'}\n",
      "Roger Federer held the ATP No. 1 ranking for **237 consecutive weeks**, from February 2, 2004, to August 17, 2008. This is the longest streak at No. 1 in ATP history.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'items'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 751, in on_llm_end\n",
      "    llm_usage = _parse_usage(response)\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 1027, in _parse_usage\n",
      "    llm_usage = _parse_usage_model(response.llm_output[key])\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 946, in _parse_usage_model\n",
      "    for key, value in input_token_details.items():\n",
      "AttributeError: 'NoneType' object has no attribute 'items'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'What was the first antitrust policy Lina Khan implemented on her first day as FTC chair in June 2021?'}\n",
      "On Lina Khan's first day as chair of the Federal Trade Commission (FTC) in June 2021, she signaled her intent to revamp antitrust enforcement broadly but did not institute a specific new policy immediately on her first day. Her early actions as chair included emphasizing aggressive scrutiny of corporate consolidation and monopolistic practices, particularly in the tech industry. Under her leadership, the FTC quickly began exploring more expansive interpretations of antitrust laws and taking a tougher stance on mergers and acquisitions.\n",
      "\n",
      "A notable change introduced in the early weeks of her role included rescinding the FTC's \"vertical merger guidelines,\" which had provided a framework for evaluating mergers where companies operate at different levels of the supply chain. This move was part of a broader initiative to update antitrust enforcement policies to address modern market dynamics. Khan's leadership has been marked by a more proactive stance toward regulating dominant companies and promoting competition.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'items'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 751, in on_llm_end\n",
      "    llm_usage = _parse_usage(response)\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 1027, in _parse_usage\n",
      "    llm_usage = _parse_usage_model(response.llm_output[key])\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 946, in _parse_usage_model\n",
      "    for key, value in input_token_details.items():\n",
      "AttributeError: 'NoneType' object has no attribute 'items'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'kamala harris 2024 vp pick'}\n",
      "As of now, Kamala Harris remains the sitting Vice President under President Joe Biden's administration. If Joe Biden decides to run for re-election in the 2024 presidential cycle, it is expected that Kamala Harris would remain his running mate. However, confirmation of ticket arrangements typically occurs closer to election season, and any decisions are ultimately up to the candidates themselves.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'items'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 751, in on_llm_end\n",
      "    llm_usage = _parse_usage(response)\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 1027, in _parse_usage\n",
      "    llm_usage = _parse_usage_model(response.llm_output[key])\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 946, in _parse_usage_model\n",
      "    for key, value in input_token_details.items():\n",
      "AttributeError: 'NoneType' object has no attribute 'items'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'uk decleration of war on germany time'}\n",
      "The United Kingdom declared war on Germany at **11:15 AM** on **September 3, 1939**. This declaration followed Germany's invasion of Poland on September 1, 1939, which marked the beginning of World War II.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'items'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 751, in on_llm_end\n",
      "    llm_usage = _parse_usage(response)\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 1027, in _parse_usage\n",
      "    llm_usage = _parse_usage_model(response.llm_output[key])\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 946, in _parse_usage_model\n",
      "    for key, value in input_token_details.items():\n",
      "AttributeError: 'NoneType' object has no attribute 'items'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'Dollywood park flooding how many injured?'}\n",
      "As of my last update in October 2023, I donâ€™t have real-time data on current events. To find out accurate and recent information about potential flooding at Dollywood and any related injuries, I recommend checking trusted news outlets or Dollywood's official website for updates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'items'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 751, in on_llm_end\n",
      "    llm_usage = _parse_usage(response)\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 1027, in _parse_usage\n",
      "    llm_usage = _parse_usage_model(response.llm_output[key])\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 946, in _parse_usage_model\n",
      "    for key, value in input_token_details.items():\n",
      "AttributeError: 'NoneType' object has no attribute 'items'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \"What was the name of Jennifer Lopez's character in the 1997 biopic about Selena Quintanilla-PÃƒÂ©rez?\"}\n",
      "Jennifer Lopez played the role of **Selena Quintanilla-PÃ©rez** in the 1997 biopic *Selena*.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'items'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 751, in on_llm_end\n",
      "    llm_usage = _parse_usage(response)\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 1027, in _parse_usage\n",
      "    llm_usage = _parse_usage_model(response.llm_output[key])\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 946, in _parse_usage_model\n",
      "    for key, value in input_token_details.items():\n",
      "AttributeError: 'NoneType' object has no attribute 'items'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'Who founded Ford Motor Company?'}\n",
      "Ford Motor Company was founded by **Henry Ford** on **June 16, 1903**.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'items'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 751, in on_llm_end\n",
      "    llm_usage = _parse_usage(response)\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 1027, in _parse_usage\n",
      "    llm_usage = _parse_usage_model(response.llm_output[key])\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 946, in _parse_usage_model\n",
      "    for key, value in input_token_details.items():\n",
      "AttributeError: 'NoneType' object has no attribute 'items'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'Who is considered the father of mixed martial arts?'}\n",
      "The man often considered the father of mixed martial arts (MMA) is **Bruce Lee**. Bruce Lee's philosophy and approach to martial arts emphasized the idea of combining techniques from various disciplines rather than adhering to a single traditional style. His martial arts system, Jeet Kune Do, encouraged adaptability, efficiency, and using whatever method works best in combat, similar to the principles central to modern MMA.\n",
      "\n",
      "Although Bruce Lee never competed in MMA as it exists today, his ideas laid the foundation for the sport's evolution. The official development of MMA as a recognized competition is often attributed to organizations like UFC (Ultimate Fighting Championship) and its early influences from Vale Tudo, Brazilian Jiu-Jitsu, and other mixed combat styles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'items'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 751, in on_llm_end\n",
      "    llm_usage = _parse_usage(response)\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 1027, in _parse_usage\n",
      "    llm_usage = _parse_usage_model(response.llm_output[key])\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 946, in _parse_usage_model\n",
      "    for key, value in input_token_details.items():\n",
      "AttributeError: 'NoneType' object has no attribute 'items'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \"Who was Erik Fleming in relation to Matthew Perry's death?\"}\n",
      "As of my last update in October 2023, there is no known connection between Erik Fleming and Matthew Perry's death. If this is a recent development or event, I recommend checking reliable news sources for the most current information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'items'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 751, in on_llm_end\n",
      "    llm_usage = _parse_usage(response)\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 1027, in _parse_usage\n",
      "    llm_usage = _parse_usage_model(response.llm_output[key])\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 946, in _parse_usage_model\n",
      "    for key, value in input_token_details.items():\n",
      "AttributeError: 'NoneType' object has no attribute 'items'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'Create NumPy array from list [1, 2, 3, 4, 5, 6]'}\n",
      "To create a NumPy array from the list `[1, 2, 3, 4, 5, 6]`, you can use the `numpy.array()` function. Here's an example:\n",
      "\n",
      "```python\n",
      "import numpy as np\n",
      "\n",
      "# List\n",
      "my_list = [1, 2, 3, 4, 5, 6]\n",
      "\n",
      "# Create NumPy array from list\n",
      "my_array = np.array(my_list)\n",
      "\n",
      "print(my_array)\n",
      "```\n",
      "\n",
      "This will output:\n",
      "\n",
      "```\n",
      "[1 2 3 4 5 6]\n",
      "```\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'items'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 751, in on_llm_end\n",
      "    llm_usage = _parse_usage(response)\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 1027, in _parse_usage\n",
      "    llm_usage = _parse_usage_model(response.llm_output[key])\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 946, in _parse_usage_model\n",
      "    for key, value in input_token_details.items():\n",
      "AttributeError: 'NoneType' object has no attribute 'items'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'ICC arrest warrants Russian officials Ukraine war crimes'}\n",
      "On March 17, 2023, the International Criminal Court (ICC) issued arrest warrants for Russian officials, including President Vladimir Putin, in connection with alleged war crimes committed during the Russian invasion of Ukraine. The ICC accused Putin and Russiaâ€™s Presidential Commissioner for Childrenâ€™s Rights, Maria Lvova-Belova, of unlawfully deporting Ukrainian children from occupied territories to Russia â€” a violation of international law.\n",
      "\n",
      "This is a significant move, as it marks the first time the ICC has sought to hold Russian officials accountable for actions during the conflict in Ukraine. While the issuance of the warrants is symbolically important, practical enforcement remains challenging, as Russia does not recognize the jurisdiction of the ICC and is highly unlikely to comply with surrendering its officials. The arrest warrants aim to highlight accountability and deter further violations of international humanitarian law during the ongoing war.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'items'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 751, in on_llm_end\n",
      "    llm_usage = _parse_usage(response)\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 1027, in _parse_usage\n",
      "    llm_usage = _parse_usage_model(response.llm_output[key])\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 946, in _parse_usage_model\n",
      "    for key, value in input_token_details.items():\n",
      "AttributeError: 'NoneType' object has no attribute 'items'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'Who is the first female Vice President of the United States?'}\n",
      "The first female Vice President of the United States is **Kamala Harris**. She assumed office on January 20, 2021, alongside President Joe Biden. Kamala Harris is also the first woman of Black and South Asian descent to hold this position.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'items'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 751, in on_llm_end\n",
      "    llm_usage = _parse_usage(response)\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 1027, in _parse_usage\n",
      "    llm_usage = _parse_usage_model(response.llm_output[key])\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 946, in _parse_usage_model\n",
      "    for key, value in input_token_details.items():\n",
      "AttributeError: 'NoneType' object has no attribute 'items'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'What was the purpose of the elaborate system of underground tunnels Louis XIV had constructed beneath the Palace of Versailles, and how did they connect to the Hall of Mirrors?'}\n",
      "Louis XIV did not construct an elaborate system of underground tunnels beneath the Palace of Versailles. The Palace of Versailles, including iconic areas such as the Hall of Mirrors, was designed with opulence and grandeur in mind, but there is no evidence or record of a large underground tunnel system beneath the structure from the time of Louis XIV.\n",
      "\n",
      "The design and architecture of Versailles focused on showcasing France's power and the glory of the Sun King rather than the use of secretive underground infrastructure. While there were functional underground spaces for drainage, storage, and other practical purposes, they were not designed as an elaborate tunnel network nor did they serve as connections to major areas like the Hall of Mirrors.\n",
      "\n",
      "If you were referring to another aspect of Versailles, feel free to clarify!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'items'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 751, in on_llm_end\n",
      "    llm_usage = _parse_usage(response)\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 1027, in _parse_usage\n",
      "    llm_usage = _parse_usage_model(response.llm_output[key])\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 946, in _parse_usage_model\n",
      "    for key, value in input_token_details.items():\n",
      "AttributeError: 'NoneType' object has no attribute 'items'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'most valued card in spads'}\n",
      "It seems like you are inquiring about the most valued card in \"spades\" (possibly referring to the card suit in standard playing cards or a card game like Spades). Could you clarify your question further? If you're asking within the context of a specific game or scenario, Iâ€™d be happy to help!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'items'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 751, in on_llm_end\n",
      "    llm_usage = _parse_usage(response)\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 1027, in _parse_usage\n",
      "    llm_usage = _parse_usage_model(response.llm_output[key])\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 946, in _parse_usage_model\n",
      "    for key, value in input_token_details.items():\n",
      "AttributeError: 'NoneType' object has no attribute 'items'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'which spinal cord segment does median nerve originate from'}\n",
      "The **median nerve** originates from the **brachial plexus**, specifically from fibers contributed by the **C6, C7, C8, and T1 spinal cord segments**. It is formed by two roots: one from the **lateral cord** (C6 and C7 fibers) and one from the **medial cord** (C8 and T1 fibers) of the brachial plexus.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'items'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 751, in on_llm_end\n",
      "    llm_usage = _parse_usage(response)\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 1027, in _parse_usage\n",
      "    llm_usage = _parse_usage_model(response.llm_output[key])\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 946, in _parse_usage_model\n",
      "    for key, value in input_token_details.items():\n",
      "AttributeError: 'NoneType' object has no attribute 'items'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'After the Colossus of Rhodes was destroyed by an earthquake in 226 BC, which Roman emperor ordered its reconstruction as a harbor-straddling statue, only to abandon the project when engineers discovered it would block ship traffic?'}\n",
      "The Colossus of Rhodes was destroyed by an earthquake in 226 BC, but no Roman emperor ever ordered its reconstruction. Historical accounts, including writings from the Roman period, do not provide evidence of such an event. It seems there may be some confusion or fictionalized storytelling regarding this scenario. The Colossus was never rebuilt, as the people of Rhodes believed that it was cursed after its destruction. \n",
      "\n",
      "If youâ€™re looking for similar stories involving large statues or ambitious engineering projects in ancient Rome, I can help clarify or provide more information!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'items'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 751, in on_llm_end\n",
      "    llm_usage = _parse_usage(response)\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 1027, in _parse_usage\n",
      "    llm_usage = _parse_usage_model(response.llm_output[key])\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 946, in _parse_usage_model\n",
      "    for key, value in input_token_details.items():\n",
      "AttributeError: 'NoneType' object has no attribute 'items'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \"What notable achievement did Megan Thee Stallion accomplish with her single 'Hiss'?\"}\n",
      "As of my most recent update in October 2023, there is no record of a single by Megan Thee Stallion titled \"Hiss.\" It's possible that this is a misunderstanding or the song in question was released after my training data was finalized. Megan Thee Stallion is widely celebrated for hit singles like \"Savage\" (especially the remix featuring BeyoncÃ©) and \"WAP\" with Cardi B, both of which achieved major commercial success and earned critical acclaim. Let me know if you're referring to a different song, and I can help clarify!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'items'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 751, in on_llm_end\n",
      "    llm_usage = _parse_usage(response)\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 1027, in _parse_usage\n",
      "    llm_usage = _parse_usage_model(response.llm_output[key])\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 946, in _parse_usage_model\n",
      "    for key, value in input_token_details.items():\n",
      "AttributeError: 'NoneType' object has no attribute 'items'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'When was Astralwerks founded?'}\n",
      "Astralwerks was founded in **1993**. It is an American record label known for electronic and dance music.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'items'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 751, in on_llm_end\n",
      "    llm_usage = _parse_usage(response)\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 1027, in _parse_usage\n",
      "    llm_usage = _parse_usage_model(response.llm_output[key])\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 946, in _parse_usage_model\n",
      "    for key, value in input_token_details.items():\n",
      "AttributeError: 'NoneType' object has no attribute 'items'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'oracle database 19c automatic ai-driven schema design feature'}\n",
      "Oracle Database 19c does not offer a feature specifically termed \"automatic AI-driven schema design.\" However, it does include automation enhancements focused on performance tuning, data management, and optimization through features such as **Autonomous Database**. \n",
      "\n",
      "Autonomous Database utilizes machine learning (ML) to perform tasks like indexing, patching, and resource management without requiring user intervention. While these capabilities indirectly help optimize schema design and database operations, they don't explicitly provide a fully AI-driven automatic schema design feature.\n",
      "\n",
      "If Oracle has introduced new features tied to AI-driven schema design beyond my training cutoff in October 2023, I recommend checking their official documentation or release notes for the most accurate information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'items'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 751, in on_llm_end\n",
      "    llm_usage = _parse_usage(response)\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 1027, in _parse_usage\n",
      "    llm_usage = _parse_usage_model(response.llm_output[key])\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 946, in _parse_usage_model\n",
      "    for key, value in input_token_details.items():\n",
      "AttributeError: 'NoneType' object has no attribute 'items'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \"When was Don't Ask, Don't Tell repealed?\"}\n",
      "\"Don't Ask, Don't Tell,\" the policy that barred openly LGBTQ+ individuals from serving in the U.S. military, was officially repealed on **September 20, 2011**. The repeal was signed into law by President Barack Obama on **December 22, 2010**, but the policy wasn't fully lifted until September 2011, following necessary preparations by the military.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'items'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 751, in on_llm_end\n",
      "    llm_usage = _parse_usage(response)\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 1027, in _parse_usage\n",
      "    llm_usage = _parse_usage_model(response.llm_output[key])\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 946, in _parse_usage_model\n",
      "    for key, value in input_token_details.items():\n",
      "AttributeError: 'NoneType' object has no attribute 'items'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'how much co2 does photosynthesis produce annually'}\n",
      "Photosynthesis does not produce carbon dioxide (CO2); instead, it is a process where plants, algae, and some bacteria *consume* CO2 and convert it into glucose (stored energy) and oxygen. During photosynthesis, organisms remove CO2 from the atmosphere and release oxygen as a byproduct.\n",
      "\n",
      "Globally, photosynthesis plays a critical role in carbon cycling and removing vast amounts of CO2 annually. It's estimated that terrestrial and oceanic photosynthetic organisms absorb approximately **100â€“120 billion metric tons** of CO2 from the atmosphere each year. This natural process helps regulate atmospheric CO2 levels and supports ecosystems by providing energy for living organisms.\n",
      "\n",
      "If you're asking how much **oxygen** photosynthesis produces annually, it's roughly proportional to the CO2 uptake, as oxygen is released during the conversion of CO2 and water into glucose. Let me know if you'd like clarification!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'items'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 751, in on_llm_end\n",
      "    llm_usage = _parse_usage(response)\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 1027, in _parse_usage\n",
      "    llm_usage = _parse_usage_model(response.llm_output[key])\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 946, in _parse_usage_model\n",
      "    for key, value in input_token_details.items():\n",
      "AttributeError: 'NoneType' object has no attribute 'items'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'How many F1 world titles has Max Verstappen won?'}\n",
      "As of October 2023, Max Verstappen has won **three Formula 1 World Championships**. He secured his titles in **2021**, **2022**, and **2023**, solidifying his dominance in the sport during these years.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'items'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 751, in on_llm_end\n",
      "    llm_usage = _parse_usage(response)\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 1027, in _parse_usage\n",
      "    llm_usage = _parse_usage_model(response.llm_output[key])\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/langfuse/langchain/CallbackHandler.py\", line 946, in _parse_usage_model\n",
      "    for key, value in input_token_details.items():\n",
      "AttributeError: 'NoneType' object has no attribute 'items'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'Which village in Donetsk Oblast was captured by Russian forces on 2 August 2024?'}\n",
      "I currently do not have information on events or developments beyond October 2023. For the latest updates regarding conflicts or specific incidents in August 2024, I recommend consulting reliable news sources or official reports.\n"
     ]
    }
   ],
   "source": [
    "from langfuse import get_client\n",
    "from langfuse.langchain import CallbackHandler\n",
    "\n",
    "# ğŸ“¡ åˆå§‹åŒ–è¿½è¸ªç»„ä»¶ï¼šCallbackHandler ä¼šæŠŠ LangChain çš„æ¯ä¸€æ­¥åŒæ­¥åˆ° Langfuse\n",
    "langfuse_handler = CallbackHandler()\n",
    "langfuse = get_client()\n",
    "\n",
    "dataset = langfuse.get_dataset('qa-dataset_langgraph-agent')  # è·å–ä¸Šä¸€æ­¥åˆ›å»ºçš„æ•°æ®é›†\n",
    "\n",
    "for item in dataset.items:\n",
    "    # âœ… item.run() ä¼šä¸ºæ¯ä¸ªæ ·æœ¬å¼€å¯ä¸€ä¸ªå­è¿½è¸ªï¼Œæ–¹ä¾¿æŸ¥çœ‹å•æ¡æ ·æœ¬çš„æ‰§è¡Œæƒ…å†µ\n",
    "    with item.run(\n",
    "        run_name=\"run_gpt-4o\", # ä½¿ç”¨å…¶ä»–æ¨¡å‹æµ‹è¯•ï¼Œæ³¨æ„ä¿®æ”¹\n",
    "        run_description=\"My first run\",  # ä½¿ç”¨å…¶ä»–æ¨¡å‹æµ‹è¯•ï¼Œæ³¨æ„ä¿®æ”¹\n",
    "        run_metadata={\"model\": \"gpt-4o\"},  # ä½¿ç”¨å…¶ä»–æ¨¡å‹æµ‹è¯•ï¼Œæ³¨æ„ä¿®æ”¹\n",
    "    ) as root_span:\n",
    "        # è¿›å…¥æ­¤ä¸Šä¸‹æ–‡çš„æ‰€æœ‰è°ƒç”¨éƒ½ä¼šè‡ªåŠ¨å…³è”åˆ°å½“å‰ dataset item\n",
    "\n",
    "        # ğŸ¯ è¿è¡Œæ ¸å¿ƒä¸šåŠ¡é€»è¾‘æ—¶ï¼Œå†å¼€ä¸€ä¸ª generation ä¸Šä¸‹æ–‡è®°å½•å•æ¬¡æ¨¡å‹è°ƒç”¨\n",
    "        with langfuse.start_as_current_generation(\n",
    "            name=\"llm-call\",\n",
    "            model=\"gpt-4o\",  # ä½¿ç”¨å…¶ä»–æ¨¡å‹æµ‹è¯•ï¼Œæ³¨æ„ä¿®æ”¹\n",
    "            input=item.input\n",
    "        ) as generation:\n",
    "            # ç”¨æˆ‘ä»¬åˆšæ‰å°è£…çš„ my_agent å®Œæˆå®é™…é—®ç­”\n",
    "            output = my_agent(str(item.input), langfuse_handler)\n",
    "            generation.update(output=output)\n",
    "\n",
    "        # ğŸ“ å¯é€‰æ‹©å¯¹ç»“æœæ‰“åˆ†ï¼ˆä¾‹å¦‚äººå·¥ç‚¹è¯„æˆ–è‡ªåŠ¨æŒ‡æ ‡ï¼‰\n",
    "        root_span.score_trace(\n",
    "            name=\"user-feedback\",\n",
    "            value=1,\n",
    "            comment=\"This is a comment\",  # å¯è®°å½•è¯„åˆ†åŸå› ï¼Œä¾¿äºå›æº¯\n",
    "        )\n",
    "\n",
    "# ğŸ”š æ‰€æœ‰è°ƒç”¨ç»“æŸååˆ·æ–°å®¢æˆ·ç«¯ï¼Œç¡®ä¿ç¼“å†²åŒºé‡Œçš„æ•°æ®éƒ½è¢«å‘é€\n",
    "langfuse.flush()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rofi0MnywIsq"
   },
   "source": [
    "ä½ å¯ä»¥åœ¨ä¸åŒçš„ Agent é…ç½®ä¹‹é—´é‡å¤è¿™ä¸€æµç¨‹ï¼Œä¾‹å¦‚ï¼š\n",
    "- æ¨¡å‹ï¼ˆå¦‚ gpt-4o-miniã€o1 ç­‰ï¼‰\n",
    "- æç¤ºè¯ï¼ˆPromptsï¼‰\n",
    "- å·¥å…·ï¼ˆå¦‚æ˜¯å¦å¯ç”¨æœç´¢èƒ½åŠ›ï¼‰\n",
    "- Agent å¤æ‚åº¦ï¼ˆå¤šAgent vs å•Agentï¼‰\n",
    "\n",
    "éšåå¯åœ¨ Langfuse ä¸­è¿›è¡Œå¹¶æ’å¯¹æ¯”ã€‚åœ¨æ­¤ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬åœ¨ 30 æ¡æ•°æ®é›†é—®é¢˜ä¸Šåˆ†åˆ«è¿è¡Œäº† 3 æ¬¡Agentï¼Œæ¯æ¬¡ä½¿ç”¨ä¸åŒçš„ OpenAI æ¨¡å‹ã€‚å¯ä»¥çœ‹åˆ°ï¼Œéšç€æ¨¡å‹èƒ½åŠ›å¢å¤§ï¼Œæ­£ç¡®å›ç­”çš„æ•°é‡æŒ‰é¢„æœŸæå‡ã€‚\n",
    "\n",
    "`Answer Correctness` åˆ†æ•°ç”±ä¸€ä¸ª[â€œæ¨¡å‹å……å½“è¯„å®¡â€ï¼ˆLLM-as-a-Judgeï¼‰è¯„ä¼°å™¨](https://langfuse.com/docs/scores/model-based-evals)ç”Ÿæˆï¼Œå®ƒä¼šåŸºäºæ•°æ®é›†ä¸­ç»™å‡ºçš„å‚è€ƒç­”æ¡ˆæ¥è¯„ä¼°è¾“å‡ºæ˜¯å¦æ­£ç¡®ã€‚\n",
    "\n",
    "![æ•°æ®é›†è¿è¡Œæ¦‚è§ˆ](https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202511041805188.png)\n",
    "![æ•°æ®é›†è¿è¡Œå¯¹æ¯”](https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202511041805669.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”¬ 5ï¼š LLM-as-a-Judge è¯„ä¼°\n",
    "\n",
    "### ä¸€ã€åˆ›å»ºæ–°çš„ LLM-as-a-Judge è¯„ä¼°å™¨\n",
    "\n",
    "1. **å¯¼èˆª**ï¼šè¿›å…¥ Langfuse æ§åˆ¶å°`å·¦ä¾§æ `çš„ **Evaluators** çš„` LLM-as-a-Judge `ã€‚\n",
    "2. **æ“ä½œ**ï¼šç‚¹å‡» `Create Evaluator` æŒ‰é’®ä»¥åˆå§‹åŒ–ä¸€ä¸ªæ–°çš„è¯„ä¼°é…ç½®ã€‚\n",
    "\n",
    "![image-20251126165332628](https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202511261653010.png)\n",
    "\n",
    "### äºŒã€è®¾ç½®é»˜è®¤æ¨¡å‹(Set up default model)\n",
    "\n",
    "æ‚¨éœ€è¦å®šä¹‰ç”¨äºæ‰§è¡Œè¯„ä¼°ä»»åŠ¡çš„é»˜è®¤ LLMï¼ˆè£åˆ¤æ¨¡å‹ï¼‰ã€‚\n",
    "\n",
    "![image-20251126165906049](https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202511261659568.png)\n",
    "\n",
    "- `LLM adapter`:  `openai`\n",
    "\n",
    "- `API Base URL`ï¼š`https://api.apiyi.com/v1`\n",
    "\n",
    "- `API Key`ï¼šåœ¨`https://api.apiyi.com`ç”³è¯·\n",
    "\n",
    "  > OpenAIå›½å†…ä»£ç†åœ°å€\n",
    "  > https://api.apiyi.com/register/?aff_code=we80\n",
    "  > æ–°ç”¨æˆ·æ³¨å†Œé€0.1ç¾é‡‘\n",
    "\n",
    "è®¾ç½®åï¼Œé€‰æ‹©æ¨¡å‹åç§°\n",
    "\n",
    "![image-20251126170023999](https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202511261700395.png)\n",
    "\n",
    "### ä¸‰ã€é€‰æ‹©è¯„ä¼°å™¨ (Pick an Evaluator)\n",
    "\n",
    "åœ¨æ­¤æ­¥éª¤ä¸­ï¼Œæ‚¨éœ€è¦ç¡®å®šè¯„ä¼°é€»è¾‘çš„æ¥æºï¼Œä¸»è¦æœ‰ä¸¤ç§æ–¹å¼ï¼Œæˆ‘ä»¬é€‰æ‹©`æ‰˜ç®¡è¯„ä¼°å™¨`ï¼š\n",
    "\n",
    "1. **æ‰˜ç®¡è¯„ä¼°å™¨ (Managed Evaluator)**ï¼š\n",
    "\n",
    "   ![image-20251126170134380](https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202511261701760.png)\n",
    "\n",
    "   - **æ¥æº**ï¼šLangfuse å®˜æ–¹æˆ–åˆä½œä¼™ä¼´ï¼ˆå¦‚ Ragasï¼‰ç»´æŠ¤çš„ç°æˆç›®å½•ã€‚\n",
    "   - **å†…å®¹**ï¼šæ¶µç›–å¸¸è§çš„è´¨é‡ç»´åº¦ï¼Œå¦‚*å¹»è§‰ (Hallucination)*ã€*ä¸Šä¸‹æ–‡ç›¸å…³æ€§ (Context-Relevance)*ã€*æ¯’æ€§ (Toxicity)*ã€*æœ‰ç”¨æ€§ (Helpfulness)*ã€‚\n",
    "   - **ä¼˜åŠ¿**ï¼šæ— éœ€ç¼–å†™ Promptï¼Œå³å¼€å³ç”¨ï¼Œä¸”æŒç»­æ›´æ–°ã€‚\n",
    "\n",
    "   > æˆ‘ä»¬é€‰æ‹©æ‰˜ç®¡è¯„ä¼°å™¨ä¸­`Answer Correctness`è¯„ä¼°å™¨\n",
    "\n",
    "2. **è‡ªå®šä¹‰è¯„ä¼°å™¨ (Custom Evaluator)**ï¼š\n",
    "\n",
    "   - **é€‚ç”¨åœºæ™¯**ï¼šå½“é€šç”¨åº“æ— æ³•æ»¡è¶³ç‰¹å®šçš„ä¸šåŠ¡é€»è¾‘éœ€æ±‚æ—¶ã€‚\n",
    "   - **é…ç½®æ­¥éª¤**ï¼š\n",
    "     1. ç¼–å†™åŒ…å« `{{variables}}` å ä½ç¬¦çš„è¯„ä¼° Promptï¼ˆä¾‹å¦‚ `{{input}}`, `{{output}}`, `{{ground_truth}}`ï¼‰ã€‚\n",
    "     2. ï¼ˆå¯é€‰ï¼‰è‡ªå®šä¹‰è¯„åˆ†æ ‡å‡†ï¼ˆ0-1åˆ†ï¼‰å’Œæ¨ç†å¼•å¯¼è¯ï¼Œä»¥è§„èŒƒ LLM çš„è¾“å‡ºã€‚\n",
    "     3. ï¼ˆå¯é€‰ï¼‰ä¸ºæ­¤è¯„ä¼°å™¨ç»‘å®šç‰¹å®šçš„æ¨¡å‹ï¼ˆå¦‚æœä¸ç»‘å®šï¼Œåˆ™ä½¿ç”¨é»˜è®¤æ¨¡å‹ï¼‰ã€‚\n",
    "   - **å¤ç”¨æ€§**ï¼šä¿å­˜åï¼Œè¯¥è¯„ä¼°å™¨å¯åœ¨æ•´ä¸ªé¡¹ç›®ä¸­å¤ç”¨ã€‚\n",
    "\n",
    "### å››ã€é€‰æ‹©è¯„ä¼°æ•°æ®æº\n",
    "\n",
    "> æˆ‘ä»¬é€‰æ‹©æ‰˜ç®¡è¯„ä¼°å™¨ä¸­`Answer Correctness`è¯„ä¼°å™¨åï¼Œè¿›å…¥è¯„ä¼°æœŸè®¾ç½®\n",
    "\n",
    "é…ç½®è¯„ä¼°å™¨è¿è¡Œçš„ç›®æ ‡æ•°æ®èŒƒå›´ï¼Œåˆ†ä¸º**ç”Ÿäº§æ•°æ®**å’Œ**æ•°æ®é›†æ•°æ®**ï¼Œæˆ‘ä»¬é€‰æ‹©`æ•°æ®é›†è¿è¡Œ (Dataset runs)`ï¼šï¼š\n",
    "\n",
    "1. **å®æ—¶ç”Ÿäº§æ•°æ® (Live Data)**ï¼š\n",
    "\n",
    "   - **ç›‘æ§ç›®æ ‡**ï¼šå®æ—¶ç›‘æ§çº¿ä¸Šåº”ç”¨çš„è¡¨ç°ã€‚\n",
    "   - **èŒƒå›´ (Scope)**ï¼šå»ºè®®é€‰æ‹© `New traces only`ï¼ˆä»…æ–°äº§ç”Ÿçš„ Traceï¼‰ï¼›ä¹Ÿå¯é€‰æ‹©å›å¡«å†å²æ•°æ®ã€‚\n",
    "   - **è¿‡æ»¤å™¨ (Filter)**ï¼šé€šè¿‡ Trace nameã€Tagsã€`userId` ç­‰å­—æ®µç²¾ç¡®ç­›é€‰ã€‚*å¼ºçƒˆå»ºè®®å…ˆé€šè¿‡ Filter ç¼©å°èŒƒå›´*ã€‚\n",
    "   - **é¢„è§ˆ**ï¼šç³»ç»Ÿä¼šå±•ç¤ºè¿‡å» 24 å°æ—¶å†…åŒ¹é…å½“å‰ Filter çš„ Trace æ ·æœ¬ï¼Œä¾›æ‚¨æ ¸å¯¹ã€‚\n",
    "   - **é‡‡æ · (Sampling)**ï¼šé…ç½®è¿è¡Œç™¾åˆ†æ¯”ï¼ˆä¾‹å¦‚ 5%ï¼‰ä»¥æ§åˆ¶æˆæœ¬å’Œè¯„ä¼°ååé‡ã€‚\n",
    "\n",
    "   ![image-20251126171503359](https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202511261715850.png)\n",
    "\n",
    "2. **æ•°æ®é›†è¿è¡Œ (Dataset runs)**ï¼š\n",
    "\n",
    "   - **è¿‡æ»¤å™¨ (Filter)**ï¼šé€šè¿‡ Dataseå­—æ®µç²¾ç¡®ç­›é€‰ã€‚*å¼ºçƒˆå»ºè®®å…ˆé€šè¿‡ Filter ç¼©å°èŒƒå›´*ã€‚\n",
    "\n",
    "   ![image-20251126172840308](https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202511261728654.png)\n",
    "\n",
    "### äº”ã€æ˜ å°„å˜é‡å¹¶é¢„è§ˆ Prompt\n",
    "\n",
    "> æ­¤æ­¥éª¤å°† Trace æˆ–æ•°æ®é›†ä¸­çš„å®é™…æ•°æ®å­—æ®µç»‘å®šåˆ° Prompt å˜é‡ï¼ˆå¦‚ `{{input}}`ï¼‰ã€‚\n",
    ">\n",
    "> 1. **æ•°æ®æ˜ å°„**ï¼š\n",
    ">    - **Live Data**ï¼šé€šå¸¸å°† Trace Input æ˜ å°„åˆ° `{{input}}`ï¼ŒTrace Output æ˜ å°„åˆ° `{{output}}`ã€‚\n",
    ">    - **JSONPath æ”¯æŒ**ï¼šå¦‚æœæ•°æ®åµŒå¥—åœ¨ JSON å¯¹è±¡ä¸­ï¼Œä½¿ç”¨ JSONPath è¡¨è¾¾å¼æå–ï¼ˆä¾‹å¦‚ `$.choices[0].message.content`ï¼‰ã€‚\n",
    ">    - **Dataset**ï¼šç³»ç»Ÿé€šå¸¸ä¼šè‡ªåŠ¨å»ºè®®æ˜ å°„ï¼ˆå¦‚ Dataset çš„ `expected_output` æ˜ å°„åˆ° `{{ground_truth}}`ï¼‰ã€‚\n",
    "> 2. **å®æ—¶é¢„è§ˆ (Live Preview)**ï¼š\n",
    ">    - Langfuse ä¼šä½¿ç”¨åŒ¹é… Filter çš„å†å² Trace å¡«å…… Promptã€‚\n",
    ">    - **æ“ä½œ**ï¼šè¯·åŠ¡å¿…åˆ‡æ¢å‡ æ¡ä¸åŒçš„ Traceï¼Œæ£€æŸ¥ Prompt ä¸­çš„æ•°æ®å¡«å……æ˜¯å¦ç¬¦åˆé¢„æœŸï¼Œç¡®ä¿è¯„ä¼°ä¸Šä¸‹æ–‡å®Œæ•´ã€‚\n",
    "\n",
    "![image-20251126172944653](https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202511261730128.png)\n",
    "\n",
    "##### 1. ç¡®å®šè¯„ä¼°èŒƒå›´ (Target Filter)\n",
    "\n",
    "- **é€‰æ‹©æ•°æ®é›†**ï¼šåœ¨ \"Target filter\" ä¸­ï¼Œé€‰æ‹©ä½ è¦è¯„ä¼°çš„ç‰¹å®šæ•°æ®é›†ï¼Œå¦‚ `qa-dataset_langgraph-agent`ã€‚\n",
    "- è¿™å†³å®šäº†è¯„ä¼°å™¨å°†é’ˆå¯¹å“ªäº›å†å²æ•°æ®æˆ–æµ‹è¯•é›†è¿è¡Œã€‚\n",
    "\n",
    "##### 2. é…ç½®è¯„ä¼° Prompt ä¸å˜é‡æ˜ å°„ (Variable Mapping)\n",
    "\n",
    "ç›®çš„æ˜¯å‘Šè¯‰è¯„ä¼°æ¨¡å‹ï¼ˆJudge LLMï¼‰ä»å“ªé‡Œè·å–æ•°æ®æ¥å¡«å…¥ Promptã€‚\n",
    "\n",
    "- **é…ç½® `{{ground_truth}}`ï¼ˆåŸºå‡†äº‹å®ï¼‰ï¼š**\n",
    "  - **æ¥æºå¯¹è±¡ (Object)**ï¼šé€‰æ‹© `Dataset item`ï¼ˆæ•°æ®é›†æ¡ç›®ï¼‰ã€‚\n",
    "  - **æ¥æºå˜é‡ (Variable)**ï¼šé€‰æ‹© `Expected output`ï¼ˆé¢„æœŸè¾“å‡º/æ ‡å‡†ç­”æ¡ˆï¼‰ã€‚\n",
    "  - *å«ä¹‰*ï¼šå‘Šè¯‰è¯„ä¼°å™¨ï¼ŒPrompt ä¸­çš„â€œåŸºå‡†äº‹å®â€å­—æ®µï¼Œåº”ç›´æ¥è¯»å–æ•°æ®é›†ä¸­é¢„è®¾å¥½çš„æ ‡å‡†ç­”æ¡ˆã€‚\n",
    "- **é…ç½® `{{answer}}`ï¼ˆå¤§æ¨¡å‹å›ç­”ï¼‰ï¼š**\n",
    "  - **æ¥æºå¯¹è±¡ (Object)**ï¼šé€‰æ‹© `Trace`ï¼ˆé“¾è·¯è¿½è¸ªæ•°æ®ï¼‰ã€‚\n",
    "  - **æ¥æºå˜é‡ (Variable)**ï¼šé€‰æ‹© `Output`ï¼ˆæ¨¡å‹å®é™…è¾“å‡ºï¼‰ã€‚\n",
    "  - *å«ä¹‰*ï¼šå‘Šè¯‰è¯„ä¼°å™¨ï¼ŒPrompt ä¸­çš„â€œå›ç­”â€å­—æ®µï¼Œåº”è¯»å–å¤§æ¨¡å‹åœ¨å®é™…è¿è¡Œï¼ˆTraceï¼‰ä¸­ç”Ÿæˆçš„æœ€ç»ˆå›å¤ã€‚\n",
    "\n",
    "##### 3. æ‰§è¡Œè¯„ä¼° (Execute)\n",
    "\n",
    "- ç‚¹å‡»å³ä¸‹è§’çš„ **\"Execute\"** æŒ‰é’®ã€‚\n",
    "- ç³»ç»Ÿå°†å¼€å§‹éå†æ•°æ®é›†ï¼Œå°†æ¯ä¸€æ¡çš„ `Expected output` å’Œå¯¹åº”çš„ Trace `Output` å¡«å…¥ä½ ç¼–å†™çš„ Prompt ä¸­ï¼Œè°ƒç”¨å¤§æ¨¡å‹ï¼ˆJudgeï¼‰è¿›è¡Œ TP/FP/FN çš„åˆ†ç±»å’Œæ‰“åˆ†ã€‚\n",
    "\n",
    "### å…­ã€æŸ¥çœ‹è¯„ä¼°è¿‡ç¨‹\n",
    "\n",
    "LLM-as-a-Judge çš„æ¯ä¸€æ¬¡è¿è¡Œæœ¬èº«ä¹Ÿæ˜¯ä¸€æ¡ Traceï¼Œæ‚¨å¯ä»¥é€šè¿‡ä»¥ä¸‹å››ç§æ–¹å¼æŸ¥çœ‹å…¶è¯¦ç»†æ‰§è¡Œè¿‡ç¨‹ï¼ˆåŒ…æ‹¬å‘é€ç»™è£åˆ¤çš„ Promptã€Token æ¶ˆè€—ã€å»¶è¿Ÿç­‰ï¼‰ï¼š\n",
    "\n",
    "![image-20251126175814773](https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202511261758011.png)\n",
    "\n",
    "- åœ¨å·¦ä¾§å¯¼èˆªæ ä¸­ï¼Œç‚¹å‡» **\"LLM-as-a-Judge\"** èœå•é¡¹ã€‚\n",
    "- **æ“ä½œ**ï¼šåœ¨ \"Logs\"ï¼ˆæ—¥å¿—ï¼‰ä¸€åˆ—ä¸‹ï¼Œç‚¹å‡» **\"View\"** æŒ‰é’®\n",
    "\n",
    "### ä¸ƒã€ç†è§£æ‰§è¡ŒçŠ¶æ€\n",
    "\n",
    "ç›‘æ§è¯„ä¼°å™¨çš„è¿è¡ŒçŠ¶å†µï¼š\n",
    "\n",
    "- **Completed**ï¼šè¯„ä¼°æˆåŠŸå®Œæˆã€‚\n",
    "- **Error**ï¼šè¯„ä¼°å¤±è´¥ï¼ˆç‚¹å‡» Execution trace ID æŸ¥çœ‹å…·ä½“æŠ¥é”™ï¼‰ã€‚\n",
    "- **Delayed**ï¼šè§¦å‘äº† LLM æä¾›å•†çš„é€Ÿç‡é™åˆ¶ï¼Œç³»ç»Ÿæ­£åœ¨è¿›è¡ŒæŒ‡æ•°é€€é¿é‡è¯•ã€‚\n",
    "- **Pending**ï¼šè¯„ä¼°ä»»åŠ¡å·²è¿›å…¥é˜Ÿåˆ—ï¼Œç­‰å¾…è¿è¡Œã€‚\n",
    "\n",
    "![image-20251126175931708](https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202511261759085.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (agent101)",
   "language": "python",
   "name": "agent101"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
