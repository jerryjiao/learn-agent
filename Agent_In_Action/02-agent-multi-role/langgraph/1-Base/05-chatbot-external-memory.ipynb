{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "env_config_overview",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### üîß ÁéØÂ¢ÉÈÖçÁΩÆÂíåÊ£ÄÊü•\n",
    "\n",
    "#### Ê¶ÇËø∞\n",
    "\n",
    "Êú¨ÊïôÁ®ãÈúÄË¶ÅÁâπÂÆöÁöÑÁéØÂ¢ÉÈÖçÁΩÆ‰ª•Á°Æ‰øùÊúÄ‰Ω≥Â≠¶‰π†‰ΩìÈ™å„ÄÇ‰ª•‰∏ãÈÖçÁΩÆÂ∞ÜÂ∏ÆÂä©‰Ω†Ôºö\n",
    "\n",
    "- ‰ΩøÁî®Áªü‰∏ÄÁöÑcondaÁéØÂ¢ÉÔºöÊøÄÊ¥ªÁªü‰∏ÄÁöÑÂ≠¶‰π†ÁéØÂ¢É\n",
    "- ÈÄöËøáÂõΩÂÜÖÈïúÂÉèÊ∫êÂø´ÈÄüÂÆâË£Ö‰æùËµñÔºöÈÖçÁΩÆpip‰ΩøÁî®Ê∏ÖÂçéÈïúÂÉèÊ∫ê\n",
    "- Âä†ÈÄüÊ®°Âûã‰∏ãËΩΩÔºöËÆæÁΩÆHuggingFaceÈïúÂÉè‰ª£ÁêÜ\n",
    "- Ê£ÄÊü•Á≥ªÁªüÈÖçÁΩÆÔºöÊ£ÄÊü•Á°¨‰ª∂ÂíåËΩØ‰ª∂ÈÖçÁΩÆ\n",
    "\n",
    "#### ÈÖçÁΩÆ\n",
    "\n",
    "- **ÊâÄÈúÄÁéØÂ¢ÉÂèäÂÖ∂‰æùËµñÂ∑≤ÁªèÈÉ®ÁΩ≤Â•Ω**\n",
    "- Âú®`Notebook`Âè≥‰∏äËßíÈÄâÊã©`jupyterÂÜÖÊ†∏`‰∏∫`python(agent101)`ÔºåÂç≥ÂèØÊâßË°å‰∏ãÊñπ‰ª£Á†Å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "env_conda_activate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================\n",
      "== Conda ÁéØÂ¢ÉÊ£ÄÊü•Êä•Âëä (‰ªÖÈíàÂØπÂΩìÂâç Bash Â≠êËøõÔøΩÔøΩ) ==\n",
      "=========================================\n",
      "‚úÖ ÂΩìÂâçÂçïÂÖÉÊ†ºÂ∑≤ÊàêÂäüÊøÄÊ¥ªÂà∞ agent101 ÁéØÂ¢É„ÄÇ\n",
      "‚úÖ Ê≠£Âú®‰ΩøÁî®ÁöÑÁéØÂ¢ÉË∑ØÂæÑ: /root/miniconda3/envs/agent101\n",
      "\n",
      "üí° ÊèêÁ§∫: ÂêéÁª≠ÁöÑPythonÂçïÂÖÉÊ†ºÂ∞Ü‰ΩøÁî®NotebookÂΩìÂâçÈÄâÊã©ÁöÑJupyterÔøΩÔøΩÊ†∏„ÄÇ\n",
      "   Â¶ÇÊûúÈúÄË¶ÅÂêéÁª≠ÂçïÂÖÉÊ†º‰πü‰ΩøÁî®Ê≠§ÁéØÂ¢ÉÔºåËØ∑ÊâßË°å‰ª•‰∏ãÊìç‰Ωú:\n",
      "   1. Ê£ÄÊü• Notebook Âè≥‰∏äËßíÊòØÂê¶Â∑≤ÈÄâÊã© 'python(agent101)'„ÄÇ\n",
      "=========================================\n"
     ]
    }
   ],
   "source": [
    "%%script bash\n",
    "\n",
    "# 1. ÊøÄÊ¥ª conda ÁéØÂ¢É (‰ªÖÂØπÂΩìÂâçÂçïÂÖÉÊ†ºÊúâÊïà)\n",
    "eval \"$(conda shell.bash hook)\"\n",
    "conda activate agent101\n",
    "\n",
    "echo \"=========================================\"\n",
    "echo \"== Conda ÁéØÂ¢ÉÊ£ÄÊü•Êä•Âëä (‰ªÖÈíàÂØπÂΩìÂâç Bash Â≠êËøõÁ®ã) ==\"\n",
    "echo \"=========================================\"\n",
    "\n",
    "# 2. Ê£ÄÊü•ÂΩìÂâçÊøÄÊ¥ªÁöÑÁéØÂ¢É\n",
    "CURRENT_ENV_NAME=$(basename $CONDA_PREFIX)\n",
    "\n",
    "if [ \"$CURRENT_ENV_NAME\" = \"agent101\" ]; then\n",
    "    echo \"‚úÖ ÂΩìÂâçÂçïÂÖÉÊ†ºÂ∑≤ÊàêÂäüÊøÄÊ¥ªÂà∞ agent101 ÁéØÂ¢É„ÄÇ\"\n",
    "    echo \"‚úÖ Ê≠£Âú®‰ΩøÁî®ÁöÑÁéØÂ¢ÉË∑ØÂæÑ: $CONDA_PREFIX\"\n",
    "    echo \"\"\n",
    "    echo \"üí° ÊèêÁ§∫: ÂêéÁª≠ÁöÑPythonÂçïÂÖÉÊ†ºÂ∞Ü‰ΩøÁî®NotebookÂΩìÂâçÈÄâÊã©ÁöÑJupyterÂÜÖÊ†∏„ÄÇ\"\n",
    "    echo \"   Â¶ÇÊûúÈúÄË¶ÅÂêéÁª≠ÂçïÂÖÉÊ†º‰πü‰ΩøÁî®Ê≠§ÁéØÂ¢ÉÔºåËØ∑ÊâßË°å‰ª•‰∏ãÊìç‰Ωú:\"\n",
    "    echo \"   1. Ê£ÄÊü• Notebook Âè≥‰∏äËßíÊòØÂê¶Â∑≤ÈÄâÊã© 'python(agent101)'„ÄÇ\"\n",
    "else\n",
    "    echo \"‚ùå ÊøÄÊ¥ªÂ§±Ë¥•ÊàñÁéØÂ¢ÉÂêçÁß∞‰∏çÂåπÈÖç„ÄÇÂΩìÂâçÁéØÂ¢É: $CURRENT_ENV_NAME\"\n",
    "    echo \"\"\n",
    "    echo \"‚ö†Ô∏è ‰∏•ÈáçÊèêÁ§∫: Âª∫ËÆÆÂ∞Ü Notebook ÁöÑ Jupyter **ÂÜÖÊ†∏ (Kernel)** ÂàáÊç¢‰∏∫ 'python(agent101)'„ÄÇ\"\n",
    "    echo \"   (ÈÄöÂ∏∏‰Ωç‰∫é Notebook Âè≥‰∏äËßíÊàñ 'ÂÜÖÊ†∏' ËèúÂçï‰∏≠)\"\n",
    "    echo \"\"\n",
    "    echo \"üìö Â§áÁî®ÊñπÊ≥ï (‰∏çÊé®Ëçê): Â¶ÇÊûúÊó†Ê≥ïÂàáÊç¢ÂÜÖÊ†∏ÔºåÂàôÂøÖÈ°ªÂú®**ÊØè‰∏™**‰ª£Á†ÅÂçïÂÖÉÊ†ºÁöÑÂ§¥ÈÉ®ÈáçÂ§ç‰ª•‰∏ãÂëΩ‰ª§:\"\n",
    "    echo \"\"\n",
    "    echo \"%%script bash\"\n",
    "    echo \"# ÂøÖÈ°ªÂú®ÊØè‰∏™ÂçïÂÖÉÊ†ºÈÉΩÊâßË°å\"\n",
    "    echo \"eval \\\"\\$(conda shell.bash hook)\\\"\"\n",
    "    echo \"conda activate agent101\"\n",
    "fi\n",
    "\n",
    "echo \"=========================================\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "env_pip_config",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For variant 'global', will try loading '/etc/xdg/pip/pip.conf'\n",
      "For variant 'global', will try loading '/etc/pip.conf'\n",
      "For variant 'user', will try loading '/root/.pip/pip.conf'\n",
      "For variant 'user', will try loading '/root/.config/pip/pip.conf'\n",
      "For variant 'site', will try loading '/root/miniconda3/envs/agent101/pip.conf'\n",
      "\u001b[31mERROR: Got unexpected number of arguments, expected 0. (example: \"/root/miniconda3/envs/agent101/bin/python -m pip config list\")\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "For variant 'global', will try loading '/etc/xdg/pip/pip.conf'\n",
      "For variant 'global', will try loading '/etc/pip.conf'\n",
      "For variant 'user', will try loading '/root/.pip/pip.conf'\n",
      "For variant 'user', will try loading '/root/.config/pip/pip.conf'\n",
      "For variant 'site', will try loading '/root/miniconda3/envs/agent101/pip.conf'\n",
      "\u001b[31mERROR: Got unexpected number of arguments, expected 0. (example: \"/root/miniconda3/envs/agent101/bin/python -m pip config list\")\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# 2. ËÆæÁΩÆpip ‰∏∫Ê∏ÖÂçéÊ∫ê\n",
    "%pip config list -v set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "%pip config list -v list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "env_hf_proxy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: HF_ENDPOINT=https://hf-mirror.com\n",
      "https://hf-mirror.com\n"
     ]
    }
   ],
   "source": [
    "# 3. ËÆæÁΩÆHuggingFace‰ª£ÁêÜ\n",
    "%env HF_ENDPOINT=https://hf-mirror.com\n",
    "# È™åËØÅÔºö‰ΩøÁî®shellÂëΩ‰ª§Ê£ÄÊü•\n",
    "!echo $HF_ENDPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "env_system_check",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: pandas==2.2.2 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: tabulate==0.9.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from pandas==2.2.2) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from pandas==2.2.2) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from pandas==2.2.2) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from pandas==2.2.2) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas==2.2.2) (1.17.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "### ÁéØÂ¢É‰ø°ÊÅØ\n",
      "| È°πÁõÆ         | ‰ø°ÊÅØ                                                                               |\n",
      "|:-------------|:-----------------------------------------------------------------------------------|\n",
      "| Êìç‰ΩúÁ≥ªÁªü     | Linux Ubuntu 22.04.4 LTS                                                           |\n",
      "| CPU ‰ø°ÊÅØ     | 11th Gen Intel(R) Core(TM) i5-1135G7 @ 2.40GHz (1 physical cores, 4 logical cores) |\n",
      "| ÂÜÖÂ≠ò‰ø°ÊÅØ     | 5.75 GB (Available: 3.52 GB)                                                       |\n",
      "| GPU ‰ø°ÊÅØ     | No GPU found (nvidia-smi not found)                                                |\n",
      "| CUDA ‰ø°ÊÅØ    | CUDA not found                                                                     |\n",
      "| Python ÁâàÊú¨  | 3.10.18                                                                            |\n",
      "| Conda ÁâàÊú¨   | conda 24.4.0                                                                       |\n",
      "| Áâ©ÁêÜÁ£ÅÁõòÁ©∫Èó¥ | Total: 145.49 GB, Used: 36.67 GB, Free: 102.59 GB                                  |\n"
     ]
    }
   ],
   "source": [
    "# üîç ÁéØÂ¢É‰ø°ÊÅØÊ£ÄÊü•ËÑöÊú¨\n",
    "#\n",
    "# Êú¨ËÑöÊú¨ÁöÑ‰ΩúÁî®Ôºö\n",
    "# 1. ÂÆâË£Ö pandas Â∫ìÁî®‰∫éÊï∞ÊçÆË°®Ê†ºÂ±ïÁ§∫\n",
    "# 2. Ê£ÄÊü•Á≥ªÁªüÁöÑÂêÑÈ°πÈÖçÁΩÆ‰ø°ÊÅØ\n",
    "# 3. ÁîüÊàêËØ¶ÁªÜÁöÑÁéØÂ¢ÉÊä•ÂëäË°®Ê†º\n",
    "#\n",
    "# ÂØπ‰∫éÂàùÂ≠¶ËÄÖÊù•ËØ¥ÔºåËøô‰∏™Ê≠•È™§Â∏ÆÂä©‰Ω†Ôºö\n",
    "# - ‰∫ÜËß£ÂΩìÂâçËøêË°åÁéØÂ¢ÉÁöÑÁ°¨‰ª∂ÈÖçÁΩÆ\n",
    "# - Á°ÆËÆ§ÊòØÂê¶Êª°Ë∂≥Ê®°ÂûãËøêË°åÁöÑÊúÄ‰ΩéË¶ÅÊ±Ç\n",
    "# - Â≠¶‰π†Â¶Ç‰ΩïÈÄöËøá‰ª£Á†ÅËé∑ÂèñÁ≥ªÁªü‰ø°ÊÅØ\n",
    "\n",
    "# ÂÆâË£Ö pandas Â∫ì - Áî®‰∫éÂàõÂª∫ÂíåÂ±ïÁ§∫Êï∞ÊçÆË°®Ê†º\n",
    "# pandas ÊòØ Python ‰∏≠ÊúÄÊµÅË°åÁöÑÊï∞ÊçÆÂ§ÑÁêÜÂíåÂàÜÊûêÂ∫ì\n",
    "%pip install pandas==2.2.2 tabulate==0.9.0\n",
    "\n",
    "import platform # ÂØºÂÖ• platform Ê®°Âùó‰ª•Ëé∑ÂèñÁ≥ªÁªü‰ø°ÊÅØ\n",
    "import os # ÂØºÂÖ• os Ê®°Âùó‰ª•‰∏éÊìç‰ΩúÁ≥ªÁªü‰∫§‰∫í\n",
    "import subprocess # ÂØºÂÖ• subprocess Ê®°Âùó‰ª•ËøêË°åÂ§ñÈÉ®ÂëΩ‰ª§\n",
    "import pandas as pd # ÂØºÂÖ• pandas Ê®°ÂùóÔºåÈÄöÂ∏∏Áî®‰∫éÊï∞ÊçÆÂ§ÑÁêÜÔºåËøôÈáåÁî®‰∫éÂàõÂª∫Ë°®Ê†º\n",
    "import shutil # ÂØºÂÖ• shutil Ê®°Âùó‰ª•Ëé∑ÂèñÁ£ÅÁõòÁ©∫Èó¥‰ø°ÊÅØ\n",
    "\n",
    "# Ëé∑Âèñ CPU ‰ø°ÊÅØÁöÑÂáΩÊï∞ÔºåÂåÖÊã¨Ê†∏ÂøÉÊï∞Èáè\n",
    "def get_cpu_info():\n",
    "    cpu_info = \"\" # ÂàùÂßãÂåñ CPU ‰ø°ÊÅØÂ≠óÁ¨¶‰∏≤\n",
    "    physical_cores = \"N/A\"\n",
    "    logical_cores = \"N/A\"\n",
    "\n",
    "    if platform.system() == \"Windows\": # Â¶ÇÊûúÊòØ Windows Á≥ªÁªü\n",
    "        cpu_info = platform.processor() # ‰ΩøÁî® platform.processor() Ëé∑Âèñ CPU ‰ø°ÊÅØ\n",
    "        try:\n",
    "            # Ëé∑Âèñ Windows ‰∏äÁöÑÊ†∏ÂøÉÊï∞Èáè (ÈúÄË¶Å WMI)\n",
    "            import wmi\n",
    "            c = wmi.WMI()\n",
    "            for proc in c.Win32_Processor():\n",
    "                physical_cores = proc.NumberOfCores\n",
    "                logical_cores = proc.NumberOfLogicalProcessors\n",
    "        except:\n",
    "            pass # Â¶ÇÊûú WMI ‰∏çÂèØÁî®ÔºåÂøΩÁï•ÈîôËØØ\n",
    "\n",
    "    elif platform.system() == \"Darwin\": # Â¶ÇÊûúÊòØ macOS Á≥ªÁªü\n",
    "        # Âú® macOS ‰∏ä‰ΩøÁî® sysctl ÂëΩ‰ª§Ëé∑Âèñ CPU ‰ø°ÊÅØÂíåÊ†∏ÂøÉÊï∞Èáè\n",
    "        os.environ['PATH'] = os.environ['PATH'] + os.pathsep + '/usr/sbin' # Êõ¥Êñ∞ PATH ÁéØÂ¢ÉÂèòÈáè\n",
    "        try:\n",
    "            process_brand = subprocess.Popen(['sysctl', \"machdep.cpu.brand_string\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_brand, stderr_brand = process_brand.communicate()\n",
    "            cpu_info = stdout_brand.decode().split(': ')[1].strip() if stdout_brand else \"Could not retrieve CPU info\"\n",
    "\n",
    "            process_physical = subprocess.Popen(['sysctl', \"hw.physicalcpu\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_physical, stderr_physical = process_physical.communicate()\n",
    "            physical_cores = stdout_physical.decode().split(': ')[1].strip() if stdout_physical else \"N/A\"\n",
    "\n",
    "            process_logical = subprocess.Popen(['sysctl', \"hw.logicalcpu\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_logical, stderr_logical = process_logical.communicate()\n",
    "            logical_cores = stdout_logical.decode().split(': ')[1].strip() if stdout_logical else \"N/A\"\n",
    "\n",
    "        except:\n",
    "            cpu_info = \"Could not retrieve CPU info\"\n",
    "            physical_cores = \"N/A\"\n",
    "            logical_cores = \"N/A\"\n",
    "\n",
    "    else:  # Linux Á≥ªÁªü\n",
    "        try:\n",
    "            # Âú® Linux ‰∏äËØªÂèñ /proc/cpuinfo Êñá‰ª∂Ëé∑Âèñ CPU ‰ø°ÊÅØÂíåÊ†∏ÂøÉÊï∞Èáè\n",
    "            with open('/proc/cpuinfo') as f:\n",
    "                physical_cores_count = 0\n",
    "                logical_cores_count = 0\n",
    "                cpu_info_lines = []\n",
    "                for line in f:\n",
    "                    if line.startswith('model name'): # Êü•Êâæ‰ª• 'model name'ÂºÄÂ§¥ÁöÑË°å\n",
    "                        if not cpu_info: # Âè™Ëé∑ÂèñÁ¨¨‰∏Ä‰∏™ model name\n",
    "                            cpu_info = line.split(': ')[1].strip()\n",
    "                    elif line.startswith('cpu cores'): # Êü•Êâæ‰ª• 'cpu cores' ÂºÄÂ§¥ÁöÑË°å\n",
    "                        physical_cores_count = int(line.split(': ')[1].strip())\n",
    "                    elif line.startswith('processor'): # Êü•Êâæ‰ª• 'processor' ÂºÄÂ§¥ÁöÑË°å\n",
    "                        logical_cores_count += 1\n",
    "                physical_cores = str(physical_cores_count) if physical_cores_count > 0 else \"N/A\"\n",
    "                logical_cores = str(logical_cores_count) if logical_cores_count > 0 else \"N/A\"\n",
    "                if not cpu_info:\n",
    "                     cpu_info = \"Could not retrieve CPU info\"\n",
    "\n",
    "        except:\n",
    "            cpu_info = \"Could not retrieve CPU info\"\n",
    "            physical_cores = \"N/A\"\n",
    "            logical_cores = \"N/A\"\n",
    "\n",
    "    return f\"{cpu_info} ({physical_cores} physical cores, {logical_cores} logical cores)\" # ËøîÂõû CPU ‰ø°ÊÅØÂíåÊ†∏ÂøÉÊï∞Èáè\n",
    "\n",
    "\n",
    "# Ëé∑ÂèñÂÜÖÂ≠ò‰ø°ÊÅØÁöÑÂáΩÊï∞\n",
    "def get_memory_info():\n",
    "    mem_info = \"\" # ÂàùÂßãÂåñÂÜÖÂ≠ò‰ø°ÊÅØÂ≠óÁ¨¶‰∏≤\n",
    "    if platform.system() == \"Windows\":\n",
    "        # Âú® Windows ‰∏ä‰∏çÂÆπÊòìÈÄöËøáÊ†áÂáÜÂ∫ìËé∑ÂèñÔºåÈúÄË¶ÅÂ§ñÈÉ®Â∫ìÊàñ PowerShell\n",
    "        mem_info = \"Requires external tools on Windows\" # ËÆæÁΩÆÊèêÁ§∫‰ø°ÊÅØ\n",
    "    elif platform.system() == \"Darwin\": # Â¶ÇÊûúÊòØ macOS Á≥ªÁªü\n",
    "        # Âú® macOS ‰∏ä‰ΩøÁî® sysctl ÂëΩ‰ª§Ëé∑ÂèñÂÜÖÂ≠òÂ§ßÂ∞è\n",
    "        process = subprocess.Popen(['sysctl', \"hw.memsize\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE) # ËøêË°å sysctl ÂëΩ‰ª§\n",
    "        stdout, stderr = process.communicate() # Ëé∑ÂèñÊ†áÂáÜËæìÂá∫ÂíåÊ†áÂáÜÈîôËØØ\n",
    "        mem_bytes = int(stdout.decode().split(': ')[1].strip()) # Ëß£ÊûêËæìÂá∫ÔºåËé∑ÂèñÂÜÖÂ≠òÂ§ßÂ∞èÔºàÂ≠óËäÇÔºâ\n",
    "        mem_gb = mem_bytes / (1024**3) # ËΩ¨Êç¢‰∏∫ GB\n",
    "        mem_info = f\"{mem_gb:.2f} GB\" # Ê†ºÂºèÂåñËæìÂá∫\n",
    "    else:  # Linux Á≥ªÁªü\n",
    "        try:\n",
    "            # Âú® Linux ‰∏äËØªÂèñ /proc/meminfo Êñá‰ª∂Ëé∑ÂèñÂÜÖÂ≠ò‰ø°ÊÅØ\n",
    "            with open('/proc/meminfo') as f:\n",
    "                total_mem_kb = 0\n",
    "                available_mem_kb = 0\n",
    "                for line in f:\n",
    "                    if line.startswith('MemTotal'): # Êü•Êâæ‰ª• 'MemTotal' ÂºÄÂ§¥ÁöÑË°å\n",
    "                        total_mem_kb = int(line.split(':')[1].strip().split()[0]) # Ëß£ÊûêË°åÔºåËé∑ÂèñÊÄªÂÜÖÂ≠òÔºàKBÔºâ\n",
    "                    elif line.startswith('MemAvailable'): # Êü•Êâæ‰ª• 'MemAvailable' ÂºÄÂ§¥ÁöÑË°å\n",
    "                         available_mem_kb = int(line.split(':')[1].strip().split()[0]) # Ëß£ÊûêË°åÔºåËé∑ÂèñÂèØÁî®ÂÜÖÂ≠òÔºàKBÔºâ\n",
    "\n",
    "                if total_mem_kb > 0:\n",
    "                    total_mem_gb = total_mem_kb / (1024**2) # ËΩ¨Êç¢‰∏∫ GB\n",
    "                    mem_info = f\"{total_mem_gb:.2f} GB\" # Ê†ºÂºèÂåñËæìÂá∫ÊÄªÂÜÖÂ≠ò\n",
    "                    if available_mem_kb > 0:\n",
    "                        available_mem_gb = available_mem_kb / (1024**2)\n",
    "                        mem_info += f\" (Available: {available_mem_gb:.2f} GB)\" # Ê∑ªÂä†ÂèØÁî®ÂÜÖÂ≠ò‰ø°ÊÅØ\n",
    "                else:\n",
    "                     mem_info = \"Could not retrieve memory info\" # Â¶ÇÊûúËØªÂèñÊñá‰ª∂Âá∫ÈîôÔºåËÆæÁΩÆÈîôËØØ‰ø°ÊÅØ\n",
    "\n",
    "        except:\n",
    "            mem_info = \"Could not retrieve memory info\" # Â¶ÇÊûúËØªÂèñÊñá‰ª∂Âá∫ÈîôÔºåËÆæÁΩÆÈîôËØØ‰ø°ÊÅØ\n",
    "    return mem_info # ËøîÂõûÂÜÖÂ≠ò‰ø°ÊÅØ\n",
    "\n",
    "# Ëé∑Âèñ GPU ‰ø°ÊÅØÁöÑÂáΩÊï∞ÔºåÂåÖÊã¨ÊòæÂ≠ò\n",
    "def get_gpu_info():\n",
    "    try:\n",
    "        # Â∞ùËØï‰ΩøÁî® nvidia-smi Ëé∑Âèñ NVIDIA GPU ‰ø°ÊÅØÂíåÊòæÂ≠ò\n",
    "        result = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total', '--format=csv,noheader'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # Â¶ÇÊûúÂëΩ‰ª§ÊàêÂäüÊâßË°å\n",
    "            gpu_lines = result.stdout.strip().split('\\n') # Ëß£ÊûêËæìÂá∫ÔºåËé∑Âèñ GPU ÂêçÁß∞ÂíåÊòæÂ≠ò\n",
    "            gpu_info_list = []\n",
    "            for line in gpu_lines:\n",
    "                name, memory = line.split(', ')\n",
    "                gpu_info_list.append(f\"{name} ({memory})\") # Ê†ºÂºèÂåñ GPU ‰ø°ÊÅØ\n",
    "            return \", \".join(gpu_info_list) if gpu_info_list else \"NVIDIA GPU found, but info not listed\" # ËøîÂõû GPU ‰ø°ÊÅØÊàñÊèêÁ§∫‰ø°ÊÅØ\n",
    "        else:\n",
    "             # Â∞ùËØï‰ΩøÁî® lshw Ëé∑ÂèñÂÖ∂‰ªñ GPU ‰ø°ÊÅØ (ÈúÄË¶ÅÂÆâË£Ö lshw)\n",
    "            try:\n",
    "                result_lshw = subprocess.run(['lshw', '-C', 'display'], capture_output=True, text=True)\n",
    "                if result_lshw.returncode == 0: # Â¶ÇÊûúÂëΩ‰ª§ÊàêÂäüÊâßË°å\n",
    "                     # ÁÆÄÂçïËß£ÊûêËæìÂá∫‰∏≠ÁöÑ product ÂêçÁß∞ÂíåÊòæÂ≠ò\n",
    "                    gpu_info_lines = []\n",
    "                    current_gpu = {}\n",
    "                    for line in result_lshw.stdout.splitlines():\n",
    "                        if 'product:' in line:\n",
    "                             if current_gpu:\n",
    "                                 gpu_info_lines.append(f\"{current_gpu.get('product', 'GPU')} ({current_gpu.get('memory', 'N/A')})\")\n",
    "                             current_gpu = {'product': line.split('product:')[1].strip()}\n",
    "                        elif 'size:' in line and 'memory' in line:\n",
    "                             current_gpu['memory'] = line.split('size:')[1].strip()\n",
    "\n",
    "                    if current_gpu: # Ê∑ªÂä†ÊúÄÂêé‰∏Ä‰∏™ GPU ÁöÑ‰ø°ÊÅØ\n",
    "                        gpu_info_lines.append(f\"{current_gpu.get('product', 'GPU')} ({current_gpu.get('memory', 'N/A')})\")\n",
    "\n",
    "                    return \", \".join(gpu_info_lines) if gpu_info_lines else \"GPU found (via lshw), but info not parsed\" # Â¶ÇÊûúÊâæÂà∞ GPU ‰ΩÜ‰ø°ÊÅØÊó†Ê≥ïËß£ÊûêÔºåËÆæÁΩÆÊèêÁ§∫‰ø°ÊÅØ\n",
    "                else:\n",
    "                    return \"No GPU found (checked nvidia-smi and lshw)\" # Â¶ÇÊûú‰∏§‰∏™ÂëΩ‰ª§ÈÉΩÊâæ‰∏çÂà∞ GPUÔºåËÆæÁΩÆÊèêÁ§∫‰ø°ÊÅØ\n",
    "            except FileNotFoundError:\n",
    "                 return \"No GPU found (checked nvidia-smi, lshw not found)\" # Â¶ÇÊûúÊâæ‰∏çÂà∞ lshw ÂëΩ‰ª§ÔºåËÆæÁΩÆÊèêÁ§∫‰ø°ÊÅØ\n",
    "    except FileNotFoundError:\n",
    "        return \"No GPU found (nvidia-smi not found)\" # Â¶ÇÊûúÊâæ‰∏çÂà∞ nvidia-smi ÂëΩ‰ª§ÔºåËÆæÁΩÆÊèêÁ§∫‰ø°ÊÅØ\n",
    "\n",
    "\n",
    "# Ëé∑Âèñ CUDA ÁâàÊú¨ÁöÑÂáΩÊï∞\n",
    "def get_cuda_version():\n",
    "    try:\n",
    "        # Â∞ùËØï‰ΩøÁî® nvcc --version Ëé∑Âèñ CUDA ÁâàÊú¨\n",
    "        result = subprocess.run(['nvcc', '--version'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # Â¶ÇÊûúÂëΩ‰ª§ÊàêÂäüÊâßË°å\n",
    "            for line in result.stdout.splitlines():\n",
    "                if 'release' in line: # Êü•ÊâæÂåÖÂê´ 'release' ÁöÑË°å\n",
    "                    return line.split('release ')[1].split(',')[0] # Ëß£ÊûêË°åÔºåÊèêÂèñÁâàÊú¨Âè∑\n",
    "        return \"CUDA not found or version not parsed\" # Â¶ÇÊûúÊâæ‰∏çÂà∞ CUDA ÊàñÁâàÊú¨Êó†Ê≥ïËß£ÊûêÔºåËÆæÁΩÆÊèêÁ§∫‰ø°ÊÅØ\n",
    "    except FileNotFoundError:\n",
    "        return \"CUDA not found\" # Â¶ÇÊûúÊâæ‰∏çÂà∞ nvcc ÂëΩ‰ª§ÔºåËÆæÁΩÆÊèêÁ§∫‰ø°ÊÅØ\n",
    "\n",
    "# Ëé∑Âèñ Python ÁâàÊú¨ÁöÑÂáΩÊï∞\n",
    "def get_python_version():\n",
    "    return platform.python_version() # Ëé∑Âèñ Python ÁâàÊú¨\n",
    "\n",
    "# Ëé∑Âèñ Conda ÁâàÊú¨ÁöÑÂáΩÊï∞\n",
    "def get_conda_version():\n",
    "    try:\n",
    "        # Â∞ùËØï‰ΩøÁî® conda --version Ëé∑Âèñ Conda ÁâàÊú¨\n",
    "        result = subprocess.run(['conda', '--version'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # Â¶ÇÊûúÂëΩ‰ª§ÊàêÂäüÊâßË°å\n",
    "            return result.stdout.strip() # ËøîÂõû Conda ÁâàÊú¨\n",
    "        return \"Conda not found or version not parsed\" # Â¶ÇÊûúÊâæ‰∏çÂà∞ Conda ÊàñÁâàÊú¨Êó†Ê≥ïËß£ÊûêÔºåËÆæÁΩÆÊèêÁ§∫‰ø°ÊÅØ\n",
    "    except FileNotFoundError:\n",
    "        return \"Conda not found\" # Â¶ÇÊûúÊâæ‰∏çÂà∞ conda ÂëΩ‰ª§ÔºåËÆæÁΩÆÊèêÁ§∫‰ø°ÊÅØ\n",
    "\n",
    "# Ëé∑ÂèñÁâ©ÁêÜÁ£ÅÁõòÁ©∫Èó¥‰ø°ÊÅØÁöÑÂáΩÊï∞\n",
    "def get_disk_space():\n",
    "    try:\n",
    "        total, used, free = shutil.disk_usage(\"/\") # Ëé∑ÂèñÊ†πÁõÆÂΩïÁöÑÁ£ÅÁõò‰ΩøÁî®ÊÉÖÂÜµ\n",
    "        total_gb = total / (1024**3) # ËΩ¨Êç¢‰∏∫ GB\n",
    "        used_gb = used / (1024**3) # ËΩ¨Êç¢‰∏∫ GB\n",
    "        free_gb = free / (1024**3) # ËΩ¨Êç¢‰∏∫ GB\n",
    "        return f\"Total: {total_gb:.2f} GB, Used: {used_gb:.2f} GB, Free: {free_gb:.2f} GB\" # Ê†ºÂºèÂåñËæìÂá∫\n",
    "    except Exception as e:\n",
    "        return f\"Could not retrieve disk info: {e}\" # Â¶ÇÊûúËé∑Âèñ‰ø°ÊÅØÂá∫ÈîôÔºåËÆæÁΩÆÈîôËØØ‰ø°ÊÅØ\n",
    "\n",
    "# Ëé∑ÂèñÁéØÂ¢É‰ø°ÊÅØ\n",
    "os_name = platform.system() # Ëé∑ÂèñÊìç‰ΩúÁ≥ªÁªüÂêçÁß∞\n",
    "os_version = platform.release() # Ëé∑ÂèñÊìç‰ΩúÁ≥ªÁªüÁâàÊú¨\n",
    "if os_name == \"Linux\":\n",
    "    try:\n",
    "        # Âú® Linux ‰∏äÂ∞ùËØïËé∑ÂèñÂèëË°åÁâàÂíåÁâàÊú¨\n",
    "        lsb_info = subprocess.run(['lsb_release', '-a'], capture_output=True, text=True)\n",
    "        if lsb_info.returncode == 0: # Â¶ÇÊûúÂëΩ‰ª§ÊàêÂäüÊâßË°å\n",
    "            for line in lsb_info.stdout.splitlines():\n",
    "                if 'Description:' in line: # Êü•ÊâæÂåÖÂê´ 'Description:' ÁöÑË°å\n",
    "                    os_version = line.split('Description:')[1].strip() # ÊèêÂèñÊèèËø∞‰ø°ÊÅØ‰Ωú‰∏∫ÁâàÊú¨\n",
    "                    break # ÊâæÂà∞ÂêéÈÄÄÂá∫Âæ™ÁéØ\n",
    "                elif 'Release:' in line: # Êü•ÊâæÂåÖÂê´ 'Release:' ÁöÑË°å\n",
    "                     os_version = line.split('Release:')[1].strip() # ÊèêÂèñÁâàÊú¨Âè∑\n",
    "                     # Â∞ùËØïËé∑Âèñ codename\n",
    "                     try:\n",
    "                         codename_info = subprocess.run(['lsb_release', '-c'], capture_output=True, text=True)\n",
    "                         if codename_info.returncode == 0:\n",
    "                             os_version += f\" ({codename_info.stdout.split(':')[1].strip()})\" # Â∞Ü codename Ê∑ªÂä†Âà∞ÁâàÊú¨‰ø°ÊÅØ‰∏≠\n",
    "                     except:\n",
    "                         pass # Â¶ÇÊûúËé∑Âèñ codename Â§±Ë¥•ÂàôÂøΩÁï•\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        pass # lsb_release ÂèØËÉΩÊú™ÂÆâË£ÖÔºåÂøΩÁï•ÈîôËØØ\n",
    "\n",
    "full_os_info = f\"{os_name} {os_version}\" # ÁªÑÂêàÂÆåÊï¥ÁöÑÊìç‰ΩúÁ≥ªÁªü‰ø°ÊÅØ\n",
    "cpu_info = get_cpu_info() # Ë∞ÉÁî®ÂáΩÊï∞Ëé∑Âèñ CPU ‰ø°ÊÅØÂíåÊ†∏ÂøÉÊï∞Èáè\n",
    "memory_info = get_memory_info() # Ë∞ÉÁî®ÂáΩÊï∞Ëé∑ÂèñÂÜÖÂ≠ò‰ø°ÊÅØ\n",
    "gpu_info = get_gpu_info() # Ë∞ÉÁî®ÂáΩÊï∞Ëé∑Âèñ GPU ‰ø°ÊÅØÂíåÊòæÂ≠ò\n",
    "cuda_version = get_cuda_version() # Ë∞ÉÁî®ÂáΩÊï∞Ëé∑Âèñ CUDA ÁâàÊú¨\n",
    "python_version = get_python_version() # Ë∞ÉÁî®ÂáΩÊï∞Ëé∑Âèñ Python ÁâàÊú¨\n",
    "conda_version = get_conda_version() # Ë∞ÉÁî®ÂáΩÊï∞Ëé∑Âèñ Conda ÁâàÊú¨\n",
    "disk_info = get_disk_space() # Ë∞ÉÁî®ÂáΩÊï∞Ëé∑ÂèñÁâ©ÁêÜÁ£ÅÁõòÁ©∫Èó¥‰ø°ÊÅØ\n",
    "\n",
    "\n",
    "# ÂàõÂª∫Áî®‰∫éÂ≠òÂÇ®Êï∞ÊçÆÁöÑÂ≠óÂÖ∏\n",
    "env_data = {\n",
    "    \"È°πÁõÆ\": [ # È°πÁõÆÂêçÁß∞ÂàóË°®\n",
    "        \"Êìç‰ΩúÁ≥ªÁªü\",\n",
    "        \"CPU ‰ø°ÊÅØ\",\n",
    "        \"ÂÜÖÂ≠ò‰ø°ÊÅØ\",\n",
    "        \"GPU ‰ø°ÊÅØ\",\n",
    "        \"CUDA ‰ø°ÊÅØ\",\n",
    "        \"Python ÁâàÊú¨\",\n",
    "        \"Conda ÁâàÊú¨\",\n",
    "        \"Áâ©ÁêÜÁ£ÅÁõòÁ©∫Èó¥\" # Ê∑ªÂä†Áâ©ÁêÜÁ£ÅÁõòÁ©∫Èó¥\n",
    "    ],\n",
    "    \"‰ø°ÊÅØ\": [ # ÂØπÂ∫îÁöÑ‰ø°ÊÅØÂàóË°®\n",
    "        full_os_info,\n",
    "        cpu_info,\n",
    "        memory_info,\n",
    "        gpu_info,\n",
    "        cuda_version,\n",
    "        python_version,\n",
    "        conda_version,\n",
    "        disk_info # Ê∑ªÂä†Áâ©ÁêÜÁ£ÅÁõòÁ©∫Èó¥‰ø°ÊÅØ\n",
    "    ]\n",
    "}\n",
    "\n",
    "# ÂàõÂª∫‰∏Ä‰∏™ pandas DataFrame\n",
    "df = pd.DataFrame(env_data)\n",
    "\n",
    "# ÊâìÂç∞Ë°®Ê†º\n",
    "print(\"### ÁéØÂ¢É‰ø°ÊÅØ\") # ÊâìÂç∞Ê†áÈ¢ò\n",
    "print(df.to_markdown(index=False)) # Â∞Ü DataFrame ËΩ¨Êç¢‰∏∫ Markdown Ê†ºÂºèÂπ∂ÊâìÂç∞Ôºå‰∏çÂåÖÂê´Á¥¢Âºï\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6c7afe-1037-41ab-98e4-494692e47402",
   "metadata": {
    "id": "af6c7afe-1037-41ab-98e4-494692e47402"
   },
   "source": [
    "# ËÅäÂ§©Êú∫Âô®‰∫∫ÔºöÊ∂àÊÅØÊëòË¶Å‰∏éÂ§ñÈÉ®Êï∞ÊçÆÂ∫ì\n",
    "\n",
    "## ËØæÁ®ãÂõûÈ°æ\n",
    "\n",
    "Âú®ÂâçÈù¢ÁöÑËØæÁ®ã‰∏≠ÔºåÊàë‰ª¨ÊûÑÂª∫‰∫Ü‰∏Ä‰∏™ÂÖ∑ÊúâËÆ∞ÂøÜËÉΩÂäõÁöÑAgent„ÄÇ\n",
    "\n",
    "## Â≠¶‰π†ÁõÆÊ†á\n",
    "\n",
    "‰ΩÜÊòØÔºåÂ¶ÇÊûúÊàë‰ª¨**Â∏åÊúõËÅäÂ§©Êú∫Âô®‰∫∫Êã•ÊúâÂèØ‰ª•Êó†ÈôêÊúüÊåÅ‰πÖÂåñÁöÑÂ≠òÂÇ®Âë¢Ôºü**\n",
    "\n",
    "Áé∞Âú®ÔºåÊàë‰ª¨Â∞Ü**‰ªãÁªç‰∏Ä‰∫õÊõ¥È´òÁ∫ßÁöÑÊ£ÄÊü•ÁÇπÂô®ÔºåÂÆÉ‰ª¨ÊîØÊåÅÂ§ñÈÉ®Êï∞ÊçÆÂ∫ì„ÄÇ**\n",
    "\n",
    "Âú®ËøôÈáåÔºåÊàë‰ª¨Â∞ÜÂ±ïÁ§∫Â¶Ç‰Ωï‰ΩøÁî® [SQLite‰Ωú‰∏∫Ê£ÄÊü•ÁÇπÂô®](https://langchain-ai.github.io/langgraph/concepts/low_level/#checkpointer)Ôºå‰ΩÜÂÖ∂‰ªñÊ£ÄÊü•ÁÇπÂô®ÔºàÂ¶Ç [Postgres](https://langchain-ai.github.io/langgraph/how-tos/persistence_postgres/)Ôºâ‰πüÊòØÂèØÁî®ÁöÑÔºÅ\n",
    "\n",
    "## Ê†∏ÂøÉÊ¶ÇÂøµ\n",
    "\n",
    "### ‰ªÄ‰πàÊòØÊ£ÄÊü•ÁÇπÂô®ÔºàCheckpointerÔºâÔºü\n",
    "Ê£ÄÊü•ÁÇπÂô®ÊòØLangGraph‰∏≠Áî®‰∫é‰øùÂ≠òÂíåÊÅ¢Â§çÂõæÊâßË°åÁä∂ÊÄÅÁöÑÁªÑ‰ª∂„ÄÇÂÆÉÂÖÅËÆ∏Ôºö\n",
    "- **Áä∂ÊÄÅÊåÅ‰πÖÂåñ**ÔºöÂ∞ÜÂØπËØùÁä∂ÊÄÅ‰øùÂ≠òÂà∞Â§ñÈÉ®Â≠òÂÇ®\n",
    "- **‰ºöËØùÊÅ¢Â§ç**ÔºöÂú®Â∫îÁî®ÈáçÂêØÂêéÊÅ¢Â§ç‰πãÂâçÁöÑÂØπËØù\n",
    "- **Â§öÁ∫øÁ®ãÊîØÊåÅ**ÔºöÊîØÊåÅÂ§ö‰∏™Âπ∂ÂèëÂØπËØù‰ºöËØù\n",
    "- **ÂéÜÂè≤ËøΩË∏™**ÔºöËÆ∞ÂΩïÂÆåÊï¥ÁöÑÊâßË°åÂéÜÂè≤\n",
    "\n",
    "### ‰∏∫‰ªÄ‰πàÈúÄË¶ÅÂ§ñÈÉ®Êï∞ÊçÆÂ∫ìÔºü\n",
    "- **ÂÜÖÂ≠òÈôêÂà∂**ÔºöPythonËøõÁ®ãÈáçÂêØÂêéÔºåÂÜÖÂ≠ò‰∏≠ÁöÑÁä∂ÊÄÅ‰ºö‰∏¢Â§±\n",
    "- **ÂèØÊâ©Â±ïÊÄß**ÔºöÊîØÊåÅÂ§ö‰∏™Áî®Êà∑ÂêåÊó∂‰ΩøÁî®\n",
    "- **ÂèØÈù†ÊÄß**ÔºöÊï∞ÊçÆÊåÅ‰πÖÂåñÔºå‰∏ç‰ºöÂõ†Á≥ªÁªüÊïÖÈöú‰∏¢Â§±\n",
    "- **Áîü‰∫ßÁéØÂ¢É**ÔºöÊª°Ë∂≥Áîü‰∫ßÁéØÂ¢ÉÁöÑÊï∞ÊçÆÂ≠òÂÇ®ÈúÄÊ±Ç"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85ed78d9-6ca2-45ac-96a9-52e341ec519d",
   "metadata": {
    "id": "85ed78d9-6ca2-45ac-96a9-52e341ec519d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# ÂÆâË£ÖÂøÖË¶ÅÁöÑ‰æùËµñÂåÖ\n",
    "# Ëøô‰∏™ÂëΩ‰ª§‰ºöÂÆâË£ÖLangGraphÁöÑSQLiteÊ£ÄÊü•ÁÇπÂô®ÂíåÂÖ∂‰ªñÊ†∏ÂøÉ‰æùËµñ\n",
    "%pip install --quiet langchain_openai==0.3.32 langchain_core==0.3.75 langgraph==0.6.7 langgraph-checkpoint-sqlite==2.0.11\n",
    "# ‰æùËµñÂåÖËØ¥ÊòéÔºö\n",
    "# - langgraph-checkpoint-sqlite: SQLiteÊ£ÄÊü•ÁÇπÂô®ÔºåÁî®‰∫éÊåÅ‰πÖÂåñÁä∂ÊÄÅ\n",
    "# - langchain_core: LangChainÊ†∏ÂøÉÂäüËÉΩ\n",
    "# - langgraph: LangGraphÂõæÊâßË°åÊ°ÜÊû∂\n",
    "# - langchain_openai: OpenAIÊ®°ÂûãÈõÜÊàê"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e10c4d4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2e10c4d4",
    "outputId": "0920788f-41e4-4957-941e-beafe979ce12"
   },
   "outputs": [],
   "source": [
    "# ÁéØÂ¢ÉÂèòÈáèÈÖçÁΩÆ\n",
    "# ËÆæÁΩÆOpenAI APIÂØÜÈí•ÔºåËøôÊòØ‰ΩøÁî®OpenAIÊ®°ÂûãÊâÄÂøÖÈúÄÁöÑ\n",
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    \"\"\"\n",
    "    ÂÆâÂÖ®Âú∞ËÆæÁΩÆÁéØÂ¢ÉÂèòÈáè\n",
    "    Â¶ÇÊûúÁéØÂ¢ÉÂèòÈáè‰∏çÂ≠òÂú®Ôºå‰ºöÊèêÁ§∫Áî®Êà∑ËæìÂÖ•\n",
    "    \"\"\"\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "# ËÆæÁΩÆOpenAI APIÂØÜÈí•\n",
    "# ‰Ω†ÈúÄË¶Å‰ªé https://platform.openai.com/api-keys Ëé∑ÂèñAPIÂØÜÈí•\n",
    "_set_env(\"OPENAI_API_KEY\")\n",
    "# ËÆæÁΩÆ OpenAI API‰ª£ÁêÜÂú∞ÂùÄ (‰æãÂ¶ÇÔºöhttps://api.apiyi.com/v1Ôºâ\n",
    "_set_env(\"OPENAI_BASE_URL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40d25c0-e9b5-4854-bf07-3cc3ff07122e",
   "metadata": {
    "id": "b40d25c0-e9b5-4854-bf07-3cc3ff07122e"
   },
   "source": [
    "## SQLite Êï∞ÊçÆÂ∫ì‰ªãÁªç\n",
    "\n",
    "ËøôÈáåÊàë‰ª¨‰ΩøÁî® [SqliteSaverÊ£ÄÊü•ÁÇπÂô®](https://langchain-ai.github.io/langgraph/concepts/low_level/#checkpointer) ‰Ωú‰∏∫Ëµ∑ÁÇπ„ÄÇ\n",
    "\n",
    "SQLiteÊòØ‰∏Ä‰∏™[Â∞èÂ∑ß„ÄÅÂø´ÈÄü„ÄÅÈ´òÂ∫¶ÊµÅË°å](https://x.com/karpathy/status/1819490455664685297)ÁöÑSQLÊï∞ÊçÆÂ∫ì„ÄÇ\n",
    "\n",
    "### SQLiteÁöÑ‰ºòÂäø\n",
    "- **ËΩªÈáèÁ∫ß**ÔºöÊó†ÈúÄÂçïÁã¨ÁöÑÊï∞ÊçÆÂ∫ìÊúçÂä°Âô®\n",
    "- **Èõ∂ÈÖçÁΩÆ**ÔºöÂºÄÁÆ±Âç≥Áî®\n",
    "- **Ë∑®Âπ≥Âè∞**ÔºöÊîØÊåÅÊâÄÊúâ‰∏ªÊµÅÊìç‰ΩúÁ≥ªÁªü\n",
    "- **ACIDÂÖºÂÆπ**ÔºöÊîØÊåÅ‰∫ãÂä°Â§ÑÁêÜ\n",
    "- **ÂµåÂÖ•Âºè**ÔºöÂèØ‰ª•Áõ¥Êé•ÂµåÂÖ•Âà∞Â∫îÁî®Á®ãÂ∫è‰∏≠\n",
    "\n",
    "Â¶ÇÊûúÊàë‰ª¨Êèê‰æõ `\":memory:\"` ÂèÇÊï∞ÔºåÂÆÉ‰ºöÂàõÂª∫‰∏Ä‰∏™ÂÜÖÂ≠ò‰∏≠ÁöÑSQLiteÊï∞ÊçÆÂ∫ì„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fae15402-17ae-4e89-8ecf-4c89e08b22fe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fae15402-17ae-4e89-8ecf-4c89e08b22fe",
    "outputId": "56f9d78d-4b40-488c-8736-ec4821045f51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂàõÂª∫ÂÜÖÂ≠òSQLiteÊï∞ÊçÆÂ∫ìËøûÊé•\n",
      "üìù Ê≥®ÊÑèÔºöÂÜÖÂ≠òÊï∞ÊçÆÂ∫ìÂú®Á®ãÂ∫èÁªìÊùüÂêé‰ºö‰∏¢Â§±Êï∞ÊçÆ\n"
     ]
    }
   ],
   "source": [
    "# ÂàõÂª∫SQLiteÊï∞ÊçÆÂ∫ìËøûÊé•\n",
    "import sqlite3\n",
    "\n",
    "# ÂàõÂª∫ÂÜÖÂ≠òÊï∞ÊçÆÂ∫ìËøûÊé•\n",
    "# \":memory:\" Ë°®Á§∫ÂàõÂª∫‰∏Ä‰∏™‰∏¥Êó∂ÁöÑÂÜÖÂ≠òÊï∞ÊçÆÂ∫ì\n",
    "# check_same_thread=False ÂÖÅËÆ∏Â§öÁ∫øÁ®ãËÆøÈóÆÔºàLangGraphÈúÄË¶ÅÔºâ\n",
    "conn = sqlite3.connect(\":memory:\", check_same_thread=False)\n",
    "\n",
    "print(\"‚úÖ Â∑≤ÂàõÂª∫ÂÜÖÂ≠òSQLiteÊï∞ÊçÆÂ∫ìËøûÊé•\")\n",
    "print(\"üìù Ê≥®ÊÑèÔºöÂÜÖÂ≠òÊï∞ÊçÆÂ∫ìÂú®Á®ãÂ∫èÁªìÊùüÂêé‰ºö‰∏¢Â§±Êï∞ÊçÆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bf53ec-6d4a-42ce-8183-344795eed403",
   "metadata": {
    "id": "c2bf53ec-6d4a-42ce-8183-344795eed403"
   },
   "source": [
    "‰ΩÜÊòØÔºåÂ¶ÇÊûúÊàë‰ª¨Êèê‰æõ‰∏Ä‰∏™Êï∞ÊçÆÂ∫ìË∑ØÂæÑÔºåÂÆÉÂ∞±‰ºö‰∏∫Êàë‰ª¨ÂàõÂª∫‰∏Ä‰∏™ÊåÅ‰πÖÂåñÁöÑÊï∞ÊçÆÂ∫ìÊñá‰ª∂ÔºÅ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58339167-920c-4994-a0a7-0a9c5d4f7cf7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "58339167-920c-4994-a0a7-0a9c5d4f7cf7",
    "outputId": "c4ce1a90-942f-4ace-a60a-339f23ac5500"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ËøûÊé•Âà∞ÊåÅ‰πÖÂåñSQLiteÊï∞ÊçÆÂ∫ì\n",
      "üìÅ Êï∞ÊçÆÂ∫ìÊñá‰ª∂‰ΩçÁΩÆ: state_db/example.db\n",
      "üíæ Êï∞ÊçÆÂ∞ÜÊåÅ‰πÖÂåñ‰øùÂ≠òÂà∞Á£ÅÁõò\n"
     ]
    }
   ],
   "source": [
    "# ÂàõÂª∫ÊåÅ‰πÖÂåñÊï∞ÊçÆÂ∫ì\n",
    "# ËÆæÁΩÆÊï∞ÊçÆÂ∫ìÊñá‰ª∂Ë∑ØÂæÑ\n",
    "db_path = \"state_db/example.db\"\n",
    "\n",
    "# ËøûÊé•Âà∞ÊåÅ‰πÖÂåñÊï∞ÊçÆÂ∫ìÊñá‰ª∂\n",
    "# Ëøô‰∏™Êï∞ÊçÆÂ∫ìÊñá‰ª∂‰ºö‰øùÂ≠òÂú®Á£ÅÁõò‰∏äÔºåÁ®ãÂ∫èÈáçÂêØÂêéÊï∞ÊçÆ‰∏ç‰ºö‰∏¢Â§±\n",
    "conn = sqlite3.connect(db_path, check_same_thread=False)\n",
    "\n",
    "print(\"‚úÖ Â∑≤ËøûÊé•Âà∞ÊåÅ‰πÖÂåñSQLiteÊï∞ÊçÆÂ∫ì\")\n",
    "print(f\"üìÅ Êï∞ÊçÆÂ∫ìÊñá‰ª∂‰ΩçÁΩÆ: {db_path}\")\n",
    "print(\"üíæ Êï∞ÊçÆÂ∞ÜÊåÅ‰πÖÂåñ‰øùÂ≠òÂà∞Á£ÅÁõò\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c7736b6-a750-48f8-a838-8e7616b12250",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3c7736b6-a750-48f8-a838-8e7616b12250",
    "outputId": "f337a1cd-3122-4447-c95d-dadd357ea6bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂàõÂª∫SQLiteÊ£ÄÊü•ÁÇπÂô®\n",
      "üîß Ê£ÄÊü•ÁÇπÂô®Â∞ÜÁÆ°ÁêÜÂØπËØùÁä∂ÊÄÅÁöÑÊåÅ‰πÖÂåñ\n"
     ]
    }
   ],
   "source": [
    "# ÂàõÂª∫SQLiteÊ£ÄÊü•ÁÇπÂô®\n",
    "# ËøôÊòØLangGraph‰∏≠Áî®‰∫éÊåÅ‰πÖÂåñÁä∂ÊÄÅÁöÑÁªÑ‰ª∂\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "# ‰ΩøÁî®SQLiteËøûÊé•ÂàõÂª∫Ê£ÄÊü•ÁÇπÂô®\n",
    "# Ëøô‰∏™Ê£ÄÊü•ÁÇπÂô®Â∞ÜË¥üË¥£‰øùÂ≠òÂíåÊÅ¢Â§çÂõæÁöÑÁä∂ÊÄÅ\n",
    "memory = SqliteSaver(conn)\n",
    "\n",
    "print(\"‚úÖ Â∑≤ÂàõÂª∫SQLiteÊ£ÄÊü•ÁÇπÂô®\")\n",
    "print(\"üîß Ê£ÄÊü•ÁÇπÂô®Â∞ÜÁÆ°ÁêÜÂØπËØùÁä∂ÊÄÅÁöÑÊåÅ‰πÖÂåñ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8cb629-213f-4b87-965e-19b812c42da1",
   "metadata": {
    "id": "9d8cb629-213f-4b87-965e-19b812c42da1"
   },
   "source": [
    "Áé∞Âú®ËÆ©Êàë‰ª¨ÈáçÊñ∞ÂÆö‰πâÊàë‰ª¨ÁöÑËÅäÂ§©Êú∫Âô®‰∫∫„ÄÇ\n",
    "\n",
    "## ËÅäÂ§©Êú∫Âô®‰∫∫Êû∂ÊûÑËÆæËÆ°\n",
    "\n",
    "Êàë‰ª¨Â∞ÜÊûÑÂª∫‰∏Ä‰∏™ÂÖ∑Êúâ‰ª•‰∏ãÂäüËÉΩÁöÑÊô∫ËÉΩËÅäÂ§©Êú∫Âô®‰∫∫Ôºö\n",
    "\n",
    "### Ê†∏ÂøÉÂäüËÉΩ\n",
    "1. **ÂØπËØùÁÆ°ÁêÜ**ÔºöÂ§ÑÁêÜÁî®Êà∑ËæìÂÖ•Âπ∂ÁîüÊàêÂõûÂ§ç\n",
    "2. **Ê∂àÊÅØÊëòË¶Å**ÔºöÂΩìÂØπËØùËøáÈïøÊó∂Ëá™Âä®ÁîüÊàêÊëòË¶Å\n",
    "3. **Áä∂ÊÄÅÊåÅ‰πÖÂåñ**Ôºö‰ΩøÁî®SQLite‰øùÂ≠òÂØπËØùÂéÜÂè≤\n",
    "4. **Êô∫ËÉΩË∑ØÁî±**ÔºöÊ†πÊçÆÂØπËØùÈïøÂ∫¶ÂÜ≥ÂÆöÊòØÂê¶ËøõË°åÊëòË¶Å\n",
    "\n",
    "### Áä∂ÊÄÅËÆæËÆ°\n",
    "- **messages**ÔºöÂ≠òÂÇ®ÂØπËØùÊ∂àÊÅØÂàóË°®\n",
    "- **summary**ÔºöÂ≠òÂÇ®ÂØπËØùÊëòË¶Å\n",
    "- **Ëá™Âä®ÊëòË¶ÅËß¶Âèë**ÔºöÂΩìÊ∂àÊÅØÊï∞ÈáèË∂ÖËøá6Êù°Êó∂Ëß¶ÂèëÊëòË¶Å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc414e29-2078-41a0-887c-af1a6a3d72c0",
   "metadata": {
    "id": "dc414e29-2078-41a0-887c-af1a6a3d72c0"
   },
   "outputs": [],
   "source": [
    "# ÂØºÂÖ•ÂøÖË¶ÅÁöÑÂ∫ì\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, RemoveMessage\n",
    "from langgraph.graph import END\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "# ÂàùÂßãÂåñOpenAIÊ®°Âûã\n",
    "# ‰ΩøÁî®GPT-4oÊ®°ÂûãÔºåtemperature=0Á°Æ‰øùËæìÂá∫Á®≥ÂÆö‰∏ÄËá¥\n",
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "# ÂÆö‰πâÁä∂ÊÄÅÁ±ª\n",
    "# ÁªßÊâøMessagesStateÔºåÊ∑ªÂä†summaryÂ≠óÊÆµÁî®‰∫éÂ≠òÂÇ®ÂØπËØùÊëòË¶Å\n",
    "class State(MessagesState):\n",
    "    \"\"\"ËÅäÂ§©Êú∫Âô®‰∫∫Áä∂ÊÄÅÁ±ª\"\"\"\n",
    "    summary: str  # Â≠òÂÇ®ÂØπËØùÊëòË¶Å\n",
    "\n",
    "def call_model(state: State):\n",
    "    \"\"\"\n",
    "    Ë∞ÉÁî®AIÊ®°ÂûãÁîüÊàêÂõûÂ§ç\n",
    "\n",
    "    Args:\n",
    "        state: ÂΩìÂâçÂØπËØùÁä∂ÊÄÅ\n",
    "\n",
    "    Returns:\n",
    "        dict: ÂåÖÂê´AIÂõûÂ§çÁöÑÁä∂ÊÄÅÊõ¥Êñ∞\n",
    "    \"\"\"\n",
    "    # Ëé∑ÂèñÁé∞ÊúâÊëòË¶ÅÔºàÂ¶ÇÊûúÂ≠òÂú®Ôºâ\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    # Â¶ÇÊûúÂ≠òÂú®ÊëòË¶ÅÔºåÂ∞ÜÂÖ∂Ê∑ªÂä†Âà∞Á≥ªÁªüÊ∂àÊÅØ‰∏≠\n",
    "    if summary:\n",
    "        # ÂàõÂª∫ÂåÖÂê´ÊëòË¶ÅÁöÑÁ≥ªÁªüÊ∂àÊÅØ\n",
    "        system_message = f\"Ê≠§ÂâçÂØπËØùÁöÑÊëòË¶ÅÔºö{summary}\"\n",
    "        # Â∞ÜÁ≥ªÁªüÊ∂àÊÅØÊ∑ªÂä†Âà∞Ê∂àÊÅØÂàóË°®ÂºÄÂ§¥\n",
    "        messages = [SystemMessage(content=system_message)] + state[\"messages\"]\n",
    "    else:\n",
    "        # Â¶ÇÊûúÊ≤°ÊúâÊëòË¶ÅÔºåÁõ¥Êé•‰ΩøÁî®ÂéüÂßãÊ∂àÊÅØ\n",
    "        messages = state[\"messages\"]\n",
    "\n",
    "    # Ë∞ÉÁî®AIÊ®°ÂûãÁîüÊàêÂõûÂ§ç\n",
    "    response = model.invoke(messages)\n",
    "    return {\"messages\": response}\n",
    "\n",
    "def summarize_conversation(state: State):\n",
    "    \"\"\"\n",
    "    ÂØπÂØπËØùËøõË°åÊëòË¶ÅÂ§ÑÁêÜ\n",
    "\n",
    "    ÂΩìÂØπËØùÊ∂àÊÅØËøáÂ§öÊó∂ÔºåÁîüÊàêÊëòË¶ÅÂπ∂Âà†Èô§ÊóßÊ∂àÊÅØ\n",
    "\n",
    "    Args:\n",
    "        state: ÂΩìÂâçÂØπËØùÁä∂ÊÄÅ\n",
    "\n",
    "    Returns:\n",
    "        dict: ÂåÖÂê´Êñ∞ÊëòË¶ÅÂíåÂà†Èô§Ê∂àÊÅØÁöÑÁä∂ÊÄÅÊõ¥Êñ∞\n",
    "    \"\"\"\n",
    "    # Ëé∑ÂèñÁé∞ÊúâÊëòË¶Å\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    if summary:\n",
    "      # Â¶ÇÊûúÊëòË¶ÅÂ∑≤Â≠òÂú®ÔºåÂàôÊâ©Â±ïÁé∞ÊúâÊëòË¶Å\n",
    "      summary_message = (\n",
    "          f\"ÁõÆÂâç‰∏∫Ê≠¢ÁöÑÂØπËØùÊëòË¶ÅÔºö{summary}\\n\\n\"\n",
    "          \"ËØ∑ÁªìÂêà‰∏äÊñπÁöÑÊñ∞Ê∂àÊÅØÔºåÊâ©Â±ïÁé∞ÊúâÊëòË¶ÅÔºö\"\n",
    "      )\n",
    "\n",
    "    else:\n",
    "        # Â¶ÇÊûúÊ≤°ÊúâÁé∞ÊúâÊëòË¶ÅÔºåÂàôÂàõÂª∫Êñ∞ÊëòË¶Å\n",
    "        summary_message = \"ËØ∑ÂØπ‰∏äÊñπÁöÑÂØπËØùÂàõÂª∫ÊëòË¶ÅÔºö\"\n",
    "\n",
    "    # Â∞ÜÊëòË¶ÅÊèêÁ§∫Ê∑ªÂä†Âà∞Ê∂àÊÅØÂéÜÂè≤‰∏≠\n",
    "    messages = state[\"messages\"] + [HumanMessage(content=summary_message)]\n",
    "    response = model.invoke(messages)\n",
    "\n",
    "    # Âà†Èô§Èô§ÊúÄËøë2Êù°Ê∂àÊÅØÂ§ñÁöÑÊâÄÊúâÊ∂àÊÅØ\n",
    "    # ‰ΩøÁî®RemoveMessageÊù•Ê†áËÆ∞Ë¶ÅÂà†Èô§ÁöÑÊ∂àÊÅØ\n",
    "    delete_messages = [RemoveMessage(id=m.id) for m in state[\"messages\"][:-2]]\n",
    "\n",
    "    return {\"summary\": response.content, \"messages\": delete_messages}\n",
    "\n",
    "def should_continue(state: State):\n",
    "    \"\"\"\n",
    "    ÂÜ≥ÂÆö‰∏ã‰∏ÄÊ≠•ÊâßË°åÂì™‰∏™ËäÇÁÇπ\n",
    "\n",
    "    Ê†πÊçÆÂØπËØùÈïøÂ∫¶ÂÜ≥ÂÆöÊòØÁªßÁª≠ÂØπËØùËøòÊòØËøõË°åÊëòË¶Å\n",
    "\n",
    "    Args:\n",
    "        state: ÂΩìÂâçÂØπËØùÁä∂ÊÄÅ\n",
    "\n",
    "    Returns:\n",
    "        str: ‰∏ã‰∏Ä‰∏™Ë¶ÅÊâßË°åÁöÑËäÇÁÇπÂêçÁß∞ÊàñEND\n",
    "    \"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    # Â¶ÇÊûúÊ∂àÊÅØË∂ÖËøá6Êù°ÔºåÂàôËøõË°åÊëòË¶Å\n",
    "    if len(messages) > 6:\n",
    "        return \"summarize_conversation\"\n",
    "\n",
    "    # Âê¶ÂàôÁªìÊùüÂØπËØù\n",
    "    return END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c13c0b-a383-4f73-9cc1-63f0eed8f190",
   "metadata": {
    "id": "41c13c0b-a383-4f73-9cc1-63f0eed8f190"
   },
   "source": [
    "Áé∞Âú®ÔºåÊàë‰ª¨‰ΩøÁî®SQLiteÊ£ÄÊü•ÁÇπÂô®ÈáçÊñ∞ÁºñËØëÂõæ„ÄÇ\n",
    "\n",
    "## ÂõæÊûÑÂª∫ËøáÁ®ã\n",
    "\n",
    "Êàë‰ª¨Â∞ÜÂàõÂª∫‰∏Ä‰∏™ÂåÖÂê´‰ª•‰∏ãÁªÑ‰ª∂ÁöÑLangGraphÔºö\n",
    "\n",
    "### ËäÇÁÇπÔºàNodesÔºâ\n",
    "1. **conversation**ÔºöÂ§ÑÁêÜÁî®Êà∑ËæìÂÖ•Âπ∂ÁîüÊàêAIÂõûÂ§ç\n",
    "2. **summarize_conversation**ÔºöÂΩìÂØπËØùËøáÈïøÊó∂ÁîüÊàêÊëòË¶Å\n",
    "\n",
    "### ËæπÔºàEdgesÔºâ\n",
    "1. **START ‚Üí conversation**Ôºö‰ªéÂºÄÂßãËäÇÁÇπÂà∞ÂØπËØùËäÇÁÇπ\n",
    "2. **conversation ‚Üí should_continue**ÔºöÊù°‰ª∂ËæπÔºåÂÜ≥ÂÆö‰∏ã‰∏ÄÊ≠•\n",
    "3. **summarize_conversation ‚Üí END**ÔºöÊëòË¶ÅÂÆåÊàêÂêéÁªìÊùü\n",
    "\n",
    "### Ê£ÄÊü•ÁÇπÂô®ÈõÜÊàê\n",
    "- ‰ΩøÁî®SQLiteÊ£ÄÊü•ÁÇπÂô®ÂÆûÁé∞Áä∂ÊÄÅÊåÅ‰πÖÂåñ\n",
    "- ÊîØÊåÅÂ§öÁ∫øÁ®ãÂπ∂ÂèëËÆøÈóÆ\n",
    "- Ëá™Âä®‰øùÂ≠òÂíåÊÅ¢Â§çÂØπËØùÁä∂ÊÄÅ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e867fd95-91eb-4ce1-82fc-bb72d611a96d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "id": "e867fd95-91eb-4ce1-82fc-bb72d611a96d",
    "outputId": "9d4ed258-a4cb-426e-dad7-9f7512a2365b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ ËÅäÂ§©Êú∫Âô®‰∫∫ÂõæÁªìÊûÑÂ∑≤ÊûÑÂª∫ÂÆåÊàê\n",
      "üìä ‰∏ãÂõæÊòæÁ§∫‰∫ÜËäÇÁÇπÂíåËæπÁöÑËøûÊé•ÂÖ≥Á≥ª\n",
      "ÂõæÂèØËßÜÂåñÔºö\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEICAIAAAA4AWNJAAAQAElEQVR4nOzdB3wT5f8H8OcunbSlQAul7K1ogbKHSsEWUH4yBFmCLJEpG1H2KlBWGSpbaFkCAgKigvyZArIFQWYZgoVSoNg9k/t/k2vTNM1o2iaXJp/3C+vl7snl1vO9Z9xwEASBAQBYnAMDAJACog8ASAPRBwCkgegDANJA9AEAaSD6AIA0Cif6HNkZ9fxxampSZuc9z3PUj6/uy5fxvFyh4GWcQi5wPC/QMM8pFALPcYxTJqBhxjiOo6nKNDSG42kKpxqvmiF9kPHyDIX4kb5Hc5DLhayPRD0f5QjGBHGkOIYGxGVR/oZqSJlC/KMxleapMROWucDKWee4LIGWjT4qZ6XQvlhB5sQ5u7Ca9d39W3oxqyeXy3/Z8DQhVp6WbOiqC9ryglxhIAHP00ZjhubA69hWORMwTmAKrY2s0PwJ5Y4zcHGIuGdpBxr4HdUOZeJON7CoNAt9KTKPW9VfTrnIguHl0VoLHclknCA3stjZc8s6enNOYprjeNW8DP5mdkrNTGqYjHKfPC9zVSV2EFzdHfzednutfinDKbkCXu+T8Cpt07xHTpTr3B3kaZkjedUWUc9X3EDiJtY8SsSMzZi4+ZS7k8s6jmmACRqblaMQlh1ulImVB7R6/oIqnmSti+oTp/pWVtBRzY1lxZvMn8yMfRzTXNTsDSJmKuXMBU5zG4nhSDkh15aTyZhckKckKJxcuIGzqjMrdubAsyvH4p3dORdXh/RUQynFzGYggVYG0J1Atb8NJWA5woLWPFUJlDtC7xwyzySGYotqnuJRkM9FzTpumZhvOc7I8hiNPplxhzMcEnPM0zA6o6uCD2csYeYq5jX3520JM5fBQVBkCEnxck9vh95fVTE014JEn5eRyduXRjbv4F3TvwQDDftWR6QncQOsNQCd2B19/Wxc36k1GIDZbF8c4enl2H1MZX0JeFYAO1dEtuhQGqEnt05Dazi78+HB95j1uXMl9gZCD5hfzwk1Ev/L2P3NP/oS5D/6UFuPgwNfw9+TgS7t+pdPeGWNd7Gc+zmmlK8zAzC/Oi1LRT9K1zc1/9Hn+aNUF7cCFZ1sm5OTk8yB+/NEDLMyyfHy0hURfcASXmtYUpCz2JfJOqfmP3ykJgvydOONW/YsI50lx+W1p8Bi0tKoMRSnDbAQ6rJIidc9Cdf7mBNnoJ8HwN4h+piTwARrbPkBsAoFiT44rRvBqf9YE55nnIwBSK4g9X+c1o3gVBdJMiujLI4pcOYAC9JzmShqXmakEJhcYXWtznm/vh6gcHC6jzdEHzNS3sdmfWUfACuB6GNGylKGwupKGbwMMRGsQv7bfXieQ3eyYRwn8FbY7qNAkx1YhfxHH4UCrQdGCFbZ4452H7A4Pc8MYPml+iYOYkM4xuGCHwB9l53kv91HfA4PA/2Uj6Sxvtopx3AFNliWYI4+L5zXjeCsso6D8hhYhYLdbYhTqEGq5yta3zZSPnPWZu8y3b1ne2CbJgyMmTFz4vgJw5gl6O2eKsJH4azZX/3y6z5mug+7tnnyNJJZhnW2OlvfNZCF5Y3afp/0GcRAF80s07JlYJs27Zkl6K0AFOHrfW7fvtG4cXNmoqiop//994pZhKD+A5ZSu7Yf/WOgi2aWCXy3HZNaEYg+Z8+d3rFj063bf5cq5e3nV2/woJFeXt6tAxvRpEWL56xavfSnfccTEhJ+2LXl/IU/Hj6851XKu0WLgIEDhrm4uDBVCVMmk/n4+G7fsal/vyFh4WtoZO8+nd56KyB49hJmTpxVPmEjH/VBnbvg5q2/h4/ot/Lb8Nqvvykm6/NJZ9ryw4eN/XHvzs1b1i8M+WbKtLEvX76oXLnq+LFTKOjPD5meIc9o3Kj5uLGTS5QoSV/p3CWIdsq//z7aved7GtO82Tufj5gwL2Ta6dMnKlas3OfjgW3b/o+S5XH/zpq58Pnz6JWrQo8cPk9zmDp9vNaKbA7fU6FCpYyMjO82rDx77lR0dJSfn/+Hnbo3a/a20Y0QFx+3Zs1yKjt4epZo1LDpZ4NG+viUpfFJSUmhy+ZduXIxPj6uSuVq77/fqXOnbjT+wYN7Awf1oO2zbdvGU6ePly5dpnWrtoM/G5mSktK5S2C/voP79B4ozlkul3fs3LpTx240NSbmJS3/9b+vUjKKFH37DKLtwFQ1ym3fbxw7ZhKtb+fO3UeOmPDo0cONYauvXL1ERYs336zbs3vfOnX8xd/d/9Ouy39eiIp6QsvTvn3nTh0/ovFaWYbmk5AQv2TxqnysAm1wVhjyX/PKeh2Oed25e2vS5NH16zcO27Br1MiJ9+7dWbBwJo0/+Mtp+vvFhGm0HWlgz4+0b8J6dP9k3txlQ4aMPn7icPimteIcHB0d7z+IoH9z54TSbpg/dxmN3Lpln7lDj1LmaxaKNn27wADa5nRkh21as3jhStpB6enp80Km/3pw//p127du3nft+pUdOzerU27fEV6pUpVDv54Z9OkISjN23ODAd987fOhs61ZtFi2ZE5+gfDJVHvdv3Tr11ctAUTJ0yWr1v+rVa5b18fXyKk2TVny9cNfubR927rFt608BLQNnzJp44uQRw2tEAeurSaNevHxOsxr5+RfRz599NXkUjaRJNPDkyb9zZi/Zuf0Xqs4sX7GA4rK4YPR3SWhwYOB7vx38Y8qk4J0/bDl2/LCbmxsF2d9/P6qe+cVL5yj/01pTGBo7fggFlLFjJm9Yv6NkiVIU3yOf/MtUj8pMSkrcv3/XpK9mU7hMS0sbM24wRYEFIV8vWbTKQeYwZepYCliU8tuVSy5c+GP0qC9D5q+g0EPLQycPlivLaDJ1FVghyX/ZRxAsUam4fu0KneLoLMHzPJ1qXn/tDTrOcifr3q0PHUZ0js381vWr5y+cGTJ4FFM1edFJYPXKzeKp0pJU9V3rq3mZGA/zuAu0UMSh07t43m7a5C0KHyuWrS9VSvmaM/96DSmEqVPWrPF6xw5daaBVQJvFS4LpNE5xhz7SaXbT5vWP/nlAY/Kxf6mEUt+/kTi8b/+uyMjH36zY6Orqmpqaeui3Ax/36i/+aPv3O9HcNm1eR/M3sDpUULp583r4xl0UKOkjrRflQyqn0Ka4du0KRYqqVZXvL+n98YBz509TZAyZt1z8YkDLoFYBQTRQr16Dcr7l79y5GRT4XkBAUPDcKU+jnviWLUeTTp06VqVKNYqPV65cohINlUca1G9M44cNHXP6zIndu7dR0KfVpODSs2c/cdK9e3dfvYrp2qVXrZqv08cZ00Ou/nVZjIbTps2nOCXOmbbAwYP7aVs1a/qW/lU7nY9VYCbg9B1z+Y8+ym4T87dd+tXxp40+acoYKus2b96yQvmK6kNKEwXpCxf/CFkwI+LeHXEflCyZ/SazypWqWj70KOl655fkVCHRhMXK4y7Ijcrw4kCxYsVod4ihh7i6FnsWHaVOJuZnQoUC5beqVFcno79UF2AF278REXe++XbxlMnBlL3pI2UeKjhQ7U+dgKIhlbli42I9i+t9RQLldloL9aJSnp86OZgGjhw9SD8t5tusSbVpZPbHWrXVw+7uHgmqotxbLQKcnZ2p+ENRlU5RVPKiARpPpUJaUzG+MFVgpWWjsKKew+uvZVZyqf5IFdWQhTPbBLWnNFTQy94pgrBnz3aKII8fZ75Mwte3PNPvwYOIfKyCCQQz3OMuKCyRtWg3UwHy5Mkja9d9vXLV0oYNmlAzAW1rrWQ09Zdf9lKZnI4qOj+v/+5bze4wJ2dpHqLO2cQ1CXncBblpdrQaevFezklUwsqdJt/7lxprpk4fR00q4tmbKZuQlJln5OhPtVK+inlpIPokJiY4O+sIcNSq5eLiqjmGglRychIzuDqU21s0b/n7qWMUdKjcQRGWgoi4bFRmFBto1MQGMhHVv8QBCl7Ll677+Ze9VIWkNqxy5Sr07zuY+rAUCsVXk0enp6d9Nuhzf/9GHu4eude0UFbBBJxgjuf7WOhC3qZNWtC/Af2HXrp0jtomJ08Zs2d3jponnT1+OrD7o64ff/C/D8UxJodnM+EE27gkyuguEFGLMjODguzf4ODJ1CBNVRj1GC9vZdPP+HFTypevqJmyTJmyBuZTrJgbZUiF8iXgObIilddSUnK8sCExKdFb1bpkWKtWbajdl3L+yd+PUtVSbMCmtnyqG84NXqqZUsbrbuKlghitF+2Uy5fPU9mNWtYqV6lGS3jr1t+LF62kk4SYjLZVae8yBpYk36tgCt3lFGu/3odqwufOn6EBb+/S7dp9MGL4eGqGjHr2VDMNnS6Sk5O9szYxlavP/HGSWQXLNM2bRrlAptx5r28XODspSxzqkyR1S7148ZyZQb73LzVUU7vM7JmLNPtoKpSv5KwqK1FVRfxHNUSqu9EJ38CsqLWLqp+379wUP1LrDDX6UnXstVrK8XcjbqtTUvNQlarG32FLDc+U7ak56eixQ9TeLI6sXr0WrSnFQfWyUeisUeO13F+nBaCIw8RiVIuWM2cscHBwoEplbOx/NFIdbh4+vE//DC9Jvleh4AoQfSySrajrceasiT8d2EP9tTduXqfGS8oD1HlBBxD1/128ePbPKxfpdETnAdoZ1DtAW3/h4tl1/PypNJuYmJh7hhVVVffjxw/T3JiZUc1UYYUNPxwzKSbq2wXU8koFe6oBUdmE2mJCFs7w8CjOzICqG3nfv2pXr15et/6bnj36UgCig0T8Fx39jKIM1RypmZmqPBTIqM1lwsThy5aHGF6GRo2aUVlp7doVVF26cPEspX8e/YxawZs0aUG1ntDQubdu36BGaKoEUdbt0e0TZgy177RoEUB9WLRG6lohFVhohosXz3n2LIrG7933w9BhnxxURRktcXGxCxfNXrV62b+Rj6l9Z+u2jbQL/N6sR5GUwhB1KVKVkyLU198satyomXi21swyYtuZKN+rYIpCr3lZJFtRxZgOemo1DF06j47Cd1u3Wxq6lrYvUzbOD9wYtpra87/fdmDalHnU0dh/wEd0Khg+bBzVeM+fP/Nh16DwsN1aMyxfrsJ77TrQF2lXLQ1dw8yJE9vmrYyp1zob2AXUvUK9s+8GNaZ4NGTwaDp2zXRfW973rxp1bDFl93Oo5sjPR0zo2qUnhSQqZWzbHkZ1Fjc39zffqDt+/FTDC0Dru3jhyvkLpk+f8QV9bN78nfnzlosbIXj2ktVrllHXOG2catVqzpm9WLzuxqhWLYOmHB5H0UGzBX3+3GX7f9o9O3jSjRvXKL4HBb3fpUvP3N+ldrdxYyeHha+hrjf6SB0CoUtWU8cZDVP7OvVYder8LoXLKZPmvIx5MW36hH4DPqIOO80so7lq+V6FPNN9VOT/NsjwOQ+p4bmr/lfEQ/isew1ae7bo4M2syTfj7vk192zY1rqWCmxV+My73UZX8KnimnsSnqwKANKwXPTp0LGVzvFyuZzX/5TWLZv3enqWYGZA1X7qu9E5iZoDqFquc5GoW+GbFRtY3ljnHz0+aQAAEABJREFUU+VpiTgZnk6gzcDxwMx5HNqz/EcfihgmPTF97dptzHTm2+VUs9W3SImJCdQcoHOSg8yELWadT5VXXmxofUslOQPHAzPncWgPuEJ/tqGp7UXipd9WxdyLxBm8yk4q1nn7hzWwwkPUNuiLFfnvkhEEPJvcCIHh+e0AzAw97mAMxwkcj+gDgHeZWpwgcALemA6gR0HucefQfGAYp+xgsrroo7zrwGYf6wzWqbDf5yXgbYLG0Oaxwjst5HJLPBoFQANqXhbHUdULr84C0APRx4wEzjrf5wVgFRB9AEAaiD4AII38Rx9HF06RxsAAB0fm7Gp13UsOThxfOC9EATCOl3FOLroPuPznjVJlHFNS5Az0k8uFGvVdmZVxceVePE1lAOYXeT+O+l1KlnXSOTX/0ee9fuXSkhVxMSj/6HZ0+2NXN87Ty+qiT82G7s8fJzMA87t0OKa4l96SdoHqBQ0DS+xf+YhBLn+ejIqMSB04yxIPxzXVWx+UpnPR9wuMv5MLoCAOhj1OiVf0/qqqvgQF7RJ+cCPh1w1RHiVlnt5OLKs5gVPe1Kp5nYugvthR1QetexJTPXom89kPnPjKjByJOc2LljITaC9/dhpO9yVOnPoNowLLvbSc+IH+KrSvzzQ6Z+Xy80JKcnrc8wwqFQ5dWINZsQMbIiPvJhcv6Vjc20kuz/NFSbTifNYLUvRvB/Ve5YxdcyBucKbjmBEnZ/2E5m9p/a7mruQ0bqfWPLJyfkVzqbi83fDPmX7xRI6F0bm4updN9x3hnHhngWB8gZUJ9B386sNb38YUxMd+69gXGnvKyALIHFhSXMZ/z1Npow2aU81AykK4ICUtIW3v+qj4mPTUrOJ8rsNDO3vnmKiRVibj5XKFeqzWLtf8Ls9xCkHQeqGhoPodLvOtDcoEnOplQjmXV1DdJcIpdB1/YvijqXLlDVo5doB6YbJ3Q64DRebIOTkLZco7/29QBWb1rp6IuXb6v9RkLjVF97XPOo8z9SbV3Ib6vph9OtGTRmMX6/g19dc1N7X20aU5SU8yrUXVt/cNhDjNI03/V3JkWp3ZNXfG5lTphFzf0qJ6Sp242DlO2DlmlflDAs/xOndN1uGdvVO0tkzWTtGxDNkpjYUfRyfeyYWVrebSrrcvM8imLoebOHFiu3btAgMDGQBYPZu63icjI0N8zQAAWD9EHwCQBqIPAEjDpvJqenq6o6MjA4CiAGUfAJAGog8ASAPRBwCkgXYfAJAGyj4AIA1EHwCQBqIPAEgD0QcApIFWZwCQBso+ACANRB8AkIZN5VW5XI7oA1BU2E5epYKPTIY3xQAUGTYVfVDwAShCEH0AQBqIPgAgDUQfAJCG7WRXXGoIULSg7AMA0rCd7CoIgq+vLwOAIsJ2oo9MJouMjGQAUETYTvShahdVvhgAFBGIPgAgDUQfAJAGog8ASAPRBwCkgegDANLgma2gHneFQiEIAgOAosB2og9D8QegSEH0AQBp2NSNUYg+AEUIog8ASAPRBwCkgegDANJA9AEAaSD6AIA0EH0AQBqcDVwcXL9+fU5FXBcaUCgUrVu3Dg0NZQBgrWzhasOmTZuK0YdXoYEyZcoMGDCAAYAVs4Xo07t3by8vL80xtWvXrlOnDgMAK2YL0eedd95544031B+LFy/eq1cvBgDWzUbu8+rXr1+pUqXE4Ro1alBdjAGAdbOR6EMNz35+fjTg5uaGgg9AkWC8z+vRncS7l+NTU3J+jWOq79F/HP2P55hCYzYyXpArOM30YoKsb2nPSjlW2WPFjKL5CCznTJRfV65GbHzc1b/+cnZ2btK4CY3MnKtqEbUWO/dI5ZqIy5d7vJDju7lXWd3Xpk7GKWfGaf1o9irwClc3LqArXj0G9s5I9PluekRqEnN05tNTcyQTc5Q6B/I8Uyiyp/IyXiFX5EjPc8ocyVO+zP561iRaiFwxhekJVarEmpFOM/PTAKeKGcoQoOx3F3KHBkFgWuGHesnENFo/pxxP4xQ5VkH93cyPuqMPp9Ack7XWIpmj8pcyMpi3r2OP8ZUZgL0yFH3WTIrwLufQtm8VBoVNLpf/EPqgbCWXDoMrMAC7pDf6rJsSUaGmy9sfIm+Y0a5l991LOHQbXYkB2B/drc5/HIhWyBlCj7kFdPOJfpTGAOyS7ujz6G6Ki4dN3QJmnUqXd5PJ2LVTMQzA/ugOMelJCqZgYAGCgkuMw7YGe6Q7+lCHlZCzyxzMhPoKFXJsarBHqF5JTFD/AbAziD4SU12axADskO7ow/Ech/OxRYiPJGIA9kd39BGUbyRGlrAEjgkcal5gl/SWfZAjLEN1jxoCPdgj3df7qMo+DCxDQKQHu6S77MPLOEQfy+CUJU0bec4JgEl0Rx+FHO0+FqK8uV+Bqw3BHqHHXWLiw0AYgP1BzUtqysedYVuDPdLT4qAQUBmwENXjyADskO7oo8j8z37NmDlx/IRhzPyo6CPIGYAd0nO9j12ekH/cu/PW7b8nfTmLhlu2DExPt9CTd1D4Afuk/1pn+8sSt2/fUA8HvtuOWQqu9wH7VGh9XsoHFe/aGr5pLQ2/UbtO/35D6tTxFydt2rz+0G8HXryILlOmrH+9hmPHTOJVV7h07hI0oP/Q2Nj/6Fuurq6NGzX/fMQEFxfXzl0C+/Ud3Kf3QPWcO3Zu3aljt8GfjYyJeblyVej1v6+mpKQ0bty8b59BFSsqH8x+/37Ep5/1nD932eLQ4BIlSq5f+/2jRw83hq2+cvWSIAhvvlm3Z/e+4vI8eHBv/0+7Lv95ISrqSZXK1dq379yp40c0fsy4wVevXqaB3377ec3qLVu3bkhIiF+yeJWBVaBZDRzUY+W34du2bTx1+njp0mVat2pLCymTyVieUSmTR58X2CXd7T68g/J96MwUa9d9vW/fD7NnLZ46eW7p0j5fThpJ+Z/GUwjYu2/nsCFjdv1w6NOBw4+fOExBSvyKo6Pjjh2b6Jf2/ngkfOPua9evhIWvcXNza97snd9/P6qe88VL55KSkgLffY/C0NjxQyigjB0zecP6HSVLlBo+ol/kk3/FWdHfTVvW9+j+yfhxU9PS0iiaUBRYEPL1kkWrHGQOU6aOpYBFab5dueTChT9Gj/oyZP4KCj3LVyw4e+40jV8WurZ2bb+2bf937MjFWjVf11w1fasg/uiS0ODAwPd+O/jHlEnBO3/Ycuz4YWYilH3APumpeWUoFKY0hcbGxVLGGzP6q8aNmtHHpk3fSkpKfBnzomQpr++3hw8bOvbtt1vR+FYBQffv392y9bsuH/YUs2758hUzyzjuHlT2uXPnJg0GBAQFz53yNOqJb9ly9PHUqWNVqlSrXr3mlSuXKKJReaRB/cY0ftjQMafPnNi9e9uokRPFS2bo17t91JsG7t27++pVTNcuvcQ4MmN6yNW/LmdkZNDwtGnzadnEOdf3b3Tw4P7zF840a/qWvlWLT4jXtwpigoCWQTSSBurVa1DOtzytQlDgeyzPlK3OCD5gl/REH8ZMeurMwwf36O/rr7+ZOVMHh9mzFtHAjZvX09PTqUyhTlmrVu2EhITIyMcUUMSP6kkeHsUTExNo4K0WAc7OzlT86d6tD9WbTpw8QgM0ngpHFLPE0KNaQI4qQRRWsmdeM3NuFSpUovpXyMKZbYLaUxo/v3oUaLLWTdizZ/u586cfP/5HHOHrW97AqlEyfatAq6m1Cu7uHlRfY6bgGJ7vA3ZKz9WGvGk3XotZzsXZRWt8TMwLrfGursXob3JykvhR52W+Li4uLZq3/P3UMQo6165diY+PoyAi/goFgtaBjTQTU5RRDzs5O4sDFLyWL1338y97d+3e9t2GleXKVejfd3CbNu0VCsVXk0dTZ9Zngz7392/k4e4xcvSnzCADq0Dhkim3VYHu0sr9GkUAO6HnPi8T73F3c3Onv1Sj0Tk+OSVZPUZMU6qUt+EZtmrVZsbMiS9fvjj5+1FqM/bxKUsjvby8qXF6bvBSzZQyXncTb6VKVahqRq3aly+f//Xg/nkh0ytXqUbR59atvxcvWtmwQRMxGUW00t5lmLFV07kKhdIljzstwG7paXXmTcsRNWq8RtUQdSWIQhcVMQ4dOlC9ei1q+v3776vqlDdvXqcSB3UPGZ4hNTxT8/PZc6eOHjtE7c3iSJpbcnIy9TpRNUr85+PjSz+d++vUPEQRh4nFqBYtZ85YQItHLTLUv0Yj1eHm4cP79M/wkuR7FUzAo/AD9kj/nRamFH7c3d2pckR9XpTn/7xy8etvFl26dI7aSop7FKfxW7ZuOHPmZFx8HHVm/7h3x0cf9TZaW6H2nRYtAvbv30XxQmzTJVRgadKkxeLFc549i6Lxe/f9MHTYJwdVUUZLXFzswkWzV61e9m/kY2q42bptIzU5+71Zj7rYKQzt2LmZFoYiFC0nNVRHPXsqfouawCmyUGc8tVirZ5XvVcgjXOsMdktPzcv0C3CpD3vZ8pAloXOpX7xG9VqzZy6iug+NHzF8PGXUOXMnU/6n9pePew3o1bNfXmbYqmXQlMPjKDqULFlKPXL+3GX7f9o9O3jSjRvXKlasHBT0fpcuPXN/l5qZx42dTP331BNHHxs1bBq6ZLXYzj1lcnD4prWdOr9LsWbKpDnUMTdt+oR+Az4K37irw/+6UPnoi4kjqJ9ec275XgUAMED3e9w3z/2Hety7jK7MwMw2zb7XoHWJ5h94MQA7o+fJqgKerGohqut9sK3BHum9yxSX/1sILvgBe6XnPi8Bl/9bCMfwOi+wU3qiD/KDpShrXQoEerBHep4uhjfqAICZ6X+uM8o/FsFxAq51Bvuk/406eLCzZeDNRWCvDDxdDFUvS1DdZYpNDfYI73EHAGngbYISozjP8ah8gT1C9JEY9bYL6HEHu6Q/+iBHAIA56bnPS4GGUAAwL91lHydXmZCBp85YgoOjwDsyADuku+zj6sZSUhB9LEGewSrVcmUA9kd39Gnd3Ts5AXUvszt/MNrRiStXzY0B2B/d0cfTy7VsVaet8yMYmNOtC3GtengzALvEGbjQ9tyh55ePxPpWK1a+pqtrMSdmhKB1azynq99MobrCxWiHmjqJzrSaI5UvnOf0psw3hcDxnKDvR3MR1I/KMLoMnEyIfZ78z62kmCfpA2dVcnU3umEBbBNn+DL/swef3zybkJokz0hnhfWLeYoSgnme8kGBKm+9eXlOqEpsSuDjOY53FNxLOHQd6ePqjhYfsF+cLd1kNHHixHbt2gUGBjIAsHo2da1zRkaG+HZjALB+iD4AIA1EHwCQBqIPAEgD0QcApIHoAwDSQPQBAGnYVF5NT093dMQN4wBFA8o+ACANRB8AkAaiDwBIA9EHAKSBVmcAkAbKPgAgDUQfAJAGog8ASMN28iqFHplMxnF4KzFA0WBT0QcFH4AiBNEHAKSB6AMA0kD0AQBpIPoAgDQQfQBAGraTXRUKRa1atRgAFBG2E314nr9z5w4DgCLCdrgsNAgAAAdSSURBVKIPVbuo8sUAoIhA9AEAaSD6AIA0EH0AQBqIPgAgDUQfAJCGTUUfuVzOAKCI4JkNkclkKP4AFBU2FX1Q+QIoQmzqxihEH4AiBNEHAKSB6AMA0kD0AQBpIPoAgDQQfQBAGog+ACANThAEVsQ1aNBAHBBfJSiuUd26dcPCwhgAWCtbuNqwZs2aTPVsQ06FBtzc3AYOHMgAwIrZQvTp1auXh4eH5pjq1au3bNmSAYAVs4Xo07lz54oVK6o/Ojs7f/zxxwwArJuN3Oc1YMAAqm2JwxSJ2rZtywDAutlI9AkMDKxatSpTdXtRRYwBgNUr5B73yIjE1ARB4JV9TzwnKAROHE//E7vWqENK7JkSJwhZkzkhK4EqIgpZ31IwmkXmTATq1GLZPXT0DWpnVnfZdW07NP2/H4oVK+ZXNejeX4lav8t0f876SU57HP2QkHusnsSq9BleFZw8S7kyAMibQutx/3lD5D83kylzKhSZOZyTMUH1tC9BFTbUv6grAGgukSrj6ySoopT6k1YcyD1jHZHC2K/nF60szdrRibXuWbpGXU8GAMYUTvQ5sfvZzYvxTdp612xQgtmxM79E3b2Q0HNCBe9yLgwADCqE6LPn20cxT9N6fFGDgcrmORHt+pWpXqc4AwD9CqHVOepBWtv+5RlkqVCz2IldLxgAGFTQ6HPmQLTMgZUsjdbWbHVblUxOUDAAMKigfV5J8TmalIF4lXUt+jfPAZhdQaOPPIPLSEdW0yYosE0AjLCpJ2xYDw7lQQBjEH3MAjUvAKMKGn04JvA8zvPaUPQBMKqg0YfanBVo48gNmwTAmEIo++A0nxuCD4BRhVD2QU7LDTUvAKMKGn14nsnQ7pMLWp0BjCpo9FEomBztPrmg7ANgFHrczcIG3hQCYG4FbnXmGIeaVy642hDAqMIo++A0nwuKPgBG2chznfNowKfdly0PYeaHog+AUQXucRfQxqEDNgmAUWh1NguUfQCMKnCrM2+hFtaMjIzvNqw8e+5UdHSUn5//h526N2v2tjipc5egAf2Hxsb+F75praura+NGzT8fMcHLy5smPXx4P2TBjH8ePfD3b9S3zyBmKQIeLgZgTIHbfSxVxVjx9cJdu7d92LnHtq0/BbQMnDFr4omTR8RJjo6OO3Zs4nl+749Hwjfuvnb9Slj4Ghqfnp7+5aSRpUv7hG3YNeSzUdt3bHr50kIPPOXsqz0NID8Kmkss0+iTmpp66LcDH/fq37FDV8/inu3f7xT47nubNq9TJyhfvmKf3gM93D2oyENlnzt3btLIk78fjY5+NmL4eB+fslWqVBs1cmJCQjwDAOtQ8HM0Z4EARNEkLS2Nwop6jH+9hvfvR8TGxYofa9WqrZ7k4VE8MTGBBiIjH7u4uJQt6yuOp8BUpowPswy0OgMYUzRancUyy8jRn2qNfxXzkopCTM/VfXFxsa6uxTTHODtb6jVbaHUGMKYQrnXmzd/q7OVdmv6OHzeFalia48uUKWvgW8WLeyYnJ2mOSUpKZBaBHncAowqh7COYv5pRoXwlZ2dnGqjv30gc8+pVDNX4ihUrZuBbZX18U1JSqIJWrZryTYcREXdevHjOLAI97gBGFbzdR7BANYOiTP9+Q6iZ+dq1K9QARL1dEyYON3rVcosWAU5OTotDgykGUdyZHTypeHG8YR3AWhT8WmfOMt1ePXv0rV691rbtYZcvn3dzc3/zjbrjx081/BV3d/d5c5etXbvig44B1Pw8+LNR/3fkV2YRqHkBGFXQ2HFoc3TE1bi+0/AS9xzCZ0Z8vhTbBMCQwniuMxo5AMB0hfFcZ1NKT+MnDBMvBdQil8up9dpBpnt5tmze6+lZghWSbd+Hff99mO5pFEn1rM76ddt9fAx1sQGASQoafWQy+mdC0/XkSXPS0tN0TkpNTRU7tnIrxNBDOnTo2rp1W52T4uPiPIoX1zlJvHEsj9DsA2BUgd/jLqd/JtxSaVIeNhMPdw/6p3OSb9lyrDCgLgpgVMGvNkS7DwDkR5HpcS9asEUAjMLTxcwCpUEAowrjnRbIagBguoLXvASmQPgBAJMV/GpDe3svRp6gKQzAKEtfbWgnUBsFMAqtzgAgDUQfAJBGwe+0kDs5yhgAgIkK2mLsUdJRjpdX5fT0n0QZAjKAMQWNPk3f91bIhScP4hhkuXbypYsHmp0BjCiE3vLKr7uc2BnNIEvUg7T2gyz16h6AIqtw+ssvHX154eCr1xp7NGprv7kuISH57M8xT28n951e2d3TkQGAQYV2tc7xXU9vX07MSFW+wtzoHLk83IfJCUwwUH0x9jB7A1/X+evZIw3MWf8kXvk+e+bixnUaXs7Lx5UBgDGFf63g83/TdNbncuR5jWys+TRBzWHKzgbimHpunCrOMI1ww2XNXiuB+ifU7wDSnMRznCLztzWTZP8Up3yKrKD5EzkWRC4vXRFBB8AEuFIZAKSBqw0BQBqIPgAgDUQfAJAGog8ASAPRBwCkgegDANL4fwAAAP//A0pzJgAAAAZJREFUAwB8ripdPtzlQQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ÂõæÊ∏≤ÊüìÊàêÂäüÔºÅ\n"
     ]
    }
   ],
   "source": [
    "# ÊûÑÂª∫LangGraph\n",
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START\n",
    "\n",
    "# ÂàõÂª∫Áä∂ÊÄÅÂõæ\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "# Ê∑ªÂä†ËäÇÁÇπ\n",
    "# conversationËäÇÁÇπÔºöÂ§ÑÁêÜÁî®Êà∑ËæìÂÖ•Âπ∂ÁîüÊàêAIÂõûÂ§ç\n",
    "workflow.add_node(\"conversation\", call_model)\n",
    "# summarize_conversationËäÇÁÇπÔºöÁîüÊàêÂØπËØùÊëòË¶Å\n",
    "workflow.add_node(\"summarize_conversation\", summarize_conversation)\n",
    "\n",
    "# Ê∑ªÂä†Ëæπ\n",
    "# ‰ªéÂºÄÂßãËäÇÁÇπÂà∞ÂØπËØùËäÇÁÇπ\n",
    "workflow.add_edge(START, \"conversation\")\n",
    "# Êù°‰ª∂ËæπÔºöÊ†πÊçÆÂØπËØùÈïøÂ∫¶ÂÜ≥ÂÆö‰∏ã‰∏ÄÊ≠•\n",
    "workflow.add_conditional_edges(\"conversation\", should_continue)\n",
    "# ÊëòË¶ÅÂÆåÊàêÂêéÁªìÊùü\n",
    "workflow.add_edge(\"summarize_conversation\", END)\n",
    "\n",
    "# ÁºñËØëÂõæÂπ∂ÈõÜÊàêSQLiteÊ£ÄÊü•ÁÇπÂô®\n",
    "# checkpointerÂèÇÊï∞ÂêØÁî®Áä∂ÊÄÅÊåÅ‰πÖÂåñ\n",
    "graph = workflow.compile(checkpointer=memory)\n",
    "\n",
    "# ÊòæÁ§∫ÂõæÁöÑMermaidÂèØËßÜÂåñ\n",
    "print(\"üéØ ËÅäÂ§©Êú∫Âô®‰∫∫ÂõæÁªìÊûÑÂ∑≤ÊûÑÂª∫ÂÆåÊàê\")\n",
    "print(\"üìä ‰∏ãÂõæÊòæÁ§∫‰∫ÜËäÇÁÇπÂíåËæπÁöÑËøûÊé•ÂÖ≥Á≥ª\")\n",
    "# display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "# Â±ïÁ§∫ÂõæÁªìÊûÑ\n",
    "# ÂõæÂèØËßÜÂåñ\n",
    "print(\"ÂõæÂèØËßÜÂåñÔºö\")\n",
    "\n",
    "# ÊñπÊ°à1ÔºöÂ∞ùËØï‰ΩøÁî® Pyppeteer Êú¨Âú∞Ê∏≤ÊüìÔºàÊé®ËçêÔºâ\n",
    "try:\n",
    "    # ÂèØËßÜÂåñÔºöÈÄöËøá Mermaid Ê∏≤ÊüìÂõæÁªìÊûÑ\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "    print(\"‚úÖ ÂõæÊ∏≤ÊüìÊàêÂäüÔºÅ\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Pyppeteer Ê∏≤ÊüìÂ§±Ë¥•: {e}\")\n",
    "    \n",
    "    # ÊñπÊ°à2ÔºöÊòæÁ§∫ Mermaid ÊñáÊú¨Ê†ºÂºè\n",
    "    print(\"\\nüìù ÂõæÁªìÊûÑÔºàMermaid ÊñáÊú¨Ê†ºÂºèÔºâÔºö\")\n",
    "    print(\"=\" * 50)\n",
    "    mermaid_text = graph.get_graph().draw_mermaid()\n",
    "    print(mermaid_text)\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # ÊñπÊ°à3ÔºöÊòæÁ§∫ÂõæÁöÑËäÇÁÇπÂíåËæπ‰ø°ÊÅØ\n",
    "    print(\"\\nüîó ÂõæÁªìÊûÑ‰ø°ÊÅØÔºö\")\n",
    "    print(\"ËäÇÁÇπ:\", list(graph.get_graph().nodes.keys()))\n",
    "    print(\"Ëæπ:\", list(graph.get_graph().edges))\n",
    "    \n",
    "    # ÊñπÊ°à4ÔºöÊèê‰æõÊâãÂä®Ê∏≤ÊüìËØ¥Êòé\n",
    "    print(\"\\nüí° ÊâãÂä®Ê∏≤ÊüìËØ¥ÊòéÔºö\")\n",
    "    print(\"1. Â§çÂà∂‰∏äÈù¢ÁöÑ Mermaid ÊñáÊú¨\")\n",
    "    print(\"2. ËÆøÈóÆ https://mermaid.live/\")\n",
    "    print(\"3. Á≤òË¥¥ÊñáÊú¨Âà∞ÁºñËæëÂô®‰∏≠Êü•ÁúãÂõæÂΩ¢\")\n",
    "    print(\"4. ÊàñËÄÖ‰ΩøÁî®ÊîØÊåÅ Mermaid ÁöÑ Markdown ÁºñËæëÂô®\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8769db99-3938-45e6-a594-56beb18d6c45",
   "metadata": {
    "id": "8769db99-3938-45e6-a594-56beb18d6c45"
   },
   "source": [
    "![image-20251004074336769](https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202510040743819.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c1f9f6-7e84-4793-ad5f-5d85708e9c96",
   "metadata": {
    "id": "8769db99-3938-45e6-a594-56beb18d6c45"
   },
   "source": [
    "Áé∞Âú®ÔºåÊàë‰ª¨ÂèØ‰ª•Â§öÊ¨°Ë∞ÉÁî®ÂõæÊù•ÊµãËØïËÅäÂ§©Êú∫Âô®‰∫∫ÁöÑÂäüËÉΩ„ÄÇ\n",
    "\n",
    "## ÊµãËØïËÅäÂ§©Êú∫Âô®‰∫∫\n",
    "\n",
    "Êàë‰ª¨Â∞ÜËøõË°å‰ª•‰∏ãÊµãËØïÔºö\n",
    "\n",
    "### ÊµãËØïÂú∫ÊôØ\n",
    "1. **Ëá™Êàë‰ªãÁªç**ÔºöÁî®Êà∑‰ªãÁªçËá™Â∑±ÁöÑÂêçÂ≠ó\n",
    "2. **ËÆ∞ÂøÜÊµãËØï**ÔºöËØ¢ÈóÆÁî®Êà∑ÂêçÂ≠óÔºåÊµãËØïAIÁöÑËÆ∞ÂøÜËÉΩÂäõ\n",
    "3. **ÂÖ¥Ë∂£ÂàÜ‰∫´**ÔºöÁî®Êà∑ÂàÜ‰∫´ÂÖ¥Ë∂£Áà±Â•Ω\n",
    "4. **Áä∂ÊÄÅÊåÅ‰πÖÂåñ**ÔºöÈ™åËØÅÁä∂ÊÄÅÊòØÂê¶Ê≠£Á°Æ‰øùÂ≠òÂà∞Êï∞ÊçÆÂ∫ì\n",
    "\n",
    "### ÈÖçÁΩÆËØ¥Êòé\n",
    "- **thread_id**ÔºöÁî®‰∫éÊ†áËØÜ‰∏çÂêåÁöÑÂØπËØù‰ºöËØù\n",
    "- **config**ÔºöÂåÖÂê´Á∫øÁ®ãIDÁöÑÈÖçÁΩÆÂØπË±°\n",
    "- **ÊåÅ‰πÖÂåñ**ÔºöÊØèÊ¨°Ë∞ÉÁî®ÈÉΩ‰ºöËá™Âä®‰øùÂ≠òÁä∂ÊÄÅÂà∞SQLiteÊï∞ÊçÆÂ∫ì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f4094a0-d240-4be8-903a-7d9f605bdc5c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0f4094a0-d240-4be8-903a-7d9f605bdc5c",
    "outputId": "94f9bc30-fbcd-44ee-b81a-4c626f4fb4fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ ÂºÄÂßãËÅäÂ§©Êú∫Âô®‰∫∫ÊµãËØï\n",
      "==================================================\n",
      "\n",
      "üìù ÊµãËØï1ÔºöÁî®Êà∑Ëá™Êàë‰ªãÁªç\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "‰Ω†Â•ΩÔºåLanceÔºÅÂæàÈ´òÂÖ¥ËÆ§ËØÜ‰Ω†„ÄÇÊúâ‰ªÄ‰πàÊàëÂèØ‰ª•Â∏ÆÂä©‰Ω†ÁöÑÂêóÔºü\n",
      "\n",
      "üß† ÊµãËØï2ÔºöAIËÆ∞ÂøÜÊµãËØï\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "‰Ω†ÂëäËØâÊàë‰Ω†ÁöÑÂêçÂ≠óÊòØLance„ÄÇ\n",
      "\n",
      "üéØ ÊµãËØï3ÔºöÁî®Êà∑ÂàÜ‰∫´ÂÖ¥Ë∂£\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Yo-Yo MaÊòØ‰∏Ä‰ΩçÈùûÂ∏∏Êù∞Âá∫ÁöÑÂ§ßÊèêÁê¥ÂÆ∂Ôºå‰ªñÁöÑÊºîÂ•èÊ∑±ÂèóËÆ∏Â§ö‰∫∫ÂñúÁà±„ÄÇ‰ªñ‰ª•ÂÖ∂‰∏∞ÂØåÁöÑÈü≥‰πêË°®ËææÂíåÊäÄÂ∑ßÈóªÂêç‰∫é‰∏ñ„ÄÇÂ¶ÇÊûú‰Ω†ÂñúÊ¨¢‰ªñÁöÑÈü≥‰πêÔºåÂèØËÉΩ‰ºöÂØπ‰ªñÁöÑ‰∏ìËæëÂíåÁé∞Âú∫ÊºîÂá∫ÊÑüÂÖ¥Ë∂£„ÄÇ‰ªñÁöÑ‰ΩúÂìÅÊ∂µÁõñ‰∫ÜÂπøÊ≥õÁöÑÂè§ÂÖ∏Èü≥‰πêÊõ≤ÁõÆÔºå‰ª•ÂèäË∑®ÁïåÂêà‰ΩúÈ°πÁõÆÔºåÊØîÂ¶Ç„Ää‰∏ùÁª∏‰πãË∑Ø„ÄãÈ°πÁõÆ„ÄÇ‰Ω†ÊúâÁâπÂà´ÂñúÊ¨¢ÁöÑÊõ≤ÁõÆÊàñ‰∏ìËæëÂêóÔºü\n",
      "\n",
      "‚úÖ ËÅäÂ§©Êú∫Âô®‰∫∫ÊµãËØïÂÆåÊàê\n",
      "üíæ ÊâÄÊúâÂØπËØùÁä∂ÊÄÅÂ∑≤‰øùÂ≠òÂà∞SQLiteÊï∞ÊçÆÂ∫ì\n"
     ]
    }
   ],
   "source": [
    "# ÂàõÂª∫ÂØπËØùÁ∫øÁ®ãÈÖçÁΩÆ\n",
    "# thread_idÁî®‰∫éÊ†áËØÜ‰∏çÂêåÁöÑÂØπËØù‰ºöËØùÔºåÁõ∏ÂêåIDÁöÑÂØπËØù‰ºöÂÖ±‰∫´Áä∂ÊÄÅ\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "print(\"üöÄ ÂºÄÂßãËÅäÂ§©Êú∫Âô®‰∫∫ÊµãËØï\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# ÊµãËØï1ÔºöÁî®Êà∑Ëá™Êàë‰ªãÁªç\n",
    "print(\"\\nüìù ÊµãËØï1ÔºöÁî®Êà∑Ëá™Êàë‰ªãÁªç\")\n",
    "input_message = HumanMessage(content=\"‰Ω†Â•ΩÔºÅÊàëÊòØLance\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config)\n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()\n",
    "\n",
    "# ÊµãËØï2ÔºöAIËÆ∞ÂøÜÊµãËØï\n",
    "print(\"\\nüß† ÊµãËØï2ÔºöAIËÆ∞ÂøÜÊµãËØï\")\n",
    "input_message = HumanMessage(content=\"ÊàëÂè´‰ªÄ‰πàÂêçÂ≠óÔºü\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config)\n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()\n",
    "\n",
    "# ÊµãËØï3ÔºöÁî®Êà∑ÂàÜ‰∫´ÂÖ¥Ë∂£\n",
    "print(\"\\nüéØ ÊµãËØï3ÔºöÁî®Êà∑ÂàÜ‰∫´ÂÖ¥Ë∂£\")\n",
    "input_message = HumanMessage(content=\"ÊàëÂñúÊ¨¢YoYoMAÁöÑÂè§ÂÖ∏Èü≥‰πê\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config)\n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()\n",
    "\n",
    "print(\"\\n‚úÖ ËÅäÂ§©Êú∫Âô®‰∫∫ÊµãËØïÂÆåÊàê\")\n",
    "print(\"üíæ ÊâÄÊúâÂØπËØùÁä∂ÊÄÅÂ∑≤‰øùÂ≠òÂà∞SQLiteÊï∞ÊçÆÂ∫ì\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f3e842-4497-45e2-a924-69672a9bcb33",
   "metadata": {
    "id": "c0f3e842-4497-45e2-a924-69672a9bcb33"
   },
   "source": [
    "ËÆ©Êàë‰ª¨Á°ÆËÆ§Áä∂ÊÄÅÂ∑≤Ê≠£Á°Æ‰øùÂ≠òÂà∞Êú¨Âú∞Êï∞ÊçÆÂ∫ì„ÄÇ\n",
    "\n",
    "## Áä∂ÊÄÅÊåÅ‰πÖÂåñÈ™åËØÅ\n",
    "\n",
    "Êàë‰ª¨Â∞ÜÊ£ÄÊü•‰ª•‰∏ãÂÜÖÂÆπÔºö\n",
    "\n",
    "### Áä∂ÊÄÅÊ£ÄÊü•È°πÁõÆ\n",
    "1. **Ê∂àÊÅØÂéÜÂè≤**ÔºöÈ™åËØÅÊâÄÊúâÂØπËØùÊ∂àÊÅØÊòØÂê¶‰øùÂ≠ò\n",
    "2. **ÊëòË¶Å‰ø°ÊÅØ**ÔºöÊ£ÄÊü•ÂØπËØùÊëòË¶ÅÊòØÂê¶Ê≠£Á°ÆÁîüÊàê\n",
    "3. **ÂÖÉÊï∞ÊçÆ**ÔºöÊü•ÁúãÊâßË°åÊ≠•È™§ÂíåÈÖçÁΩÆ‰ø°ÊÅØ\n",
    "4. **Êó∂Èó¥Êà≥**ÔºöÁ°ÆËÆ§Áä∂ÊÄÅ‰øùÂ≠òÊó∂Èó¥\n",
    "\n",
    "### Áä∂ÊÄÅÁªìÊûÑËØ¥Êòé\n",
    "- **values**ÔºöÂåÖÂê´ÂÆûÈôÖÁöÑÁä∂ÊÄÅÊï∞ÊçÆÔºàÊ∂àÊÅØÂíåÊëòË¶ÅÔºâ\n",
    "- **next**Ôºö‰∏ã‰∏ÄÊ≠•Ë¶ÅÊâßË°åÁöÑËäÇÁÇπ\n",
    "- **config**ÔºöÈÖçÁΩÆ‰ø°ÊÅØÔºåÂåÖÊã¨Á∫øÁ®ãIDÂíåÊ£ÄÊü•ÁÇπID\n",
    "- **metadata**ÔºöÊâßË°åÂÖÉÊï∞ÊçÆÔºåÂåÖÊã¨Ê≠•È™§Êï∞ÂíåÁà∂ËäÇÁÇπ‰ø°ÊÅØ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2ab158a-5a82-417a-8841-730a4cc18ea7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d2ab158a-5a82-417a-8841-730a4cc18ea7",
    "outputId": "6e9803ce-656c-425e-ad73-0dd5f09bdf10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Ê£ÄÊü•‰øùÂ≠òÁöÑÂØπËØùÁä∂ÊÄÅ\n",
      "==================================================\n",
      "üìä Áä∂ÊÄÅÊ¶ÇËßà:\n",
      "  - Ê∂àÊÅØÊï∞Èáè: 6\n",
      "  - ÊòØÂê¶ÊúâÊëòË¶Å: Âê¶\n",
      "  - ÊâßË°åÊ≠•È™§: 7\n",
      "  - ÂàõÂª∫Êó∂Èó¥: 2025-11-14T03:53:17.855089+00:00\n",
      "\n",
      "üí¨ Ê∂àÊÅØÂéÜÂè≤:\n",
      "  1. üë§ Áî®Êà∑: ‰Ω†Â•ΩÔºÅÊàëÊòØLance\n",
      "  2. ü§ñ AI: ‰Ω†Â•ΩÔºåLanceÔºÅÂæàÈ´òÂÖ¥ËÆ§ËØÜ‰Ω†„ÄÇÊúâ‰ªÄ‰πàÊàëÂèØ‰ª•Â∏ÆÂä©‰Ω†ÁöÑÂêóÔºü\n",
      "  3. üë§ Áî®Êà∑: ÊàëÂè´‰ªÄ‰πàÂêçÂ≠óÔºü\n",
      "  4. ü§ñ AI: ‰Ω†ÂëäËØâÊàë‰Ω†ÁöÑÂêçÂ≠óÊòØLance„ÄÇ\n",
      "  5. üë§ Áî®Êà∑: ÊàëÂñúÊ¨¢YoYoMAÁöÑÂè§ÂÖ∏Èü≥‰πê\n",
      "  6. ü§ñ AI: Yo-Yo MaÊòØ‰∏Ä‰ΩçÈùûÂ∏∏Êù∞Âá∫ÁöÑÂ§ßÊèêÁê¥ÂÆ∂Ôºå‰ªñÁöÑÊºîÂ•èÊ∑±ÂèóËÆ∏Â§ö‰∫∫ÂñúÁà±„ÄÇ‰ªñ‰ª•ÂÖ∂‰∏∞ÂØåÁöÑÈü≥‰πêË°®ËææÂíåÊäÄÂ∑ßÈóªÂêç‰∫é‰∏ñ...\n",
      "\n",
      "‚úÖ Áä∂ÊÄÅÊåÅ‰πÖÂåñÈ™åËØÅÂÆåÊàê\n",
      "üíæ Áä∂ÊÄÅÂ∑≤ÊàêÂäü‰øùÂ≠òÂà∞SQLiteÊï∞ÊçÆÂ∫ì\n"
     ]
    }
   ],
   "source": [
    "# Ëé∑ÂèñÂΩìÂâçÂØπËØùÁä∂ÊÄÅ\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "graph_state = graph.get_state(config)\n",
    "\n",
    "print(\"üîç Ê£ÄÊü•‰øùÂ≠òÁöÑÂØπËØùÁä∂ÊÄÅ\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# ÊòæÁ§∫Áä∂ÊÄÅ‰ø°ÊÅØ\n",
    "print(f\"üìä Áä∂ÊÄÅÊ¶ÇËßà:\")\n",
    "print(f\"  - Ê∂àÊÅØÊï∞Èáè: {len(graph_state.values['messages'])}\")\n",
    "print(f\"  - ÊòØÂê¶ÊúâÊëòË¶Å: {'ÊòØ' if graph_state.values.get('summary') else 'Âê¶'}\")\n",
    "print(f\"  - ÊâßË°åÊ≠•È™§: {graph_state.metadata.get('step', 'N/A')}\")\n",
    "print(f\"  - ÂàõÂª∫Êó∂Èó¥: {graph_state.created_at}\")\n",
    "\n",
    "print(f\"\\nüí¨ Ê∂àÊÅØÂéÜÂè≤:\")\n",
    "for i, msg in enumerate(graph_state.values['messages'], 1):\n",
    "    msg_type = \"üë§ Áî®Êà∑\" if hasattr(msg, 'content') and isinstance(msg, HumanMessage) else \"ü§ñ AI\"\n",
    "    print(f\"  {i}. {msg_type}: {msg.content[:50]}{'...' if len(msg.content) > 50 else ''}\")\n",
    "\n",
    "if graph_state.values.get('summary'):\n",
    "    print(f\"\\nüìù ÂØπËØùÊëòË¶Å:\")\n",
    "    print(f\"  {graph_state.values['summary'][:100]}{'...' if len(graph_state.values['summary']) > 100 else ''}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Áä∂ÊÄÅÊåÅ‰πÖÂåñÈ™åËØÅÂÆåÊàê\")\n",
    "print(f\"üíæ Áä∂ÊÄÅÂ∑≤ÊàêÂäü‰øùÂ≠òÂà∞SQLiteÊï∞ÊçÆÂ∫ì\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e21152d-ed9c-408d-b7d5-f634c9ce81e2",
   "metadata": {
    "id": "1e21152d-ed9c-408d-b7d5-f634c9ce81e2"
   },
   "source": [
    "### Áä∂ÊÄÅÊåÅ‰πÖÂåñÈ™åËØÅ\n",
    "\n",
    "‰ΩøÁî®SQLiteÁ≠âÊï∞ÊçÆÂ∫ìÊÑèÂë≥ÁùÄÁä∂ÊÄÅÊòØÊåÅ‰πÖÂåñÁöÑÔºÅ\n",
    "\n",
    "## ÊåÅ‰πÖÂåñÁöÑ‰ºòÂäø\n",
    "\n",
    "### Êï∞ÊçÆÊåÅ‰πÖÊÄß\n",
    "- **Á®ãÂ∫èÈáçÂêØ**ÔºöÂç≥‰ΩøÈáçÂêØPythonÂÜÖÊ†∏ÔºåÊï∞ÊçÆ‰ªçÁÑ∂‰øùÂ≠ò\n",
    "- **‰ºöËØùÊÅ¢Â§ç**ÔºöÂèØ‰ª•ÊÅ¢Â§ç‰πãÂâçÁöÑÂØπËØùÁä∂ÊÄÅ\n",
    "- **Â§öÂÆû‰æãÊîØÊåÅ**ÔºöÂ§ö‰∏™Â∫îÁî®ÂÆû‰æãÂèØ‰ª•ÂÖ±‰∫´Âêå‰∏ÄÊï∞ÊçÆÂ∫ì\n",
    "\n",
    "### ÂÆûÈôÖÂ∫îÁî®Âú∫ÊôØ\n",
    "1. **WebÂ∫îÁî®**ÔºöÁî®Êà∑ÂÖ≥Èó≠ÊµèËßàÂô®ÂêéÈáçÊñ∞ÊâìÂºÄÔºåÂØπËØùÁªßÁª≠\n",
    "2. **APIÊúçÂä°**ÔºöÊúçÂä°ÈáçÂêØÂêéÔºåÁî®Êà∑‰ºöËØù‰∏ç‰ºö‰∏¢Â§±\n",
    "3. **Â§öÁî®Êà∑Á≥ªÁªü**Ôºö‰∏çÂêåÁî®Êà∑Êã•ÊúâÁã¨Á´ãÁöÑÂØπËØùÁ∫øÁ®ã\n",
    "4. **Êï∞ÊçÆÂàÜÊûê**ÔºöÂèØ‰ª•ÂàÜÊûêÂéÜÂè≤ÂØπËØùÊï∞ÊçÆ\n",
    "\n",
    "## ÊµãËØïÊåÅ‰πÖÂåñÂäüËÉΩ\n",
    "\n",
    "ËÆ©Êàë‰ª¨È™åËØÅÁä∂ÊÄÅÁ°ÆÂÆûË¢´ÊåÅ‰πÖÂåñ‰øùÂ≠ò‰∫Ü„ÄÇÂç≥‰ΩøÈáçÊñ∞Ëé∑ÂèñÁä∂ÊÄÅÔºåÊï∞ÊçÆ‰ªçÁÑ∂Â≠òÂú®„ÄÇ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9a44dc5-be04-45fa-a6fc-27b0f8ee4678",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b9a44dc5-be04-45fa-a6fc-27b0f8ee4678",
    "outputId": "09f0a6ba-bea1-4991-dd7d-68a0ac771fc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ ÈáçÊñ∞Ëé∑ÂèñÁä∂ÊÄÅÔºåÈ™åËØÅÊåÅ‰πÖÂåñ\n",
      "==================================================\n",
      "üìä Áä∂ÊÄÅÊÅ¢Â§çÈ™åËØÅ:\n",
      "  - Ê∂àÊÅØÊï∞Èáè: 6\n",
      "  - ÊòØÂê¶ÊúâÊëòË¶Å: Âê¶\n",
      "  - Áä∂ÊÄÅÂÆåÊï¥ÊÄß: ‚úÖ ÂÆåÊï¥\n",
      "\n",
      "üíæ ÊåÅ‰πÖÂåñÁä∂ÊÄÅ:\n",
      "  - Êï∞ÊçÆÂ∫ìÊñá‰ª∂: state_db/example.db\n",
      "  - Á∫øÁ®ãID: 1\n",
      "  - Ê£ÄÊü•ÁÇπID: N/A\n",
      "\n",
      "üéâ ÊåÅ‰πÖÂåñÈ™åËØÅÊàêÂäüÔºÅ\n",
      "‚ú® Áä∂ÊÄÅÂ∑≤ÊàêÂäü‰øùÂ≠òÂà∞SQLiteÊï∞ÊçÆÂ∫ìÔºåÂèØ‰ª•Ë∑®‰ºöËØùÊÅ¢Â§ç\n"
     ]
    }
   ],
   "source": [
    "# ÈáçÊñ∞Ëé∑ÂèñÁä∂ÊÄÅÔºåÈ™åËØÅÊåÅ‰πÖÂåñ\n",
    "# Âç≥‰ΩøÈáçÊñ∞ÂàõÂª∫ÈÖçÁΩÆÂØπË±°ÔºåÁä∂ÊÄÅ‰ªçÁÑ∂ÂèØ‰ª•‰ªéÊï∞ÊçÆÂ∫ìÊÅ¢Â§ç\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "graph_state = graph.get_state(config)\n",
    "\n",
    "print(\"üîÑ ÈáçÊñ∞Ëé∑ÂèñÁä∂ÊÄÅÔºåÈ™åËØÅÊåÅ‰πÖÂåñ\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# È™åËØÅÁä∂ÊÄÅÊòØÂê¶ÂÆåÊï¥ÊÅ¢Â§ç\n",
    "print(f\"üìä Áä∂ÊÄÅÊÅ¢Â§çÈ™åËØÅ:\")\n",
    "print(f\"  - Ê∂àÊÅØÊï∞Èáè: {len(graph_state.values['messages'])}\")\n",
    "print(f\"  - ÊòØÂê¶ÊúâÊëòË¶Å: {'ÊòØ' if graph_state.values.get('summary') else 'Âê¶'}\")\n",
    "print(f\"  - Áä∂ÊÄÅÂÆåÊï¥ÊÄß: {'‚úÖ ÂÆåÊï¥' if graph_state.values else '‚ùå ‰∏çÂÆåÊï¥'}\")\n",
    "\n",
    "print(f\"\\nüíæ ÊåÅ‰πÖÂåñÁä∂ÊÄÅ:\")\n",
    "print(f\"  - Êï∞ÊçÆÂ∫ìÊñá‰ª∂: {db_path}\")\n",
    "print(f\"  - Á∫øÁ®ãID: {config['configurable']['thread_id']}\")\n",
    "print(f\"  - Ê£ÄÊü•ÁÇπID: {graph_state.config.get('checkpoint_id', 'N/A')}\")\n",
    "\n",
    "print(f\"\\nüéâ ÊåÅ‰πÖÂåñÈ™åËØÅÊàêÂäüÔºÅ\")\n",
    "print(f\"‚ú® Áä∂ÊÄÅÂ∑≤ÊàêÂäü‰øùÂ≠òÂà∞SQLiteÊï∞ÊçÆÂ∫ìÔºåÂèØ‰ª•Ë∑®‰ºöËØùÊÅ¢Â§ç\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b89d33",
   "metadata": {
    "id": "53b89d33"
   },
   "source": [
    "## Â≠¶‰π†ÊÄªÁªì\n",
    "\n",
    "ÊÅ≠ÂñúÔºÅ‰Ω†Â∑≤ÁªèÊàêÂäüÂ≠¶‰π†‰∫ÜÂ¶Ç‰Ωï‰ΩøÁî®Â§ñÈÉ®Êï∞ÊçÆÂ∫ìÂÆûÁé∞ËÅäÂ§©Êú∫Âô®‰∫∫ÁöÑÊåÅ‰πÖÂåñÂÜÖÂ≠ò„ÄÇ\n",
    "\n",
    "### üéØ Ê†∏ÂøÉÁü•ËØÜÁÇπ\n",
    "\n",
    "#### 1. Ê£ÄÊü•ÁÇπÂô®ÔºàCheckpointerÔºâ\n",
    "- **‰ΩúÁî®**ÔºöÁÆ°ÁêÜÂõæÁä∂ÊÄÅÁöÑ‰øùÂ≠òÂíåÊÅ¢Â§ç\n",
    "- **Á±ªÂûã**ÔºöÂÜÖÂ≠òÊ£ÄÊü•ÁÇπÂô® vs Êï∞ÊçÆÂ∫ìÊ£ÄÊü•ÁÇπÂô®\n",
    "- **‰ºòÂäø**ÔºöÊîØÊåÅÁä∂ÊÄÅÊåÅ‰πÖÂåñ„ÄÅÂ§öÁ∫øÁ®ãËÆøÈóÆ„ÄÅ‰ºöËØùÊÅ¢Â§ç\n",
    "\n",
    "#### 2. SQLiteÊï∞ÊçÆÂ∫ì\n",
    "- **ÁâπÁÇπ**ÔºöËΩªÈáèÁ∫ß„ÄÅÈõ∂ÈÖçÁΩÆ„ÄÅË∑®Âπ≥Âè∞\n",
    "- **Â∫îÁî®**ÔºöÈÄÇÂêà‰∏≠Â∞èÂûãÂ∫îÁî®ÁöÑÊåÅ‰πÖÂåñÂ≠òÂÇ®\n",
    "- **ÈõÜÊàê**Ôºö‰∏éLangGraphÊó†ÁºùÈõÜÊàê\n",
    "\n",
    "#### 3. Áä∂ÊÄÅÁÆ°ÁêÜ\n",
    "- **Ê∂àÊÅØÂéÜÂè≤**ÔºöÂ≠òÂÇ®ÂÆåÊï¥ÁöÑÂØπËØùËÆ∞ÂΩï\n",
    "- **ÊëòË¶ÅÊú∫Âà∂**ÔºöËá™Âä®ÁîüÊàêÂØπËØùÊëòË¶ÅÔºåËäÇÁúÅÂ≠òÂÇ®Á©∫Èó¥\n",
    "- **Êô∫ËÉΩË∑ØÁî±**ÔºöÊ†πÊçÆÂØπËØùÈïøÂ∫¶ÂÜ≥ÂÆöÊòØÂê¶ËøõË°åÊëòË¶Å\n",
    "\n",
    "#### 4. ÂõæÊû∂ÊûÑËÆæËÆ°\n",
    "- **ËäÇÁÇπ**ÔºöconversationÔºàÂØπËØùÔºâ„ÄÅsummarize_conversationÔºàÊëòË¶ÅÔºâ\n",
    "- **Ëæπ**ÔºöÊù°‰ª∂ËæπÂÆûÁé∞Êô∫ËÉΩË∑ØÁî±\n",
    "- **Áä∂ÊÄÅ**ÔºöÁªßÊâøMessagesStateÔºåÊ∑ªÂä†summaryÂ≠óÊÆµ\n",
    "\n",
    "### üõ†Ô∏è ÂÆûË∑µÊäÄËÉΩ\n",
    "\n",
    "#### ‰ª£Á†ÅÂÆûÁé∞\n",
    "- ‚úÖ ÂàõÂª∫SQLiteÊï∞ÊçÆÂ∫ìËøûÊé•\n",
    "- ‚úÖ ÈÖçÁΩÆÊ£ÄÊü•ÁÇπÂô®\n",
    "- ‚úÖ ËÆæËÆ°Áä∂ÊÄÅÁ±ª\n",
    "- ‚úÖ ÂÆûÁé∞ËäÇÁÇπÂáΩÊï∞\n",
    "- ‚úÖ ÊûÑÂª∫Êù°‰ª∂Ëæπ\n",
    "- ‚úÖ ÁºñËØëÂõæÂπ∂ÈõÜÊàêÊ£ÄÊü•ÁÇπÂô®\n",
    "\n",
    "#### ÊµãËØïÈ™åËØÅ\n",
    "- ‚úÖ Â§öËΩÆÂØπËØùÊµãËØï\n",
    "- ‚úÖ Áä∂ÊÄÅÊåÅ‰πÖÂåñÈ™åËØÅ\n",
    "- ‚úÖ ËÆ∞ÂøÜËÉΩÂäõÊµãËØï\n",
    "- ‚úÖ ÊëòË¶ÅÂäüËÉΩÊµãËØï\n",
    "\n",
    "\n",
    "#### Áõ∏ÂÖ≥ËµÑÊ∫ê\n",
    "- [LangGraphÂÆòÊñπÊñáÊ°£](https://langchain-ai.github.io/langgraph/)\n",
    "- [SQLiteÊ£ÄÊü•ÁÇπÂô®ÊñáÊ°£](https://langchain-ai.github.io/langgraph/concepts/low_level/#checkpointer)\n",
    "- [PostgreSQLÊ£ÄÊü•ÁÇπÂô®](https://langchain-ai.github.io/langgraph/how-tos/persistence_postgres/)\n",
    "\n",
    "### üí° ÂÖ≥ÈîÆÊî∂Ëé∑\n",
    "\n",
    "1. **ÊåÅ‰πÖÂåñÁöÑÈáçË¶ÅÊÄß**ÔºöÁîü‰∫ßÁéØÂ¢ÉÂøÖÈ°ªËÄÉËôëÊï∞ÊçÆÊåÅ‰πÖÂåñ\n",
    "2. **Áä∂ÊÄÅÁÆ°ÁêÜ**ÔºöÂêàÁêÜËÆæËÆ°Áä∂ÊÄÅÁªìÊûÑÔºåÂπ≥Ë°°ÊÄßËÉΩÂíåÂäüËÉΩ\n",
    "3. **Ê®°ÂùóÂåñËÆæËÆ°**ÔºöÂ∞ÜÂ§çÊùÇÂäüËÉΩÂàÜËß£‰∏∫Áã¨Á´ãÁöÑËäÇÁÇπ\n",
    "4. **ÊµãËØïÈ©±Âä®**ÔºöÈÄöËøáÊµãËØïÈ™åËØÅÂäüËÉΩÁöÑÊ≠£Á°ÆÊÄß\n",
    "\n",
    "### üéâ ÊÅ≠ÂñúÂÆåÊàêÔºÅ\n",
    "\n",
    "‰Ω†Â∑≤ÁªèÊéåÊè°‰∫ÜLangGraph‰∏≠ÁöÑÂü∫Á°ÄÂäüËÉΩÔºöËäÇÁÇπ„ÄÅËæπ„ÄÅÁä∂ÊÄÅ„ÄÅË∑ØÁî±ÔºåÁü≠ÊúüËÆ∞ÂøÜÂíåÈïøÊúüËÆ∞ÂøÜ„ÄÇ\n",
    "\n",
    "ÁªßÁª≠Êé¢Á¥¢‰∏ã‰∏Ä‰∏™Ê®°ÂùóÔºåÂ≠¶‰π†Êõ¥Â§öÈ´òÁ∫ßÂäüËÉΩÔºÅ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd13de06-fc5a-41f5-82b8-728828630dbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (agent101)",
   "language": "python",
   "name": "agent101"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
