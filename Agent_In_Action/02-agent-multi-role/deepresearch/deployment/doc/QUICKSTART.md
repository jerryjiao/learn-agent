# å¿«é€Ÿå¯åŠ¨æŒ‡å—

è¿™æ˜¯æ·±åº¦ç ”ç©¶åŠ©æ‰‹çš„å¿«é€Ÿéƒ¨ç½²å’Œä½¿ç”¨æŒ‡å—ï¼Œ5åˆ†é’Ÿå†…å³å¯å®Œæˆéƒ¨ç½²ã€‚

## ğŸ“‹ å‰ç½®è¦æ±‚

- âœ… Docker å’Œ Docker Compose
- âœ… Python 3.11+
- âœ… LangGraph CLI
- âœ… OpenAI API å¯†é’¥

## ğŸš€ å¿«é€Ÿéƒ¨ç½²ï¼ˆ5æ­¥ï¼‰

### ç¬¬1æ­¥ï¼šå®‰è£… LangGraph CLI

```bash
pip install langgraph-cli==0.4.2
```

### ç¬¬2æ­¥ï¼šé…ç½®ç¯å¢ƒå˜é‡

```bash
# å¤åˆ¶ç¯å¢ƒå˜é‡æ¨¡æ¿
cp .env-example .env

# ç¼–è¾‘ .env æ–‡ä»¶ï¼Œå¡«å…¥ä½ çš„ API å¯†é’¥
# å¿…éœ€ï¼šOPENAI_API_KEY
# å¯é€‰ï¼šTAVILY_API_KEY, LANGSMITH_API_KEY
```

### ç¬¬3æ­¥ï¼šæ„å»º Docker é•œåƒ

```bash
# åœ¨ deployment ç›®å½•ä¸‹æ‰§è¡Œ
langgraph build -t research-assistant-image
```

> ğŸ’¡ æç¤ºï¼šé¦–æ¬¡æ„å»ºå¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ

### ç¬¬4æ­¥ï¼šå¯åŠ¨æœåŠ¡

```bash
docker compose --env-file .env up -d
```

ç­‰å¾…æœåŠ¡å¯åŠ¨ï¼ˆçº¦30ç§’ï¼‰ï¼Œä½ ä¼šçœ‹åˆ°ä¸‰ä¸ªå®¹å™¨ï¼š
- âœ… langgraph-redis (ç«¯å£ 6380)
- âœ… langgraph-postgres (ç«¯å£ 5433)
- âœ… langgraph-api (ç«¯å£ 8124)

### ç¬¬5æ­¥ï¼šéªŒè¯éƒ¨ç½²

```bash
# æ–¹æ³•1ï¼šè®¿é—®APIæ–‡æ¡£
# æµè§ˆå™¨æ‰“å¼€: http://localhost:8124/docs

# æ–¹æ³•2ï¼šè¿è¡Œæµ‹è¯•è„šæœ¬
python test_connection.py
```

## ğŸ¯ åŸºæœ¬ä½¿ç”¨

### æ–¹å¼1ï¼šä½¿ç”¨ Python SDK

```python
from langgraph_sdk import get_client

# è¿æ¥åˆ°æœåŠ¡
client = get_client(url="http://localhost:8124")

# åˆ›å»ºçº¿ç¨‹
thread = await client.threads.create()

# å¯åŠ¨ç ”ç©¶
async for event in client.runs.stream(
    thread["thread_id"],
    "research_assistant",
    input={
        "topic": "äººå·¥æ™ºèƒ½åœ¨åŒ»ç–—é¢†åŸŸçš„åº”ç”¨",
        "max_analysts": 3
    },
    stream_mode="values"
):
    if "final_report" in event:
        print(event["final_report"])
```

### æ–¹å¼2ï¼šä½¿ç”¨ Remote Graph

```python
from langgraph.pregel.remote import RemoteGraph

# åˆ›å»ºè¿œç¨‹å›¾å®ä¾‹
remote_graph = RemoteGraph(
    "research_assistant", 
    url="http://localhost:8124"
)

# æ‰§è¡Œç ”ç©¶
result = await remote_graph.ainvoke({
    "topic": "åŒºå—é“¾æŠ€æœ¯çš„å‘å±•è¶‹åŠ¿",
    "max_analysts": 3
})

print(result["final_report"])
```

### æ–¹å¼3ï¼šä½¿ç”¨ LangGraph Studio

åœ¨æµè§ˆå™¨ä¸­è®¿é—®ï¼š
```
https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:8124
```

## ğŸ“Š é…ç½®å‚æ•°

åœ¨è°ƒç”¨æ—¶å¯ä»¥é€šè¿‡ `config` å‚æ•°é…ç½®ï¼š

```python
config = {
    "configurable": {
        "topic": "ç ”ç©¶ä¸»é¢˜",           # ç ”ç©¶çš„ä¸»é¢˜
        "max_analysts": 3,             # åˆ†æå¸ˆæ•°é‡ï¼ˆå»ºè®®2-5ï¼‰
        "max_interview_turns": 2,      # è®¿è°ˆè½®æ¬¡ï¼ˆå»ºè®®2-3ï¼‰
        "enable_human_feedback": True  # æ˜¯å¦å¯ç”¨äººæœºååŒ
    }
}
```

## ğŸ”§ å¸¸ç”¨å‘½ä»¤

### æŸ¥çœ‹æœåŠ¡çŠ¶æ€
```bash
docker compose ps
```

### æŸ¥çœ‹æ—¥å¿—
```bash
docker compose logs -f langgraph-api
```

### é‡å¯æœåŠ¡
```bash
docker compose restart
```

### åœæ­¢æœåŠ¡
```bash
docker compose down
```

### æ¸…ç†æ•°æ®
```bash
docker compose down -v
```

## ğŸ› å¸¸è§é—®é¢˜

### Q1: ç«¯å£è¢«å ç”¨

**é”™è¯¯**: `Error starting userland proxy: listen tcp4 0.0.0.0:8124: bind: address already in use`

**è§£å†³**: ä¿®æ”¹ `docker-compose.yml` ä¸­çš„ç«¯å£æ˜ å°„
```yaml
ports:
    - "8125:8000"  # å°† 8124 æ”¹ä¸ºå…¶ä»–ç«¯å£
```

### Q2: API å¯†é’¥é”™è¯¯

**é”™è¯¯**: `AuthenticationError: Invalid API key`

**è§£å†³**: æ£€æŸ¥ `.env` æ–‡ä»¶ä¸­çš„ API å¯†é’¥æ˜¯å¦æ­£ç¡®

### Q3: æ„å»ºå¤±è´¥

**é”™è¯¯**: `Error building image`

**è§£å†³**: æ¸…ç† Docker ç¼“å­˜åé‡æ–°æ„å»º
```bash
docker system prune -a
langgraph build -t research-assistant-image
```

### Q4: è¿æ¥è¶…æ—¶

**é”™è¯¯**: `Connection timeout`

**è§£å†³**: 
1. æ£€æŸ¥æœåŠ¡æ˜¯å¦å¯åŠ¨ï¼š`docker compose ps`
2. æŸ¥çœ‹æ—¥å¿—ï¼š`docker compose logs -f`
3. å¢åŠ å¥åº·æ£€æŸ¥è¶…æ—¶æ—¶é—´

## ğŸ“š è¿›é˜¶ä½¿ç”¨

### äººæœºååŒæ¨¡å¼

```python
# 1. å¯åŠ¨ç ”ç©¶åˆ°åˆ†æå¸ˆç”Ÿæˆé˜¶æ®µ
async for event in client.runs.stream(...):
    if "analysts" in event:
        print("ç”Ÿæˆçš„åˆ†æå¸ˆï¼š", event["analysts"])
        break

# 2. æä¾›äººç±»åé¦ˆ
await client.threads.update_state(
    thread["thread_id"],
    {"human_analyst_feedback": "æ·»åŠ ä¸€ä½é‡‘èåˆ†æå¸ˆ"},
    as_node="human_feedback"
)

# 3. ç»§ç»­æ‰§è¡Œ
async for event in client.runs.stream(...):
    if "final_report" in event:
        print(event["final_report"])
```

### è‡ªå®šä¹‰æœç´¢æº

ç¼–è¾‘ `research_assistant.py`ï¼Œæ·»åŠ è‡ªå®šä¹‰æ£€ç´¢èŠ‚ç‚¹ï¼š

```python
def search_custom_source(state: InterviewState):
    """è‡ªå®šä¹‰æ£€ç´¢æº"""
    # å®ç°ä½ çš„æ£€ç´¢é€»è¾‘
    return {"context": [formatted_docs]}

# åœ¨ interview_builder ä¸­æ·»åŠ èŠ‚ç‚¹
interview_builder.add_node("search_custom", search_custom_source)
interview_builder.add_edge("ask_question", "search_custom")
```

## ğŸ“– å®Œæ•´æ–‡æ¡£

è¯¦ç»†æ–‡æ¡£è¯·å‚è€ƒï¼š
- [README.md](./README.md) - å®Œæ•´éƒ¨ç½²æ–‡æ¡£
- [LangGraph æ–‡æ¡£](https://langchain-ai.github.io/langgraph/)
- [LangGraph Platform](https://langchain-ai.github.io/langgraph/cloud/)

## ğŸ’¡ æç¤º

1. **é¦–æ¬¡ä½¿ç”¨å»ºè®®**ï¼šå…ˆè¿è¡Œ `test_connection.py` ç¡®ä¿éƒ¨ç½²æ­£å¸¸
2. **æ€§èƒ½ä¼˜åŒ–**ï¼šæ ¹æ® API é™åˆ¶è°ƒæ•´åˆ†æå¸ˆæ•°é‡å’Œè®¿è°ˆè½®æ¬¡
3. **æˆæœ¬æ§åˆ¶**ï¼šä½¿ç”¨ LangSmith ç›‘æ§ token æ¶ˆè€—
4. **è°ƒè¯•æŠ€å·§**ï¼šå¯ç”¨ `LANGSMITH_TRACING` æŸ¥çœ‹è¯¦ç»†æ‰§è¡Œè¿‡ç¨‹

## ğŸ†˜ è·å–å¸®åŠ©

å¦‚é‡é—®é¢˜ï¼š
1. æŸ¥çœ‹æ—¥å¿—ï¼š`docker compose logs -f`
2. è¿è¡Œæµ‹è¯•ï¼š`python test_connection.py`
3. å‚è€ƒå®Œæ•´æ–‡æ¡£ï¼š[README.md](./README.md)
4. æäº¤ Issue

---

ç¥ä½ ä½¿ç”¨æ„‰å¿«ï¼ğŸ‰

