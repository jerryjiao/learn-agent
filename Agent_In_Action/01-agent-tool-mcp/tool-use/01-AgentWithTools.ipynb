{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "826g9MUI5EFg"
   },
   "source": [
    "# 基于提示词的工具调用智能体（Prompt-Parsed Tool Agent）\n",
    "\n",
    "这是一个基于大语言模型（LLM）的智能体系统，演示了如何让AI智能体使用工具来执行具体任务。该系统展示了现代AI智能体的核心概念：**工具调用（Tool Calling）**。\n",
    "\n",
    "- 本 Notebook 演示“无函数调用 API”的方案：通过提示词约定输出格式，模型以 Markdown 代码块返回自定义 JSON：\n",
    "  ```action\n",
    "  {\n",
    "    \"tool_name\": \"...\",\n",
    "    \"args\": { ... }\n",
    "  }\n",
    "  ```\n",
    "  代码使用解析器提取并执行相应工具。\n",
    "\n",
    "#### 核心功能\n",
    "1. **智能体循环（Agent Loop）**：智能体能够持续思考和行动，直到完成任务\n",
    "2. **工具调用机制**：智能体可以调用预定义的工具（如文件操作）\n",
    "3. **结构化响应解析**：将LLM的自然语言响应解析为结构化的工具调用指令\n",
    "4. **记忆管理**：维护对话历史，让智能体能够基于之前的交互做出决策\n",
    "\n",
    "#### 技术架构\n",
    "- **LLM引擎**：使用OpenAI GPT-4o模型\n",
    "- **工具系统**：预定义的工具函数（list_files, read_file, terminate）\n",
    "- **解析器**：将LLM响应解析为JSON格式的工具调用\n",
    "- **循环控制**：防止无限循环的安全机制\n",
    "\n",
    "#### 工作机制\n",
    "- **提示约定**：在 `agent_rules` 明确要求“每次响应必须包含 action JSON 代码块”。\n",
    "- **响应解析**：使用 `extract_markdown_block` 提取 ```action ...``` 代码块，再由 `parse_action` 进行 `json.loads` 与结构校验。\n",
    "- **工具执行**：根据 `tool_name` 分派到本地工具（`list_files`、`read_file`、`terminate`）。\n",
    "- **错误自愈**：若解析失败或格式不符，向模型反馈错误信息写入记忆，促使其下轮自我修正直至给出合规 JSON。\n",
    "- **循环控制**：多轮对话在 `memory` 中累积思考与结果；遇到 `terminate` 则输出总结并结束。\n",
    "\n",
    "#### 适用场景\n",
    "- 使用不支持 Function Calling 的模型或代理层；\n",
    "- 需要完全自定义输出格式/协议；\n",
    "- 希望观察与教学“从错误到自我修正”的智能体行为。\n",
    "\n",
    "#### 学习目标\n",
    "- 掌握以提示工程约束模型输出并自定义解析器的方式；\n",
    "- 学会设计健壮的解析与错误反馈回路（容错重试、自我修正）；\n",
    "- 理解工具分派、状态记忆与终止条件的通用实现；\n",
    "- 对比原生 Function Calling 与提示解析两种路线的权衡。\n",
    "\n",
    "\n",
    "#### 学习价值\n",
    "这个示例非常适合我们来理解：\n",
    "- 智能体如何与外部工具交互\n",
    "- LLM如何生成结构化的工具调用指令\n",
    "- 如何构建一个完整的智能体工作流\n",
    "- 现代AI应用的基本架构模式\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KEYrzG2vB8Ip",
    "outputId": "717160c7-7cce-45b4-cd98-712136fead31"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple',\n",
       " 'Requirement already satisfied: openai==1.107.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (1.107.0)',\n",
       " 'Requirement already satisfied: anyio<5,>=3.5.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from openai==1.107.0) (4.11.0)',\n",
       " 'Requirement already satisfied: distro<2,>=1.7.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from openai==1.107.0) (1.9.0)',\n",
       " 'Requirement already satisfied: httpx<1,>=0.23.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from openai==1.107.0) (0.28.1)',\n",
       " 'Requirement already satisfied: jiter<1,>=0.4.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from openai==1.107.0) (0.11.0)',\n",
       " 'Requirement already satisfied: pydantic<3,>=1.9.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from openai==1.107.0) (2.11.9)',\n",
       " 'Requirement already satisfied: sniffio in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from openai==1.107.0) (1.3.1)',\n",
       " 'Requirement already satisfied: tqdm>4 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from openai==1.107.0) (4.67.1)',\n",
       " 'Requirement already satisfied: typing-extensions<5,>=4.11 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from openai==1.107.0) (4.14.1)',\n",
       " 'Requirement already satisfied: exceptiongroup>=1.0.2 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai==1.107.0) (1.3.0)',\n",
       " 'Requirement already satisfied: idna>=2.8 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai==1.107.0) (3.10)',\n",
       " 'Requirement already satisfied: certifi in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai==1.107.0) (2025.10.5)',\n",
       " 'Requirement already satisfied: httpcore==1.* in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai==1.107.0) (1.0.9)',\n",
       " 'Requirement already satisfied: h11>=0.16 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.107.0) (0.16.0)',\n",
       " 'Requirement already satisfied: annotated-types>=0.6.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai==1.107.0) (0.7.0)',\n",
       " 'Requirement already satisfied: pydantic-core==2.33.2 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai==1.107.0) (2.33.2)',\n",
       " 'Requirement already satisfied: typing-inspection>=0.4.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai==1.107.0) (0.4.2)',\n",
       " \"\\x1b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\\x1b[0m\\x1b[33m\",\n",
       " '\\x1b[0m']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 安装必要的依赖包\n",
    "!!pip install openai==1.107.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3vX9MGgw6_Xk",
    "outputId": "33bc90b0-361b-4058-9fcd-40ed195f1a3a"
   },
   "outputs": [],
   "source": [
    "# 导入必要的模块\n",
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    \"\"\"\n",
    "    设置环境变量的辅助函数\n",
    "\n",
    "    参数:\n",
    "        var (str): 要设置的环境变量名称\n",
    "\n",
    "    功能:\n",
    "        - 检查环境变量是否已存在\n",
    "        - 如果不存在，则提示用户输入并设置\n",
    "    \"\"\"\n",
    "    if not os.environ.get(var):  # 检查环境变量是否已设置\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")  # 安全地获取用户输入\n",
    "\n",
    "# 设置 OpenAI API代理地址 (例如：https://api.apiyi.com/v1）\n",
    "# 设置 DeepSeek地址(例如：https://api.deepseek.com）\n",
    "_set_env(\"OPENAI_BASE_URL\")\n",
    "# 设置 OpenAI API 密钥\n",
    "# 这是使用 OpenAI / DeepSeek 等模型所必需的\n",
    "_set_env(\"OPENAI_API_KEY\")\n",
    "# 设置 大语言模型名称（gpt-4o / deepseek-chat）\n",
    "_set_env(\"MODEL_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'deepseek-chat'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 打印模型名称\n",
    "os.environ['MODEL_NAME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mwe2eeOQB0cC",
    "outputId": "5aa97079-b278-43f9-b555-fc00bd35761b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What would you like me to do?  当前目录有哪些文件\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent thinking...\n",
      "Agent response: <停下来逐步思考。用户询问当前目录中有哪些文件。我需要使用list_files工具来列出目录中的所有文件。这个工具不需要任何参数。>\n",
      "\n",
      "```action\n",
      "{\n",
      "    \"tool_name\": \"list_files\",\n",
      "    \"args\": {}\n",
      "}\n",
      "```\n",
      "Action result: {'result': ['.ipynb_checkpoints', '02-AgentLoopWithFunctionCalling.ipynb', '01-AgentWithTools.ipynb']}\n",
      "Agent thinking...\n",
      "Agent response: <停下来逐步思考。用户之前询问了当前目录中的文件，我已经列出了它们。现在用户提供了文件列表的结果，但没有提出新的问题或请求。由于任务已经完成（列出了文件），我应该使用terminate工具结束对话，并提供一个摘要消息。>\n",
      "\n",
      "```action\n",
      "{\n",
      "    \"tool_name\": \"terminate\",\n",
      "    \"args\": {\n",
      "        \"message\": \"当前目录中的文件已列出：.ipynb_checkpoints、02-AgentLoopWithFunctionCalling.ipynb 和 01-AgentWithTools.ipynb。\"\n",
      "    }\n",
      "}\n",
      "```\n",
      "当前目录中的文件已列出：.ipynb_checkpoints、02-AgentLoopWithFunctionCalling.ipynb 和 01-AgentWithTools.ipynb。\n"
     ]
    }
   ],
   "source": [
    "# ===== 导入必要的库 =====\n",
    "import json  # 用于JSON数据处理\n",
    "import os    # 用于操作系统相关操作\n",
    "import sys   # 用于系统相关操作\n",
    "from typing import List, Dict   # 类型提示，提高代码可读性\n",
    "from openai import OpenAI       # 用于调用OpenAI API\n",
    "# ===== 核心工具函数定义 =====\n",
    "\n",
    "def extract_markdown_block(response: str, block_type: str = \"json\") -> str:\n",
    "    \"\"\"\n",
    "    从LLM响应中提取代码块内容\n",
    "\n",
    "    参数:\n",
    "        response: LLM的原始响应文本\n",
    "        block_type: 要提取的代码块类型，默认为\"json\"\n",
    "\n",
    "    返回:\n",
    "        提取出的代码块内容\n",
    "    \"\"\"\n",
    "    # 检查响应中是否包含代码块标记\n",
    "    if not '```' in response:\n",
    "        return response\n",
    "\n",
    "    # 分割响应并提取第一个代码块\n",
    "    code_block = response.split('```')[1].strip()\n",
    "\n",
    "    # 如果代码块以指定类型开头，则移除类型标识\n",
    "    if code_block.startswith(block_type):\n",
    "        code_block = code_block[len(block_type):].strip()\n",
    "\n",
    "    return code_block\n",
    "\n",
    "def generate_response(messages: List[Dict]) -> str:\n",
    "    \"\"\"\n",
    "    调用LLM生成响应\n",
    "\n",
    "    参数:\n",
    "        messages: 消息列表，包含系统提示和对话历史\n",
    "\n",
    "    返回:\n",
    "        LLM生成的响应文本\n",
    "    \"\"\"\n",
    "    # 使用LiteLLM调用OpenAI GPT-4o模型\n",
    "\n",
    "    client=OpenAI(\n",
    "        base_url=os.environ['OPENAI_BASE_URL'],\n",
    "        api_key=os.environ['OPENAI_API_KEY']\n",
    "    )\n",
    "    response = client.chat.completions.create(\n",
    "        model=os.environ['MODEL_NAME'],  # 指定使用的模型\n",
    "        messages=messages,      # 传入消息列表\n",
    "        max_tokens=1024         # 限制最大token数量\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "def parse_action(response: str) -> Dict:\n",
    "    \"\"\"\n",
    "    解析LLM响应，提取结构化的工具调用指令\n",
    "\n",
    "    参数:\n",
    "        response: LLM的响应文本\n",
    "\n",
    "    返回:\n",
    "        包含工具名称和参数的字典\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 从响应中提取action代码块\n",
    "        response = extract_markdown_block(response, \"action\")\n",
    "\n",
    "        # 将JSON字符串解析为Python字典\n",
    "        response_json = json.loads(response)\n",
    "\n",
    "        # 验证响应格式是否正确\n",
    "        if \"tool_name\" in response_json and \"args\" in response_json:\n",
    "            return response_json\n",
    "        else:\n",
    "            # 如果格式不正确，返回错误信息\n",
    "            return {\"tool_name\": \"error\", \"args\": {\"message\": \"You must respond with a JSON tool invocation.\"}}\n",
    "    except json.JSONDecodeError:\n",
    "        # 如果JSON解析失败，返回错误信息\n",
    "        return {\"tool_name\": \"error\", \"args\": {\"message\": \"Invalid JSON response. You must respond with a JSON tool invocation.\"}}\n",
    "\n",
    "# ===== 智能体可用的工具函数 =====\n",
    "\n",
    "def list_files() -> List[str]:\n",
    "    \"\"\"\n",
    "    列出当前目录中的所有文件\n",
    "\n",
    "    返回:\n",
    "        文件名列表\n",
    "    \"\"\"\n",
    "    return os.listdir(\".\")\n",
    "\n",
    "def read_file(file_name: str) -> str:\n",
    "    \"\"\"\n",
    "    读取指定文件的内容\n",
    "\n",
    "    参数:\n",
    "        file_name: 要读取的文件名\n",
    "\n",
    "    返回:\n",
    "        文件内容或错误信息\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_name, \"r\") as file:\n",
    "            return file.read()\n",
    "    except FileNotFoundError:\n",
    "        return f\"Error: {file_name} not found.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# ===== 智能体系统提示词定义 =====\n",
    "# 这个提示词定义了智能体的行为规则和可用工具\n",
    "agent_rules = [{\n",
    "    \"role\": \"system\",\n",
    "    \"content\": \"\"\"\n",
    "你是一个AI智能体，可以通过使用可用工具来执行任务。\n",
    "\n",
    "可用工具:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"list_files\": {\n",
    "        \"description\": \"列出当前目录中的所有文件。\",\n",
    "        \"parameters\": {}\n",
    "    },\n",
    "    \"read_file\": {\n",
    "        \"description\": \"读取文件的内容。\",\n",
    "        \"parameters\": {\n",
    "            \"file_name\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"要读取的文件名。\"\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"terminate\": {\n",
    "        \"description\": \"结束智能体循环并提供任务摘要。\",\n",
    "        \"parameters\": {\n",
    "            \"message\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"返回给用户的摘要消息。\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "如果用户询问文件、文档或内容，请先列出文件，然后再读取它们。\n",
    "\n",
    "当你完成任务后，使用\"terminate\"工具结束对话，我将向用户提供结果。\n",
    "\n",
    "重要！！！每个响应都必须包含一个动作。\n",
    "你必须始终按照以下格式响应：\n",
    "\n",
    "<停下来逐步思考。参数映射到args。在这里插入你逐步思考的丰富描述。>\n",
    "\n",
    "```action\n",
    "{\n",
    "    \"tool_name\": \"插入工具名称\",\n",
    "    \"args\": {...在这里填入任何必需的参数...}\n",
    "}```\n",
    "\"\"\"\n",
    "}]\n",
    "\n",
    "# ===== 智能体主循环初始化 =====\n",
    "iterations = 0        # 当前迭代次数\n",
    "max_iterations = 10   # 最大迭代次数，防止无限循环\n",
    "\n",
    "# 获取用户任务\n",
    "user_task = input(\"What would you like me to do? \")\n",
    "\n",
    "# 初始化对话记忆，包含用户的任务\n",
    "memory = [{\"role\": \"user\", \"content\": user_task}]\n",
    "\n",
    "# ===== 智能体主循环 =====\n",
    "# 这是智能体的核心工作循环，持续执行直到任务完成或达到最大迭代次数\n",
    "while iterations < max_iterations:\n",
    "    # 1. 构建提示：将智能体规则与对话记忆结合\n",
    "    prompt = agent_rules + memory\n",
    "\n",
    "    # 2. 调用LLM生成响应\n",
    "    print(\"Agent thinking...\")\n",
    "    response = generate_response(prompt)\n",
    "    print(f\"Agent response: {response}\")\n",
    "\n",
    "    # 3. 解析响应以确定要执行的动作\n",
    "    action = parse_action(response)\n",
    "    result = \"Action executed\"  # 默认结果\n",
    "\n",
    "    # 4. 根据解析出的动作执行相应的工具函数\n",
    "    if action[\"tool_name\"] == \"list_files\":\n",
    "        result = {\"result\": list_files()}\n",
    "    elif action[\"tool_name\"] == \"read_file\":\n",
    "        result = {\"result\": read_file(action[\"args\"][\"file_name\"])}\n",
    "    elif action[\"tool_name\"] == \"error\":\n",
    "        result = {\"error\": action[\"args\"][\"message\"]}\n",
    "    elif action[\"tool_name\"] == \"terminate\":\n",
    "        print(action[\"args\"][\"message\"])\n",
    "        break  # 终止循环\n",
    "    else:\n",
    "        result = {\"error\": \"Unknown action: \" + action[\"tool_name\"]}\n",
    "\n",
    "    print(f\"Action result: {result}\")\n",
    "\n",
    "    # 5. 更新对话记忆，添加智能体响应和执行结果\n",
    "    memory.extend([\n",
    "        {\"role\": \"assistant\", \"content\": response},\n",
    "        {\"role\": \"system\", \"content\": json.dumps(result)}\n",
    "    ])\n",
    "\n",
    "    # 6. 检查终止条件\n",
    "    if action[\"tool_name\"] == \"terminate\":\n",
    "        break\n",
    "\n",
    "    iterations += 1  # 增加迭代计数\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 运行结果分析\n",
    "\n",
    "从上面的运行结果可以看到，智能体成功完成了用户的任务：\"当前目录中有些文件\"。\n",
    "\n",
    "\n",
    "## 核心代码逻辑回顾\n",
    "\n",
    "### 1. 智能体循环架构\n",
    "```python\n",
    "while iterations < max_iterations:\n",
    "    # 1. 构建提示：将智能体规则与对话记忆结合\n",
    "    prompt = agent_rules + memory\n",
    "    \n",
    "    # 2. 调用LLM生成响应\n",
    "    response = generate_response(prompt)\n",
    "    \n",
    "    # 3. 解析响应以确定要执行的动作\n",
    "    action = parse_action(response)\n",
    "    \n",
    "    # 4. 根据解析出的动作执行相应的工具函数\n",
    "    # 5. 更新对话记忆\n",
    "    # 6. 检查终止条件\n",
    "```\n",
    "\n",
    "**关键特点**：\n",
    "- **记忆机制**：每次交互都会更新`memory`，让智能体记住之前的对话\n",
    "- **错误恢复**：当LLM输出格式错误时，系统会反馈错误信息，让智能体自我修正\n",
    "- **工具调用**：将自然语言响应解析为结构化的工具调用指令\n",
    "\n",
    "### 2. 工具调用机制\n",
    "```python\n",
    "def parse_action(response: str) -> Dict:\n",
    "    # 从响应中提取action代码块\n",
    "    response = extract_markdown_block(response, \"action\")\n",
    "    # 将JSON字符串解析为Python字典\n",
    "    response_json = json.loads(response)\n",
    "```\n",
    "\n",
    "**工作原理**：\n",
    "- LLM被要求输出特定格式的JSON代码块\n",
    "- 系统解析这个JSON，提取工具名称和参数\n",
    "- 根据工具名称调用相应的函数\n",
    "\n",
    "### 3. 错误处理机制\n",
    "从运行结果可以看到，智能体在6轮交互中出现了3次格式错误（第1、3、5轮），但系统通过以下机制实现了自我修正：\n",
    "\n",
    "1. **格式验证**：`parse_action`函数检查JSON格式是否正确\n",
    "2. **错误反馈**：将错误信息添加到对话记忆中\n",
    "3. **学习能力**：智能体从错误中学习，调整后续响应\n",
    "\n",
    "## 学习要点\n",
    "\n",
    "### 1. 智能体的\"思考\"过程\n",
    "- 智能体实际上是在每次循环中重新\"思考\"整个对话历史\n",
    "- 通过`memory`变量维护完整的对话上下文\n",
    "- 每次调用LLM时都会传入完整的对话历史\n",
    "\n",
    "### 2. 工具调用的实现方式\n",
    "- 不是使用函数调用（Function Calling），而是通过提示词工程\n",
    "- LLM被训练输出特定格式的JSON\n",
    "- 系统解析JSON后执行相应的工具函数\n",
    "\n",
    "### 3. 错误恢复能力\n",
    "- 智能体具备从错误中学习的能力\n",
    "- 通过错误反馈机制实现自我修正\n",
    "- 这体现了现代AI系统的鲁棒性\n",
    "\n",
    "### 4. 实际应用价值\n",
    "这种架构模式在现代AI应用中非常常见：\n",
    "- **RAG系统**：检索增强生成\n",
    "- **Agent框架**：如LangChain、LangGraph\n",
    "- **工具调用**：让AI能够操作外部系统\n",
    "\n",
    "通过这个简单的例子，我们可以看到智能体系统的核心工作原理，为学习更复杂的AI应用奠定了基础。"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (agent101)",
   "language": "python",
   "name": "agent101"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
