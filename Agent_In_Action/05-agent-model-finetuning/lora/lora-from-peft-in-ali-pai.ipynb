{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P5wPUmY-5kgH"
   },
   "source": [
    "# ğŸš€ ä½¿ç”¨ Hugging Face PEFT åº“å®ç° LoRA å¾®è°ƒ \n",
    "\n",
    "## ğŸ“– æ•™ç¨‹æ¦‚è¿°\n",
    "\n",
    "æœ¬æ•™ç¨‹å°†å±•ç¤ºå¦‚ä½•ä½¿ç”¨ **Hugging Face PEFTï¼ˆParameter-Efficient Fine-Tuningï¼‰** åº“å®ç° LoRA å¾®è°ƒï¼Œè¿™æ˜¯å·¥ä¸šç•Œæ¨èçš„æ ‡å‡†æ–¹æ³•ã€‚\n",
    "\n",
    "### ğŸ¯ ä¸ºä»€ä¹ˆä½¿ç”¨ PEFT åº“ï¼Ÿ\n",
    "\n",
    "#### âœ… PEFT åº“çš„ä¼˜åŠ¿\n",
    "\n",
    "1. **å·¥ä¸šçº§å®ç°**ï¼šç»è¿‡å¤§è§„æ¨¡éªŒè¯ï¼Œç¨³å®šå¯é \n",
    "2. **æ˜“äºä½¿ç”¨**ï¼šå‡ è¡Œä»£ç å³å¯åº”ç”¨ LoRA\n",
    "3. **åŠŸèƒ½ä¸°å¯Œ**ï¼šæ”¯æŒ LoRAã€LoHaã€LoKr ç­‰å¤šç§æ–¹æ³•\n",
    "4. **ç”Ÿæ€é›†æˆ**ï¼šä¸ Transformersã€Accelerate æ— ç¼é›†æˆ\n",
    "5. **æŒç»­ç»´æŠ¤**ï¼šHugging Face å®˜æ–¹æ”¯æŒ\n",
    "\n",
    "#### ğŸ“Š ä¸æ‰‹åŠ¨å®ç°çš„å¯¹æ¯”\n",
    "\n",
    "| ç‰¹æ€§ | æ‰‹åŠ¨å®ç° | PEFT åº“ |\n",
    "|------|---------|---------|\n",
    "| **ä»£ç é‡** | å¤šï¼ˆéœ€å®ç° LoRA å±‚ï¼Œçº¦ 200+ è¡Œï¼‰ | å°‘ï¼ˆå‡ è¡Œé…ç½®ï¼Œçº¦ 10 è¡Œï¼‰ |\n",
    "| **å­¦ä¹ ä»·å€¼** | â­â­â­â­â­ æ·±å…¥ç†è§£åŸç† | â­â­â­ å¿«é€Ÿåº”ç”¨å®è·µ |\n",
    "| **ç»´æŠ¤æˆæœ¬** | é«˜ï¼ˆéœ€è‡ªå·±ç»´æŠ¤å’Œè°ƒè¯•ï¼‰ | ä½ï¼ˆHugging Face å®˜æ–¹ç»´æŠ¤ï¼‰ |\n",
    "| **åŠŸèƒ½å®Œæ•´æ€§** | åŸºç¡€åŠŸèƒ½ï¼ˆä»… LoRAï¼‰ | ä¸°å¯ŒåŠŸèƒ½ï¼ˆLoRA/LoHa/LoKr/AdaLoRAï¼‰ |\n",
    "| **é”™è¯¯é£é™©** | è¾ƒé«˜ï¼ˆæ‰‹åŠ¨å®ç°æ˜“å‡ºé”™ï¼‰ | è¾ƒä½ï¼ˆç»è¿‡å……åˆ†æµ‹è¯•ï¼‰ |\n",
    "| **æ€§èƒ½ä¼˜åŒ–** | éœ€è‡ªè¡Œä¼˜åŒ– | å†…ç½®å¤šç§ä¼˜åŒ–ç­–ç•¥ |\n",
    "| **ç”Ÿæ€å…¼å®¹æ€§** | éœ€æ‰‹åŠ¨é€‚é… | ä¸ Transformers æ— ç¼é›†æˆ |\n",
    "| **æ¨èåœºæ™¯** | ğŸ“ å­¦ä¹ ç ”ç©¶ã€ç†è§£åŸç† | ğŸ­ ç”Ÿäº§ç¯å¢ƒã€å¿«é€Ÿå¼€å‘ |\n",
    "| **å¼€å‘å‘¨æœŸ** | 1-2 å¤© | 1-2 å°æ—¶ |\n",
    "\n",
    "### ğŸ“ å­¦ä¹ è·¯å¾„å»ºè®®\n",
    "\n",
    "1. **ç¬¬ä¸€æ­¥**ï¼šå­¦ä¹  PEFT åº“ï¼ˆæŒæ¡å·¥å…·ï¼‰\n",
    "2. **ç¬¬äºŒæ­¥**ï¼šå­¦ä¹ æ‰‹åŠ¨å®ç°ï¼ˆç†è§£åŸç†ï¼‰\n",
    "3. **ç¬¬ä¸‰æ­¥**ï¼šå®é™…é¡¹ç›®ä¸­ä½¿ç”¨ PEFT\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“¦ æ ¸å¿ƒä¾èµ–ç‰ˆæœ¬ï¼ˆæœ¬æ•™ç¨‹æµ‹è¯•é…ç½®ï¼‰\n",
    "\n",
    "### ğŸ¯ æ¨èé…ç½®ï¼ˆå·²éªŒè¯ç¨³å®šç‰ˆæœ¬ï¼‰\n",
    "\n",
    "| ä¾èµ–åŒ… | ç‰ˆæœ¬ | è¯´æ˜ |\n",
    "|--------|------|------|\n",
    "| **torch** | 2.8.0+ | PyTorch æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼ˆé˜¿é‡Œäº‘ PAI é¢„è£…ï¼‰ |\n",
    "| **transformers** | 4.57.1 | Hugging Face é¢„è®­ç»ƒæ¨¡å‹åº“ |\n",
    "| **peft** | 0.18.0 | å‚æ•°é«˜æ•ˆå¾®è°ƒåº“ï¼ˆæ ¸å¿ƒï¼‰ |\n",
    "| **accelerate** | 1.11.0 | åˆ†å¸ƒå¼è®­ç»ƒåŠ é€Ÿåº“ |\n",
    "| **pandas** | 2.3.3 | æ•°æ®å¤„ç† |\n",
    "| **numpy** | 1.26.4 | æ•°å€¼è®¡ç®— |\n",
    "| **tqdm** | 4.67.1 | è¿›åº¦æ¡æ˜¾ç¤º |\n",
    "| **matplotlib** | 3.10.7 | å¯è§†åŒ– |\n",
    "| **requests** | 2.32.5 | HTTP è¯·æ±‚ |\n",
    "| **safetensors** | 0.6.2 | æ¨¡å‹æƒé‡æ ¼å¼ |\n",
    "\n",
    "### ğŸ’¡ ç¯å¢ƒè¯´æ˜\n",
    "\n",
    "æœ¬æ•™ç¨‹æä¾›ä¸¤ç§è¿è¡Œç¯å¢ƒï¼š\n",
    "\n",
    "1. **é˜¿é‡Œäº‘ PAI-DSW**ï¼ˆæ¨èæ–°æ‰‹ï¼‰\n",
    "   - âœ… å¼€ç®±å³ç”¨ï¼Œæ— éœ€é…ç½® GPU ç¯å¢ƒ\n",
    "   - âœ… é¢„è£…æ·±åº¦å­¦ä¹ æ¡†æ¶\n",
    "   - âœ… åªéœ€å®‰è£…/å‡çº§å°‘é‡ä¾èµ–åŒ…\n",
    "   - ğŸ“ é•œåƒï¼š`modelscope:1.32.0-pytorch2.8.0-gpu-py311-cu124-ubuntu22.04`\n",
    "\n",
    "2. **ç§æœ‰ç¯å¢ƒéƒ¨ç½²**ï¼ˆé€‚åˆæœ‰ç»éªŒç”¨æˆ·ï¼‰\n",
    "   - âš™ï¸ éœ€è¦è‡ªè¡Œé…ç½® CUDAã€cuDNN ç¯å¢ƒ\n",
    "   - ğŸ“¦ éœ€è¦æ‰‹åŠ¨å®‰è£…æ‰€æœ‰ä¾èµ–\n",
    "   - ğŸ’ª æ›´çµæ´»ï¼Œå¯è‡ªå®šä¹‰é…ç½®\n",
    "   - ğŸ“‹ è¯¦ç»†è¦æ±‚è§ä¸‹ä¸€èŠ‚\n",
    "\n",
    "âš ï¸ **é‡è¦æç¤º**ï¼š\n",
    "- é˜¿é‡Œäº‘ PAI ç”¨æˆ·ï¼šè¯·å‹¿å‡çº§ PyTorchï¼ˆä¸ CUDA 12.4 è€¦åˆï¼‰\n",
    "- ç§æœ‰ç¯å¢ƒç”¨æˆ·ï¼šè¯·å…ˆå®‰è£… PyTorchï¼Œç„¶åå†å®‰è£…å…¶ä»–ä¾èµ–\n",
    "- æ‰€æœ‰ä¾èµ–ç‰ˆæœ¬å‡å·²åœ¨ A10 (24GB) GPU ä¸Šæµ‹è¯•é€šè¿‡\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-zxStQdi5kgI"
   },
   "source": [
    "# 1ï¸âƒ£ ç¯å¢ƒå‡†å¤‡å’Œä¾èµ–å®‰è£…\n",
    "\n",
    "## ğŸ–¥ï¸ è¿è¡Œç¯å¢ƒè¦æ±‚å¯¹æ¯”\n",
    "\n",
    "### ğŸ“Š ç¯å¢ƒé…ç½®å¯¹æ¯”è¡¨\n",
    "\n",
    "| é…ç½®é¡¹ | é˜¿é‡Œäº‘ PAI-DSW | ç§æœ‰ç¯å¢ƒéƒ¨ç½² |\n",
    "|--------|----------------|--------------|\n",
    "| **æ“ä½œç³»ç»Ÿ** | Ubuntu 22.04 | Ubuntu 20.04+ / CentOS 7+ / Windows 10+ |\n",
    "| **Python ç‰ˆæœ¬** | Python 3.11 | Python 3.9 - 3.11 |\n",
    "| **GPU å‹å·** | A10 (24GB) | NVIDIA GPUï¼ˆæ”¯æŒ CUDAï¼‰ |\n",
    "| **GPU æ˜¾å­˜** | 24GB | â‰¥ 16GBï¼ˆæ¨è 24GB+ï¼‰ |\n",
    "| **CUDA ç‰ˆæœ¬** | CUDA 12.4 | CUDA 11.8+ / CUDA 12.x |\n",
    "| **é¢„è£…é•œåƒ** | modelscope:1.32.0-pytorch2.8.0-gpu-py311-cu124-ubuntu22.04 | éœ€æ‰‹åŠ¨é…ç½®ç¯å¢ƒ |\n",
    "| **PyTorch ç‰ˆæœ¬** | 2.8.0ï¼ˆé¢„è£…ï¼‰ | 2.0.0+ |\n",
    "| **ç¯å¢ƒå‡†å¤‡** | âœ… å¼€ç®±å³ç”¨ | âš™ï¸ éœ€æ‰‹åŠ¨å®‰è£…ä¾èµ– |\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ’» ç§æœ‰ç¯å¢ƒéƒ¨ç½²è¯¦ç»†è¦æ±‚\n",
    "\n",
    "### ğŸ”§ ç¡¬ä»¶è¦æ±‚\n",
    "\n",
    "| ç»„ä»¶ | æœ€ä½é…ç½® | æ¨èé…ç½® | è¯´æ˜ |\n",
    "|------|---------|---------|------|\n",
    "| **GPU** | NVIDIA GTX 1080 Ti (11GB) | NVIDIA A10/A100/RTX 4090 (24GB+) | æ˜¾å­˜è¶Šå¤§ï¼Œå¯è®­ç»ƒçš„æ¨¡å‹è¶Šå¤§ |\n",
    "| **GPU æ˜¾å­˜** | 16GB | 24GB+ | æœ¬æ•™ç¨‹ä½¿ç”¨ BERT-base çº¦éœ€ 12GB |\n",
    "| **å†…å­˜ (RAM)** | 16GB | 32GB+ | æ•°æ®é¢„å¤„ç†å’Œæ¨¡å‹åŠ è½½éœ€è¦ |\n",
    "| **å­˜å‚¨ç©ºé—´** | 20GB | 50GB+ | æ¨¡å‹æƒé‡ã€æ•°æ®é›†ã€ç¼“å­˜ |\n",
    "| **CPU** | 4 æ ¸å¿ƒ | 8+ æ ¸å¿ƒ | æ•°æ®é¢„å¤„ç†å’Œæ¨¡å‹åŠ è½½ |\n",
    "\n",
    "### ğŸ§ è½¯ä»¶è¦æ±‚\n",
    "\n",
    "| è½¯ä»¶ | ç‰ˆæœ¬è¦æ±‚ | å®‰è£…è¯´æ˜ |\n",
    "|------|---------|---------|\n",
    "| **æ“ä½œç³»ç»Ÿ** | Ubuntu 20.04+<br>CentOS 7+<br>Windows 10+ | Linux æ¨èç”¨äºç”Ÿäº§ç¯å¢ƒ |\n",
    "| **Python** | 3.9 - 3.11 | æ¨èä½¿ç”¨ Anaconda/Miniconda |\n",
    "| **CUDA** | 11.8+ æˆ– 12.x | ä¸ GPU é©±åŠ¨ç‰ˆæœ¬åŒ¹é… |\n",
    "| **cuDNN** | 8.x+ | ä¸ CUDA ç‰ˆæœ¬åŒ¹é… |\n",
    "| **NVIDIA é©±åŠ¨** | 470.x+ | æ”¯æŒ CUDA 11.8+<br>525.x+ æ”¯æŒ CUDA 12.x |\n",
    "\n",
    "### ğŸ“¦ Python ä¾èµ–åŒ…è¦æ±‚\n",
    "\n",
    "#### æ ¸å¿ƒæ¡†æ¶\n",
    "\n",
    "```bash\n",
    "# PyTorchï¼ˆæ ¹æ® CUDA ç‰ˆæœ¬é€‰æ‹©ï¼‰\n",
    "# CUDA 11.8\n",
    "pip install torch==2.0.0 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "# CUDA 12.1\n",
    "pip install torch==2.1.0 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "```\n",
    "\n",
    "#### å¿…éœ€ä¾èµ–ï¼ˆæœ¬æ•™ç¨‹æµ‹è¯•ç‰ˆæœ¬ï¼‰\n",
    "\n",
    "```bash\n",
    "pip install \\\n",
    "    transformers==4.57.1 \\\n",
    "    peft==0.18.0 \\\n",
    "    accelerate==1.11.0 \\\n",
    "    pandas==2.3.3 \\\n",
    "    numpy==1.26.4 \\\n",
    "    tqdm==4.67.1 \\\n",
    "    matplotlib==3.10.7 \\\n",
    "    requests==2.32.5 \\\n",
    "    safetensors==0.6.2\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“¦ é˜¿é‡Œäº‘ PAI-DSW ä¾èµ–è¯´æ˜\n",
    "\n",
    "é˜¿é‡Œäº‘ PAI-DSW å·²é¢„è£…å¤§éƒ¨åˆ†æ·±åº¦å­¦ä¹ ä¾èµ–ï¼Œæˆ‘ä»¬åªéœ€è¦å®‰è£…/å‡çº§éƒ¨åˆ†å…³é”®åŒ…ã€‚\n",
    "\n",
    "### ğŸ” é˜¿é‡Œäº‘ PAI é¢„è£…ç¯å¢ƒï¼ˆæ— éœ€å®‰è£…ï¼‰\n",
    "\n",
    "| åŒ…å | é¢„è£…ç‰ˆæœ¬ | è¯´æ˜ |\n",
    "|------|---------|------|\n",
    "| **torch** | 2.8.0+cu124 | âš ï¸ è¯·å‹¿å‡çº§ï¼ˆä¸ CUDA 12.4 ç´§å¯†è€¦åˆï¼‰ |\n",
    "| **transformers** | 4.45.0+ | å¯å‡çº§åˆ° 4.57.1 |\n",
    "| **pandas** | 2.2.2+ | å¯å‡çº§åˆ° 2.3.3 |\n",
    "| **numpy** | 1.26.3+ | å¯å‡çº§åˆ° 1.26.4 |\n",
    "| **tqdm** | 4.66.4+ | å¯å‡çº§åˆ° 4.67.1 |\n",
    "| **matplotlib** | 3.9.0+ | å¯å‡çº§åˆ° 3.10.7 |\n",
    "| **requests** | 2.32.3+ | å¯å‡çº§åˆ° 2.32.5 |\n",
    "| **safetensors** | 0.4.3+ | å¯å‡çº§åˆ° 0.6.2 |\n",
    "\n",
    "### ğŸ”§ éœ€è¦å®‰è£…/å‡çº§çš„åŒ…\n",
    "\n",
    "| åŒ…å | ç›®æ ‡ç‰ˆæœ¬ | è¯´æ˜ |\n",
    "|------|---------|------|\n",
    "| **peft** | 0.18.0 | âœ… éœ€å®‰è£…/å‡çº§ï¼ˆæ ¸å¿ƒåº“ï¼‰ |\n",
    "| **accelerate** | 1.11.0 | âœ… éœ€å®‰è£…/å‡çº§ |\n",
    "| **transformers** | 4.57.1 | â¬†ï¸ å‡çº§åˆ°æœ€æ–°ç¨³å®šç‰ˆ |\n",
    "| **å…¶ä»–ä¾èµ–** | è§ä¸Šè¡¨ | â¬†ï¸ å¯é€‰å‡çº§åˆ°ç»Ÿä¸€ç‰ˆæœ¬ |\n",
    "\n",
    "ğŸ’¡ **é˜¿é‡Œäº‘ PAI æ³¨æ„äº‹é¡¹**ï¼š\n",
    "- âš ï¸ **ä¸è¦å‡çº§ PyTorch**ï¼šPAI ç¯å¢ƒçš„ torch ä¸ CUDA ç´§å¯†è€¦åˆï¼Œå‡çº§å¯èƒ½å¯¼è‡´ç¯å¢ƒæŸå\n",
    "- âœ… å¯ä»¥å®‰å…¨å‡çº§ transformersã€peftã€accelerate ç­‰çº¯ Python åŒ…\n",
    "- ğŸ”„ å¦‚æœé‡åˆ°ä¾èµ–å†²çªï¼Œä¼˜å…ˆä¿æŒ PAI é¢„è£…ç‰ˆæœ¬ç¨³å®šæ€§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-04T23:43:28.110014Z",
     "iopub.status.busy": "2025-12-04T23:43:28.109879Z",
     "iopub.status.idle": "2025-12-04T23:43:33.075266Z",
     "shell.execute_reply": "2025-12-04T23:43:33.074706Z",
     "shell.execute_reply.started": "2025-12-04T23:43:28.109998Z"
    },
    "id": "BzbG7r5Z5kgJ",
    "outputId": "3b8ac9a6-2ddc-4295-cf12-9fe2bedb36c4",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/site-packages (4.57.1)\n",
      "Requirement already satisfied: peft in /usr/local/lib/python3.11/site-packages (0.18.0)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/site-packages (1.11.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/site-packages (1.26.4)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/site-packages (4.67.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/site-packages (3.10.7)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/site-packages (2.32.5)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/site-packages (0.6.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/site-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/site-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.11/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/site-packages (from peft) (7.1.3)\n",
      "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/site-packages (from peft) (2.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /usr/local/lib/python3.11/site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests) (2025.11.12)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/site-packages (from torch>=1.13.0->peft) (1.14.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/site-packages (from torch>=1.13.0->peft) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/site-packages (from torch>=1.13.0->peft) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.11/site-packages (from torch>=1.13.0->peft) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.11/site-packages (from torch>=1.13.0->peft) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.11/site-packages (from torch>=1.13.0->peft) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.11/site-packages (from torch>=1.13.0->peft) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.11/site-packages (from torch>=1.13.0->peft) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.11/site-packages (from torch>=1.13.0->peft) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.11/site-packages (from torch>=1.13.0->peft) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.11/site-packages (from torch>=1.13.0->peft) (3.4.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/site-packages (from triton==3.4.0->torch>=1.13.0->peft) (65.5.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/site-packages (from jinja2->torch>=1.13.0->peft) (3.0.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "âœ… ä¾èµ–åŒ…å®‰è£…å®Œæˆï¼\n",
      "ğŸ’¡ é˜¿é‡Œäº‘ PAI-DSW å·²é¢„è£… PyTorchã€Transformers ç­‰ï¼Œæ— éœ€é‡å¤å®‰è£…\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“¦ ä¾èµ–å®‰è£…ï¼ˆç»Ÿä¸€å®‰è£…è„šæœ¬ï¼‰\n",
    "# \n",
    "# ä½¿ç”¨è¯´æ˜ï¼š\n",
    "# â˜ï¸ é˜¿é‡Œäº‘ PAI-DSW ç”¨æˆ·ï¼šç›´æ¥è¿è¡Œå³å¯ï¼Œä¼šè‡ªåŠ¨å‡çº§åˆ°æŒ‡å®šç‰ˆæœ¬\n",
    "# ğŸ’» ç§æœ‰ç¯å¢ƒç”¨æˆ·ï¼šè¿è¡Œå‰è¯·ç¡®ä¿å·²å®‰è£… PyTorchï¼ˆè§ä¸Šæ–¹\"ç§æœ‰ç¯å¢ƒéƒ¨ç½²è¯¦ç»†è¦æ±‚\"ï¼‰\n",
    "# \n",
    "# âš ï¸ é‡è¦æç¤ºï¼š\n",
    "# - æœ¬è„šæœ¬ä¸ä¼šå®‰è£… PyTorchï¼Œè¯·ç¡®ä¿ç³»ç»Ÿå·²æœ‰ PyTorch\n",
    "# - é˜¿é‡Œäº‘ PAI å·²é¢„è£… PyTorch 2.8.0ï¼ˆè¯·å‹¿å‡çº§ï¼‰\n",
    "# - ç§æœ‰ç¯å¢ƒéœ€å…ˆå®‰è£… PyTorchï¼Œç„¶åå†è¿è¡Œæ­¤è„šæœ¬\n",
    "\n",
    "%pip install -q \\\n",
    "    transformers==4.57.1 \\\n",
    "    peft==0.18.0 \\\n",
    "    accelerate==1.11.0 \\\n",
    "    pandas==2.3.3 \\\n",
    "    numpy==1.26.4 \\\n",
    "    tqdm==4.67.1 \\\n",
    "    matplotlib==3.10.7 \\\n",
    "    requests==2.32.5 \\\n",
    "    safetensors==0.6.2\n",
    "\n",
    "# ğŸ“Š æ˜¾ç¤ºå®‰è£…ç»“æœ\n",
    "print(\"=\" * 70)\n",
    "print(\"âœ… ä¾èµ–åŒ…å®‰è£…/å‡çº§å®Œæˆï¼\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nğŸ’¡ ç¯å¢ƒæ£€æŸ¥æç¤ºï¼š\")\n",
    "print(\"   â˜ï¸  é˜¿é‡Œäº‘ PAI ç”¨æˆ·ï¼š\")\n",
    "print(\"      - PyTorch å·²é¢„è£… (2.8.0+cu124)ï¼Œæ— éœ€å®‰è£…\")\n",
    "print(\"      - å…¶ä»–ä¾èµ–å·²å‡çº§åˆ°æŒ‡å®šç‰ˆæœ¬\")\n",
    "print(\"\\n   ğŸ’» ç§æœ‰ç¯å¢ƒç”¨æˆ·ï¼š\")\n",
    "print(\"      - è¯·ç¡®ä¿å·²å•ç‹¬å®‰è£… PyTorch\")\n",
    "print(\"      - è¿è¡Œä¸‹ä¸€ä¸ªå•å…ƒæ ¼æ£€æŸ¥ PyTorch æ˜¯å¦æ­£å¸¸å·¥ä½œ\")\n",
    "print(\"\\n   âš ï¸  å¦‚é‡åˆ°ç‰ˆæœ¬å†²çªï¼š\")\n",
    "print(\"      - å¯ç§»é™¤ç‰ˆæœ¬å·ï¼ˆå¦‚ transformers æ”¹ä¸º transformersï¼‰\")\n",
    "print(\"      - æˆ–é™çº§åˆ° PAI é¢„è£…ç‰ˆæœ¬\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gN_sfOsl5kgK"
   },
   "source": [
    "# 2ï¸âƒ£ å¯¼å…¥ä¾èµ–åº“å’Œç¯å¢ƒæ£€æŸ¥\n",
    "\n",
    "## ğŸ”§ æ ¸å¿ƒåº“å¯¼å…¥è¯´æ˜\n",
    "\n",
    "ä¸‹é¢æˆ‘ä»¬å°†å¯¼å…¥æ‰€æœ‰éœ€è¦çš„åº“ï¼Œå¹¶æ£€æŸ¥è¿è¡Œç¯å¢ƒã€‚\n",
    "\n",
    "### ğŸ’¡ é¢„æœŸè¾“å‡º\n",
    "\n",
    "#### â˜ï¸ é˜¿é‡Œäº‘ PAI-DSW ç¯å¢ƒ\n",
    "- PyTorch: 2.8.x\n",
    "- Transformers: 4.57.x\n",
    "- PEFT: 0.18.x\n",
    "- CUDA: 12.4 / 12.8\n",
    "- GPU: NVIDIA A10 (24GB)\n",
    "\n",
    "#### ğŸ’» ç§æœ‰ç¯å¢ƒ\n",
    "- PyTorch: 2.0.x+\n",
    "- Transformers: 4.57.x\n",
    "- PEFT: 0.18.x\n",
    "- CUDA: 11.8+ / 12.x\n",
    "- GPU: æ ¹æ®æ‚¨çš„ç¡¬ä»¶é…ç½®\n",
    "\n",
    "âš ï¸ **å¦‚æœæ£€æµ‹ä¸åˆ° GPU**ï¼š\n",
    "- æ£€æŸ¥ NVIDIA é©±åŠ¨æ˜¯å¦æ­£ç¡®å®‰è£…\n",
    "- æ£€æŸ¥ CUDA ç‰ˆæœ¬ä¸ PyTorch æ˜¯å¦åŒ¹é…\n",
    "- å¯ä»¥ç»§ç»­ä½¿ç”¨ CPU è¿è¡Œï¼ˆé€Ÿåº¦è¾ƒæ…¢ï¼‰\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-04T23:43:33.075789Z",
     "iopub.status.busy": "2025-12-04T23:43:33.075629Z",
     "iopub.status.idle": "2025-12-04T23:43:40.949963Z",
     "shell.execute_reply": "2025-12-04T23:43:40.949326Z",
     "shell.execute_reply.started": "2025-12-04T23:43:33.075772Z"
    },
    "id": "_ZYeCSUI5kgK",
    "outputId": "7c9dfd76-ed5e-4331-c077-640ca00331e8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "/usr/local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” ç¯å¢ƒæ£€æŸ¥\n",
      "============================================================\n",
      "ğŸ® ä½¿ç”¨è®¾å¤‡: cuda\n",
      "   GPU å‹å·: NVIDIA A10\n",
      "   GPU æ•°é‡: 1\n",
      "   CUDA ç‰ˆæœ¬: 12.8\n",
      "ğŸ Python åº“ç‰ˆæœ¬:\n",
      "   PyTorch: 2.8.0+cu128\n",
      "   Transformers: 4.57.1\n",
      "   PEFT: 0.18.0\n",
      "\n",
      "âœ… ç¯å¢ƒå‡†å¤‡å®Œæˆï¼\n"
     ]
    }
   ],
   "source": [
    "# ğŸ”§ å¯¼å…¥æ‰€æœ‰å¿…éœ€çš„åº“\n",
    "# åŠŸèƒ½ï¼šå‡†å¤‡è®­ç»ƒæ‰€éœ€çš„æ‰€æœ‰ä¾èµ–\n",
    "\n",
    "import io\n",
    "import os\n",
    "import random\n",
    "import zipfile\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,  # åºåˆ—åˆ†ç±»æ¨¡å‹ï¼ˆç”¨äºæ–‡æœ¬åˆ†ç±»ï¼‰\n",
    "    AutoTokenizer,                        # è‡ªåŠ¨é€‰æ‹©åˆé€‚çš„åˆ†è¯å™¨\n",
    "    get_linear_schedule_with_warmup,     # å¸¦é¢„çƒ­çš„çº¿æ€§å­¦ä¹ ç‡è°ƒåº¦å™¨\n",
    ")\n",
    "from peft import (\n",
    "    LoraConfig,        # LoRA é…ç½®ç±»\n",
    "    TaskType,          # ä»»åŠ¡ç±»å‹æšä¸¾\n",
    "    get_peft_model,    # å°† LoRA åº”ç”¨åˆ°æ¨¡å‹çš„æ ¸å¿ƒå‡½æ•°\n",
    ")\n",
    "from tqdm import tqdm  # è¿›åº¦æ¡æ˜¾ç¤º\n",
    "import requests        # HTTP è¯·æ±‚ï¼ˆç”¨äºä¸‹è½½æ•°æ®ï¼‰\n",
    "\n",
    "# ğŸ¯ è®¾ç½®éšæœºç§å­ï¼Œç¡®ä¿ç»“æœå¯å¤ç°\n",
    "# è¯´æ˜ï¼šåœ¨æ·±åº¦å­¦ä¹ ä¸­ï¼Œå¾ˆå¤šæ“ä½œæ¶‰åŠéšæœºæ€§ï¼ˆå¦‚å‚æ•°åˆå§‹åŒ–ã€æ•°æ®æ‰“ä¹±ï¼‰\n",
    "#      å›ºå®šéšæœºç§å­å¯ä»¥è®©æ¯æ¬¡è¿è¡Œå¾—åˆ°ç›¸åŒçš„ç»“æœï¼Œä¾¿äºè°ƒè¯•å’Œå¯¹æ¯”\n",
    "torch.manual_seed(42)   # PyTorch çš„éšæœºç§å­\n",
    "random.seed(42)         # Python æ ‡å‡†åº“çš„éšæœºç§å­\n",
    "\n",
    "# ğŸ® è®¾å¤‡é€‰æ‹©ï¼šä¼˜å…ˆä½¿ç”¨ GPUï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨ CPU\n",
    "# è¯´æ˜ï¼šCUDA æ˜¯ NVIDIA GPU çš„å¹¶è¡Œè®¡ç®—å¹³å°\n",
    "#      torch.cuda.is_available() æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„ GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# ğŸ“Š æ˜¾ç¤ºç¯å¢ƒä¿¡æ¯\n",
    "print(\"ğŸ” ç¯å¢ƒæ£€æŸ¥\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"ğŸ® ä½¿ç”¨è®¾å¤‡: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU å‹å·: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   GPU æ•°é‡: {torch.cuda.device_count()}\")\n",
    "    print(f\"   CUDA ç‰ˆæœ¬: {torch.version.cuda}\")\n",
    "else:\n",
    "    print(\"   âš ï¸  æœªæ£€æµ‹åˆ° GPUï¼Œå°†ä½¿ç”¨ CPUï¼ˆè®­ç»ƒé€Ÿåº¦è¾ƒæ…¢ï¼‰\")\n",
    "\n",
    "print(f\"ğŸ Python åº“ç‰ˆæœ¬:\")\n",
    "print(f\"   PyTorch: {torch.__version__}\")\n",
    "try:\n",
    "    import transformers\n",
    "    print(f\"   Transformers: {transformers.__version__}\")\n",
    "    import peft\n",
    "    print(f\"   PEFT: {peft.__version__}\")\n",
    "except ImportError as e:\n",
    "    print(f\"   âš ï¸ éƒ¨åˆ†åº“æœªå®‰è£…: {e}\")\n",
    "\n",
    "print(\"\\nâœ… ç¯å¢ƒå‡†å¤‡å®Œæˆï¼\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mygKDZAe5kgK"
   },
   "source": [
    "# 3ï¸âƒ£ æ•°æ®å‡†å¤‡å’Œé¢„å¤„ç†\n",
    "\n",
    "## ğŸ“Š æ•°æ®é›†ä»‹ç»\n",
    "\n",
    "æˆ‘ä»¬ä½¿ç”¨ **SMS Spam Collection** æ•°æ®é›†è¿›è¡Œåƒåœ¾çŸ­ä¿¡åˆ†ç±»ä»»åŠ¡ã€‚\n",
    "\n",
    "### æ•°æ®é›†æ¦‚è§ˆ\n",
    "\n",
    "| å±æ€§ | è¯¦æƒ… |\n",
    "|:-----|:-----|\n",
    "| **æ•°æ®æ¥æº** | UCI Machine Learning Repository |\n",
    "| **æ•°æ®è§„æ¨¡** | 5,572 æ¡çŸ­ä¿¡ |\n",
    "| **ä»»åŠ¡ç±»å‹** | äºŒåˆ†ç±»ï¼ˆspam åƒåœ¾çŸ­ä¿¡ vs ham æ­£å¸¸çŸ­ä¿¡ï¼‰ |\n",
    "| **æ ‡ç­¾åˆ†å¸ƒ** | ä¸å¹³è¡¡ï¼ˆham çº¦ 86.6%, spam çº¦ 13.4%ï¼‰ |\n",
    "| **æ•°æ®æ ¼å¼** | TSVï¼ˆåˆ¶è¡¨ç¬¦åˆ†éš”ï¼‰ |\n",
    "| **æ–‡æœ¬è¯­è¨€** | è‹±æ–‡ |\n",
    "| **å¹³å‡é•¿åº¦** | ~80 å­—ç¬¦ |\n",
    "\n",
    "### æ ‡ç­¾è¯´æ˜\n",
    "\n",
    "| æ ‡ç­¾ | å«ä¹‰ | æ•°é‡ | å æ¯” | ç¤ºä¾‹ |\n",
    "|:----|:-----|:-----|:----|:-----|\n",
    "| **ham** | æ­£å¸¸çŸ­ä¿¡ | 4,825 | 86.6% | \"Hey, want to grab lunch?\" |\n",
    "| **spam** | åƒåœ¾çŸ­ä¿¡ | 747 | 13.4% | \"FREE! Click to win $5000!\" |\n",
    "\n",
    "## ğŸ”§ æ•°æ®å¤„ç†æµç¨‹\n",
    "\n",
    "```\n",
    "åŸå§‹æ•°æ®ä¸‹è½½ â†’ ç±»åˆ«å¹³è¡¡é‡‡æ · â†’ åˆ’åˆ†è®­ç»ƒ/éªŒè¯/æµ‹è¯•é›† â†’ åˆ†è¯ç¼–ç  â†’ DataLoader åŠ è½½\n",
    "     â†“              â†“                    â†“                  â†“              â†“\n",
    "  5,572æ¡      å¹³è¡¡åˆ°1,494æ¡      70%/10%/20%åˆ’åˆ†      TokenåŒ–      æ‰¹é‡è®­ç»ƒ\n",
    "```\n",
    "\n",
    "### å¤„ç†æ­¥éª¤è¯´æ˜\n",
    "\n",
    "| æ­¥éª¤ | æ“ä½œ | ç›®çš„ | è¾“å‡º |\n",
    "|:----|:-----|:----|:-----|\n",
    "| **1. æ•°æ®ä¸‹è½½** | ä» UCI è‡ªåŠ¨ä¸‹è½½ | è·å–åŸå§‹æ•°æ® | 5,572 æ¡åŸå§‹çŸ­ä¿¡ |\n",
    "| **2. ç±»åˆ«å¹³è¡¡** | ä¸‹é‡‡æ ·å¤šæ•°ç±» | è§£å†³ç±»åˆ«ä¸å¹³è¡¡ | 1,494 æ¡å¹³è¡¡æ•°æ® |\n",
    "| **3. æ•°æ®åˆ’åˆ†** | 70%/10%/20% åˆ‡åˆ† | è®­ç»ƒ/éªŒè¯/æµ‹è¯• | ä¸‰ä¸ªæ•°æ®é›† |\n",
    "| **4. åˆ†è¯ç¼–ç ** | GPT-2 Tokenizer | æ–‡æœ¬ â†’ Token ID | æ•°å­—å¼ é‡ |\n",
    "| **5. DataLoader** | æ‰¹é‡åŠ è½½ | é«˜æ•ˆè®­ç»ƒ | Batch è¿­ä»£å™¨ |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-04T23:43:40.951010Z",
     "iopub.status.busy": "2025-12-04T23:43:40.950710Z",
     "iopub.status.idle": "2025-12-04T23:43:40.963075Z",
     "shell.execute_reply": "2025-12-04T23:43:40.962376Z",
     "shell.execute_reply.started": "2025-12-04T23:43:40.950994Z"
    },
    "id": "xn1FLJSN5kgL",
    "outputId": "abbd2b06-aa1d-46e6-bc03-2126644f74e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æ•°æ®å¤„ç†å‡½æ•°å®šä¹‰å®Œæˆ\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“Š æ•°æ®å¤„ç†å·¥å…·å‡½æ•°\n",
    "# åŠŸèƒ½ï¼šæä¾›æ•°æ®ä¸‹è½½ã€å¹³è¡¡ã€åˆ’åˆ†å’ŒåŠ è½½çš„å®Œæ•´å·¥å…·é›†\n",
    "\n",
    "def create_balanced_dataset(df):\n",
    "    \"\"\"\n",
    "    åˆ›å»ºç±»åˆ«å¹³è¡¡çš„æ•°æ®é›†\n",
    "\n",
    "    ğŸ¯ ç›®çš„ï¼šè§£å†³æ•°æ®ä¸å¹³è¡¡é—®é¢˜\n",
    "    åŸå§‹æ•°æ®ä¸­ hamï¼ˆæ­£å¸¸çŸ­ä¿¡ï¼‰è¿œå¤šäº spamï¼ˆåƒåœ¾çŸ­ä¿¡ï¼‰ï¼Œ\n",
    "    è¿™ä¼šå¯¼è‡´æ¨¡å‹åå‘é¢„æµ‹å¤šæ•°ç±»ã€‚é€šè¿‡ä¸‹é‡‡æ ·å¤šæ•°ç±»ï¼Œ\n",
    "    ä½¿ä¸¤ä¸ªç±»åˆ«çš„æ ·æœ¬æ•°é‡ç›¸ç­‰ã€‚\n",
    "\n",
    "    å‚æ•°ï¼š\n",
    "        df: pandas DataFrameï¼ŒåŒ…å« Label å’Œ Text åˆ—\n",
    "\n",
    "    è¿”å›ï¼š\n",
    "        balanced_df: ç±»åˆ«å¹³è¡¡åçš„ DataFrame\n",
    "\n",
    "    ç¤ºä¾‹ï¼š\n",
    "        åŸå§‹ï¼šham(4825æ¡) + spam(747æ¡) = 5572æ¡\n",
    "        å¹³è¡¡åï¼šham(747æ¡) + spam(747æ¡) = 1494æ¡\n",
    "    \"\"\"\n",
    "    label_col = df[\"Label\"]\n",
    "\n",
    "    # ğŸ” å…¼å®¹æ€§å¤„ç†ï¼šæ ‡ç­¾å¯èƒ½æ˜¯å­—ç¬¦ä¸²ï¼ˆ'spam'/'ham'ï¼‰æˆ–æ•°å­—ï¼ˆ0/1ï¼‰\n",
    "    spam_mask = (label_col == \"spam\") | (label_col == 1)\n",
    "    ham_mask = (label_col == \"ham\") | (label_col == 0)\n",
    "\n",
    "    # ç»Ÿè®¡åƒåœ¾çŸ­ä¿¡æ•°é‡ï¼ˆå°‘æ•°ç±»ï¼‰\n",
    "    spam_count = int(spam_mask.sum())\n",
    "\n",
    "    if spam_count == 0 or ham_mask.sum() == 0:\n",
    "        raise ValueError(\"æ•°æ®é›†ç¼ºå°‘ spam æˆ– ham ç±»åˆ«ï¼Œæ— æ³•å¹³è¡¡\")\n",
    "\n",
    "    # ğŸ² ä»å¤šæ•°ç±»ï¼ˆhamï¼‰ä¸­éšæœºé‡‡æ ·ï¼Œæ•°é‡ä¸å°‘æ•°ç±»ç›¸åŒ\n",
    "    # random_state=123 ç¡®ä¿æ¯æ¬¡é‡‡æ ·ç»“æœç›¸åŒï¼Œä¾¿äºå¤ç°\n",
    "    ham_subset = df[ham_mask].sample(spam_count, random_state=123)\n",
    "\n",
    "    # ğŸ“¦ åˆå¹¶ä¸¤ä¸ªç±»åˆ«çš„æ•°æ®\n",
    "    balanced = pd.concat([ham_subset, df[spam_mask]])\n",
    "\n",
    "    # ğŸ”€ éšæœºæ‰“ä¹±æ•°æ®ï¼Œé¿å…æ•°æ®é¡ºåºåå·®\n",
    "    return balanced.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "\n",
    "\n",
    "def random_split(df, train_frac=0.7, val_frac=0.1):\n",
    "    \"\"\"\n",
    "    éšæœºåˆ’åˆ†æ•°æ®é›†ä¸ºè®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†\n",
    "\n",
    "    ğŸ¯ ç›®çš„ï¼šå°†æ•°æ®åˆ†ä¸ºä¸‰éƒ¨åˆ†\n",
    "    - è®­ç»ƒé›†ï¼šç”¨äºæ¨¡å‹å‚æ•°æ›´æ–°\n",
    "    - éªŒè¯é›†ï¼šç”¨äºè°ƒæ•´è¶…å‚æ•°å’Œæ—©åœ\n",
    "    - æµ‹è¯•é›†ï¼šç”¨äºæœ€ç»ˆæ€§èƒ½è¯„ä¼°\n",
    "\n",
    "    å‚æ•°ï¼š\n",
    "        df: pandas DataFrame\n",
    "        train_frac: è®­ç»ƒé›†æ¯”ä¾‹ï¼ˆé»˜è®¤ 0.7 = 70%ï¼‰\n",
    "        val_frac: éªŒè¯é›†æ¯”ä¾‹ï¼ˆé»˜è®¤ 0.1 = 10%ï¼‰\n",
    "\n",
    "    è¿”å›ï¼š\n",
    "        train_df, val_df, test_df: ä¸‰ä¸ªæ•°æ®æ¡†\n",
    "\n",
    "    ç¤ºä¾‹ï¼š\n",
    "        æ€»å…±1494æ¡ â†’ è®­ç»ƒ1046æ¡(70%) + éªŒè¯149æ¡(10%) + æµ‹è¯•299æ¡(20%)\n",
    "    \"\"\"\n",
    "    # ğŸ”€ éšæœºæ‰“ä¹±æ•°æ®\n",
    "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "\n",
    "    # ğŸ“ è®¡ç®—åˆ’åˆ†ç‚¹\n",
    "    train_end = int(len(df) * train_frac)\n",
    "    val_end = train_end + int(len(df) * val_frac)\n",
    "\n",
    "    # âœ‚ï¸ æ‰§è¡Œåˆ’åˆ†\n",
    "    train_df = df[:train_end]\n",
    "    val_df = df[train_end:val_end]\n",
    "    test_df = df[val_end:]\n",
    "\n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "\n",
    "def ensure_sms_file(local_path=\"./SMSSpamCollection.tsv\"):\n",
    "    \"\"\"\n",
    "    ç¡®ä¿ SMS æ•°æ®æ–‡ä»¶å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è‡ªåŠ¨ä¸‹è½½\n",
    "\n",
    "    ğŸ¯ ç›®çš„ï¼šè‡ªåŠ¨åŒ–æ•°æ®å‡†å¤‡æµç¨‹\n",
    "    å¦‚æœæœ¬åœ°å·²æœ‰æ•°æ®æ–‡ä»¶ï¼Œç›´æ¥è¿”å›è·¯å¾„ï¼›\n",
    "    å¦‚æœæ²¡æœ‰ï¼Œåˆ™ä» UCI ä»“åº“ä¸‹è½½å¹¶è§£å‹ã€‚\n",
    "\n",
    "    å‚æ•°ï¼š\n",
    "        local_path: æœ¬åœ°æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰\n",
    "\n",
    "    è¿”å›ï¼š\n",
    "        str: æ•°æ®æ–‡ä»¶çš„å®é™…è·¯å¾„\n",
    "\n",
    "    è¯´æ˜ï¼š\n",
    "        æ•°æ®æ–‡ä»¶æ ¼å¼ä¸º TSVï¼ˆTab-Separated Valuesï¼‰ï¼Œæ¯è¡ŒåŒ…å«æ ‡ç­¾å’Œæ–‡æœ¬\n",
    "    \"\"\"\n",
    "    # âœ… å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œç›´æ¥è¿”å›\n",
    "    if os.path.exists(local_path):\n",
    "        return local_path\n",
    "\n",
    "    # ğŸ“¥ ä» UCI æœºå™¨å­¦ä¹ ä»“åº“ä¸‹è½½æ•°æ®\n",
    "    url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip\"\n",
    "    print(f\"ğŸ“¥ æ­£åœ¨ä» UCI ä»“åº“ä¸‹è½½æ•°æ®...\")\n",
    "    print(f\"   URL: {url}\")\n",
    "\n",
    "    try:\n",
    "        # ğŸŒ å‘é€ HTTP è¯·æ±‚ä¸‹è½½ ZIP æ–‡ä»¶\n",
    "        resp = requests.get(url, timeout=30)\n",
    "        resp.raise_for_status()  # å¦‚æœè¯·æ±‚å¤±è´¥ï¼ŒæŠ›å‡ºå¼‚å¸¸\n",
    "\n",
    "        # ğŸ“¦ è§£å‹ ZIP æ–‡ä»¶ï¼Œè¯»å–å…¶ä¸­çš„ SMSSpamCollection æ–‡ä»¶\n",
    "        with zipfile.ZipFile(io.BytesIO(resp.content)) as zf:\n",
    "            raw = zf.read(\"SMSSpamCollection\").decode(\"utf-8\")\n",
    "\n",
    "        # ğŸ’¾ ä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶\n",
    "        out_path = \"SMSSpamCollection.tsv\"\n",
    "        with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(raw)\n",
    "\n",
    "        print(f\"âœ… æ•°æ®ä¸‹è½½æˆåŠŸï¼Œä¿å­˜åˆ°: {out_path}\")\n",
    "        return out_path\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ æ•°æ®ä¸‹è½½å¤±è´¥: {e}\")\n",
    "        print(f\"ğŸ’¡ è¯·æ‰‹åŠ¨ä¸‹è½½å¹¶æ”¾ç½®åˆ°å½“å‰ç›®å½•\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def load_sms_dataframe():\n",
    "    \"\"\"\n",
    "    åŠ è½½å¹¶é¢„å¤„ç† SMS æ•°æ®é›†\n",
    "\n",
    "    ğŸ¯ ç›®çš„ï¼šä¸€ç«™å¼æ•°æ®åŠ è½½å‡½æ•°\n",
    "    æ•´åˆäº†ä¸‹è½½ã€è¯»å–ã€å¹³è¡¡ã€æ ‡ç­¾è½¬æ¢å’Œåˆ’åˆ†çš„å®Œæ•´æµç¨‹\n",
    "\n",
    "    è¿”å›ï¼š\n",
    "        train_df, val_df, test_df: ä¸‰ä¸ªå·²å¤„ç†çš„ DataFrame\n",
    "\n",
    "    æ•°æ®å¤„ç†æ­¥éª¤ï¼š\n",
    "        1. ç¡®ä¿æ•°æ®æ–‡ä»¶å­˜åœ¨ï¼ˆè‡ªåŠ¨ä¸‹è½½ï¼‰\n",
    "        2. è¯»å– TSV æ–‡ä»¶\n",
    "        3. å¹³è¡¡ç±»åˆ«åˆ†å¸ƒ\n",
    "        4. æ ‡ç­¾è½¬æ¢ï¼ˆhamâ†’0, spamâ†’1ï¼‰\n",
    "        5. åˆ’åˆ†è®­ç»ƒ/éªŒè¯/æµ‹è¯•é›†\n",
    "    \"\"\"\n",
    "    # ğŸ“‚ è·å–æ•°æ®æ–‡ä»¶è·¯å¾„ï¼ˆå¦‚éœ€è¦ä¼šè‡ªåŠ¨ä¸‹è½½ï¼‰\n",
    "    data_path = ensure_sms_file()\n",
    "\n",
    "    # ğŸ“– è¯»å– TSV æ–‡ä»¶\n",
    "    # sep=\"\\t\" æŒ‡å®šåˆ¶è¡¨ç¬¦åˆ†éš”\n",
    "    # names æŒ‡å®šåˆ—å\n",
    "    # header=None è¡¨ç¤ºæ–‡ä»¶æ²¡æœ‰è¡¨å¤´è¡Œ\n",
    "    df = pd.read_csv(data_path, sep=\"\\t\", names=[\"Label\", \"Text\"], header=None)\n",
    "\n",
    "    print(f\"ğŸ“Š åŸå§‹æ•°æ®åŠ è½½å®Œæˆ: {len(df)} æ¡\")\n",
    "    print(f\"   - ham (æ­£å¸¸): {(df['Label']=='ham').sum()} æ¡\")\n",
    "    print(f\"   - spam (åƒåœ¾): {(df['Label']=='spam').sum()} æ¡\")\n",
    "\n",
    "    # âš–ï¸ åˆ›å»ºç±»åˆ«å¹³è¡¡çš„æ•°æ®é›†\n",
    "    balanced = create_balanced_dataset(df)\n",
    "    print(f\"âš–ï¸  æ•°æ®å¹³è¡¡å: {len(balanced)} æ¡ï¼ˆæ¯ç±» {len(balanced)//2} æ¡ï¼‰\")\n",
    "\n",
    "    # ğŸ”„ æ ‡ç­¾è½¬æ¢ï¼šå­—ç¬¦ä¸² â†’ æ•°å­—\n",
    "    # æœºå™¨å­¦ä¹ æ¨¡å‹éœ€è¦æ•°å­—æ ‡ç­¾\n",
    "    label_map = {\"ham\": 0, \"spam\": 1}\n",
    "    balanced[\"Label\"] = balanced[\"Label\"].apply(\n",
    "        lambda v: label_map[v] if v in label_map else int(v)\n",
    "    )\n",
    "\n",
    "    # âœ‚ï¸ åˆ’åˆ†æ•°æ®é›†\n",
    "    train_df, val_df, test_df = random_split(balanced, train_frac=0.7, val_frac=0.1)\n",
    "    print(f\"âœ‚ï¸  æ•°æ®åˆ’åˆ†å®Œæˆ:\")\n",
    "    print(f\"   - è®­ç»ƒé›†: {len(train_df)} æ¡\")\n",
    "    print(f\"   - éªŒè¯é›†: {len(val_df)} æ¡\")\n",
    "    print(f\"   - æµ‹è¯•é›†: {len(test_df)} æ¡\")\n",
    "\n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "\n",
    "# ğŸ“ åˆå­¦è€…æç¤ºï¼š\n",
    "# ä»¥ä¸Šå‡½æ•°æ„æˆäº†å®Œæ•´çš„æ•°æ®å¤„ç†æµæ°´çº¿ï¼Œæ¯ä¸ªå‡½æ•°èŒè´£å•ä¸€ï¼Œä¾¿äºç†è§£å’Œè°ƒè¯•ã€‚\n",
    "# åœ¨å®é™…é¡¹ç›®ä¸­ï¼Œå»ºè®®å°†æ•°æ®å¤„ç†ä»£ç æ¨¡å—åŒ–ï¼Œæé«˜ä»£ç å¤ç”¨æ€§ã€‚\n",
    "print(\"âœ… æ•°æ®å¤„ç†å‡½æ•°å®šä¹‰å®Œæˆ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-04T23:43:40.963753Z",
     "iopub.status.busy": "2025-12-04T23:43:40.963605Z",
     "iopub.status.idle": "2025-12-04T23:43:40.970286Z",
     "shell.execute_reply": "2025-12-04T23:43:40.969688Z",
     "shell.execute_reply.started": "2025-12-04T23:43:40.963738Z"
    },
    "id": "gISqIzXT5kgL",
    "outputId": "102f903b-b9b4-4be0-a945-ee8967e68bc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dataset ç±»å®šä¹‰å®Œæˆ\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“¦ PyTorch Dataset ç±»å®šä¹‰\n",
    "# åŠŸèƒ½ï¼šå°† DataFrame è½¬æ¢ä¸º PyTorch å¯ç”¨çš„æ•°æ®é›†æ ¼å¼\n",
    "\n",
    "class SpamSequenceDataset(Dataset):\n",
    "    \"\"\"\n",
    "    SMS åƒåœ¾çŸ­ä¿¡æ•°æ®é›†ç±»\n",
    "\n",
    "    ğŸ¯ ç›®çš„ï¼šå°† pandas DataFrame è½¬æ¢ä¸º PyTorch Dataset\n",
    "    è¿™ä¸ªç±»ç»§æ‰¿è‡ª torch.utils.data.Datasetï¼Œå®ç°äº† PyTorch æ•°æ®åŠ è½½çš„æ ‡å‡†æ¥å£\n",
    "\n",
    "    ä¸æ‰‹åŠ¨å®ç°çš„åŒºåˆ«ï¼š\n",
    "    - æ‰‹åŠ¨å®ç°ï¼šä½¿ç”¨ tiktoken åˆ†è¯å™¨ï¼Œæ‰‹åŠ¨å¤„ç† padding\n",
    "    - PEFTç‰ˆæœ¬ï¼šä½¿ç”¨ Hugging Face Tokenizerï¼Œè‡ªåŠ¨å¤„ç† padding å’Œ attention_mask\n",
    "\n",
    "    å…³é”®ç‰¹æ€§ï¼š\n",
    "    1. ä½¿ç”¨ Hugging Face tokenizerï¼Œä¸æ¨¡å‹å®Œç¾é…åˆ\n",
    "    2. è‡ªåŠ¨ç”Ÿæˆ attention_maskï¼ˆæ ‡è®°å“ªäº›æ˜¯çœŸå® tokenï¼Œå“ªäº›æ˜¯ paddingï¼‰\n",
    "    3. æ‰¹é‡é¢„å¤„ç†æ‰€æœ‰æ–‡æœ¬ï¼Œæé«˜æ•ˆç‡\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, df, tokenizer, max_length=96):\n",
    "        \"\"\"\n",
    "        åˆå§‹åŒ–æ•°æ®é›†\n",
    "\n",
    "        å‚æ•°ï¼š\n",
    "            df: pandas DataFrameï¼ŒåŒ…å« 'Text' å’Œ 'Label' åˆ—\n",
    "            tokenizer: Hugging Face tokenizer å¯¹è±¡\n",
    "            max_length: æœ€å¤§åºåˆ—é•¿åº¦ï¼Œè¶…è¿‡ä¼šæˆªæ–­ï¼Œä¸è¶³ä¼šå¡«å……\n",
    "\n",
    "        å¤„ç†æµç¨‹ï¼š\n",
    "            1. æ‰¹é‡åˆ†è¯æ‰€æœ‰æ–‡æœ¬\n",
    "            2. ç»Ÿä¸€é•¿åº¦ï¼ˆæˆªæ–­/å¡«å……åˆ° max_lengthï¼‰\n",
    "            3. è½¬æ¢ä¸º PyTorch tensors\n",
    "            4. ä¿å­˜ labels ä¸ºæ•°å­—å¼ é‡\n",
    "        \"\"\"\n",
    "        # ğŸ”¤ æ‰¹é‡åˆ†è¯æ‰€æœ‰æ–‡æœ¬\n",
    "        # tokenizer() å‡½æ•°çš„å‚æ•°è¯´æ˜ï¼š\n",
    "        # - truncation=True: å¦‚æœæ–‡æœ¬è¶…è¿‡ max_lengthï¼Œè‡ªåŠ¨æˆªæ–­\n",
    "        # - padding=\"max_length\": å¡«å……åˆ° max_length é•¿åº¦\n",
    "        # - max_length=96: æœ€å¤§åºåˆ—é•¿åº¦\n",
    "        # - return_tensors=\"pt\": è¿”å› PyTorch tensors\n",
    "        encodings = tokenizer(\n",
    "            df[\"Text\"].tolist(),          # å°† pandas Series è½¬ä¸º list\n",
    "            truncation=True,               # å¯ç”¨æˆªæ–­\n",
    "            padding=\"max_length\",          # å¡«å……åˆ°æœ€å¤§é•¿åº¦\n",
    "            max_length=max_length,         # æœ€å¤§é•¿åº¦\n",
    "            return_tensors=\"pt\",           # è¿”å› PyTorch å¼ é‡\n",
    "        )\n",
    "\n",
    "        # ğŸ“Š ä¿å­˜ç¼–ç ç»“æœ\n",
    "        # input_ids: token ID åºåˆ—ï¼Œå½¢çŠ¶ [N, max_length]\n",
    "        self.input_ids = encodings[\"input_ids\"]\n",
    "\n",
    "        # attention_mask: æ³¨æ„åŠ›æ©ç ï¼Œå½¢çŠ¶ [N, max_length]\n",
    "        # 1 è¡¨ç¤ºçœŸå® tokenï¼Œ0 è¡¨ç¤º padding token\n",
    "        # æ¨¡å‹ä¼šå¿½ç•¥ attention_mask=0 çš„ä½ç½®\n",
    "        self.attention_mask = encodings[\"attention_mask\"]\n",
    "\n",
    "        # ğŸ·ï¸ ä¿å­˜æ ‡ç­¾\n",
    "        # è½¬æ¢ä¸º long ç±»å‹ï¼ˆint64ï¼‰ï¼Œè¿™æ˜¯ PyTorch äº¤å‰ç†µæŸå¤±è¦æ±‚çš„ç±»å‹\n",
    "        self.labels = torch.tensor(df[\"Label\"].tolist(), dtype=torch.long)\n",
    "\n",
    "        # ğŸ“ ä¿å­˜æ•°æ®é›†å¤§å°\n",
    "        self._len = len(self.labels)\n",
    "\n",
    "        print(f\"âœ… æ•°æ®é›†åˆ›å»ºå®Œæˆ:\")\n",
    "        print(f\"   - æ ·æœ¬æ•°: {self._len}\")\n",
    "        print(f\"   - åºåˆ—é•¿åº¦: {max_length}\")\n",
    "        print(f\"   - è¾“å…¥å½¢çŠ¶: {self.input_ids.shape}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        è¿”å›æ•°æ®é›†å¤§å°\n",
    "\n",
    "        ğŸ¯ ç›®çš„ï¼šå‘Šè¯‰ DataLoader æ•°æ®é›†æœ‰å¤šå°‘æ ·æœ¬\n",
    "        è¿™æ˜¯ PyTorch Dataset å¿…é¡»å®ç°çš„æ–¹æ³•ä¹‹ä¸€\n",
    "        \"\"\"\n",
    "        return self._len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        è·å–å•ä¸ªæ ·æœ¬\n",
    "\n",
    "        ğŸ¯ ç›®çš„ï¼šæ ¹æ®ç´¢å¼•è¿”å›ä¸€ä¸ªæ ·æœ¬\n",
    "        è¿™æ˜¯ PyTorch Dataset å¿…é¡»å®ç°çš„æ–¹æ³•ä¹‹ä¸€\n",
    "\n",
    "        å‚æ•°ï¼š\n",
    "            idx: æ ·æœ¬ç´¢å¼•ï¼ˆ0 åˆ° len-1ï¼‰\n",
    "\n",
    "        è¿”å›ï¼š\n",
    "            dict: åŒ…å« input_ids, attention_mask, labels çš„å­—å…¸\n",
    "\n",
    "        è¯´æ˜ï¼š\n",
    "            è¿”å›å­—å…¸æ ¼å¼æ˜¯ Hugging Face æ¨¡å‹çš„æ ‡å‡†è¾“å…¥æ ¼å¼ï¼Œ\n",
    "            å¯ä»¥ç›´æ¥ä½¿ç”¨ model(**batch) è¿›è¡Œè§£åŒ…ä¼ å‚\n",
    "        \"\"\"\n",
    "        return {\n",
    "            \"input_ids\": self.input_ids[idx],           # Token ID åºåˆ—\n",
    "            \"attention_mask\": self.attention_mask[idx], # æ³¨æ„åŠ›æ©ç \n",
    "            \"labels\": self.labels[idx],                 # æ ‡ç­¾ï¼ˆ0 æˆ– 1ï¼‰\n",
    "        }\n",
    "\n",
    "\n",
    "# ğŸ“ åˆå­¦è€…æç¤ºï¼š\n",
    "# Dataset ç±»åªè´Ÿè´£æ•°æ®çš„\"ç»„ç»‡\"ï¼Œä¸è´Ÿè´£æ•°æ®çš„\"æ‰¹é‡åŠ è½½\"ã€‚\n",
    "# æ‰¹é‡åŠ è½½ç”± DataLoader å®Œæˆï¼Œå®ƒä¼šï¼š\n",
    "# 1. è°ƒç”¨ __getitem__ è·å–å¤šä¸ªæ ·æœ¬\n",
    "# 2. è‡ªåŠ¨å°†è¿™äº›æ ·æœ¬ç»„åˆæˆ batch\n",
    "# 3. å¯é€‰åœ°æ‰“ä¹±æ•°æ®é¡ºåºï¼ˆshuffle=Trueï¼‰\n",
    "# 4. å¯é€‰åœ°ä½¿ç”¨å¤šè¿›ç¨‹åŠ é€Ÿï¼ˆnum_workers>0ï¼‰\n",
    "\n",
    "print(\"âœ… Dataset ç±»å®šä¹‰å®Œæˆ\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a26Ygnx65kgM"
   },
   "source": [
    "# 4ï¸âƒ£ æ‰§è¡Œæ•°æ®åŠ è½½\n",
    "\n",
    "## ğŸš€ åˆ›å»º Tokenizer å’ŒåŠ è½½æ•°æ®\n",
    "\n",
    "ç°åœ¨æˆ‘ä»¬å°†ï¼š\n",
    "1. åŠ è½½ GPT-2 tokenizer\n",
    "2. åŠ è½½å¹¶å¤„ç† SMS æ•°æ®é›†\n",
    "3. åˆ›å»º PyTorch DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-12-05T00:54:20.043771Z",
     "iopub.status.busy": "2025-12-05T00:54:20.043545Z",
     "iopub.status.idle": "2025-12-05T01:10:35.418115Z",
     "shell.execute_reply": "2025-12-05T01:10:35.417410Z",
     "shell.execute_reply.started": "2025-12-05T00:54:20.043751Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
      "Requirement already satisfied: modelscope==1.32.0 in /usr/local/lib/python3.11/site-packages (1.32.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/site-packages (from modelscope==1.32.0) (3.20.0)\n",
      "Requirement already satisfied: requests>=2.25 in /usr/local/lib/python3.11/site-packages (from modelscope==1.32.0) (2.32.5)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/site-packages (from modelscope==1.32.0) (65.5.1)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/site-packages (from modelscope==1.32.0) (4.67.1)\n",
      "Requirement already satisfied: urllib3>=1.26 in /usr/local/lib/python3.11/site-packages (from modelscope==1.32.0) (2.5.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests>=2.25->modelscope==1.32.0) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests>=2.25->modelscope==1.32.0) (3.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests>=2.25->modelscope==1.32.0) (2025.11.12)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "/usr/local/lib/python3.11/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "\n",
      " _   .-')                _ .-') _     ('-.             .-')                              _ (`-.    ('-.\n",
      "( '.( OO )_             ( (  OO) )  _(  OO)           ( OO ).                           ( (OO  ) _(  OO)\n",
      " ,--.   ,--.).-'),-----. \\     .'_ (,------.,--.     (_)---\\_)   .-----.  .-'),-----.  _.`     \\(,------.\n",
      " |   `.'   |( OO'  .-.  ',`'--..._) |  .---'|  |.-') /    _ |   '  .--./ ( OO'  .-.  '(__...--'' |  .---'\n",
      " |         |/   |  | |  ||  |  \\  ' |  |    |  | OO )\\  :` `.   |  |('-. /   |  | |  | |  /  | | |  |\n",
      " |  |'.'|  |\\_) |  |\\|  ||  |   ' |(|  '--. |  |`-' | '..`''.) /_) |OO  )\\_) |  |\\|  | |  |_.' |(|  '--.\n",
      " |  |   |  |  \\ |  | |  ||  |   / : |  .--'(|  '---.'.-._)   \\ ||  |`-'|   \\ |  | |  | |  .___.' |  .--'\n",
      " |  |   |  |   `'  '-'  '|  '--'  / |  `---.|      | \\       /(_'  '--'\\    `'  '-'  ' |  |      |  `---.\n",
      " `--'   `--'     `-----' `-------'  `------'`------'  `-----'    `-----'      `-----'  `--'      `------'\n",
      "\n",
      "Downloading Model from https://www.modelscope.cn to directory: /mnt/workspace/gpt2\n",
      "Processing 4 items:   0%|                           | 0.00/4.00 [00:00<?, ?it/s]\n",
      "Downloading [onnx/decoder_model.onnx]:   0%|         | 0.00/623M [00:00<?, ?B/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:   0%| | 0.00/623M [00:00<?, ?B/\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [flax_model.msgpack]:   0%|              | 0.00/475M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:   0%|               | 0.00/523M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  34%|â–| 215M/623M [00:02<00:04, 98.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "Downloading [flax_model.msgpack]:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 426M/475M [00:02<00:00, 161MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  52%|â–ˆâ–ˆâ–ˆâ–‹   | 271M/523M [00:03<00:02, 89.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  34%|â–| 211M/623M [00:04<00:09,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  53%|â–ˆâ–ˆâ–ˆâ–‹   | 275M/523M [00:19<00:02, 89.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  35%|â–| 220M/623M [00:19<00:04, 98.3MB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  34%|â–| 214M/623M [00:19<00:09,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [flax_model.msgpack]:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 431M/475M [00:19<00:00, 161MB/s]\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  35%|â–| 221M/623M [00:20<00:50, 8.39MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  53%|â–ˆâ–ˆâ–ˆâ–‹   | 276M/523M [00:20<00:25, 10.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  34%|â–| 215M/623M [00:21<00:53,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  36%|â–| 222M/623M [00:22<00:58, 7.15MB/s]\u001b[A\n",
      "\n",
      "\n",
      "Downloading [flax_model.msgpack]:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 432M/475M [00:23<00:03, 14.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  35%|â–| 216M/623M [00:24<01:05,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  53%|â–ˆâ–ˆâ–ˆâ–‹   | 277M/523M [00:24<00:32, 8.02MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [flax_model.msgpack]:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 433M/475M [00:26<00:03, 11.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  35%|â–| 218M/623M [00:31<01:41,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  36%|â–| 226M/623M [00:34<01:53, 3.67MB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  35%|â–| 219M/623M [00:34<02:02,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  36%|â–| 227M/623M [00:37<02:13, 3.12MB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  35%|â–| 220M/623M [00:38<02:34,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  54%|â–ˆâ–ˆâ–ˆâ–‹   | 280M/523M [00:39<00:31, 8.02MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [flax_model.msgpack]:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 437M/475M [00:39<00:03, 11.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  35%|â–| 221M/623M [00:41<03:16,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [flax_model.msgpack]:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 438M/475M [00:42<00:06, 5.58MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  54%|â–ˆâ–ˆâ–ˆâ–Š   | 281M/523M [00:43<01:14, 3.42MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [flax_model.msgpack]:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 439M/475M [00:45<00:07, 4.85MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  36%|â–| 222M/623M [00:45<04:19,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  37%|â–| 230M/623M [00:46<03:23, 2.03MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  54%|â–ˆâ–ˆâ–ˆâ–Š   | 282M/523M [00:47<01:26, 2.93MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  36%|â–| 223M/623M [00:49<05:45,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  37%|â–| 232M/623M [00:51<04:12, 1.62MB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  36%|â–| 224M/623M [00:52<06:55,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  37%|â–| 233M/623M [00:54<04:47, 1.42MB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  36%|â–| 225M/623M [00:56<08:44,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [flax_model.msgpack]:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 443M/475M [00:57<00:11, 2.98MB/s]\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  38%|â–| 234M/623M [00:57<05:33, 1.22MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  54%|â–ˆâ–ˆâ–ˆâ–Š   | 284M/523M [00:58<02:15, 1.85MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  36%|â–| 226M/623M [00:59<10:25,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  38%|â–| 235M/623M [01:00<06:25, 1.06MB/s]\u001b[A\n",
      "\n",
      "\n",
      "Downloading [flax_model.msgpack]:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 444M/475M [01:00<00:12, 2.61MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  36%|â–| 227M/623M [01:03<12:31,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  38%|â–Š | 236M/623M [01:03<07:37, 888kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  55%|â–ˆâ–ˆâ–ˆâ–Š   | 285M/523M [01:03<02:45, 1.51MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  38%|â–Š | 237M/623M [01:06<09:21, 721kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  37%|â–| 228M/623M [01:07<14:50,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [flax_model.msgpack]:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 447M/475M [01:09<00:16, 1.80MB/s]\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  38%|â–Š | 238M/623M [01:09<10:51, 620kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  37%|â–| 229M/623M [01:10<16:43,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  55%|â–ˆâ–ˆâ–ˆâ–Š   | 287M/523M [01:11<03:35, 1.15MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  38%|â–Š | 239M/623M [01:13<12:46, 526kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  37%|â–| 230M/623M [01:14<18:24,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–   | 288M/523M [01:15<04:13, 969kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  38%|â–Š | 240M/623M [01:15<13:39, 491kB/s]\u001b[A\n",
      "\n",
      "\n",
      "Downloading [flax_model.msgpack]:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 449M/475M [01:15<00:19, 1.41MB/s]\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  39%|â–Š | 241M/623M [01:18<14:00, 477kB/s]\u001b[A\n",
      "\n",
      "\n",
      "Downloading [flax_model.msgpack]:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 450M/475M [01:18<00:20, 1.28MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–   | 289M/523M [01:18<04:40, 875kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  37%|â–| 231M/623M [01:20<24:04,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  39%|â–Š | 242M/623M [01:21<15:08, 440kB/s]\u001b[A\n",
      "\n",
      "\n",
      "Downloading [flax_model.msgpack]:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 451M/475M [01:21<00:22, 1.11MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–   | 290M/523M [01:23<05:51, 695kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  39%|â–Š | 243M/623M [01:24<15:58, 416kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  37%|â–| 232M/623M [01:24<23:45,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [flax_model.msgpack]:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 452M/475M [01:24<00:24, 954kB/s]\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  39%|â–Š | 244M/623M [01:27<16:43, 396kB/s]\u001b[A\n",
      "\n",
      "\n",
      "Downloading [flax_model.msgpack]:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 453M/475M [01:27<00:28, 812kB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  37%|â–| 233M/623M [01:27<23:22,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–   | 291M/523M [01:27<06:59, 580kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  39%|â–Š | 245M/623M [01:30<17:27, 379kB/s]\u001b[A\n",
      "\n",
      "\n",
      "Downloading [flax_model.msgpack]:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 454M/475M [01:30<00:32, 674kB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  38%|â–| 234M/623M [01:31<23:05,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–   | 292M/523M [01:32<08:13, 490kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  39%|â–Š | 246M/623M [01:33<17:39, 374kB/s]\u001b[A\n",
      "\n",
      "\n",
      "Downloading [flax_model.msgpack]:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 455M/475M [01:34<00:36, 569kB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  38%|â–| 235M/623M [01:34<22:49,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–   | 293M/523M [01:35<09:05, 441kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  40%|â–Š | 247M/623M [01:36<18:30, 356kB/s]\u001b[A\n",
      "\n",
      "\n",
      "Downloading [flax_model.msgpack]:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 456M/475M [01:37<00:38, 509kB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  38%|â–| 236M/623M [01:38<23:01,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  40%|â–Š | 248M/623M [01:39<19:22, 339kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–   | 294M/523M [01:40<10:27, 382kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [flax_model.msgpack]:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 457M/475M [01:40<00:38, 477kB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  38%|â–| 237M/623M [01:41<23:06,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  40%|â–Š | 249M/623M [01:43<19:26, 337kB/s]\u001b[A\n",
      "\n",
      "\n",
      "Downloading [flax_model.msgpack]:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 458M/475M [01:43<00:40, 437kB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 295M/523M [01:44<11:30, 346kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  38%|â–| 238M/623M [01:45<23:07,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  40%|â–Š | 250M/623M [01:46<19:09, 341kB/s]\u001b[A\n",
      "\n",
      "\n",
      "Downloading [flax_model.msgpack]:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 459M/475M [01:46<00:40, 411kB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 296M/523M [01:47<11:53, 333kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  38%|â–| 239M/623M [01:49<22:49,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  40%|â–Š | 251M/623M [01:49<19:40, 331kB/s]\u001b[A\n",
      "\n",
      "\n",
      "Downloading [flax_model.msgpack]:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 460M/475M [01:50<00:42, 363kB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 297M/523M [01:51<12:39, 312kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  40%|â–Š | 252M/623M [01:52<18:58, 342kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  38%|â–| 240M/623M [01:52<22:19,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [flax_model.msgpack]:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 461M/475M [01:53<00:40, 354kB/s]\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  41%|â–Š | 253M/623M [01:55<18:29, 350kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 298M/523M [01:55<12:37, 311kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [flax_model.msgpack]:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 462M/475M [01:56<00:37, 354kB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  39%|â–| 241M/623M [01:57<25:40,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  41%|â–Š | 254M/623M [01:58<18:32, 348kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 299M/523M [01:58<13:04, 299kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [flax_model.msgpack]:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 463M/475M [01:59<00:36, 339kB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  39%|â–| 242M/623M [02:01<24:32,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  41%|â–Š | 255M/623M [02:01<18:28, 349kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 300M/523M [02:02<13:31, 288kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [flax_model.msgpack]:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 464M/475M [02:03<00:33, 335kB/s]\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  41%|â–Š | 256M/623M [02:03<17:50, 360kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  39%|â–| 243M/623M [02:04<23:48,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [flax_model.msgpack]:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 465M/475M [02:05<00:29, 341kB/s]\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  41%|â–Š | 257M/623M [02:07<18:45, 341kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 301M/523M [02:07<14:18, 271kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  39%|â–| 244M/623M [02:08<23:03,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [flax_model.msgpack]:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 466M/475M [02:08<00:26, 346kB/s]\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  41%|â–Š | 258M/623M [02:10<18:20, 348kB/s]\u001b[A\n",
      "\n",
      "\n",
      "Downloading [flax_model.msgpack]:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 467M/475M [02:11<00:22, 358kB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  39%|â–| 245M/623M [02:11<23:06,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  42%|â–Š | 259M/623M [02:13<18:43, 340kB/s]\u001b[A\n",
      "\n",
      "\n",
      "Downloading [flax_model.msgpack]:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 468M/475M [02:14<00:18, 377kB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 302M/523M [02:14<17:30, 220kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  39%|â–| 246M/623M [02:14<21:48,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  42%|â–Š | 260M/623M [02:16<18:08, 350kB/s]\u001b[A\n",
      "\n",
      "\n",
      "Downloading [flax_model.msgpack]:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 469M/475M [02:17<00:16, 361kB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  40%|â–| 247M/623M [02:18<21:29,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  42%|â–Š | 261M/623M [02:18<16:51, 376kB/s]\u001b[A\n",
      "\n",
      "\n",
      "Downloading [flax_model.msgpack]:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 470M/475M [02:20<00:13, 365kB/s]\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  42%|â–Š | 262M/623M [02:21<16:19, 387kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 303M/523M [02:21<19:43, 195kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  40%|â–| 248M/623M [02:21<21:51,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [flax_model.msgpack]:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 471M/475M [02:23<00:10, 360kB/s]\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  42%|â–Š | 263M/623M [02:24<17:17, 364kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 304M/523M [02:25<18:10, 210kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  40%|â–| 249M/623M [02:25<22:03,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [flax_model.msgpack]:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 472M/475M [02:26<00:08, 343kB/s]\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  42%|â–Š | 264M/623M [02:27<17:15, 364kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  40%|â–| 250M/623M [02:28<22:09,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [flax_model.msgpack]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 473M/475M [02:29<00:05, 349kB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 305M/523M [02:29<17:32, 217kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  43%|â–Š | 265M/623M [02:30<17:45, 353kB/s]\u001b[A\n",
      "\n",
      "\n",
      "Downloading [flax_model.msgpack]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 474M/475M [02:32<00:02, 359kB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  40%|â–| 251M/623M [02:33<23:29,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 306M/523M [02:33<16:03, 236kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  43%|â–Š | 266M/623M [02:33<18:08, 344kB/s]\u001b[A\n",
      "\n",
      "\n",
      "Downloading [flax_model.msgpack]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 475M/475M [02:34<00:00, 3.23MB/s]\u001b[A\u001b[A\u001b[A\n",
      "Processing 4 items:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–               | 1.00/4.00 [02:34<07:44, 155s/it]\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 307M/523M [02:35<14:03, 268kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  40%|â–| 252M/623M [02:36<21:56,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  43%|â–Š | 267M/623M [02:36<17:31, 355kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 308M/523M [02:38<12:36, 298kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  43%|â–Š | 268M/623M [02:38<16:48, 370kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  41%|â–| 253M/623M [02:38<20:19,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 309M/523M [02:40<11:10, 334kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  43%|â–Š | 269M/623M [02:41<15:53, 390kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  41%|â–| 254M/623M [02:42<19:59,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  43%|â–Š | 270M/623M [02:43<15:00, 411kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 310M/523M [02:43<10:51, 343kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  41%|â–| 255M/623M [02:44<18:52,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  43%|â–Š | 271M/623M [02:45<14:40, 420kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 311M/523M [02:46<10:14, 361kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  41%|â–| 256M/623M [02:47<18:29,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  44%|â–Š | 272M/623M [02:47<13:58, 439kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 312M/523M [02:49<10:16, 358kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  44%|â–‰ | 273M/623M [02:50<13:27, 455kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  41%|â–| 257M/623M [02:50<18:19,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 313M/523M [02:52<10:06, 363kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  44%|â–‰ | 274M/623M [02:52<13:16, 460kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  41%|â–| 258M/623M [02:53<17:24,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  44%|â–‰ | 275M/623M [02:54<13:41, 445kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 314M/523M [02:54<10:03, 363kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  42%|â–| 259M/623M [02:55<16:57,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  44%|â–‰ | 276M/623M [02:57<13:29, 450kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 315M/523M [02:57<09:46, 371kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  42%|â–| 260M/623M [02:58<16:56,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  44%|â–‰ | 277M/623M [02:59<13:18, 455kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 316M/523M [03:00<09:43, 371kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  45%|â–‰ | 278M/623M [03:01<12:47, 472kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  42%|â–| 261M/623M [03:01<17:25,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 317M/523M [03:02<09:27, 380kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  45%|â–‰ | 279M/623M [03:03<12:51, 468kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  42%|â–| 262M/623M [03:04<17:19,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 318M/523M [03:05<09:25, 379kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  45%|â–‰ | 280M/623M [03:05<12:52, 466kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  42%|â–| 263M/623M [03:07<17:06,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  45%|â–‰ | 281M/623M [03:08<12:54, 464kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 319M/523M [03:08<09:23, 379kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  42%|â–| 264M/623M [03:09<16:37,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  45%|â–‰ | 282M/623M [03:10<13:30, 442kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 320M/523M [03:10<09:01, 393kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  43%|â–| 265M/623M [03:12<16:00,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  45%|â–‰ | 283M/623M [03:13<13:39, 435kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 321M/523M [03:14<09:25, 374kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  43%|â–| 266M/623M [03:15<16:00,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  46%|â–‰ | 284M/623M [03:15<13:03, 454kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 322M/523M [03:17<09:31, 369kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  46%|â–‰ | 285M/623M [03:17<12:35, 470kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  43%|â–| 267M/623M [03:17<16:11,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  46%|â–‰ | 286M/623M [03:19<12:38, 467kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 323M/523M [03:19<09:32, 366kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  43%|â–| 268M/623M [03:20<15:53,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  46%|â–‰ | 287M/623M [03:22<12:48, 459kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 324M/523M [03:22<09:13, 376kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  43%|â–| 269M/623M [03:23<16:19,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  46%|â–‰ | 288M/623M [03:24<12:33, 467kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 325M/523M [03:25<09:24, 367kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  43%|â–| 270M/623M [03:26<16:26,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  46%|â–‰ | 289M/623M [03:26<12:24, 471kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 326M/523M [03:28<09:17, 370kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  47%|â–‰ | 290M/623M [03:28<12:07, 480kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  43%|â–| 271M/623M [03:29<16:33,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  47%|â–‰ | 291M/623M [03:30<12:13, 475kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 327M/523M [03:31<09:09, 374kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  44%|â–| 272M/623M [03:32<16:31,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  47%|â–‰ | 292M/623M [03:33<12:22, 468kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 328M/523M [03:34<09:19, 365kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  44%|â–| 273M/623M [03:34<16:05,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  47%|â–‰ | 293M/623M [03:35<12:07, 476kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 329M/523M [03:36<09:09, 370kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  47%|â–‰ | 294M/623M [03:37<12:04, 477kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  44%|â–| 274M/623M [03:37<16:34,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 330M/523M [03:39<08:40, 388kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  47%|â–‰ | 295M/623M [03:39<12:35, 456kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  44%|â–| 275M/623M [03:40<16:31,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 331M/523M [03:42<08:41, 385kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  47%|â–‰ | 296M/623M [03:42<12:12, 469kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  44%|â–| 276M/623M [03:43<16:13,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  48%|â–‰ | 297M/623M [03:44<12:17, 464kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 332M/523M [03:45<09:03, 368kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  44%|â–| 277M/623M [03:45<15:28,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  48%|â–‰ | 298M/623M [03:46<12:05, 470kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 333M/523M [03:47<08:42, 381kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  45%|â–| 278M/623M [03:48<15:52,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  48%|â–‰ | 299M/623M [03:48<12:21, 459kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 334M/523M [03:50<08:46, 376kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  48%|â–‰ | 300M/623M [03:51<12:12, 463kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  45%|â–| 279M/623M [03:51<15:55,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  48%|â–‰ | 301M/623M [03:53<11:46, 478kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 335M/523M [03:53<08:48, 373kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  45%|â–| 280M/623M [03:54<16:05,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  48%|â–‰ | 302M/623M [03:55<12:00, 468kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 336M/523M [03:56<08:40, 376kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  45%|â–| 281M/623M [03:57<15:55,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  49%|â–‰ | 303M/623M [03:57<11:52, 472kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 337M/523M [03:58<08:36, 377kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  49%|â–‰ | 304M/623M [03:59<11:54, 469kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  45%|â–| 282M/623M [04:00<16:16,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 338M/523M [04:01<08:25, 383kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  49%|â–‰ | 305M/623M [04:02<11:44, 474kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  45%|â–| 283M/623M [04:03<16:42,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  49%|â–‰ | 306M/623M [04:04<11:38, 477kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 339M/523M [04:04<08:28, 379kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  46%|â–| 284M/623M [04:05<16:19,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  49%|â–‰ | 307M/623M [04:06<11:35, 477kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 340M/523M [04:07<08:25, 379kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  49%|â–‰ | 308M/623M [04:08<11:16, 489kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  46%|â–| 285M/623M [04:08<16:20,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 341M/523M [04:10<08:33, 371kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  50%|â–‰ | 309M/623M [04:10<10:51, 506kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  46%|â–| 286M/623M [04:12<16:44,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  50%|â–‰ | 310M/623M [04:12<10:54, 502kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 342M/523M [04:13<08:35, 368kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  50%|â–‰ | 311M/623M [04:14<11:15, 485kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  46%|â–| 287M/623M [04:15<16:43,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 343M/523M [04:15<08:08, 386kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  50%|â–ˆ | 312M/623M [04:17<11:36, 468kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  46%|â–| 288M/623M [04:17<16:17,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 344M/523M [04:18<08:04, 386kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  50%|â–ˆ | 313M/623M [04:19<11:38, 466kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  46%|â–| 289M/623M [04:20<16:14,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 345M/523M [04:21<08:13, 378kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  50%|â–ˆ | 314M/623M [04:21<11:43, 461kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  47%|â–| 290M/623M [04:23<15:40,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 346M/523M [04:23<08:03, 383kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  51%|â–ˆ | 315M/623M [04:24<11:53, 453kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  47%|â–| 291M/623M [04:26<15:31,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 347M/523M [04:26<07:52, 390kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  51%|â–ˆ | 316M/623M [04:26<11:52, 452kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 348M/523M [04:28<07:35, 402kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  47%|â–| 292M/623M [04:28<15:38,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  51%|â–ˆ | 317M/623M [04:29<12:01, 446kB/s]\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  51%|â–ˆ | 318M/623M [04:31<11:51, 450kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 349M/523M [04:31<07:42, 394kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  47%|â–| 293M/623M [04:31<15:22,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  51%|â–ˆ | 319M/623M [04:33<11:51, 448kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 350M/523M [04:34<07:45, 389kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  47%|â–| 294M/623M [04:34<15:38,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  51%|â–ˆ | 320M/623M [04:35<11:22, 466kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 351M/523M [04:36<07:40, 391kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  47%|â–| 295M/623M [04:37<15:16,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  51%|â–ˆ | 321M/623M [04:38<11:58, 441kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 352M/523M [04:39<07:36, 392kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  47%|â–| 296M/623M [04:39<15:01,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  52%|â–ˆ | 322M/623M [04:40<12:01, 438kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 353M/523M [04:42<07:26, 399kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  48%|â–| 297M/623M [04:42<15:00,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  52%|â–ˆ | 323M/623M [04:43<11:47, 445kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 354M/523M [04:44<07:34, 390kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  48%|â–| 298M/623M [04:45<14:50,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  52%|â–ˆ | 324M/623M [04:45<11:39, 449kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 355M/523M [04:47<07:32, 389kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  52%|â–ˆ | 325M/623M [04:47<11:36, 449kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  48%|â–| 299M/623M [04:48<14:49,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  52%|â–ˆ | 326M/623M [04:49<11:22, 457kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 356M/523M [04:50<07:23, 394kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  48%|â–| 300M/623M [04:50<14:41,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  52%|â–ˆ | 327M/623M [04:52<11:20, 457kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357M/523M [04:53<07:43, 375kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  48%|â–| 301M/623M [04:53<15:06,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  53%|â–ˆ | 328M/623M [04:54<10:55, 472kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 358M/523M [04:56<07:39, 376kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  53%|â–ˆ | 329M/623M [04:56<10:51, 474kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  48%|â–| 302M/623M [04:56<15:06,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 359M/523M [04:58<07:18, 391kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  53%|â–ˆ | 330M/623M [04:58<10:49, 474kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  49%|â–| 303M/623M [04:59<15:36,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 360M/523M [05:00<06:59, 407kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  53%|â–ˆ | 331M/623M [05:01<11:32, 443kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  49%|â–| 304M/623M [05:02<15:30,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 361M/523M [05:03<07:00, 403kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  53%|â–ˆ | 332M/623M [05:03<11:21, 448kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  49%|â–| 305M/623M [05:05<15:00,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 362M/523M [05:05<06:44, 416kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  53%|â–ˆ | 333M/623M [05:06<12:07, 419kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  49%|â–| 306M/623M [05:08<14:49,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 363M/523M [05:08<06:43, 415kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  54%|â–ˆ | 334M/623M [05:08<11:48, 428kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  49%|â–| 307M/623M [05:10<14:32,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 364M/523M [05:11<06:47, 409kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  54%|â–ˆ | 335M/623M [05:11<11:41, 431kB/s]\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  54%|â–ˆ | 336M/623M [05:13<11:28, 438kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  49%|â–| 308M/623M [05:13<14:40,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 365M/523M [05:13<06:48, 404kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  54%|â–ˆ | 337M/623M [05:16<11:31, 434kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  50%|â–| 309M/623M [05:16<14:20,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 366M/523M [05:16<06:56, 394kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  54%|â–ˆ | 338M/623M [05:18<11:35, 430kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  50%|â–| 310M/623M [05:18<13:48,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 367M/523M [05:19<06:58, 391kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  54%|â–ˆ | 339M/623M [05:20<11:24, 435kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  50%|â–| 311M/623M [05:21<14:15,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 368M/523M [05:21<06:47, 398kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  55%|â–ˆ | 340M/623M [05:23<11:09, 444kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  50%|â–Œ| 312M/623M [05:24<14:02,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 369M/523M [05:24<06:54, 389kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  55%|â–ˆ | 341M/623M [05:25<11:09, 442kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  50%|â–Œ| 313M/623M [05:26<13:47,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 370M/523M [05:27<06:59, 382kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  55%|â–ˆ | 342M/623M [05:27<10:55, 450kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  50%|â–Œ| 314M/623M [05:29<14:00,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  55%|â–ˆ | 343M/623M [05:29<10:37, 462kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 371M/523M [05:30<06:58, 380kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  55%|â–ˆ | 344M/623M [05:32<11:05, 440kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 372M/523M [05:32<06:36, 399kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  51%|â–Œ| 315M/623M [05:32<14:22,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  55%|â–ˆ | 345M/623M [05:34<10:48, 450kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  51%|â–Œ| 316M/623M [05:35<13:53,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 373M/523M [05:35<06:49, 384kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  56%|â–ˆ | 346M/623M [05:37<10:45, 450kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  51%|â–Œ| 317M/623M [05:37<13:53,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 374M/523M [05:38<06:54, 376kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  56%|â–ˆ | 347M/623M [05:39<10:33, 457kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  51%|â–Œ| 318M/623M [05:40<13:57,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 375M/523M [05:41<06:38, 389kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  56%|â–ˆ | 348M/623M [05:41<10:41, 450kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  51%|â–Œ| 319M/623M [05:43<13:45,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  56%|â–ˆ | 349M/623M [05:43<10:26, 459kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 376M/523M [05:43<06:46, 378kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  51%|â–Œ| 320M/623M [05:46<13:55,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 377M/523M [05:46<06:28, 393kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  56%|â–ˆ | 350M/623M [05:46<10:42, 446kB/s]\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  56%|â–ˆâ–| 351M/623M [05:48<10:31, 453kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  51%|â–Œ| 321M/623M [05:49<13:58,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 378M/523M [05:49<06:27, 392kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  56%|â–ˆâ–| 352M/623M [05:51<10:43, 443kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  52%|â–Œ| 322M/623M [05:51<13:50,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 379M/523M [05:51<06:30, 386kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  57%|â–ˆâ–| 353M/623M [05:53<10:24, 454kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 380M/523M [05:54<06:17, 397kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  52%|â–Œ| 323M/623M [05:54<14:18,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  57%|â–ˆâ–| 354M/623M [05:55<10:29, 449kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 381M/523M [05:56<06:06, 405kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  52%|â–Œ| 324M/623M [05:57<14:21,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  57%|â–ˆâ–| 355M/623M [05:58<10:24, 450kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 382M/523M [05:59<05:55, 415kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  57%|â–ˆâ–| 356M/623M [06:00<10:23, 450kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  52%|â–Œ| 325M/623M [06:00<14:36,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 383M/523M [06:01<06:02, 404kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  57%|â–ˆâ–| 357M/623M [06:02<10:07, 460kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  52%|â–Œ| 326M/623M [06:03<14:49,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 384M/523M [06:04<05:56, 408kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  57%|â–ˆâ–| 358M/623M [06:04<09:56, 467kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  52%|â–Œ| 327M/623M [06:06<14:29,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  58%|â–ˆâ–| 359M/623M [06:07<10:15, 450kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 385M/523M [06:07<06:03, 397kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  53%|â–Œ| 328M/623M [06:09<14:07,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  58%|â–ˆâ–| 360M/623M [06:09<10:07, 454kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 386M/523M [06:09<06:00, 398kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  58%|â–ˆâ–| 361M/623M [06:11<09:55, 462kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  53%|â–Œ| 329M/623M [06:12<14:19,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 387M/523M [06:12<05:58, 397kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  58%|â–ˆâ–| 362M/623M [06:14<10:25, 438kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 388M/523M [06:14<05:44, 410kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  53%|â–Œ| 330M/623M [06:15<14:15,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  58%|â–ˆâ–| 363M/623M [06:16<09:57, 457kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 389M/523M [06:17<05:49, 401kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  53%|â–Œ| 331M/623M [06:18<13:59,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  58%|â–ˆâ–| 364M/623M [06:18<09:59, 453kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 390M/523M [06:20<05:49, 398kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  59%|â–ˆâ–| 365M/623M [06:20<09:35, 470kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  53%|â–Œ| 332M/623M [06:21<14:08,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  59%|â–ˆâ–| 366M/623M [06:22<09:31, 472kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 391M/523M [06:23<06:05, 378kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  53%|â–Œ| 333M/623M [06:23<13:22,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  59%|â–ˆâ–| 367M/623M [06:25<09:41, 463kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 392M/523M [06:26<06:05, 375kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  54%|â–Œ| 334M/623M [06:26<13:18,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  59%|â–ˆâ–| 368M/623M [06:27<09:43, 459kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  54%|â–Œ| 335M/623M [06:29<13:10,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 393M/523M [06:29<06:01, 376kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  59%|â–ˆâ–| 369M/623M [06:30<09:47, 454kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  54%|â–Œ| 336M/623M [06:31<13:10,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  59%|â–ˆâ–| 370M/623M [06:31<09:16, 477kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 394M/523M [06:32<06:08, 366kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  60%|â–ˆâ–| 371M/623M [06:34<09:13, 478kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  54%|â–Œ| 337M/623M [06:34<13:09,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 395M/523M [06:35<06:17, 355kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  60%|â–ˆâ–| 372M/623M [06:36<09:19, 471kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  54%|â–Œ| 338M/623M [06:37<12:40,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 396M/523M [06:38<06:05, 363kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  60%|â–ˆâ–| 373M/623M [06:38<09:25, 464kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  54%|â–Œ| 339M/623M [06:39<12:52,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 397M/523M [06:40<05:53, 373kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  60%|â–ˆâ–| 374M/623M [06:41<09:40, 451kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  55%|â–Œ| 340M/623M [06:42<13:02,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  60%|â–ˆâ–| 375M/623M [06:43<09:16, 468kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 398M/523M [06:43<05:55, 368kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  55%|â–Œ| 341M/623M [06:45<12:39,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  60%|â–ˆâ–| 376M/623M [06:45<09:14, 468kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 399M/523M [06:46<05:46, 375kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  55%|â–Œ| 342M/623M [06:48<12:44,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  60%|â–ˆâ–| 377M/623M [06:48<09:31, 452kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 400M/523M [06:48<05:40, 378kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  61%|â–ˆâ–| 378M/623M [06:50<09:10, 468kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  55%|â–Œ| 343M/623M [06:51<13:13,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 401M/523M [06:51<05:32, 383kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  61%|â–ˆâ–| 379M/623M [06:52<09:14, 462kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  55%|â–Œ| 344M/623M [06:54<13:18,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 402M/523M [06:54<05:32, 381kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  61%|â–ˆâ–| 380M/623M [06:54<08:54, 477kB/s]\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  61%|â–ˆâ–| 381M/623M [06:56<08:57, 473kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  55%|â–Œ| 345M/623M [06:56<13:08,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 403M/523M [06:57<05:32, 377kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  61%|â–ˆâ–| 382M/623M [06:58<08:40, 487kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 404M/523M [06:59<05:25, 382kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  56%|â–Œ| 346M/623M [07:00<13:39,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  61%|â–ˆâ–| 383M/623M [07:01<08:44, 481kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 405M/523M [07:02<05:15, 391kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  56%|â–Œ| 347M/623M [07:02<13:28,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  62%|â–ˆâ–| 384M/623M [07:03<08:59, 466kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 406M/523M [07:04<05:05, 401kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  62%|â–ˆâ–| 385M/623M [07:05<08:53, 468kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  56%|â–Œ| 348M/623M [07:06<13:40,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 407M/523M [07:07<05:02, 402kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  62%|â–ˆâ–| 386M/623M [07:07<08:52, 468kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  56%|â–Œ| 349M/623M [07:08<13:33,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 408M/523M [07:10<04:56, 406kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  62%|â–ˆâ–| 387M/623M [07:10<09:09, 451kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  56%|â–Œ| 350M/623M [07:11<13:04,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  62%|â–ˆâ–| 388M/623M [07:12<08:42, 473kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 409M/523M [07:13<05:13, 381kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  56%|â–Œ| 351M/623M [07:14<12:42,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  62%|â–ˆâ–| 389M/623M [07:15<09:18, 440kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 410M/523M [07:15<05:03, 390kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  56%|â–Œ| 352M/623M [07:16<12:28,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  63%|â–ˆâ–| 390M/623M [07:17<09:09, 445kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 411M/523M [07:18<05:05, 384kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  57%|â–Œ| 353M/623M [07:19<12:19,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  63%|â–ˆâ–| 391M/623M [07:19<09:06, 446kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 412M/523M [07:21<05:00, 386kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  63%|â–ˆâ–| 392M/623M [07:21<08:51, 457kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  57%|â–Œ| 354M/623M [07:22<12:26,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 413M/523M [07:23<04:58, 385kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  63%|â–ˆâ–| 393M/623M [07:24<08:36, 467kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  57%|â–Œ| 355M/623M [07:25<12:55,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  63%|â–ˆâ–| 394M/623M [07:26<08:41, 461kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 414M/523M [07:26<04:48, 395kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  57%|â–Œ| 356M/623M [07:28<12:58,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  63%|â–ˆâ–| 395M/623M [07:28<08:34, 465kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 415M/523M [07:29<04:50, 388kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  64%|â–ˆâ–| 396M/623M [07:30<08:21, 475kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  57%|â–Œ| 357M/623M [07:31<12:35,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 416M/523M [07:32<04:57, 376kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  64%|â–ˆâ–| 397M/623M [07:32<08:21, 474kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  57%|â–Œ| 358M/623M [07:34<12:35,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  64%|â–ˆâ–| 398M/623M [07:35<08:13, 479kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 417M/523M [07:35<04:59, 370kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  58%|â–Œ| 359M/623M [07:36<12:08,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  64%|â–ˆâ–| 399M/623M [07:37<08:03, 487kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 418M/523M [07:38<05:01, 365kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  64%|â–ˆâ–| 400M/623M [07:39<08:08, 479kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  58%|â–Œ| 360M/623M [07:39<12:28,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 419M/523M [07:40<04:46, 379kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  64%|â–ˆâ–| 401M/623M [07:42<08:36, 452kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  58%|â–Œ| 361M/623M [07:42<12:25,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 420M/523M [07:43<04:45, 377kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  64%|â–ˆâ–| 402M/623M [07:44<08:29, 456kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  58%|â–Œ| 362M/623M [07:45<12:08,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 421M/523M [07:46<04:42, 378kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  65%|â–ˆâ–| 403M/623M [07:46<08:19, 462kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  58%|â–Œ| 363M/623M [07:48<12:18,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  65%|â–ˆâ–| 404M/623M [07:48<08:15, 464kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 422M/523M [07:48<04:33, 387kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  58%|â–Œ| 364M/623M [07:50<12:06,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  65%|â–ˆâ–| 405M/623M [07:50<08:09, 468kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 423M/523M [07:51<04:36, 379kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  65%|â–ˆâ–| 406M/623M [07:53<08:16, 459kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  59%|â–Œ| 365M/623M [07:53<11:44,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 424M/523M [07:54<04:32, 380kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  65%|â–ˆâ–| 407M/623M [07:55<08:04, 468kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  59%|â–Œ| 366M/623M [07:56<12:07,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 425M/523M [07:57<04:25, 386kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  65%|â–ˆâ–| 408M/623M [07:57<08:12, 458kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  59%|â–Œ| 367M/623M [07:59<12:10,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 426M/523M [07:59<04:23, 384kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  66%|â–ˆâ–| 409M/623M [08:00<08:07, 462kB/s]\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  66%|â–ˆâ–| 410M/623M [08:02<07:55, 470kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  59%|â–Œ| 368M/623M [08:02<12:08,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 427M/523M [08:02<04:28, 373kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  66%|â–ˆâ–| 411M/623M [08:04<07:59, 464kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  59%|â–Œ| 369M/623M [08:04<11:42,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 428M/523M [08:05<04:26, 372kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  66%|â–ˆâ–| 412M/623M [08:06<07:48, 474kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  59%|â–Œ| 370M/623M [08:07<11:57,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 429M/523M [08:08<04:19, 379kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  66%|â–ˆâ–| 413M/623M [08:08<07:45, 474kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  60%|â–Œ| 371M/623M [08:10<11:51,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 430M/523M [08:10<04:11, 386kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  66%|â–ˆâ–| 414M/623M [08:11<07:55, 462kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  60%|â–Œ| 372M/623M [08:13<11:28,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  67%|â–ˆâ–| 415M/623M [08:13<07:51, 463kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 431M/523M [08:14<04:19, 371kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  67%|â–ˆâ–| 416M/623M [08:15<07:36, 476kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  60%|â–Œ| 373M/623M [08:16<11:53,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 432M/523M [08:16<04:12, 376kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  67%|â–ˆâ–| 417M/623M [08:18<07:49, 461kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  60%|â–Œ| 374M/623M [08:18<11:38,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 433M/523M [08:19<04:06, 382kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  67%|â–ˆâ–| 418M/623M [08:20<07:46, 461kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  60%|â–Œ| 375M/623M [08:21<11:29,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  67%|â–ˆâ–| 419M/623M [08:22<07:25, 481kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 434M/523M [08:22<04:12, 368kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  67%|â–ˆâ–| 420M/623M [08:24<07:26, 478kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  60%|â–Œ| 376M/623M [08:24<11:47,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 435M/523M [08:25<04:03, 378kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  68%|â–ˆâ–| 421M/623M [08:26<07:22, 480kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  60%|â–Œ| 377M/623M [08:27<11:27,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  68%|â–ˆâ–| 422M/623M [08:28<06:47, 518kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 436M/523M [08:29<04:41, 322kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  61%|â–Œ| 378M/623M [08:29<10:57,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  68%|â–ˆâ–| 423M/623M [08:30<06:54, 507kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 437M/523M [08:32<04:22, 342kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  61%|â–Œ| 379M/623M [08:32<10:54,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  68%|â–ˆâ–| 424M/623M [08:32<07:17, 478kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 438M/523M [08:34<04:08, 357kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  68%|â–ˆâ–| 425M/623M [08:35<07:18, 474kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  61%|â–Œ| 380M/623M [08:35<11:04,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 439M/523M [08:37<03:58, 368kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  68%|â–ˆâ–| 426M/623M [08:37<07:16, 475kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  61%|â–Œ| 381M/623M [08:38<11:10,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  68%|â–ˆâ–| 427M/623M [08:39<07:21, 466kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 440M/523M [08:40<03:57, 364kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  61%|â–Œ| 382M/623M [08:40<10:59,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  69%|â–ˆâ–| 428M/623M [08:41<07:11, 475kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 441M/523M [08:43<04:00, 357kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  61%|â–Œ| 383M/623M [08:43<11:04,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  69%|â–ˆâ–| 429M/623M [08:43<06:55, 491kB/s]\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  69%|â–ˆâ–| 430M/623M [08:46<07:02, 480kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  62%|â–Œ| 384M/623M [08:46<10:56,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 442M/523M [08:46<03:58, 354kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  69%|â–ˆâ–| 431M/623M [08:48<07:17, 461kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  62%|â–Œ| 385M/623M [08:48<10:44,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 443M/523M [08:48<03:47, 367kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  69%|â–ˆâ–| 432M/623M [08:50<07:19, 457kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  62%|â–Œ| 386M/623M [08:51<10:26,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 444M/523M [08:51<03:46, 364kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  69%|â–ˆâ–| 433M/623M [08:53<07:30, 444kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  62%|â–Œ| 387M/623M [08:54<10:30,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 445M/523M [08:54<03:36, 376kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  70%|â–ˆâ–| 434M/623M [08:55<07:10, 462kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  62%|â–Œ| 388M/623M [08:56<10:31,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 446M/523M [08:57<03:41, 363kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  70%|â–ˆâ–| 435M/623M [08:57<06:59, 470kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  62%|â–Œ| 389M/623M [08:59<10:23,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  70%|â–ˆâ–| 436M/623M [08:59<07:03, 464kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 447M/523M [09:00<03:41, 359kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  63%|â–‹| 390M/623M [09:02<10:26,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  70%|â–ˆâ–| 437M/623M [09:02<07:08, 456kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 448M/523M [09:03<03:27, 377kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  70%|â–ˆâ–| 438M/623M [09:04<07:05, 457kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  63%|â–‹| 391M/623M [09:05<10:36,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 449M/523M [09:05<03:27, 373kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  70%|â–ˆâ–| 439M/623M [09:06<06:54, 467kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  63%|â–‹| 392M/623M [09:07<10:13,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  71%|â–ˆâ–| 440M/623M [09:09<06:52, 466kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 450M/523M [09:09<03:33, 357kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  63%|â–‹| 393M/623M [09:10<10:12,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  71%|â–ˆâ–| 441M/623M [09:11<07:02, 452kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 451M/523M [09:11<03:26, 365kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  63%|â–‹| 394M/623M [09:12<10:07,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  71%|â–ˆâ–| 442M/623M [09:13<07:06, 446kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 452M/523M [09:14<03:14, 382kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  63%|â–‹| 395M/623M [09:15<10:03,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  71%|â–ˆâ–| 443M/623M [09:16<07:10, 440kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 453M/523M [09:16<03:06, 393kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  64%|â–‹| 396M/623M [09:18<10:25,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  71%|â–ˆâ–| 444M/623M [09:18<07:05, 442kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 454M/523M [09:19<03:07, 383kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  71%|â–ˆâ–| 445M/623M [09:21<06:56, 449kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  64%|â–‹| 397M/623M [09:21<10:15,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 455M/523M [09:22<03:08, 377kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  72%|â–ˆâ–| 446M/623M [09:23<06:50, 453kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  64%|â–‹| 398M/623M [09:23<10:19,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 456M/523M [09:25<03:00, 389kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  72%|â–ˆâ–| 447M/623M [09:25<06:54, 446kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  64%|â–‹| 399M/623M [09:26<10:19,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  72%|â–ˆâ–| 448M/623M [09:27<06:41, 458kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 457M/523M [09:28<03:01, 379kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  64%|â–‹| 400M/623M [09:29<10:28,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  72%|â–ˆâ–| 449M/623M [09:30<06:30, 468kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 458M/523M [09:30<02:57, 381kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  64%|â–‹| 401M/623M [09:32<10:14,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  72%|â–ˆâ–| 450M/623M [09:32<06:33, 462kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 459M/523M [09:33<02:49, 395kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  72%|â–ˆâ–| 451M/623M [09:34<06:20, 475kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  64%|â–‹| 402M/623M [09:35<10:56,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 460M/523M [09:36<02:49, 388kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  73%|â–ˆâ–| 452M/623M [09:36<06:15, 478kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  65%|â–‹| 403M/623M [09:38<10:43,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  73%|â–ˆâ–| 453M/623M [09:38<06:06, 488kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 461M/523M [09:39<02:55, 370kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  73%|â–ˆâ–| 454M/623M [09:40<05:56, 498kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  65%|â–‹| 404M/623M [09:41<10:38,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 462M/523M [09:42<02:58, 356kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  73%|â–ˆâ–| 455M/623M [09:42<05:46, 509kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  65%|â–‹| 405M/623M [09:44<10:29,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  73%|â–ˆâ–| 456M/623M [09:44<05:54, 496kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 463M/523M [09:45<02:55, 356kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  65%|â–‹| 406M/623M [09:46<10:04,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  73%|â–ˆâ–| 457M/623M [09:47<05:58, 486kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 464M/523M [09:48<02:49, 362kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  73%|â–ˆâ–| 458M/623M [09:49<06:03, 477kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  65%|â–‹| 407M/623M [09:49<09:55,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 465M/523M [09:51<02:49, 357kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  74%|â–ˆâ–| 459M/623M [09:51<06:12, 462kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  65%|â–‹| 408M/623M [09:52<09:43,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  74%|â–ˆâ–| 460M/623M [09:53<06:01, 474kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 466M/523M [09:53<02:44, 361kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  66%|â–‹| 409M/623M [09:55<10:14,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  74%|â–ˆâ–| 461M/623M [09:55<05:45, 493kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 467M/523M [09:56<02:40, 364kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  74%|â–ˆâ–| 462M/623M [09:58<05:53, 479kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  66%|â–‹| 410M/623M [09:58<10:21,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 468M/523M [09:59<02:31, 379kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  74%|â–ˆâ–| 463M/623M [10:00<05:58, 469kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  66%|â–‹| 411M/623M [10:01<10:04,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 469M/523M [10:02<02:33, 367kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  74%|â–ˆâ–| 464M/623M [10:02<05:41, 489kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  66%|â–‹| 412M/623M [10:03<09:59,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  75%|â–ˆâ–| 465M/623M [10:04<05:42, 485kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 470M/523M [10:05<02:28, 372kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  66%|â–‹| 413M/623M [10:06<09:47,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  75%|â–ˆâ–| 466M/623M [10:07<05:56, 462kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 471M/523M [10:07<02:24, 376kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  66%|â–‹| 414M/623M [10:09<09:40,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  75%|â–ˆâ–| 467M/623M [10:09<05:51, 467kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 472M/523M [10:10<02:20, 378kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  75%|â–ˆâ–Œ| 468M/623M [10:11<05:55, 459kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  67%|â–‹| 415M/623M [10:12<09:41,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 473M/523M [10:13<02:13, 390kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  75%|â–ˆâ–Œ| 469M/623M [10:14<06:02, 446kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  67%|â–‹| 416M/623M [10:14<09:26,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 474M/523M [10:15<02:10, 392kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  75%|â–ˆâ–Œ| 470M/623M [10:16<06:03, 443kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  67%|â–‹| 417M/623M [10:17<09:26,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 475M/523M [10:18<02:09, 385kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  76%|â–ˆâ–Œ| 471M/623M [10:18<05:59, 445kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  67%|â–‹| 418M/623M [10:20<09:26,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 476M/523M [10:21<02:06, 389kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  76%|â–ˆâ–Œ| 472M/623M [10:21<05:53, 449kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  67%|â–‹| 419M/623M [10:23<09:30,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  76%|â–ˆâ–Œ| 473M/623M [10:23<05:37, 467kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 477M/523M [10:24<02:09, 371kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  76%|â–ˆâ–Œ| 474M/623M [10:25<05:31, 472kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  67%|â–‹| 420M/623M [10:26<09:32,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 478M/523M [10:26<02:01, 386kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  76%|â–ˆâ–Œ| 475M/623M [10:27<05:34, 465kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  68%|â–‹| 421M/623M [10:28<09:37,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 479M/523M [10:29<01:55, 397kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  76%|â–ˆâ–Œ| 476M/623M [10:30<05:40, 454kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  68%|â–‹| 422M/623M [10:31<09:20,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 480M/523M [10:32<01:58, 378kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  77%|â–ˆâ–Œ| 477M/623M [10:32<05:38, 453kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  68%|â–‹| 423M/623M [10:33<08:46,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  77%|â–ˆâ–Œ| 478M/623M [10:34<05:32, 459kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 481M/523M [10:35<01:58, 370kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  68%|â–‹| 424M/623M [10:36<09:07,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  77%|â–ˆâ–Œ| 479M/623M [10:36<05:22, 469kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 482M/523M [10:38<01:56, 367kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  77%|â–ˆâ–Œ| 480M/623M [10:39<05:24, 463kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  68%|â–‹| 425M/623M [10:39<09:15,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 483M/523M [10:40<01:49, 381kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  77%|â–ˆâ–Œ| 481M/623M [10:41<05:29, 453kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  68%|â–‹| 426M/623M [10:42<09:16,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 484M/523M [10:43<01:42, 398kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  77%|â–ˆâ–Œ| 482M/623M [10:43<05:25, 455kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  68%|â–‹| 427M/623M [10:45<09:08,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  77%|â–ˆâ–Œ| 483M/623M [10:46<05:17, 464kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 485M/523M [10:46<01:44, 378kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  69%|â–‹| 428M/623M [10:47<08:54,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  78%|â–ˆâ–Œ| 484M/623M [10:48<05:14, 465kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 486M/523M [10:49<01:43, 371kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  78%|â–ˆâ–Œ| 485M/623M [10:50<05:12, 464kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  69%|â–‹| 429M/623M [10:50<08:54,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 487M/523M [10:51<01:38, 378kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  78%|â–ˆâ–Œ| 486M/623M [10:52<05:13, 460kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  69%|â–‹| 430M/623M [10:53<09:02,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 488M/523M [10:54<01:36, 377kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  78%|â–ˆâ–Œ| 487M/623M [10:55<05:09, 462kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  69%|â–‹| 431M/623M [10:56<08:44,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 489M/523M [10:57<01:33, 377kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  78%|â–ˆâ–Œ| 488M/623M [10:57<05:17, 447kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  69%|â–‹| 432M/623M [10:59<08:49,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 490M/523M [10:59<01:28, 390kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  78%|â–ˆâ–Œ| 489M/623M [10:59<05:06, 460kB/s]\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  79%|â–ˆâ–Œ| 490M/623M [11:01<04:59, 467kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  69%|â–‹| 433M/623M [11:02<08:59,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 491M/523M [11:02<01:25, 390kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  79%|â–ˆâ–Œ| 491M/623M [11:04<05:04, 456kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  70%|â–‹| 434M/623M [11:05<09:00,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 492M/523M [11:05<01:21, 397kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  79%|â–ˆâ–Œ| 492M/623M [11:06<05:03, 454kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  70%|â–‹| 435M/623M [11:07<08:47,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 493M/523M [11:07<01:19, 394kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  79%|â–ˆâ–Œ| 493M/623M [11:09<05:06, 446kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 494M/523M [11:10<01:16, 393kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  70%|â–‹| 436M/623M [11:10<08:49,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  79%|â–ˆâ–Œ| 494M/623M [11:11<05:00, 452kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 495M/523M [11:13<01:14, 388kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  79%|â–ˆâ–Œ| 495M/623M [11:13<04:49, 465kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  70%|â–‹| 437M/623M [11:13<08:55,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 496M/523M [11:15<01:10, 399kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  80%|â–ˆâ–Œ| 496M/623M [11:15<04:53, 455kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  70%|â–‹| 438M/623M [11:16<08:41,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 497M/523M [11:18<01:07, 400kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  80%|â–ˆâ–Œ| 497M/623M [11:18<04:53, 451kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  70%|â–‹| 439M/623M [11:19<08:44,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  80%|â–ˆâ–Œ| 498M/623M [11:20<04:51, 451kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 498M/523M [11:20<01:03, 405kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  71%|â–‹| 440M/623M [11:21<08:38,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  80%|â–ˆâ–Œ| 499M/623M [11:22<04:43, 460kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 499M/523M [11:24<01:08, 361kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  71%|â–‹| 441M/623M [11:24<08:23,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  80%|â–ˆâ–Œ| 500M/623M [11:24<04:30, 478kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 500M/523M [11:26<01:01, 390kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  80%|â–ˆâ–Œ| 501M/623M [11:27<04:32, 471kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  71%|â–‹| 442M/623M [11:27<08:36,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 501M/523M [11:29<00:59, 383kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  81%|â–ˆâ–Œ| 502M/623M [11:29<04:39, 456kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  71%|â–‹| 443M/623M [11:30<08:32,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 502M/523M [11:31<00:53, 405kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  81%|â–ˆâ–Œ| 503M/623M [11:32<04:45, 442kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  71%|â–‹| 444M/623M [11:33<08:20,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  81%|â–ˆâ–Œ| 504M/623M [11:34<04:35, 455kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 503M/523M [11:34<00:52, 393kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  71%|â–‹| 445M/623M [11:36<08:38,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  81%|â–ˆâ–Œ| 505M/623M [11:36<04:28, 463kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 504M/523M [11:37<00:49, 393kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  72%|â–‹| 446M/623M [11:38<08:15,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  81%|â–ˆâ–Œ| 506M/623M [11:38<04:34, 449kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 505M/523M [11:40<00:48, 383kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  81%|â–ˆâ–‹| 507M/623M [11:41<04:22, 465kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  72%|â–‹| 447M/623M [11:41<08:22,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 506M/523M [11:43<00:46, 376kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  81%|â–ˆâ–‹| 508M/623M [11:43<04:16, 472kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  72%|â–‹| 448M/623M [11:44<08:15,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  82%|â–ˆâ–‹| 509M/623M [11:45<04:15, 470kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 507M/523M [11:45<00:43, 377kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  72%|â–‹| 449M/623M [11:47<08:13,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  82%|â–ˆâ–‹| 510M/623M [11:47<04:14, 468kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 508M/523M [11:48<00:40, 377kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  82%|â–ˆâ–‹| 511M/623M [11:49<04:03, 484kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  72%|â–‹| 450M/623M [11:50<08:15,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 509M/523M [11:51<00:38, 370kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  82%|â–ˆâ–‹| 512M/623M [11:51<04:00, 485kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  72%|â–‹| 451M/623M [11:53<08:07,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 510M/523M [11:54<00:35, 379kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  82%|â–ˆâ–‹| 513M/623M [11:54<04:05, 471kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  73%|â–‹| 452M/623M [11:56<08:13,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  82%|â–ˆâ–‹| 514M/623M [11:56<03:58, 481kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 511M/523M [11:57<00:33, 372kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  83%|â–ˆâ–‹| 515M/623M [11:58<03:56, 480kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  73%|â–‹| 453M/623M [11:58<08:12,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 512M/523M [11:59<00:29, 380kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  83%|â–ˆâ–‹| 516M/623M [12:00<04:02, 464kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  73%|â–‹| 454M/623M [12:01<07:54,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 513M/523M [12:02<00:26, 379kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  83%|â–ˆâ–‹| 517M/623M [12:02<03:55, 474kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  73%|â–‹| 455M/623M [12:04<07:50,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 514M/523M [12:05<00:24, 376kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  83%|â–ˆâ–‹| 518M/623M [12:05<03:58, 464kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  73%|â–‹| 456M/623M [12:07<07:56,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  83%|â–ˆâ–‹| 519M/623M [12:07<03:57, 461kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 515M/523M [12:07<00:21, 384kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  73%|â–‹| 457M/623M [12:09<07:40,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  83%|â–ˆâ–‹| 520M/623M [12:10<04:03, 445kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 516M/523M [12:10<00:17, 395kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  84%|â–ˆâ–‹| 521M/623M [12:12<03:55, 456kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  73%|â–‹| 458M/623M [12:12<07:45,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 517M/523M [12:13<00:15, 394kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  84%|â–ˆâ–‹| 522M/623M [12:14<03:57, 448kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  74%|â–‹| 459M/623M [12:15<07:24,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 518M/523M [12:15<00:12, 388kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  84%|â–ˆâ–‹| 523M/623M [12:17<04:02, 434kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  74%|â–‹| 460M/623M [12:17<07:15,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 519M/523M [12:18<00:10, 378kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  84%|â–ˆâ–‹| 524M/623M [12:19<03:48, 456kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  74%|â–‹| 461M/623M [12:20<07:29,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  84%|â–ˆâ–‹| 525M/623M [12:21<03:42, 463kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 520M/523M [12:21<00:07, 375kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  84%|â–ˆâ–‹| 526M/623M [12:23<03:30, 485kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  74%|â–‹| 462M/623M [12:23<07:37,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 521M/523M [12:24<00:04, 360kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  85%|â–ˆâ–‹| 527M/623M [12:25<03:22, 498kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  74%|â–‹| 463M/623M [12:26<07:34,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  85%|â–ˆâ–‹| 528M/623M [12:27<03:23, 490kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 522M/523M [12:27<00:02, 355kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  74%|â–‹| 464M/623M [12:29<07:25,\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 523M/523M [12:29<00:00, 731kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Processing 4 items:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ          | 2.00/4.00 [12:30<13:48, 414s/it]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  75%|â–‹| 465M/623M [12:31<06:43,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  85%|â–ˆâ–‹| 530M/623M [12:31<03:03, 534kB/s]\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  85%|â–ˆâ–‹| 531M/623M [12:33<02:52, 562kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  75%|â–‹| 466M/623M [12:33<06:08,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  85%|â–ˆâ–‹| 532M/623M [12:34<02:43, 587kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  75%|â–‹| 467M/623M [12:35<05:47,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  86%|â–ˆâ–‹| 533M/623M [12:36<02:32, 621kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  75%|â–Š| 468M/623M [12:37<05:38,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  86%|â–ˆâ–‹| 534M/623M [12:37<02:26, 639kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  75%|â–Š| 469M/623M [12:38<05:17,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  86%|â–ˆâ–‹| 535M/623M [12:39<02:23, 644kB/s]\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  86%|â–ˆâ–‹| 536M/623M [12:40<02:16, 671kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  75%|â–Š| 470M/623M [12:41<05:18,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  86%|â–ˆâ–‹| 537M/623M [12:42<02:15, 667kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  76%|â–Š| 471M/623M [12:43<05:12,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  86%|â–ˆâ–‹| 538M/623M [12:43<02:12, 675kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  76%|â–Š| 472M/623M [12:44<04:56,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  86%|â–ˆâ–‹| 539M/623M [12:45<02:13, 664kB/s]\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  87%|â–ˆâ–‹| 540M/623M [12:46<02:09, 677kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  76%|â–Š| 473M/623M [12:46<05:00,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  87%|â–ˆâ–‹| 541M/623M [12:48<02:07, 678kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  76%|â–Š| 474M/623M [12:48<04:55,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  87%|â–ˆâ–‹| 542M/623M [12:49<02:05, 681kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  76%|â–Š| 475M/623M [12:50<04:50,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  87%|â–ˆâ–‹| 543M/623M [12:51<02:04, 678kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  76%|â–Š| 476M/623M [12:52<04:46,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  87%|â–ˆâ–‹| 544M/623M [12:53<02:02, 677kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  77%|â–Š| 477M/623M [12:54<04:32,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  87%|â–ˆâ–‹| 545M/623M [12:54<02:07, 646kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  77%|â–Š| 478M/623M [12:56<04:31,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  88%|â–ˆâ–Š| 546M/623M [12:56<02:03, 658kB/s]\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  88%|â–ˆâ–Š| 547M/623M [12:57<02:00, 667kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  77%|â–Š| 479M/623M [12:58<04:40,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  88%|â–ˆâ–Š| 548M/623M [12:59<01:59, 663kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  77%|â–Š| 480M/623M [13:00<04:27,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  88%|â–ˆâ–Š| 549M/623M [13:01<01:59, 655kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  77%|â–Š| 481M/623M [13:01<04:28,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  88%|â–ˆâ–Š| 550M/623M [13:02<01:56, 663kB/s]\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  88%|â–ˆâ–Š| 551M/623M [13:04<01:48, 698kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  77%|â–Š| 482M/623M [13:04<04:39,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  89%|â–ˆâ–Š| 552M/623M [13:05<01:47, 694kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  77%|â–Š| 483M/623M [13:06<04:35,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  89%|â–ˆâ–Š| 553M/623M [13:07<01:47, 686kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  78%|â–Š| 484M/623M [13:08<04:41,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  89%|â–ˆâ–Š| 554M/623M [13:08<01:42, 706kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  78%|â–Š| 485M/623M [13:10<04:33,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  89%|â–ˆâ–Š| 555M/623M [13:10<01:44, 689kB/s]\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  89%|â–ˆâ–Š| 556M/623M [13:11<01:41, 696kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  78%|â–Š| 486M/623M [13:12<04:37,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  89%|â–ˆâ–Š| 557M/623M [13:13<01:38, 706kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  78%|â–Š| 487M/623M [13:14<04:34,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  90%|â–ˆâ–Š| 558M/623M [13:14<01:37, 701kB/s]\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  90%|â–ˆâ–Š| 559M/623M [13:16<01:37, 694kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  78%|â–Š| 488M/623M [13:16<04:28,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  90%|â–ˆâ–Š| 560M/623M [13:17<01:35, 696kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  78%|â–Š| 489M/623M [13:18<04:30,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  90%|â–ˆâ–Š| 561M/623M [13:19<01:33, 703kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  79%|â–Š| 490M/623M [13:20<04:36,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  90%|â–ˆâ–Š| 562M/623M [13:20<01:31, 706kB/s]\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  90%|â–ˆâ–Š| 563M/623M [13:22<01:29, 708kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  79%|â–Š| 491M/623M [13:22<04:27,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  90%|â–ˆâ–Š| 564M/623M [13:23<01:26, 717kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  79%|â–Š| 492M/623M [13:24<04:31,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  91%|â–ˆâ–Š| 565M/623M [13:24<01:27, 702kB/s]\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  91%|â–ˆâ–Š| 566M/623M [13:26<01:25, 705kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  79%|â–Š| 493M/623M [13:26<04:26,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  91%|â–ˆâ–Š| 567M/623M [13:28<01:26, 682kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  79%|â–Š| 494M/623M [13:28<04:11,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  91%|â–ˆâ–Š| 568M/623M [13:29<01:26, 672kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  79%|â–Š| 495M/623M [13:30<04:13,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  91%|â–ˆâ–Š| 569M/623M [13:31<01:22, 692kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  80%|â–Š| 496M/623M [13:32<04:13,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  91%|â–ˆâ–Š| 570M/623M [13:32<01:22, 678kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  80%|â–Š| 497M/623M [13:33<03:59,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  92%|â–ˆâ–Š| 571M/623M [13:34<01:21, 671kB/s]\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  92%|â–ˆâ–Š| 572M/623M [13:35<01:20, 673kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  80%|â–Š| 498M/623M [13:35<04:01,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  92%|â–ˆâ–Š| 573M/623M [13:37<01:17, 681kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  80%|â–Š| 499M/623M [13:37<04:00,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  92%|â–ˆâ–Š| 574M/623M [13:38<01:15, 687kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  80%|â–Š| 500M/623M [13:40<04:08,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  92%|â–ˆâ–Š| 575M/623M [13:40<01:13, 690kB/s]\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  92%|â–ˆâ–Š| 576M/623M [13:41<01:11, 695kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  80%|â–Š| 501M/623M [13:42<04:03,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  93%|â–ˆâ–Š| 577M/623M [13:43<01:08, 711kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  81%|â–Š| 502M/623M [13:44<04:10,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  93%|â–ˆâ–Š| 578M/623M [13:44<01:06, 721kB/s]\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  93%|â–ˆâ–Š| 579M/623M [13:46<01:06, 702kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  81%|â–Š| 503M/623M [13:46<04:09,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  93%|â–ˆâ–Š| 580M/623M [13:47<01:04, 706kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  81%|â–Š| 504M/623M [13:48<04:01,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  93%|â–ˆâ–Š| 581M/623M [13:49<01:03, 694kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  81%|â–Š| 505M/623M [13:50<04:00,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  93%|â–ˆâ–Š| 582M/623M [13:50<01:01, 703kB/s]\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  94%|â–ˆâ–Š| 583M/623M [13:52<01:00, 700kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  81%|â–Š| 506M/623M [13:52<03:59,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  94%|â–ˆâ–Š| 584M/623M [13:53<00:57, 716kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  81%|â–Š| 507M/623M [13:54<03:56,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  94%|â–ˆâ–‰| 585M/623M [13:55<00:57, 694kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  81%|â–Š| 508M/623M [13:56<03:47,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  94%|â–ˆâ–‰| 586M/623M [13:56<00:57, 687kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  82%|â–Š| 509M/623M [13:58<03:41,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  94%|â–ˆâ–‰| 587M/623M [13:58<00:56, 681kB/s]\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  94%|â–ˆâ–‰| 588M/623M [13:59<00:54, 684kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  82%|â–Š| 510M/623M [14:00<03:41,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  94%|â–ˆâ–‰| 589M/623M [14:01<00:54, 666kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  82%|â–Š| 511M/623M [14:01<03:32,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  95%|â–ˆâ–‰| 590M/623M [14:03<00:51, 674kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  82%|â–Š| 512M/623M [14:03<03:32,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  95%|â–ˆâ–‰| 591M/623M [14:04<00:51, 657kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  82%|â–Š| 513M/623M [14:05<03:31,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  95%|â–ˆâ–‰| 592M/623M [14:06<00:49, 669kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  82%|â–Š| 514M/623M [14:07<03:30,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  95%|â–ˆâ–‰| 593M/623M [14:07<00:47, 668kB/s]\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  95%|â–ˆâ–‰| 594M/623M [14:09<00:44, 689kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  83%|â–Š| 515M/623M [14:09<03:30,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  95%|â–ˆâ–‰| 595M/623M [14:10<00:43, 686kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  83%|â–Š| 516M/623M [14:11<03:32,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  96%|â–ˆâ–‰| 596M/623M [14:12<00:42, 682kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  83%|â–Š| 517M/623M [14:13<03:24,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  96%|â–ˆâ–‰| 597M/623M [14:13<00:40, 679kB/s]\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  96%|â–ˆâ–‰| 598M/623M [14:15<00:39, 679kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  83%|â–Š| 518M/623M [14:15<03:24,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  96%|â–ˆâ–‰| 599M/623M [14:16<00:37, 690kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  83%|â–Š| 519M/623M [14:17<03:30,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  96%|â–ˆâ–‰| 600M/623M [14:18<00:34, 703kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  83%|â–Š| 520M/623M [14:19<03:26,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  96%|â–ˆâ–‰| 601M/623M [14:19<00:33, 694kB/s]\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  97%|â–ˆâ–‰| 602M/623M [14:21<00:32, 692kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  84%|â–Š| 521M/623M [14:21<03:21,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  97%|â–ˆâ–‰| 603M/623M [14:23<00:31, 677kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  84%|â–Š| 522M/623M [14:23<03:17,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  97%|â–ˆâ–‰| 604M/623M [14:24<00:29, 679kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  84%|â–Š| 523M/623M [14:25<03:16,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  97%|â–ˆâ–‰| 605M/623M [14:26<00:28, 674kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  84%|â–Š| 524M/623M [14:27<03:09,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  97%|â–ˆâ–‰| 606M/623M [14:27<00:27, 666kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  84%|â–Š| 525M/623M [14:29<03:09,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  97%|â–ˆâ–‰| 607M/623M [14:29<00:25, 675kB/s]\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  98%|â–ˆâ–‰| 608M/623M [14:30<00:23, 689kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  84%|â–Š| 526M/623M [14:31<03:12,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  98%|â–ˆâ–‰| 609M/623M [14:32<00:21, 692kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  85%|â–Š| 527M/623M [14:33<03:11,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  98%|â–ˆâ–‰| 610M/623M [14:33<00:20, 697kB/s]\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  98%|â–ˆâ–‰| 611M/623M [14:35<00:18, 696kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  85%|â–Š| 528M/623M [14:35<03:09,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  98%|â–ˆâ–‰| 612M/623M [14:36<00:17, 677kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  85%|â–Š| 529M/623M [14:37<03:04,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  98%|â–ˆâ–‰| 613M/623M [14:38<00:15, 685kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  85%|â–Š| 530M/623M [14:38<02:59,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  98%|â–ˆâ–‰| 614M/623M [14:39<00:14, 694kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  85%|â–Š| 531M/623M [14:41<03:02,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  99%|â–ˆâ–‰| 615M/623M [14:41<00:12, 685kB/s]\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  99%|â–ˆâ–‰| 616M/623M [14:42<00:11, 690kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  85%|â–Š| 532M/623M [14:43<03:01,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  99%|â–ˆâ–‰| 617M/623M [14:44<00:09, 671kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  86%|â–Š| 533M/623M [14:44<02:54,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  99%|â–ˆâ–‰| 618M/623M [14:46<00:08, 668kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  86%|â–Š| 534M/623M [14:46<02:49,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  99%|â–ˆâ–‰| 619M/623M [14:47<00:06, 671kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  86%|â–Š| 535M/623M [14:48<02:45,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]:  99%|â–ˆâ–‰| 620M/623M [14:49<00:05, 667kB/s]\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]: 100%|â–ˆâ–‰| 621M/623M [14:50<00:03, 688kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  86%|â–Š| 536M/623M [14:50<02:53,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]: 100%|â–ˆâ–‰| 622M/623M [14:52<00:02, 686kB/s]\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  86%|â–Š| 537M/623M [14:52<02:49,\u001b[A\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]: 100%|â–ˆâ–‰| 623M/623M [14:53<00:00, 695kB/s]\u001b[A\n",
      "Downloading [onnx/decoder_model.onnx]: 100%|â–ˆâ–ˆ| 623M/623M [14:54<00:00, 731kB/s]\u001b[A\n",
      "\n",
      "\n",
      "Processing 4 items:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 3.00/4.00 [14:54<04:51, 291s/it]\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  86%|â–Š| 539M/623M [14:55<02:14,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  87%|â–Š| 540M/623M [14:56<01:54,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  87%|â–Š| 541M/623M [14:57<01:40,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  87%|â–Š| 542M/623M [14:57<01:30,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  87%|â–Š| 543M/623M [14:58<01:23,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  87%|â–Š| 544M/623M [14:59<01:17,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  87%|â–Š| 545M/623M [15:00<01:14,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  88%|â–‰| 546M/623M [15:01<01:11,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  88%|â–‰| 547M/623M [15:02<01:08,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  88%|â–‰| 548M/623M [15:03<01:06,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  88%|â–‰| 549M/623M [15:03<01:05,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  88%|â–‰| 550M/623M [15:04<01:04,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  88%|â–‰| 551M/623M [15:05<01:02,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  89%|â–‰| 552M/623M [15:06<01:01,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  89%|â–‰| 553M/623M [15:07<01:00,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  89%|â–‰| 554M/623M [15:08<00:59,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  89%|â–‰| 555M/623M [15:09<00:58,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  89%|â–‰| 556M/623M [15:09<00:58,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  89%|â–‰| 557M/623M [15:10<00:57,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  90%|â–‰| 558M/623M [15:11<00:56,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  90%|â–‰| 559M/623M [15:12<00:55,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  90%|â–‰| 560M/623M [15:13<00:54,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  90%|â–‰| 561M/623M [15:14<00:53,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  90%|â–‰| 562M/623M [15:15<00:52,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  90%|â–‰| 563M/623M [15:15<00:51,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  90%|â–‰| 564M/623M [15:16<00:51,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  91%|â–‰| 565M/623M [15:17<00:50,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  91%|â–‰| 566M/623M [15:18<00:49,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  91%|â–‰| 567M/623M [15:19<00:48,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  91%|â–‰| 568M/623M [15:20<00:47,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  91%|â–‰| 569M/623M [15:21<00:46,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  91%|â–‰| 570M/623M [15:21<00:45,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  92%|â–‰| 571M/623M [15:22<00:44,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  92%|â–‰| 572M/623M [15:23<00:44,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  92%|â–‰| 573M/623M [15:24<00:43,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  92%|â–‰| 574M/623M [15:25<00:42,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  92%|â–‰| 575M/623M [15:26<00:41,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  92%|â–‰| 576M/623M [15:27<00:40,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  93%|â–‰| 577M/623M [15:27<00:39,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  93%|â–‰| 578M/623M [15:28<00:38,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  93%|â–‰| 579M/623M [15:29<00:37,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  93%|â–‰| 580M/623M [15:30<00:37,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  93%|â–‰| 581M/623M [15:31<00:36,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  93%|â–‰| 582M/623M [15:32<00:35,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  94%|â–‰| 583M/623M [15:33<00:34,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  94%|â–‰| 584M/623M [15:33<00:33,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  94%|â–‰| 585M/623M [15:34<00:33,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  94%|â–‰| 586M/623M [15:35<00:32,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  94%|â–‰| 587M/623M [15:36<00:31,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  94%|â–‰| 588M/623M [15:37<00:30,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  94%|â–‰| 589M/623M [15:38<00:29,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  95%|â–‰| 590M/623M [15:39<00:28,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  95%|â–‰| 591M/623M [15:39<00:27,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  95%|â–‰| 592M/623M [15:40<00:26,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  95%|â–‰| 593M/623M [15:41<00:26,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  95%|â–‰| 594M/623M [15:42<00:25,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  95%|â–‰| 595M/623M [15:43<00:24,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  96%|â–‰| 596M/623M [15:44<00:23,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  96%|â–‰| 597M/623M [15:45<00:22,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  96%|â–‰| 598M/623M [15:45<00:21,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  96%|â–‰| 599M/623M [15:46<00:20,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  96%|â–‰| 600M/623M [15:47<00:20,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  96%|â–‰| 601M/623M [15:48<00:19,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  97%|â–‰| 602M/623M [15:49<00:18,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  97%|â–‰| 603M/623M [15:50<00:17,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  97%|â–‰| 604M/623M [15:51<00:16,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  97%|â–‰| 605M/623M [15:52<00:15,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  97%|â–‰| 606M/623M [15:52<00:14,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  97%|â–‰| 607M/623M [15:53<00:14,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  98%|â–‰| 608M/623M [15:54<00:13,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  98%|â–‰| 609M/623M [15:55<00:12,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  98%|â–‰| 610M/623M [15:56<00:11,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  98%|â–‰| 611M/623M [15:57<00:10,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  98%|â–‰| 612M/623M [15:58<00:09,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  98%|â–‰| 613M/623M [15:58<00:08,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  98%|â–‰| 614M/623M [15:59<00:08,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  99%|â–‰| 615M/623M [16:00<00:07,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  99%|â–‰| 616M/623M [16:01<00:06,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  99%|â–‰| 617M/623M [16:02<00:05,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  99%|â–‰| 618M/623M [16:03<00:04,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  99%|â–‰| 619M/623M [16:04<00:03,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]:  99%|â–‰| 620M/623M [16:04<00:02,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]: 100%|â–‰| 621M/623M [16:05<00:02,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]: 100%|â–‰| 622M/623M [16:06<00:01,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]: 100%|â–‰| 623M/623M [16:07<00:00,\u001b[A\u001b[A\n",
      "\n",
      "Downloading [onnx/decoder_with_past_model.onnx]: 100%|â–ˆ| 623M/623M [16:07<00:00,\u001b[A\u001b[A\n",
      "Processing 4 items: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.00/4.00 [16:08<00:00, 242s/it]\n",
      "\n",
      "Successfully Downloaded from model openai-community/gpt2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ä½¿ç”¨modelscope ä¸‹è½½æ¨¡å‹\n",
    "!pip install modelscope==1.32.0\n",
    "!modelscope download --model openai-community/gpt2 --local_dir \"/mnt/workspace/gpt2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-05T01:12:14.633296Z",
     "iopub.status.busy": "2025-12-05T01:12:14.633066Z",
     "iopub.status.idle": "2025-12-05T01:12:18.006153Z",
     "shell.execute_reply": "2025-12-05T01:12:18.005391Z",
     "shell.execute_reply.started": "2025-12-05T01:12:14.633277Z"
    },
    "id": "SV0tXlOo5kgM",
    "outputId": "8999e89e-409a-4182-a9c8-42f2e363f41f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¤ åŠ è½½ GPT-2 Tokenizer...\n",
      "ğŸ“‚ ä»æœ¬åœ°è·¯å¾„åŠ è½½: /mnt/workspace/gpt2\n",
      "   âš™ï¸  è®¾ç½® pad_token = eos_token (ID: 50256)\n",
      "âœ… Tokenizer åŠ è½½å®Œæˆ\n",
      "   - è¯è¡¨å¤§å°: 50,257\n",
      "   - æ¨¡å‹ç±»å‹: GPT2TokenizerFast\n",
      "\n",
      "ğŸ“Š åŠ è½½ SMS æ•°æ®é›†...\n",
      "ğŸ“¥ æ­£åœ¨ä» UCI ä»“åº“ä¸‹è½½æ•°æ®...\n",
      "   URL: https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip\n",
      "âœ… æ•°æ®ä¸‹è½½æˆåŠŸï¼Œä¿å­˜åˆ°: SMSSpamCollection.tsv\n",
      "ğŸ“Š åŸå§‹æ•°æ®åŠ è½½å®Œæˆ: 5572 æ¡\n",
      "   - ham (æ­£å¸¸): 4825 æ¡\n",
      "   - spam (åƒåœ¾): 747 æ¡\n",
      "âš–ï¸  æ•°æ®å¹³è¡¡å: 1494 æ¡ï¼ˆæ¯ç±» 747 æ¡ï¼‰\n",
      "âœ‚ï¸  æ•°æ®åˆ’åˆ†å®Œæˆ:\n",
      "   - è®­ç»ƒé›†: 1045 æ¡\n",
      "   - éªŒè¯é›†: 149 æ¡\n",
      "   - æµ‹è¯•é›†: 300 æ¡\n",
      "\n",
      "ğŸ“ è®¾ç½®æœ€å¤§åºåˆ—é•¿åº¦: 96\n",
      "\n",
      "ğŸ”¨ åˆ›å»º PyTorch Dataset...\n",
      "âœ… æ•°æ®é›†åˆ›å»ºå®Œæˆ:\n",
      "   - æ ·æœ¬æ•°: 1045\n",
      "   - åºåˆ—é•¿åº¦: 96\n",
      "   - è¾“å…¥å½¢çŠ¶: torch.Size([1045, 96])\n",
      "âœ… æ•°æ®é›†åˆ›å»ºå®Œæˆ:\n",
      "   - æ ·æœ¬æ•°: 149\n",
      "   - åºåˆ—é•¿åº¦: 96\n",
      "   - è¾“å…¥å½¢çŠ¶: torch.Size([149, 96])\n",
      "âœ… æ•°æ®é›†åˆ›å»ºå®Œæˆ:\n",
      "   - æ ·æœ¬æ•°: 300\n",
      "   - åºåˆ—é•¿åº¦: 96\n",
      "   - è¾“å…¥å½¢çŠ¶: torch.Size([300, 96])\n",
      "\n",
      "ğŸ“¦ åˆ›å»º DataLoader...\n",
      "âœ… DataLoader åˆ›å»ºå®Œæˆ\n",
      "   - è®­ç»ƒæ‰¹æ¬¡æ•°: 131\n",
      "   - éªŒè¯æ‰¹æ¬¡æ•°: 19\n",
      "   - æµ‹è¯•æ‰¹æ¬¡æ•°: 38\n",
      "   - æ¯æ‰¹å¤§å°: 8\n",
      "\n",
      "ğŸ” æ ·æœ¬æ£€æŸ¥:\n",
      "   - input_ids å½¢çŠ¶: torch.Size([8, 96])\n",
      "   - attention_mask å½¢çŠ¶: torch.Size([8, 96])\n",
      "   - labels å½¢çŠ¶: torch.Size([8])\n",
      "   - æ ‡ç­¾åˆ†å¸ƒ: [0, 0, 0, 1, 1, 0, 0, 1]\n",
      "\n",
      "âœ… æ•°æ®å‡†å¤‡å®Œæˆï¼\n"
     ]
    }
   ],
   "source": [
    "# ğŸ”¤ åŠ è½½ Tokenizer\n",
    "# åŠŸèƒ½ï¼šä» Hugging Face Hub åŠ è½½é¢„è®­ç»ƒçš„ GPT-2 åˆ†è¯å™¨\n",
    "\n",
    "print(\"ğŸ”¤ åŠ è½½ GPT-2 Tokenizer...\")\n",
    "model_dir = \"/mnt/workspace/gpt2\"\n",
    "\n",
    "print(f\"ğŸ“‚ ä»æœ¬åœ°è·¯å¾„åŠ è½½: {model_dir}\")\n",
    "# ğŸ“¥ ä» Hugging Face ä¸‹è½½å¹¶åŠ è½½ GPT-2 tokenizer\n",
    "# AutoTokenizer.from_pretrained() ä¼šï¼š\n",
    "# 1. æ£€æŸ¥æœ¬åœ°ç¼“å­˜ï¼ˆ~/.cache/huggingface/ï¼‰\n",
    "# 2. å¦‚æœæ²¡æœ‰ï¼Œä» Hub ä¸‹è½½\n",
    "# 3. åŠ è½½è¯è¡¨å’Œåˆ†è¯è§„åˆ™\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "# åŠ è½½ Tokenizer (æ­¤æ—¶å®Œå…¨ä¸éœ€è¦è”ç½‘)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "\n",
    "# ğŸ”§ é…ç½® padding token\n",
    "# GPT-2 åŸå§‹è®¾è®¡ç”¨äºç”Ÿæˆä»»åŠ¡ï¼Œæ²¡æœ‰ padding token\n",
    "# ä½†åˆ†ç±»ä»»åŠ¡éœ€è¦å°†ä¸åŒé•¿åº¦çš„æ–‡æœ¬å¯¹é½åˆ°ç›¸åŒé•¿åº¦\n",
    "# è§£å†³æ–¹æ¡ˆï¼šå°† eos_tokenï¼ˆç»“æŸç¬¦ï¼‰å¤ç”¨ä¸º pad_token\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    print(f\"   âš™ï¸  è®¾ç½® pad_token = eos_token (ID: {tokenizer.eos_token_id})\")\n",
    "\n",
    "print(f\"âœ… Tokenizer åŠ è½½å®Œæˆ\")\n",
    "print(f\"   - è¯è¡¨å¤§å°: {tokenizer.vocab_size:,}\")\n",
    "print(f\"   - æ¨¡å‹ç±»å‹: {tokenizer.__class__.__name__}\")\n",
    "\n",
    "# ğŸ“Š åŠ è½½å¹¶åˆ’åˆ†æ•°æ®\n",
    "print(\"\\nğŸ“Š åŠ è½½ SMS æ•°æ®é›†...\")\n",
    "train_df, val_df, test_df = load_sms_dataframe()\n",
    "\n",
    "# ğŸ“ è®¾ç½®æœ€å¤§åºåˆ—é•¿åº¦\n",
    "# è¯´æ˜ï¼šè¿™ä¸ªå€¼éœ€è¦å¹³è¡¡ä»¥ä¸‹å› ç´ ï¼š\n",
    "# - å¤ªçŸ­ï¼šå¯èƒ½æˆªæ–­é‡è¦ä¿¡æ¯\n",
    "# - å¤ªé•¿ï¼šå¢åŠ è®¡ç®—æˆæœ¬å’Œæ˜¾å­˜å ç”¨\n",
    "# - 96 æ˜¯ç»è¿‡å®éªŒçš„åˆç†å€¼ï¼Œè¶³ä»¥è¦†ç›–å¤§éƒ¨åˆ†çŸ­ä¿¡\n",
    "max_length = 96\n",
    "print(f\"\\nğŸ“ è®¾ç½®æœ€å¤§åºåˆ—é•¿åº¦: {max_length}\")\n",
    "\n",
    "# ğŸ”¨ åˆ›å»º PyTorch Dataset\n",
    "print(\"\\nğŸ”¨ åˆ›å»º PyTorch Dataset...\")\n",
    "train_dataset = SpamSequenceDataset(train_df, tokenizer, max_length=max_length)\n",
    "val_dataset = SpamSequenceDataset(val_df, tokenizer, max_length=max_length)\n",
    "test_dataset = SpamSequenceDataset(test_df, tokenizer, max_length=max_length)\n",
    "\n",
    "# ğŸ“¦ åˆ›å»º DataLoader\n",
    "# åŠŸèƒ½ï¼šæ‰¹é‡åŠ è½½æ•°æ®ï¼Œæ”¯æŒè‡ªåŠ¨æ‰“ä¹±ã€å¤šè¿›ç¨‹ç­‰\n",
    "print(\"\\nğŸ“¦ åˆ›å»º DataLoader...\")\n",
    "\n",
    "# ğŸ¯ DataLoader å‚æ•°è¯´æ˜ï¼š\n",
    "# - batch_size: æ¯æ‰¹æ ·æœ¬æ•°é‡\n",
    "#   - è¾ƒå¤§ï¼šè®­ç»ƒå¿«ï¼Œä½†æ˜¾å­˜å ç”¨é«˜\n",
    "#   - è¾ƒå°ï¼šæ˜¾å­˜å‹å¥½ï¼Œä½†è®­ç»ƒæ…¢\n",
    "#   - 8 æ˜¯é€‚ä¸­çš„å€¼\n",
    "# - shuffle: æ˜¯å¦æ‰“ä¹±æ•°æ®\n",
    "#   - è®­ç»ƒé›†ï¼šTrueï¼ˆé¿å…é¡ºåºåå·®ï¼‰\n",
    "#   - éªŒè¯/æµ‹è¯•é›†ï¼šFalseï¼ˆä¿æŒé¡ºåºï¼Œä¾¿äºåˆ†æï¼‰\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "print(f\"âœ… DataLoader åˆ›å»ºå®Œæˆ\")\n",
    "print(f\"   - è®­ç»ƒæ‰¹æ¬¡æ•°: {len(train_loader)}\")\n",
    "print(f\"   - éªŒè¯æ‰¹æ¬¡æ•°: {len(val_loader)}\")\n",
    "print(f\"   - æµ‹è¯•æ‰¹æ¬¡æ•°: {len(test_loader)}\")\n",
    "print(f\"   - æ¯æ‰¹å¤§å°: 8\")\n",
    "\n",
    "# ğŸ” æ•°æ®æ£€æŸ¥ï¼šæŸ¥çœ‹ä¸€ä¸ªæ ·æœ¬\n",
    "print(\"\\nğŸ” æ ·æœ¬æ£€æŸ¥:\")\n",
    "sample_batch = next(iter(train_loader))\n",
    "print(f\"   - input_ids å½¢çŠ¶: {sample_batch['input_ids'].shape}\")\n",
    "print(f\"   - attention_mask å½¢çŠ¶: {sample_batch['attention_mask'].shape}\")\n",
    "print(f\"   - labels å½¢çŠ¶: {sample_batch['labels'].shape}\")\n",
    "print(f\"   - æ ‡ç­¾åˆ†å¸ƒ: {sample_batch['labels'].tolist()}\")\n",
    "\n",
    "print(\"\\nâœ… æ•°æ®å‡†å¤‡å®Œæˆï¼\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qoz3DaTj5kgM"
   },
   "source": [
    "# 5ï¸âƒ£ ä½¿ç”¨ PEFT åº“åº”ç”¨ LoRA\n",
    "\n",
    "## ğŸ¯ PEFT æ ¸å¿ƒæ¦‚å¿µ\n",
    "\n",
    "**PEFT (Parameter-Efficient Fine-Tuning)** æ˜¯ Hugging Face æä¾›çš„å‚æ•°é«˜æ•ˆå¾®è°ƒåº“ï¼Œæ”¯æŒå¤šç§æ–¹æ³•ã€‚\n",
    "\n",
    "### æ”¯æŒçš„å¾®è°ƒæ–¹æ³•\n",
    "\n",
    "| æ–¹æ³• | å…¨ç§° | åŸç† | å‚æ•°æ•ˆç‡ | æ€§èƒ½ | æ¨èåœºæ™¯ |\n",
    "|:----|:-----|:----|:--------|:----|:---------|\n",
    "| **LoRA** | Low-Rank Adaptation | ä½ç§©çŸ©é˜µåˆ†è§£ | â­â­â­â­â­ | â­â­â­â­ | é€šç”¨ï¼ˆæœ¬æ•™ç¨‹ä½¿ç”¨ï¼‰ |\n",
    "| **LoHa** | Low-Rank Hadamard | Hadamard ä¹˜ç§¯ | â­â­â­â­ | â­â­â­â­ | å›¾åƒç”Ÿæˆ |\n",
    "| **LoKr** | Low-Rank Kronecker | Kronecker ä¹˜ç§¯ | â­â­â­â­ | â­â­â­â­ | å¤§æ¨¡å‹å‹ç¼© |\n",
    "| **Prefix Tuning** | å‰ç¼€å¾®è°ƒ | å¯å­¦ä¹ å‰ç¼€å‘é‡ | â­â­â­ | â­â­â­ | ç”Ÿæˆä»»åŠ¡ |\n",
    "| **P-Tuning** | æç¤ºå¾®è°ƒ | è¿ç»­æç¤ºå­¦ä¹  | â­â­â­ | â­â­â­ | NLU ä»»åŠ¡ |\n",
    "| **Adapter** | é€‚é…å™¨å±‚ | æ’å…¥å°å‹ç½‘ç»œå±‚ | â­â­â­ | â­â­â­â­ | å¤šä»»åŠ¡å­¦ä¹  |\n",
    "\n",
    "ğŸ’¡ **ä¸ºä»€ä¹ˆé€‰æ‹© LoRA**ï¼š\n",
    "- âœ… å‚æ•°æ•ˆç‡æœ€é«˜ï¼ˆé€šå¸¸åªéœ€è®­ç»ƒ 0.1% ~ 1% çš„å‚æ•°ï¼‰\n",
    "- âœ… å®ç°ç®€å•ï¼Œæ˜“äºç†è§£\n",
    "- âœ… é€‚ç”¨äºå„ç§æ¨¡å‹æ¶æ„ï¼ˆTransformerã€CNN ç­‰ï¼‰\n",
    "- âœ… å·¥ä¸šç•ŒéªŒè¯æœ€å……åˆ†ï¼Œåº”ç”¨æœ€å¹¿æ³›\n",
    "\n",
    "## ğŸ”§ LoRA é…ç½®è¯¦è§£\n",
    "\n",
    "ä½¿ç”¨ PEFT åº“åº”ç”¨ LoRA åªéœ€ä¸‰æ­¥ï¼š\n",
    "\n",
    "| æ­¥éª¤ | æ“ä½œ | æ ¸å¿ƒå‡½æ•°/ç±» | è¯´æ˜ |\n",
    "|:----|:-----|:-----------|:----|\n",
    "| **1ï¸âƒ£ åˆ›å»ºé…ç½®** | å®šä¹‰ LoRA å‚æ•° | `LoraConfig()` | è®¾ç½® rankã€alphaã€dropout ç­‰ |\n",
    "| **2ï¸âƒ£ åŠ è½½æ¨¡å‹** | åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ | `AutoModel.from_pretrained()` | è·å–åŸºç¡€æ¨¡å‹ |\n",
    "| **3ï¸âƒ£ åº”ç”¨ LoRA** | å°†é…ç½®åº”ç”¨åˆ°æ¨¡å‹ | `get_peft_model()` | è‡ªåŠ¨æ›¿æ¢ç›®æ ‡å±‚ |\n",
    "\n",
    "è®©æˆ‘ä»¬æ·±å…¥äº†è§£ `LoraConfig` çš„æ¯ä¸ªå‚æ•°ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-05T01:12:18.007021Z",
     "iopub.status.busy": "2025-12-05T01:12:18.006841Z",
     "iopub.status.idle": "2025-12-05T01:12:21.419998Z",
     "shell.execute_reply": "2025-12-05T01:12:21.419278Z",
     "shell.execute_reply.started": "2025-12-05T01:12:18.007005Z"
    },
    "id": "EDNZbN1N5kgM",
    "outputId": "a0ef27b2-1810-4dc4-afea-2b643b475805"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– æ­¥éª¤ 1: åŠ è½½åŸºç¡€æ¨¡å‹...\n",
      "============================================================\n",
      "ğŸ“‚ æ­£åœ¨ä»æœ¬åœ°åŠ è½½åˆ†ç±»æ¨¡å‹: /mnt/workspace/gpt2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at /mnt/workspace/gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… åŸºç¡€æ¨¡å‹åŠ è½½å®Œæˆ\n",
      "   - æ¨¡å‹ç±»å‹: GPT2ForSequenceClassification\n",
      "   - åˆ†ç±»ç±»åˆ«: 2\n",
      "   - è¯è¡¨å¤§å°: 50,257\n",
      "\n",
      "ğŸ”§ æ­¥éª¤ 2: åˆ›å»º LoRA é…ç½®...\n",
      "============================================================\n",
      "âœ… LoRA é…ç½®åˆ›å»ºå®Œæˆ:\n",
      "   - ç§© (r): 8\n",
      "   - ç¼©æ”¾å› å­ (alpha): 16\n",
      "   - Dropout: 0.05\n",
      "   - ç›®æ ‡æ¨¡å—: {'c_proj', 'c_attn', 'c_fc'}\n",
      "\n",
      "ğŸš€ æ­¥éª¤ 3: åº”ç”¨ LoRA...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/peft/tuners/lora/layer.py:2285: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… LoRA åº”ç”¨å®Œæˆï¼\n",
      "\n",
      "ğŸ“Š å‚æ•°ç»Ÿè®¡:\n",
      "trainable params: 1,181,184 || all params: 125,622,528 || trainable%: 0.9403\n",
      "\n",
      "ğŸ® æ¨¡å‹å·²ç§»åŠ¨åˆ°è®¾å¤‡: cuda\n",
      "\n",
      "ğŸ” æ¨¡å‹ç»“æ„é¢„è§ˆ:\n",
      "   - æ¨¡å‹ç±»å‹: PeftModelForSequenceClassification\n",
      "   - åŸºç¡€æ¨¡å‹: LoraModel\n",
      "   - LoRA é…ç½®: {'default': LoraConfig(task_type=<TaskType.SEQ_CLS: 'SEQ_CLS'>, peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, peft_version='0.18.0', base_model_name_or_path='/mnt/workspace/gpt2', revision=None, inference_mode=False, r=8, target_modules={'c_proj', 'c_attn', 'c_fc'}, exclude_modules=None, lora_alpha=16, lora_dropout=0.05, fan_in_fan_out=True, bias='none', use_rslora=False, modules_to_save=['classifier', 'score'], init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', trainable_token_indices=None, loftq_config={}, eva_config=None, corda_config=None, use_dora=False, alora_invocation_tokens=None, use_qalora=False, qalora_group_size=16, layer_replication=None, runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False), lora_bias=False, target_parameters=None, arrow_config=None, ensure_weight_tying=False)}\n",
      "\n",
      "âœ… æ¨¡å‹å‡†å¤‡å®Œæˆï¼\n"
     ]
    }
   ],
   "source": [
    "# ğŸ¤– åŠ è½½åŸºç¡€æ¨¡å‹å¹¶åº”ç”¨ LoRA\n",
    "# åŠŸèƒ½ï¼šè¿™æ˜¯ PEFT åº“ä½¿ç”¨çš„æ ¸å¿ƒæ­¥éª¤\n",
    "\n",
    "print(\"ğŸ¤– æ­¥éª¤ 1: åŠ è½½åŸºç¡€æ¨¡å‹...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ğŸ“¥ ä» Hugging Face Hub åŠ è½½ GPT-2 åˆ†ç±»æ¨¡å‹\n",
    "# AutoModelForSequenceClassification ä¼šï¼š\n",
    "# 1. åŠ è½½ GPT-2 çš„é¢„è®­ç»ƒæƒé‡\n",
    "# 2. åœ¨é¡¶éƒ¨æ·»åŠ ä¸€ä¸ªåˆ†ç±»å¤´ï¼ˆçº¿æ€§å±‚ï¼‰\n",
    "# 3. num_labels=2 è¡¨ç¤ºäºŒåˆ†ç±»ä»»åŠ¡\n",
    "# base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "#     \"gpt2\",           # æ¨¡å‹åç§°\n",
    "#     num_labels=2      # åˆ†ç±»ç±»åˆ«æ•°\n",
    "# )\n",
    "print(f\"ğŸ“‚ æ­£åœ¨ä»æœ¬åœ°åŠ è½½åˆ†ç±»æ¨¡å‹: {model_dir}\")\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_dir,          # ğŸ‘ˆ è¿™é‡Œæ”¹æˆè·¯å¾„ï¼Œä¸å†å†™ \"gpt2\"\n",
    "    num_labels=2,       # åˆ†ç±»ç±»åˆ«æ•° (åƒåœ¾çŸ­ä¿¡ vs æ­£å¸¸çŸ­ä¿¡)\n",
    ")\n",
    "\n",
    "# ğŸ”§ é…ç½®æ¨¡å‹çš„ padding token\n",
    "# å¿…é¡»ä¸ tokenizer çš„é…ç½®ä¿æŒä¸€è‡´\n",
    "base_model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "# ğŸ“ è°ƒæ•´ embedding å±‚å¤§å°\n",
    "# GPT-2 çš„è¯è¡¨å¤§å°æ˜¯ 50257ï¼Œå¦‚æœ tokenizer æ·»åŠ äº†æ–° tokenï¼Œéœ€è¦è°ƒæ•´\n",
    "base_model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "print(f\"âœ… åŸºç¡€æ¨¡å‹åŠ è½½å®Œæˆ\")\n",
    "print(f\"   - æ¨¡å‹ç±»å‹: {base_model.__class__.__name__}\")\n",
    "print(f\"   - åˆ†ç±»ç±»åˆ«: {base_model.config.num_labels}\")\n",
    "print(f\"   - è¯è¡¨å¤§å°: {base_model.config.vocab_size:,}\")\n",
    "\n",
    "# ğŸ”§ æ­¥éª¤ 2: åˆ›å»º LoRA é…ç½®\n",
    "print(\"\\nğŸ”§ æ­¥éª¤ 2: åˆ›å»º LoRA é…ç½®...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ğŸ“‹ LoRA é…ç½®å‚æ•°è¯¦è§£\n",
    "lora_config = LoraConfig(\n",
    "    # ğŸ¯ task_type: ä»»åŠ¡ç±»å‹\n",
    "    # - TaskType.SEQ_CLS: åºåˆ—åˆ†ç±»ä»»åŠ¡\n",
    "    # - TaskType.CAUSAL_LM: å› æœè¯­è¨€æ¨¡å‹ï¼ˆç”Ÿæˆä»»åŠ¡ï¼‰\n",
    "    # - TaskType.SEQ_2_SEQ_LM: åºåˆ—åˆ°åºåˆ—ä»»åŠ¡\n",
    "    # ä¸åŒä»»åŠ¡ç±»å‹ä¼šå½±å“ LoRA å±‚çš„æ’å…¥ä½ç½®\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "\n",
    "    # ğŸ“Š r: LoRA çš„ç§©ï¼ˆrankï¼‰\n",
    "    # è¿™æ˜¯ LoRA æœ€æ ¸å¿ƒçš„è¶…å‚æ•°ï¼\n",
    "    # - æ§åˆ¶ A å’Œ B çŸ©é˜µçš„ä¸­é—´ç»´åº¦\n",
    "    # - è¾ƒå°çš„å€¼ï¼ˆå¦‚ 4-8ï¼‰ï¼šå‚æ•°å°‘ï¼Œè®­ç»ƒå¿«ï¼Œä½†è¡¨è¾¾èƒ½åŠ›å¼±\n",
    "    # - è¾ƒå¤§çš„å€¼ï¼ˆå¦‚ 16-32ï¼‰ï¼šå‚æ•°å¤šï¼Œè¡¨è¾¾èƒ½åŠ›å¼ºï¼Œä½†æ¥è¿‘å…¨é‡å¾®è°ƒ\n",
    "    # - æ¨èèµ·å§‹å€¼ï¼š8\n",
    "    # - æœ¬æ•™ç¨‹ä½¿ç”¨ï¼š8ï¼ˆå¹³è¡¡æ•ˆç‡å’Œæ€§èƒ½ï¼‰\n",
    "    r=8,\n",
    "\n",
    "    # ğŸšï¸ lora_alpha: LoRA ç¼©æ”¾å› å­\n",
    "    # - æ§åˆ¶ LoRA è¾“å‡ºçš„å½±å“å¼ºåº¦\n",
    "    # - å¸¸è§è®¾ç½®ï¼šalpha = 2Ã—r æˆ– alpha = r\n",
    "    # - æœ¬æ•™ç¨‹ï¼šalpha = 2Ã—r = 16\n",
    "    # - æ•°å­¦å…¬å¼ï¼šLoRA è¾“å‡ºä¼šä¹˜ä»¥ (alpha/r) çš„ç¼©æ”¾ç³»æ•°\n",
    "    lora_alpha=16,\n",
    "\n",
    "    # ğŸ² lora_dropout: Dropout æ¯”ç‡\n",
    "    # - åœ¨ LoRA å±‚ä¸­åº”ç”¨ dropout æ­£åˆ™åŒ–\n",
    "    # - èŒƒå›´ï¼š0.0ï¼ˆä¸ä½¿ç”¨ï¼‰åˆ° 0.2ï¼ˆè¾ƒå¼ºæ­£åˆ™åŒ–ï¼‰\n",
    "    # - ä½œç”¨ï¼šé˜²æ­¢è¿‡æ‹Ÿåˆï¼Œæé«˜æ³›åŒ–èƒ½åŠ›\n",
    "    # - æœ¬æ•™ç¨‹ï¼š0.05ï¼ˆè½»å¾®æ­£åˆ™åŒ–ï¼‰\n",
    "    lora_dropout=0.05,\n",
    "\n",
    "    # ğŸ¯ target_modules: è¦æ›¿æ¢çš„æ¨¡å—åç§°åˆ—è¡¨\n",
    "    # è¿™æ˜¯ PEFT åº“çš„å¼ºå¤§åŠŸèƒ½ï¼šé€‰æ‹©æ€§åœ°åªå¯¹éƒ¨åˆ†å±‚åº”ç”¨ LoRA\n",
    "    # GPT-2 çš„æ¨¡å—åç§°ï¼š\n",
    "    # - \"c_attn\": æ³¨æ„åŠ›å±‚çš„ QKV æŠ•å½±ï¼ˆæœ€é‡è¦ï¼‰\n",
    "    # - \"c_proj\": æ³¨æ„åŠ›å±‚çš„è¾“å‡ºæŠ•å½±\n",
    "    # - \"c_fc\": å‰é¦ˆç½‘ç»œçš„ç¬¬ä¸€å±‚\n",
    "    # - \"c_proj\": å‰é¦ˆç½‘ç»œçš„ç¬¬äºŒå±‚ï¼ˆä¸æ³¨æ„åŠ›åŒåï¼ŒPEFT ä¼šåŒºåˆ†ï¼‰\n",
    "    #\n",
    "    # ğŸ’¡ é€‰æ‹©ç­–ç•¥ï¼š\n",
    "    # - åªæ›¿æ¢ [\"c_attn\"]: æœ€å°‘å‚æ•°ï¼Œé€‚åˆæ˜¾å­˜æå°åœºæ™¯\n",
    "    # - æ›¿æ¢ [\"c_attn\", \"c_proj\"]: å¹³è¡¡é€‰æ‹©\n",
    "    # - æ›¿æ¢ [\"c_attn\", \"c_fc\", \"c_proj\"]: æœ¬æ•™ç¨‹ä½¿ç”¨ï¼Œè¦†ç›–ä¸»è¦å±‚\n",
    "    # - ä¸å»ºè®®æ›¿æ¢ embedding å±‚å’Œåˆ†ç±»å¤´\n",
    "    target_modules=[\"c_attn\", \"c_fc\", \"c_proj\"],\n",
    "\n",
    "    # âš™ï¸ å…¶ä»–å¯é€‰å‚æ•°ï¼ˆä½¿ç”¨é»˜è®¤å€¼ï¼‰ï¼š\n",
    "    # - bias=\"none\": ä¸è®­ç»ƒ bias å‚æ•°\n",
    "    # - fan_in_fan_out=False: æƒé‡çŸ©é˜µçš„ç»„ç»‡æ–¹å¼\n",
    "    # - modules_to_save=None: é™¤ LoRA å¤–éœ€è¦è®­ç»ƒçš„æ¨¡å—\n",
    ")\n",
    "\n",
    "print(\"âœ… LoRA é…ç½®åˆ›å»ºå®Œæˆ:\")\n",
    "print(f\"   - ç§© (r): {lora_config.r}\")\n",
    "print(f\"   - ç¼©æ”¾å› å­ (alpha): {lora_config.lora_alpha}\")\n",
    "print(f\"   - Dropout: {lora_config.lora_dropout}\")\n",
    "print(f\"   - ç›®æ ‡æ¨¡å—: {lora_config.target_modules}\")\n",
    "\n",
    "# ğŸš€ æ­¥éª¤ 3: åº”ç”¨ LoRA åˆ°æ¨¡å‹\n",
    "print(\"\\nğŸš€ æ­¥éª¤ 3: åº”ç”¨ LoRA...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ğŸ”‘ æ ¸å¿ƒå‡½æ•°ï¼šget_peft_model()\n",
    "# åŠŸèƒ½ï¼šå°† LoRA é…ç½®åº”ç”¨åˆ°åŸºç¡€æ¨¡å‹\n",
    "# å·¥ä½œåŸç†ï¼š\n",
    "# 1. éå†æ¨¡å‹çš„æ‰€æœ‰æ¨¡å—\n",
    "# 2. æ‰¾åˆ° target_modules ä¸­æŒ‡å®šçš„çº¿æ€§å±‚\n",
    "# 3. ç”¨ LoRA å¢å¼ºç‰ˆæœ¬æ›¿æ¢è¿™äº›å±‚\n",
    "# 4. å†»ç»“åŸå§‹å‚æ•°ï¼Œåªè®© LoRA å‚æ•°å¯è®­ç»ƒ\n",
    "model = get_peft_model(base_model, lora_config)\n",
    "\n",
    "print(\"âœ… LoRA åº”ç”¨å®Œæˆï¼\")\n",
    "\n",
    "# ğŸ“Š æ‰“å°å‚æ•°ç»Ÿè®¡\n",
    "# print_trainable_parameters() æ˜¯ PEFT æ¨¡å‹çš„ä¾¿æ·æ–¹æ³•\n",
    "# ä¼šæ˜¾ç¤ºå¯è®­ç»ƒå‚æ•°æ•°é‡å’Œå æ¯”\n",
    "print(\"\\nğŸ“Š å‚æ•°ç»Ÿè®¡:\")\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "# ğŸ® å°†æ¨¡å‹ç§»åŠ¨åˆ° GPU/CPU\n",
    "model.to(device)\n",
    "print(f\"\\nğŸ® æ¨¡å‹å·²ç§»åŠ¨åˆ°è®¾å¤‡: {device}\")\n",
    "\n",
    "# ğŸ” æ¨¡å‹ç»“æ„æ£€æŸ¥ï¼ˆå¯é€‰ï¼‰\n",
    "print(\"\\nğŸ” æ¨¡å‹ç»“æ„é¢„è§ˆ:\")\n",
    "print(f\"   - æ¨¡å‹ç±»å‹: {type(model).__name__}\")\n",
    "print(f\"   - åŸºç¡€æ¨¡å‹: {type(model.base_model).__name__}\")\n",
    "print(f\"   - LoRA é…ç½®: {model.peft_config}\")\n",
    "\n",
    "print(\"\\nâœ… æ¨¡å‹å‡†å¤‡å®Œæˆï¼\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_KGarAk35kgN"
   },
   "source": [
    "# 6ï¸âƒ£ è®­ç»ƒå’Œè¯„ä¼°å‡½æ•°\n",
    "\n",
    "## ğŸ¯ è®­ç»ƒæµç¨‹æ¦‚è¿°\n",
    "\n",
    "æ ‡å‡†çš„æ·±åº¦å­¦ä¹ è®­ç»ƒæµç¨‹åŒ…æ‹¬ï¼š\n",
    "1. **è®­ç»ƒå¾ªç¯**ï¼šå‰å‘ä¼ æ’­ â†’ è®¡ç®—æŸå¤± â†’ åå‘ä¼ æ’­ â†’ æ›´æ–°å‚æ•°\n",
    "2. **è¯„ä¼°å¾ªç¯**ï¼šåœ¨éªŒè¯é›†ä¸Šè®¡ç®—æ€§èƒ½æŒ‡æ ‡\n",
    "3. **å­¦ä¹ ç‡è°ƒåº¦**ï¼šåŠ¨æ€è°ƒæ•´å­¦ä¹ ç‡\n",
    "4. **æ—©åœæœºåˆ¶**ï¼šé˜²æ­¢è¿‡æ‹Ÿåˆ\n",
    "\n",
    "## ğŸ“Š PEFT æ¨¡å‹çš„è®­ç»ƒç‰¹ç‚¹\n",
    "\n",
    "ä½¿ç”¨ PEFT åï¼Œè®­ç»ƒä»£ç ä¸æ™®é€š PyTorch æ¨¡å‹**å®Œå…¨ç›¸åŒ**ï¼\n",
    "- âœ… è‡ªåŠ¨åªä¼˜åŒ– LoRA å‚æ•°\n",
    "- âœ… è‡ªåŠ¨å†»ç»“åŸå§‹å‚æ•°\n",
    "- âœ… æ— éœ€æ‰‹åŠ¨ç­›é€‰å‚æ•°\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-05T01:12:21.420995Z",
     "iopub.status.busy": "2025-12-05T01:12:21.420588Z",
     "iopub.status.idle": "2025-12-05T01:12:21.432882Z",
     "shell.execute_reply": "2025-12-05T01:12:21.432325Z",
     "shell.execute_reply.started": "2025-12-05T01:12:21.420979Z"
    },
    "id": "P8ZBEAGB5kgN",
    "outputId": "638beada-b0e4-4b22-b279-a749c0290c87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… è®­ç»ƒå’Œè¯„ä¼°å‡½æ•°å®šä¹‰å®Œæˆ\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“Š è¯„ä¼°å‡½æ•°å®šä¹‰\n",
    "# åŠŸèƒ½ï¼šè®¡ç®—æ¨¡å‹åœ¨æ•°æ®é›†ä¸Šçš„å‡†ç¡®ç‡å’ŒæŸå¤±\n",
    "\n",
    "def evaluate(model, data_loader):\n",
    "    \"\"\"\n",
    "    è¯„ä¼°æ¨¡å‹æ€§èƒ½\n",
    "\n",
    "    ğŸ¯ ç›®çš„ï¼šåœ¨éªŒè¯é›†æˆ–æµ‹è¯•é›†ä¸Šè®¡ç®—å‡†ç¡®ç‡å’Œå¹³å‡æŸå¤±\n",
    "\n",
    "    å‚æ•°ï¼š\n",
    "        model: å¾…è¯„ä¼°çš„æ¨¡å‹\n",
    "        data_loader: DataLoader å¯¹è±¡ï¼ˆéªŒè¯é›†æˆ–æµ‹è¯•é›†ï¼‰\n",
    "\n",
    "    è¿”å›ï¼š\n",
    "        acc: å‡†ç¡®ç‡ (0-1 ä¹‹é—´)\n",
    "        avg_loss: å¹³å‡æŸå¤±å€¼\n",
    "\n",
    "    å·¥ä½œæµç¨‹ï¼š\n",
    "        1. åˆ‡æ¢åˆ°è¯„ä¼°æ¨¡å¼ (model.eval())\n",
    "        2. ç¦ç”¨æ¢¯åº¦è®¡ç®— (torch.no_grad())\n",
    "        3. éå†æ‰€æœ‰æ‰¹æ¬¡è®¡ç®—æŸå¤±å’Œå‡†ç¡®ç‡\n",
    "        4. è¿”å›å¹³å‡å€¼\n",
    "    \"\"\"\n",
    "    # ğŸ”§ åˆ‡æ¢åˆ°è¯„ä¼°æ¨¡å¼\n",
    "    # ä½œç”¨ï¼š\n",
    "    # 1. ç¦ç”¨ Dropoutï¼ˆæ‰€æœ‰ç¥ç»å…ƒéƒ½å‚ä¸è®¡ç®—ï¼‰\n",
    "    # 2. ç¦ç”¨ Batch Normalization çš„æ›´æ–°ï¼ˆä½¿ç”¨è®­ç»ƒæ—¶çš„ç»Ÿè®¡é‡ï¼‰\n",
    "    # 3. æŸäº›å±‚çš„è¡Œä¸ºä¼šæ”¹å˜\n",
    "    model.eval()\n",
    "\n",
    "    # ğŸ“Š åˆå§‹åŒ–ç»Ÿè®¡å˜é‡\n",
    "    total_loss = 0.0    # ç´¯ç§¯æŸå¤±\n",
    "    correct = 0         # æ­£ç¡®é¢„æµ‹æ•°\n",
    "    total = 0           # æ€»æ ·æœ¬æ•°\n",
    "\n",
    "    # ğŸš« ç¦ç”¨æ¢¯åº¦è®¡ç®—\n",
    "    # ä½œç”¨ï¼šèŠ‚çœæ˜¾å­˜ï¼ŒåŠ å¿«è®¡ç®—é€Ÿåº¦\n",
    "    # è¯„ä¼°æ—¶ä¸éœ€è¦æ¢¯åº¦ï¼Œå› ä¸ºä¸è¿›è¡Œå‚æ•°æ›´æ–°\n",
    "    with torch.no_grad():\n",
    "        # ğŸ”„ éå†æ•°æ®æ‰¹æ¬¡\n",
    "        for batch in data_loader:\n",
    "            # ğŸ® å°†æ•°æ®ç§»åŠ¨åˆ°è®¾å¤‡ï¼ˆGPU/CPUï¼‰\n",
    "            # å­—å…¸æ¨å¯¼å¼ï¼šå°† batch ä¸­çš„æ¯ä¸ªå¼ é‡éƒ½ç§»åŠ¨åˆ°ç›®æ ‡è®¾å¤‡\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "            # ğŸ”® å‰å‘ä¼ æ’­\n",
    "            # model(**batch) ç­‰ä»·äº model(input_ids=..., attention_mask=..., labels=...)\n",
    "            # Hugging Face æ¨¡å‹è¿”å›ä¸€ä¸ªåŒ…å« loss å’Œ logits çš„å¯¹è±¡\n",
    "            outputs = model(**batch)\n",
    "\n",
    "            # ğŸ“‰ æå–æŸå¤±å€¼\n",
    "            # å½“ä¼ å…¥ labels æ—¶ï¼Œæ¨¡å‹ä¼šè‡ªåŠ¨è®¡ç®—äº¤å‰ç†µæŸå¤±\n",
    "            loss = outputs.loss\n",
    "\n",
    "            # ğŸ¯ è·å–é¢„æµ‹ç»“æœ\n",
    "            # logits: [batch_size, num_labels] å½¢çŠ¶çš„å¼ é‡\n",
    "            # argmax(dim=-1): æ²¿æœ€åä¸€ç»´å–æœ€å¤§å€¼çš„ç´¢å¼•ï¼Œå¾—åˆ°é¢„æµ‹ç±»åˆ«\n",
    "            preds = outputs.logits.argmax(dim=-1)\n",
    "\n",
    "            # ğŸ“Š ç´¯ç§¯ç»Ÿè®¡é‡\n",
    "            total_loss += loss.item()  # ç´¯åŠ æŸå¤±ï¼ˆè½¬ä¸º Python æ•°å€¼ï¼‰\n",
    "            correct += (preds == batch[\"labels\"]).sum().item()  # ç»Ÿè®¡æ­£ç¡®é¢„æµ‹æ•°\n",
    "            total += batch[\"labels\"].size(0)  # ç´¯åŠ æ ·æœ¬æ•°\n",
    "\n",
    "    # ğŸ“ è®¡ç®—å¹³å‡å€¼\n",
    "    avg_loss = total_loss / max(len(data_loader), 1)  # å¹³å‡æŸå¤±\n",
    "    acc = correct / total if total > 0 else 0.0        # å‡†ç¡®ç‡\n",
    "\n",
    "    return acc, avg_loss\n",
    "\n",
    "\n",
    "# ğŸš€ è®­ç»ƒå‡½æ•°å®šä¹‰\n",
    "# åŠŸèƒ½ï¼šæ‰§è¡Œå®Œæ•´çš„è®­ç»ƒæµç¨‹\n",
    "\n",
    "def train(model, train_loader, val_loader, epochs=3, lr=5e-4):\n",
    "    \"\"\"\n",
    "    è®­ç»ƒ LoRA æ¨¡å‹\n",
    "\n",
    "    ğŸ¯ ç›®çš„ï¼šæ‰§è¡Œå®Œæ•´çš„è®­ç»ƒå¾ªç¯ï¼ŒåŒ…æ‹¬ä¼˜åŒ–å™¨ã€å­¦ä¹ ç‡è°ƒåº¦å’Œæ¢¯åº¦è£å‰ª\n",
    "\n",
    "    å‚æ•°ï¼š\n",
    "        model: PEFT æ¨¡å‹ï¼ˆå·²åº”ç”¨ LoRAï¼‰\n",
    "        train_loader: è®­ç»ƒæ•°æ®åŠ è½½å™¨\n",
    "        val_loader: éªŒè¯æ•°æ®åŠ è½½å™¨\n",
    "        epochs: è®­ç»ƒè½®æ•°ï¼ˆé»˜è®¤ 3ï¼‰\n",
    "        lr: å­¦ä¹ ç‡ï¼ˆé»˜è®¤ 5e-4ï¼‰\n",
    "\n",
    "    è®­ç»ƒæµç¨‹ï¼š\n",
    "        æ¯ä¸ª epoch:\n",
    "            1. è®­ç»ƒé˜¶æ®µï¼šéå†è®­ç»ƒé›†ï¼Œæ›´æ–°å‚æ•°\n",
    "            2. è¯„ä¼°é˜¶æ®µï¼šåœ¨éªŒè¯é›†ä¸Šè®¡ç®—æ€§èƒ½\n",
    "            3. å­¦ä¹ ç‡è°ƒåº¦ï¼šæ ¹æ®éªŒè¯æŸå¤±è°ƒæ•´å­¦ä¹ ç‡\n",
    "\n",
    "    ğŸ’¡ LoRA å¾®è°ƒçš„å­¦ä¹ ç‡å»ºè®®ï¼š\n",
    "    - å…¨é‡å¾®è°ƒï¼š1e-5 ~ 5e-5ï¼ˆå°å­¦ä¹ ç‡ï¼‰\n",
    "    - LoRA å¾®è°ƒï¼š5e-4 ~ 1e-3ï¼ˆå¯ä»¥ç”¨è¾ƒå¤§å­¦ä¹ ç‡ï¼‰\n",
    "    \"\"\"\n",
    "    print(\"ğŸš€ å¼€å§‹è®­ç»ƒ...\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # âš™ï¸ åˆ›å»ºä¼˜åŒ–å™¨\n",
    "    # AdamW: Adam ä¼˜åŒ–å™¨çš„æ”¹è¿›ç‰ˆï¼Œå¸¦æƒé‡è¡°å‡ï¼ˆWeight Decayï¼‰\n",
    "    # model.parameters() ä¼šè‡ªåŠ¨åªè¿”å› requires_grad=True çš„å‚æ•°\n",
    "    # å› æ­¤è¿™é‡Œä¼šè‡ªåŠ¨åªä¼˜åŒ– LoRA å‚æ•°ï¼\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "    print(f\"âš™ï¸  ä¼˜åŒ–å™¨: AdamW (lr={lr})\")\n",
    "\n",
    "    # ğŸ“… åˆ›å»ºå­¦ä¹ ç‡è°ƒåº¦å™¨\n",
    "    # get_linear_schedule_with_warmup: å¸¦é¢„çƒ­çš„çº¿æ€§å­¦ä¹ ç‡è°ƒåº¦\n",
    "    #\n",
    "    # ğŸ”¥ Warmupï¼ˆé¢„çƒ­ï¼‰çš„ä½œç”¨ï¼š\n",
    "    # - è®­ç»ƒåˆæœŸä½¿ç”¨è¾ƒå°çš„å­¦ä¹ ç‡ï¼Œé€æ¸å¢åŠ åˆ°ç›®æ ‡å­¦ä¹ ç‡\n",
    "    # - é˜²æ­¢è®­ç»ƒåˆæœŸæ¢¯åº¦è¿‡å¤§å¯¼è‡´çš„ä¸ç¨³å®š\n",
    "    # - å…¬å¼ï¼šlr = base_lr * (current_step / warmup_steps)\n",
    "    #\n",
    "    # ğŸ“‰ çº¿æ€§è¡°å‡ï¼š\n",
    "    # - Warmup ç»“æŸåï¼Œå­¦ä¹ ç‡çº¿æ€§é™ä½åˆ° 0\n",
    "    # - æœ‰åŠ©äºè®­ç»ƒåæœŸçš„ç²¾ç»†è°ƒæ•´\n",
    "    total_steps = epochs * len(train_loader)  # æ€»è®­ç»ƒæ­¥æ•°\n",
    "    warmup_steps = max(10, int(0.1 * total_steps))  # Warmup æ­¥æ•°ï¼ˆ10% çš„æ€»æ­¥æ•°ï¼‰\n",
    "\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=warmup_steps,\n",
    "        num_training_steps=total_steps,\n",
    "    )\n",
    "\n",
    "    print(f\"ğŸ“… å­¦ä¹ ç‡è°ƒåº¦å™¨: Linear with Warmup\")\n",
    "    print(f\"   - æ€»æ­¥æ•°: {total_steps}\")\n",
    "    print(f\"   - Warmup æ­¥æ•°: {warmup_steps}\")\n",
    "\n",
    "    # ğŸ”„ è®­ç»ƒå¾ªç¯\n",
    "    for epoch in range(epochs):\n",
    "        # ğŸ“š è®­ç»ƒé˜¶æ®µ\n",
    "        model.train()  # åˆ‡æ¢åˆ°è®­ç»ƒæ¨¡å¼\n",
    "        running_loss = 0.0\n",
    "\n",
    "        # ğŸ“Š ä½¿ç”¨ tqdm æ˜¾ç¤ºè¿›åº¦æ¡\n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "\n",
    "        for batch in pbar:\n",
    "            # ğŸ® æ•°æ®ç§»åŠ¨åˆ°è®¾å¤‡\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "            # ğŸ§¹ æ¸…ç©ºæ¢¯åº¦\n",
    "            # PyTorch é»˜è®¤ç´¯ç§¯æ¢¯åº¦ï¼Œå¿…é¡»æ‰‹åŠ¨æ¸…é›¶\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # ğŸ”® å‰å‘ä¼ æ’­\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "\n",
    "            # ğŸ”„ åå‘ä¼ æ’­\n",
    "            # è®¡ç®—æ‰€æœ‰å‚æ•°çš„æ¢¯åº¦\n",
    "            loss.backward()\n",
    "\n",
    "            # âœ‚ï¸ æ¢¯åº¦è£å‰ª\n",
    "            # é™åˆ¶æ¢¯åº¦èŒƒæ•°ï¼Œé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸\n",
    "            # max_norm=1.0: å¦‚æœæ¢¯åº¦èŒƒæ•° > 1.0ï¼ŒæŒ‰æ¯”ä¾‹ç¼©æ”¾åˆ° 1.0\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "            # âš¡ å‚æ•°æ›´æ–°\n",
    "            optimizer.step()      # ä½¿ç”¨æ¢¯åº¦æ›´æ–°å‚æ•°\n",
    "            scheduler.step()      # æ›´æ–°å­¦ä¹ ç‡\n",
    "\n",
    "            # ğŸ“Š ç´¯ç§¯æŸå¤±\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # ğŸ“ˆ æ›´æ–°è¿›åº¦æ¡æ˜¾ç¤º\n",
    "            pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "\n",
    "        # ğŸ“Š è®¡ç®—æœ¬è½®å¹³å‡æŸå¤±\n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "\n",
    "        # ğŸ“ˆ éªŒè¯é˜¶æ®µ\n",
    "        val_acc, val_loss = evaluate(model, val_loader)\n",
    "\n",
    "        # ğŸ“¢ æ‰“å°ç»“æœ\n",
    "        print(f\"Epoch {epoch+1}/{epochs}:\")\n",
    "        print(f\"   - è®­ç»ƒæŸå¤±: {avg_train_loss:.4f}\")\n",
    "        print(f\"   - éªŒè¯æŸå¤±: {val_loss:.4f}\")\n",
    "        print(f\"   - éªŒè¯å‡†ç¡®ç‡: {val_acc*100:.1f}%\")\n",
    "        print(f\"   - å½“å‰å­¦ä¹ ç‡: {scheduler.get_last_lr()[0]:.2e}\")\n",
    "\n",
    "    print(\"\\nâœ… è®­ç»ƒå®Œæˆï¼\")\n",
    "\n",
    "\n",
    "# ğŸ“ åˆå­¦è€…æç¤ºï¼š\n",
    "# ä»¥ä¸Šè®­ç»ƒå‡½æ•°é›†æˆäº†å¤šä¸ªè®­ç»ƒæŠ€å·§ï¼š\n",
    "# 1. AdamW ä¼˜åŒ–å™¨ï¼šæ¯” SGD æ”¶æ•›æ›´å¿«ï¼Œæ¯” Adam æ³›åŒ–æ›´å¥½\n",
    "# 2. å­¦ä¹ ç‡é¢„çƒ­ï¼šè®­ç»ƒåˆæœŸç¨³å®šæ€§æ›´å¥½\n",
    "# 3. æ¢¯åº¦è£å‰ªï¼šé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸\n",
    "# 4. è¿›åº¦æ¡æ˜¾ç¤ºï¼šå®æ—¶ç›‘æ§è®­ç»ƒçŠ¶æ€\n",
    "#\n",
    "# è¿™äº›éƒ½æ˜¯å·¥ä¸šç•Œçš„æ ‡å‡†åšæ³•ï¼Œå»ºè®®åœ¨è‡ªå·±çš„é¡¹ç›®ä¸­ä½¿ç”¨ã€‚\n",
    "\n",
    "print(\"âœ… è®­ç»ƒå’Œè¯„ä¼°å‡½æ•°å®šä¹‰å®Œæˆ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-05T01:12:21.433401Z",
     "iopub.status.busy": "2025-12-05T01:12:21.433251Z",
     "iopub.status.idle": "2025-12-05T01:12:43.211959Z",
     "shell.execute_reply": "2025-12-05T01:12:43.211436Z",
     "shell.execute_reply.started": "2025-12-05T01:12:21.433387Z"
    },
    "id": "YaOHSKxX5kgN",
    "outputId": "042747af-da5f-460c-95f1-d4b1249a6da7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš™ï¸  è®­ç»ƒå‚æ•°:\n",
      "   - è®­ç»ƒè½®æ•°: 3\n",
      "   - å­¦ä¹ ç‡: 0.0005\n",
      "   - æ‰¹æ¬¡å¤§å°: 8\n",
      "   - ä¼˜åŒ–å™¨: AdamW\n",
      "   - å­¦ä¹ ç‡è°ƒåº¦: Linear with Warmup\n",
      "\n",
      "ğŸš€ å¼€å§‹è®­ç»ƒ...\n",
      "============================================================\n",
      "âš™ï¸  ä¼˜åŒ–å™¨: AdamW (lr=0.0005)\n",
      "ğŸ“… å­¦ä¹ ç‡è°ƒåº¦å™¨: Linear with Warmup\n",
      "   - æ€»æ­¥æ•°: 393\n",
      "   - Warmup æ­¥æ•°: 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 131/131 [00:06<00:00, 18.89it/s, loss=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3:\n",
      "   - è®­ç»ƒæŸå¤±: 0.7801\n",
      "   - éªŒè¯æŸå¤±: 0.1406\n",
      "   - éªŒè¯å‡†ç¡®ç‡: 98.0%\n",
      "   - å½“å‰å­¦ä¹ ç‡: 3.70e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 131/131 [00:06<00:00, 20.54it/s, loss=0.0042]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3:\n",
      "   - è®­ç»ƒæŸå¤±: 0.1401\n",
      "   - éªŒè¯æŸå¤±: 0.0571\n",
      "   - éªŒè¯å‡†ç¡®ç‡: 99.3%\n",
      "   - å½“å‰å­¦ä¹ ç‡: 1.85e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 131/131 [00:06<00:00, 20.46it/s, loss=0.0040]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3:\n",
      "   - è®­ç»ƒæŸå¤±: 0.1165\n",
      "   - éªŒè¯æŸå¤±: 0.0470\n",
      "   - éªŒè¯å‡†ç¡®ç‡: 98.0%\n",
      "   - å½“å‰å­¦ä¹ ç‡: 0.00e+00\n",
      "\n",
      "âœ… è®­ç»ƒå®Œæˆï¼\n",
      "\n",
      "ğŸ“Š æœ€ç»ˆæµ‹è¯•...\n",
      "============================================================\n",
      "âœ… æµ‹è¯•ç»“æœ:\n",
      "   - æµ‹è¯•æŸå¤±: 0.0755\n",
      "   - æµ‹è¯•å‡†ç¡®ç‡: 98.33%\n",
      "\n",
      "ğŸ‰ ä¼˜ç§€ï¼æ¨¡å‹è¾¾åˆ°äº† 95%+ çš„å‡†ç¡®ç‡ï¼\n"
     ]
    }
   ],
   "source": [
    "# ğŸš€ æ‰§è¡Œè®­ç»ƒ\n",
    "# åŠŸèƒ½ï¼šè°ƒç”¨è®­ç»ƒå‡½æ•°å¼€å§‹å¾®è°ƒ\n",
    "\n",
    "# âš™ï¸ è®­ç»ƒå‚æ•°è®¾ç½®\n",
    "EPOCHS = 3          # è®­ç»ƒè½®æ•°\n",
    "LEARNING_RATE = 5e-4  # å­¦ä¹ ç‡\n",
    "\n",
    "print(\"âš™ï¸  è®­ç»ƒå‚æ•°:\")\n",
    "print(f\"   - è®­ç»ƒè½®æ•°: {EPOCHS}\")\n",
    "print(f\"   - å­¦ä¹ ç‡: {LEARNING_RATE}\")\n",
    "print(f\"   - æ‰¹æ¬¡å¤§å°: 8\")\n",
    "print(f\"   - ä¼˜åŒ–å™¨: AdamW\")\n",
    "print(f\"   - å­¦ä¹ ç‡è°ƒåº¦: Linear with Warmup\")\n",
    "print(\"\")\n",
    "\n",
    "# ğŸš€ å¼€å§‹è®­ç»ƒ\n",
    "train(model, train_loader, val_loader, epochs=EPOCHS, lr=LEARNING_RATE)\n",
    "\n",
    "# ğŸ“Š åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°\n",
    "print(\"\\nğŸ“Š æœ€ç»ˆæµ‹è¯•...\")\n",
    "print(\"=\" * 60)\n",
    "test_acc, test_loss = evaluate(model, test_loader)\n",
    "\n",
    "print(f\"âœ… æµ‹è¯•ç»“æœ:\")\n",
    "print(f\"   - æµ‹è¯•æŸå¤±: {test_loss:.4f}\")\n",
    "print(f\"   - æµ‹è¯•å‡†ç¡®ç‡: {test_acc*100:.2f}%\")\n",
    "\n",
    "# ğŸ¯ æ€§èƒ½åˆ†æ\n",
    "if test_acc >= 0.95:\n",
    "    print(\"\\nğŸ‰ ä¼˜ç§€ï¼æ¨¡å‹è¾¾åˆ°äº† 95%+ çš„å‡†ç¡®ç‡ï¼\")\n",
    "elif test_acc >= 0.90:\n",
    "    print(\"\\nğŸ‘ å¾ˆå¥½ï¼æ¨¡å‹è¾¾åˆ°äº† 90%+ çš„å‡†ç¡®ç‡ï¼\")\n",
    "elif test_acc >= 0.85:\n",
    "    print(\"\\nâœ… ä¸é”™ï¼æ¨¡å‹è¾¾åˆ°äº† 85%+ çš„å‡†ç¡®ç‡ï¼\")\n",
    "else:\n",
    "    print(\"\\nğŸ’¡ æç¤ºï¼šå‡†ç¡®ç‡åä½ï¼Œå»ºè®®è°ƒæ•´è¶…å‚æ•°æˆ–å¢åŠ è®­ç»ƒè½®æ•°\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sGoDGjov5kgN"
   },
   "source": [
    "# 8ï¸âƒ£ å®é™…åº”ç”¨ï¼šæ–‡æœ¬åˆ†ç±»æ¨ç†\n",
    "\n",
    "## ğŸ¯ ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œé¢„æµ‹\n",
    "\n",
    "ç°åœ¨è®©æˆ‘ä»¬ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹å¯¹æ–°æ–‡æœ¬è¿›è¡Œåˆ†ç±»ï¼Œçœ‹çœ‹æ•ˆæœå¦‚ä½•ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-05T01:12:43.212651Z",
     "iopub.status.busy": "2025-12-05T01:12:43.212491Z",
     "iopub.status.idle": "2025-12-05T01:12:43.307070Z",
     "shell.execute_reply": "2025-12-05T01:12:43.306537Z",
     "shell.execute_reply.started": "2025-12-05T01:12:43.212631Z"
    },
    "id": "juft7yHg5kgN",
    "outputId": "41309ad4-304d-4485-e1ed-19d0c494aace"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”® æ¨ç†æ¼”ç¤º\n",
      "============================================================\n",
      "æµ‹è¯• 6 æ¡æ ·æœ¬...\n",
      "\n",
      "ã€æ ·æœ¬ 1ã€‘\n",
      "æ–‡æœ¬: Hey, want to grab lunch together?\n",
      "é¢„æµ‹: HAM\n",
      "ç½®ä¿¡åº¦: ham=1.000, spam=0.000\n",
      "âœ… åˆ†ç±»ç»“æœï¼šæ­£å¸¸çŸ­ä¿¡\n",
      "\n",
      "ã€æ ·æœ¬ 2ã€‘\n",
      "æ–‡æœ¬: URGENT! You've won $5000! Click now to claim your prize!\n",
      "é¢„æµ‹: SPAM\n",
      "ç½®ä¿¡åº¦: ham=0.000, spam=1.000\n",
      "ğŸš¨ åˆ†ç±»ç»“æœï¼šåƒåœ¾çŸ­ä¿¡\n",
      "\n",
      "ã€æ ·æœ¬ 3ã€‘\n",
      "æ–‡æœ¬: The meeting has been moved to 2pm\n",
      "é¢„æµ‹: SPAM\n",
      "ç½®ä¿¡åº¦: ham=0.058, spam=0.942\n",
      "ğŸš¨ åˆ†ç±»ç»“æœï¼šåƒåœ¾çŸ­ä¿¡\n",
      "\n",
      "ã€æ ·æœ¬ 4ã€‘\n",
      "æ–‡æœ¬: Free iPhone! Limited time offer! Call immediately!\n",
      "é¢„æµ‹: SPAM\n",
      "ç½®ä¿¡åº¦: ham=0.000, spam=1.000\n",
      "ğŸš¨ åˆ†ç±»ç»“æœï¼šåƒåœ¾çŸ­ä¿¡\n",
      "\n",
      "ã€æ ·æœ¬ 5ã€‘\n",
      "æ–‡æœ¬: Thanks for your help yesterday\n",
      "é¢„æµ‹: HAM\n",
      "ç½®ä¿¡åº¦: ham=0.983, spam=0.017\n",
      "âœ… åˆ†ç±»ç»“æœï¼šæ­£å¸¸çŸ­ä¿¡\n",
      "\n",
      "ã€æ ·æœ¬ 6ã€‘\n",
      "æ–‡æœ¬: Congratulations! You are selected as winner. Text WIN now!\n",
      "é¢„æµ‹: SPAM\n",
      "ç½®ä¿¡åº¦: ham=0.000, spam=1.000\n",
      "ğŸš¨ åˆ†ç±»ç»“æœï¼šåƒåœ¾çŸ­ä¿¡\n",
      "\n",
      "âœ… æ¨ç†æ¼”ç¤ºå®Œæˆï¼\n"
     ]
    }
   ],
   "source": [
    "# ğŸ”® æ¨ç†æ¼”ç¤º\n",
    "# åŠŸèƒ½ï¼šä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹å¯¹æ–°æ–‡æœ¬è¿›è¡Œåˆ†ç±»é¢„æµ‹\n",
    "\n",
    "# ğŸ“ å‡†å¤‡æµ‹è¯•æ ·æœ¬\n",
    "# åŒ…å«æ˜æ˜¾çš„æ­£å¸¸çŸ­ä¿¡å’Œåƒåœ¾çŸ­ä¿¡\n",
    "sample_texts = [\n",
    "    \"Hey, want to grab lunch together?\",                           # æ­£å¸¸çŸ­ä¿¡\n",
    "    \"URGENT! You've won $5000! Click now to claim your prize!\",   # åƒåœ¾çŸ­ä¿¡\n",
    "    \"The meeting has been moved to 2pm\",                          # æ­£å¸¸çŸ­ä¿¡\n",
    "    \"Free iPhone! Limited time offer! Call immediately!\",         # åƒåœ¾çŸ­ä¿¡\n",
    "    \"Thanks for your help yesterday\",                              # æ­£å¸¸çŸ­ä¿¡\n",
    "    \"Congratulations! You are selected as winner. Text WIN now!\",  # åƒåœ¾çŸ­ä¿¡\n",
    "]\n",
    "\n",
    "print(\"ğŸ”® æ¨ç†æ¼”ç¤º\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"æµ‹è¯• {len(sample_texts)} æ¡æ ·æœ¬...\\n\")\n",
    "\n",
    "# ğŸ”§ åˆ‡æ¢åˆ°è¯„ä¼°æ¨¡å¼\n",
    "model.eval()\n",
    "\n",
    "# ğŸ”„ éå†æ¯ä¸ªæµ‹è¯•æ ·æœ¬\n",
    "for i, text in enumerate(sample_texts, 1):\n",
    "    # ğŸ”¤ ä½¿ç”¨ tokenizer ç¼–ç æ–‡æœ¬\n",
    "    # å‚æ•°è¯´æ˜ï¼š\n",
    "    # - return_tensors=\"pt\": è¿”å› PyTorch å¼ é‡\n",
    "    # - truncation=True: å¦‚æœè¶…é•¿åˆ™æˆªæ–­\n",
    "    # - padding=\"max_length\": å¡«å……åˆ°æœ€å¤§é•¿åº¦\n",
    "    # - max_length: ä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´\n",
    "    encoded = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=max_length,\n",
    "    )\n",
    "\n",
    "    # ğŸ® å°†æ•°æ®ç§»åŠ¨åˆ°è®¾å¤‡\n",
    "    encoded = {k: v.to(device) for k, v in encoded.items()}\n",
    "\n",
    "    # ğŸš« ç¦ç”¨æ¢¯åº¦è®¡ç®—ï¼ˆæ¨ç†æ—¶ä¸éœ€è¦ï¼‰\n",
    "    with torch.no_grad():\n",
    "        # ğŸ”® å‰å‘ä¼ æ’­è·å– logits\n",
    "        logits = model(**encoded).logits\n",
    "\n",
    "        # ğŸ“Š è®¡ç®—æ¦‚ç‡åˆ†å¸ƒ\n",
    "        # softmax å°† logits è½¬æ¢ä¸ºæ¦‚ç‡ï¼ˆå’Œä¸º 1ï¼‰\n",
    "        probs = torch.softmax(logits, dim=-1)[0]\n",
    "\n",
    "    # ğŸ¯ è·å–é¢„æµ‹ç»“æœ\n",
    "    pred = torch.argmax(probs).item()  # é¢„æµ‹ç±»åˆ«ï¼ˆ0 æˆ– 1ï¼‰\n",
    "    label = \"spam\" if pred == 1 else \"ham\"  # è½¬æ¢ä¸ºæ–‡æœ¬æ ‡ç­¾\n",
    "\n",
    "    # ğŸ“Š æå–æ¦‚ç‡å€¼\n",
    "    ham_prob = probs[0].item()   # æ­£å¸¸çŸ­ä¿¡æ¦‚ç‡\n",
    "    spam_prob = probs[1].item()  # åƒåœ¾çŸ­ä¿¡æ¦‚ç‡\n",
    "\n",
    "    # ğŸ“¢ æ‰“å°ç»“æœ\n",
    "    print(f\"ã€æ ·æœ¬ {i}ã€‘\")\n",
    "    print(f\"æ–‡æœ¬: {text[:60]}{'...' if len(text) > 60 else ''}\")\n",
    "    print(f\"é¢„æµ‹: {label.upper()}\")\n",
    "    print(f\"ç½®ä¿¡åº¦: ham={ham_prob:.3f}, spam={spam_prob:.3f}\")\n",
    "\n",
    "    # ğŸ¨ æ·»åŠ è¡¨æƒ…ç¬¦å·å¢å¼ºå¯è¯»æ€§\n",
    "    if pred == 1:\n",
    "        print(\"ğŸš¨ åˆ†ç±»ç»“æœï¼šåƒåœ¾çŸ­ä¿¡\")\n",
    "    else:\n",
    "        print(\"âœ… åˆ†ç±»ç»“æœï¼šæ­£å¸¸çŸ­ä¿¡\")\n",
    "\n",
    "    print()\n",
    "\n",
    "print(\"âœ… æ¨ç†æ¼”ç¤ºå®Œæˆï¼\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wtM7rWqo5kgN"
   },
   "source": [
    "# 9ï¸âƒ£ æ¨¡å‹ä¿å­˜å’ŒåŠ è½½\n",
    "\n",
    "## ğŸ’¾ PEFT æ¨¡å‹çš„ä¿å­˜ç­–ç•¥\n",
    "\n",
    "PEFT åº“æä¾›äº†éå¸¸æ–¹ä¾¿çš„æ¨¡å‹ä¿å­˜åŠŸèƒ½ï¼š\n",
    "\n",
    "### ğŸ¯ ä¸¤ç§ä¿å­˜æ–¹å¼\n",
    "\n",
    "1. **åªä¿å­˜ LoRA å‚æ•°**ï¼ˆæ¨èï¼‰\n",
    "   - æ–‡ä»¶å¾ˆå°ï¼ˆå‡  MBï¼‰\n",
    "   - éœ€è¦é…åˆåŸå§‹æ¨¡å‹ä½¿ç”¨\n",
    "   - é€‚åˆæ¨¡å‹åˆ†å‘å’Œå¤šä»»åŠ¡åœºæ™¯\n",
    "\n",
    "2. **ä¿å­˜åˆå¹¶åçš„å®Œæ•´æ¨¡å‹**\n",
    "   - å°† LoRA å‚æ•°åˆå¹¶åˆ°åŸå§‹æƒé‡\n",
    "   - æ–‡ä»¶è¾ƒå¤§\n",
    "   - å¯ä»¥ä½œä¸ºç‹¬ç«‹æ¨¡å‹ä½¿ç”¨\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-05T01:12:43.307613Z",
     "iopub.status.busy": "2025-12-05T01:12:43.307466Z",
     "iopub.status.idle": "2025-12-05T01:12:43.344021Z",
     "shell.execute_reply": "2025-12-05T01:12:43.343448Z",
     "shell.execute_reply.started": "2025-12-05T01:12:43.307598Z"
    },
    "id": "BxrpSq8M5kgN",
    "outputId": "c646ec5b-7024-49fe-faf0-2d45d5a87291"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ ä¿å­˜ LoRA å‚æ•°...\n",
      "âœ… LoRA å‚æ•°å·²ä¿å­˜åˆ°: ./lora_sms_spam_classifier\n",
      "ğŸ“‚ ä¿å­˜çš„æ–‡ä»¶: ['adapter_config.json', 'README.md', 'adapter_model.safetensors']\n",
      "ğŸ“Š æ€»å¤§å°: 4.52 MB\n",
      "\n",
      "ğŸ’¡ åŠ è½½ LoRA æ¨¡å‹çš„æ–¹æ³•:\n",
      "```python\n",
      "from peft import PeftModel\n",
      "from transformers import AutoModelForSequenceClassification\n",
      "\n",
      "# 1. åŠ è½½åŸºç¡€æ¨¡å‹\n",
      "base_model = AutoModelForSequenceClassification.from_pretrained(\"gpt2\", num_labels=2)\n",
      "\n",
      "# 2. åŠ è½½ LoRA é€‚é…å™¨\n",
      "model = PeftModel.from_pretrained(base_model, \"./lora_sms_spam_classifier\")\n",
      "\n",
      "# 3. ä½¿ç”¨æ¨¡å‹è¿›è¡Œæ¨ç†\n",
      "model.eval()\n",
      "# ... æ¨ç†ä»£ç  ...\n",
      "```\n",
      "\n",
      "============================================================\n",
      "\n",
      "ğŸ”— æ–¹å¼ 2ï¼šåˆå¹¶ LoRA å‚æ•°åˆ°åŸºç¡€æ¨¡å‹\n",
      "ğŸ’¡ åˆå¹¶æ“ä½œä¼šå°† LoRA å‚æ•°åŠ åˆ°åŸå§‹æƒé‡ä¸Šï¼š\n",
      "   W_new = W_original + Î±/r * (A @ B)\n",
      "\n",
      "âš ï¸  æ³¨æ„ï¼šåˆå¹¶åå°†å¤±å»åˆ‡æ¢ LoRA é€‚é…å™¨çš„èƒ½åŠ›\n",
      "\n",
      "ğŸ”§ åˆå¹¶ä»£ç ç¤ºä¾‹ï¼ˆä¸æ‰§è¡Œï¼Œä»…å±•ç¤ºï¼‰:\n",
      "```python\n",
      "# åˆå¹¶ LoRA å‚æ•°åˆ°åŸºç¡€æ¨¡å‹\n",
      "merged_model = model.merge_and_unload()\n",
      "\n",
      "# ä¿å­˜å®Œæ•´æ¨¡å‹\n",
      "merged_model.save_pretrained(\"./merged_sms_spam_classifier\")\n",
      "tokenizer.save_pretrained(\"./merged_sms_spam_classifier\")\n",
      "\n",
      "# åŠ è½½å®Œæ•´æ¨¡å‹\n",
      "loaded_model = AutoModelForSequenceClassification.from_pretrained(\n",
      "    \"./merged_sms_spam_classifier\"\n",
      ")\n",
      "```\n",
      "\n",
      "âœ… æ¨¡å‹ä¿å­˜å®Œæˆï¼\n",
      "\n",
      "ğŸ“Š ä¸¤ç§ä¿å­˜æ–¹å¼å¯¹æ¯”:\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚      ç‰¹æ€§       â”‚  LoRA å‚æ•°   â”‚  å®Œæ•´æ¨¡å‹    â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚  æ–‡ä»¶å¤§å°       â”‚  å‡  MB       â”‚  æ•°ç™¾ MB     â”‚\n",
      "â”‚  åŠ è½½é€Ÿåº¦       â”‚  å¿«          â”‚  è¾ƒæ…¢        â”‚\n",
      "â”‚  å¤šä»»åŠ¡åˆ‡æ¢     â”‚  æ”¯æŒ        â”‚  ä¸æ”¯æŒ      â”‚\n",
      "â”‚  ç‹¬ç«‹ä½¿ç”¨       â”‚  éœ€åŸºç¡€æ¨¡å‹  â”‚  å¯ç‹¬ç«‹ä½¿ç”¨  â”‚\n",
      "â”‚  æ¨èåœºæ™¯       â”‚  ç”Ÿäº§ç¯å¢ƒ    â”‚  æ¼”ç¤º/éƒ¨ç½²   â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
     ]
    }
   ],
   "source": [
    "# ğŸ’¾ æ–¹å¼ 1ï¼šåªä¿å­˜ LoRA å‚æ•°ï¼ˆæ¨èï¼‰\n",
    "# åŠŸèƒ½ï¼šä¿å­˜è½»é‡çº§çš„ LoRA é€‚é…å™¨æ–‡ä»¶\n",
    "\n",
    "print(\"ğŸ’¾ ä¿å­˜ LoRA å‚æ•°...\")\n",
    "\n",
    "# ğŸ“ æŒ‡å®šä¿å­˜è·¯å¾„\n",
    "lora_save_path = \"./lora_sms_spam_classifier\"\n",
    "\n",
    "# ğŸ’¾ ä¿å­˜ LoRA é€‚é…å™¨\n",
    "# save_pretrained() ä¼šä¿å­˜ï¼š\n",
    "# 1. adapter_config.json: LoRA é…ç½®\n",
    "# 2. adapter_model.safetensors: LoRA æƒé‡ï¼ˆæ¨èæ ¼å¼ï¼‰\n",
    "# æˆ– adapter_model.bin: LoRA æƒé‡ï¼ˆä¼ ç»Ÿæ ¼å¼ï¼‰\n",
    "model.save_pretrained(lora_save_path)\n",
    "\n",
    "print(f\"âœ… LoRA å‚æ•°å·²ä¿å­˜åˆ°: {lora_save_path}\")\n",
    "\n",
    "# ğŸ“Š æ£€æŸ¥ä¿å­˜çš„æ–‡ä»¶\n",
    "import os\n",
    "saved_files = os.listdir(lora_save_path)\n",
    "print(f\"ğŸ“‚ ä¿å­˜çš„æ–‡ä»¶: {saved_files}\")\n",
    "\n",
    "# ğŸ“ æ£€æŸ¥æ–‡ä»¶å¤§å°\n",
    "total_size = sum(os.path.getsize(os.path.join(lora_save_path, f)) for f in saved_files)\n",
    "print(f\"ğŸ“Š æ€»å¤§å°: {total_size / (1024*1024):.2f} MB\")\n",
    "\n",
    "# ğŸ’¡ åŠ è½½æ–¹å¼ç¤ºä¾‹ï¼ˆä»£ç ä»…ä¾›å‚è€ƒï¼Œä¸å®é™…æ‰§è¡Œï¼‰\n",
    "print(\"\\nğŸ’¡ åŠ è½½ LoRA æ¨¡å‹çš„æ–¹æ³•:\")\n",
    "print(\"```python\")\n",
    "print(\"from peft import PeftModel\")\n",
    "print(\"from transformers import AutoModelForSequenceClassification\")\n",
    "print(\"\")\n",
    "print(\"# 1. åŠ è½½åŸºç¡€æ¨¡å‹\")\n",
    "print('base_model = AutoModelForSequenceClassification.from_pretrained(\"gpt2\", num_labels=2)')\n",
    "print(\"\")\n",
    "print(\"# 2. åŠ è½½ LoRA é€‚é…å™¨\")\n",
    "print('model = PeftModel.from_pretrained(base_model, \"./lora_sms_spam_classifier\")')\n",
    "print(\"\")\n",
    "print(\"# 3. ä½¿ç”¨æ¨¡å‹è¿›è¡Œæ¨ç†\")\n",
    "print(\"model.eval()\")\n",
    "print(\"# ... æ¨ç†ä»£ç  ...\")\n",
    "print(\"```\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# ğŸ”— æ–¹å¼ 2ï¼šåˆå¹¶å¹¶ä¿å­˜å®Œæ•´æ¨¡å‹ï¼ˆå¯é€‰ï¼‰\n",
    "print(\"\\nğŸ”— æ–¹å¼ 2ï¼šåˆå¹¶ LoRA å‚æ•°åˆ°åŸºç¡€æ¨¡å‹\")\n",
    "\n",
    "# ğŸ“ åˆå¹¶è¯´æ˜\n",
    "print(\"ğŸ’¡ åˆå¹¶æ“ä½œä¼šå°† LoRA å‚æ•°åŠ åˆ°åŸå§‹æƒé‡ä¸Šï¼š\")\n",
    "print(\"   W_new = W_original + Î±/r * (A @ B)\")\n",
    "print(\"\")\n",
    "print(\"âš ï¸  æ³¨æ„ï¼šåˆå¹¶åå°†å¤±å»åˆ‡æ¢ LoRA é€‚é…å™¨çš„èƒ½åŠ›\")\n",
    "print(\"\")\n",
    "\n",
    "# ğŸ”§ åˆå¹¶æ¨¡å‹ï¼ˆç¤ºä¾‹ä»£ç ï¼‰\n",
    "print(\"ğŸ”§ åˆå¹¶ä»£ç ç¤ºä¾‹ï¼ˆä¸æ‰§è¡Œï¼Œä»…å±•ç¤ºï¼‰:\")\n",
    "print(\"```python\")\n",
    "print(\"# åˆå¹¶ LoRA å‚æ•°åˆ°åŸºç¡€æ¨¡å‹\")\n",
    "print(\"merged_model = model.merge_and_unload()\")\n",
    "print(\"\")\n",
    "print(\"# ä¿å­˜å®Œæ•´æ¨¡å‹\")\n",
    "print('merged_model.save_pretrained(\"./merged_sms_spam_classifier\")')\n",
    "print('tokenizer.save_pretrained(\"./merged_sms_spam_classifier\")')\n",
    "print(\"\")\n",
    "print(\"# åŠ è½½å®Œæ•´æ¨¡å‹\")\n",
    "print('loaded_model = AutoModelForSequenceClassification.from_pretrained(')\n",
    "print('    \"./merged_sms_spam_classifier\"')\n",
    "print(')')\n",
    "print(\"```\")\n",
    "\n",
    "print(\"\\nâœ… æ¨¡å‹ä¿å­˜å®Œæˆï¼\")\n",
    "\n",
    "# ğŸ“Š ä¿å­˜æ–¹å¼å¯¹æ¯”\n",
    "print(\"\\nğŸ“Š ä¸¤ç§ä¿å­˜æ–¹å¼å¯¹æ¯”:\")\n",
    "print(\"â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\")\n",
    "print(\"â”‚      ç‰¹æ€§       â”‚  LoRA å‚æ•°   â”‚  å®Œæ•´æ¨¡å‹    â”‚\")\n",
    "print(\"â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\")\n",
    "print(\"â”‚  æ–‡ä»¶å¤§å°       â”‚  å‡  MB       â”‚  æ•°ç™¾ MB     â”‚\")\n",
    "print(\"â”‚  åŠ è½½é€Ÿåº¦       â”‚  å¿«          â”‚  è¾ƒæ…¢        â”‚\")\n",
    "print(\"â”‚  å¤šä»»åŠ¡åˆ‡æ¢     â”‚  æ”¯æŒ        â”‚  ä¸æ”¯æŒ      â”‚\")\n",
    "print(\"â”‚  ç‹¬ç«‹ä½¿ç”¨       â”‚  éœ€åŸºç¡€æ¨¡å‹  â”‚  å¯ç‹¬ç«‹ä½¿ç”¨  â”‚\")\n",
    "print(\"â”‚  æ¨èåœºæ™¯       â”‚  ç”Ÿäº§ç¯å¢ƒ    â”‚  æ¼”ç¤º/éƒ¨ç½²   â”‚\")\n",
    "print(\"â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oKyoKzQm5kgO"
   },
   "source": [
    "# ğŸ“ æ•™ç¨‹æ€»ç»“\n",
    "\n",
    "## âœ¨ æ ¸å¿ƒè¦ç‚¹å›é¡¾\n",
    "\n",
    "### PEFT åº“ä½¿ç”¨æµç¨‹\n",
    "\n",
    "| æ­¥éª¤ | ä»£ç  | è¯´æ˜ |\n",
    "|:----|:-----|:----|\n",
    "| **1ï¸âƒ£ åˆ›å»ºé…ç½®** | `lora_config = LoraConfig(...)` | å®šä¹‰ LoRA è¶…å‚æ•° |\n",
    "| **2ï¸âƒ£ åŠ è½½æ¨¡å‹** | `base_model = AutoModel.from_pretrained(...)` | åŠ è½½é¢„è®­ç»ƒåŸºç¡€æ¨¡å‹ |\n",
    "| **3ï¸âƒ£ åº”ç”¨ LoRA** | `model = get_peft_model(base_model, lora_config)` | å°† LoRA åº”ç”¨åˆ°æ¨¡å‹ |\n",
    "| **4ï¸âƒ£ è®­ç»ƒæ¨¡å‹** | `optimizer.step()` + `loss.backward()` | æ ‡å‡† PyTorch è®­ç»ƒ |\n",
    "| **5ï¸âƒ£ ä¿å­˜æ¨¡å‹** | `model.save_pretrained(path)` | ä¿å­˜ LoRA å‚æ•°ï¼ˆ~å‡ MBï¼‰|\n",
    "\n",
    "### å…³é”®ä¼˜åŠ¿å¯¹æ¯”\n",
    "\n",
    "| ç‰¹æ€§ | æ‰‹åŠ¨å®ç° | PEFT åº“ | æ”¹è¿› |\n",
    "|:----|:--------|:--------|:-----|\n",
    "| **ä»£ç é‡** | ~200 è¡Œ | ~10 è¡Œ | å‡å°‘ 95% |\n",
    "| **å¼€å‘æ—¶é—´** | 2-3 å¤© | 30 åˆ†é’Ÿ | èŠ‚çœ 90%+ |\n",
    "| **ç»´æŠ¤æˆæœ¬** | é«˜ | ä½ | å®˜æ–¹ç»´æŠ¤ |\n",
    "| **åŠŸèƒ½å®Œæ•´æ€§** | åŸºç¡€ | ä¸°å¯Œ | æ”¯æŒå¤šç§æ–¹æ³• |\n",
    "| **ç”Ÿäº§å¯ç”¨** | éœ€éªŒè¯ | å·¥ä¸šçº§ | å¤§è§„æ¨¡éªŒè¯ |\n",
    "\n",
    "## ğŸ¯ è¶…å‚æ•°é…ç½®å»ºè®®\n",
    "\n",
    "### LoRA æ ¸å¿ƒå‚æ•°\n",
    "\n",
    "| å‚æ•° | æ¨èå€¼ | èŒƒå›´ | è¯´æ˜ | å½±å“ |\n",
    "|:----|:------|:----|:-----|:----|\n",
    "| **rank (r)** | 8 | 4-64 | LoRA ç§©ï¼Œæ§åˆ¶å‚æ•°é‡ | râ†‘ â†’ å‚æ•°é‡â†‘ï¼Œè¡¨è¾¾èƒ½åŠ›â†‘ |\n",
    "| **alpha** | 16 | r ~ 2r | ç¼©æ”¾å› å­ | é€šå¸¸è®¾ä¸º 2Ã—r |\n",
    "| **dropout** | 0.05 | 0.0-0.2 | æ­£åˆ™åŒ–å¼ºåº¦ | dropoutâ†‘ â†’ æ³›åŒ–èƒ½åŠ›â†‘ |\n",
    "| **target_modules** | [\"c_attn\", \"c_fc\"] | æ¨¡å‹ç›¸å…³ | åº”ç”¨ LoRA çš„å±‚ | å±‚æ•°â†‘ â†’ å‚æ•°é‡â†‘ |\n",
    "\n",
    "### è®­ç»ƒè¶…å‚æ•°\n",
    "\n",
    "| å‚æ•° | æ¨èå€¼ | èŒƒå›´ | è¯´æ˜ |\n",
    "|:----|:------|:----|:-----|\n",
    "| **learning_rate** | 5e-4 | 1e-4 ~ 1e-3 | LoRA å¯ç”¨è¾ƒå¤§å­¦ä¹ ç‡ |\n",
    "| **batch_size** | 8 | 4-32 | æ ¹æ® GPU æ˜¾å­˜è°ƒæ•´ |\n",
    "| **epochs** | 3 | 3-10 | å°æ•°æ®é›† 3-5 è½®å³å¯ |\n",
    "| **warmup_ratio** | 0.1 | 0.05-0.15 | é¢„çƒ­æ­¥æ•°å æ¯” |\n",
    "| **weight_decay** | 0.01 | 0.0-0.1 | æƒé‡è¡°å‡ï¼ˆæ­£åˆ™åŒ–ï¼‰ |\n",
    "\n",
    "ğŸ’¡ **è°ƒå‚å»ºè®®**ï¼š\n",
    "- ğŸ”¸ **æ˜¾å­˜ä¸è¶³**ï¼šå‡å° batch_sizeã€é™ä½ rank\n",
    "- ğŸ”¸ **è¿‡æ‹Ÿåˆ**ï¼šå¢åŠ  dropoutã€å‡å°‘ epochs\n",
    "- ğŸ”¸ **æ¬ æ‹Ÿåˆ**ï¼šå¢åŠ  rankã€æé«˜ learning_rateã€å¢åŠ  epochs\n",
    "- ğŸ”¸ **è®­ç»ƒä¸ç¨³å®š**ï¼šé™ä½ learning_rateã€å¢åŠ  warmup\n",
    "\n",
    "## ğŸ’¡ æœ€ä½³å®è·µæ¸…å•\n",
    "\n",
    "| å®è·µ | è¯´æ˜ | é‡è¦æ€§ |\n",
    "|:----|:-----|:------|\n",
    "| âœ… **å­¦ä¹ ç‡é¢„çƒ­** | è®­ç»ƒåˆæœŸä½¿ç”¨å°å­¦ä¹ ç‡ï¼Œé€æ¸å¢åŠ  | â­â­â­â­â­ |\n",
    "| âœ… **æ¢¯åº¦è£å‰ª** | é™åˆ¶æ¢¯åº¦èŒƒæ•°ï¼Œé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸ | â­â­â­â­â­ |\n",
    "| âœ… **ç›‘æ§éªŒè¯é›†** | æ¯ä¸ª epoch åè¯„ä¼°ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ | â­â­â­â­â­ |\n",
    "| âœ… **ä¿å­˜ LoRA å‚æ•°** | åªä¿å­˜è½»é‡çº§é€‚é…å™¨ï¼ˆ~å‡ MBï¼‰ | â­â­â­â­ |\n",
    "| âœ… **å›ºå®šéšæœºç§å­** | ç¡®ä¿ç»“æœå¯å¤ç° | â­â­â­â­ |\n",
    "| âœ… **æ•°æ®å¢å¼º** | å¯¹äºå°æ•°æ®é›†ï¼Œä½¿ç”¨æ•°æ®å¢å¼ºæŠ€æœ¯ | â­â­â­ |\n",
    "| âœ… **æ··åˆç²¾åº¦è®­ç»ƒ** | ä½¿ç”¨ FP16/BF16 åŠ é€Ÿè®­ç»ƒ | â­â­â­ |\n",
    "\n",
    "## ğŸš€ è¿›é˜¶æ–¹å‘\n",
    "\n",
    "| æ–¹å‘ | è¯´æ˜ | éš¾åº¦ | æ¨èèµ„æº |\n",
    "|:----|:-----|:----|:---------|\n",
    "| **QLoRA** | LoRA + 4-bit é‡åŒ–ï¼Œæ˜¾å­˜éœ€æ±‚é™ä½ 75% | â­â­â­ | PEFT å®˜æ–¹æ–‡æ¡£ |\n",
    "| **å¤šä»»åŠ¡ LoRA** | ä¸€ä¸ªåŸºç¡€æ¨¡å‹ + å¤šä¸ª LoRA é€‚é…å™¨ | â­â­â­ | Hugging Face æ•™ç¨‹ |\n",
    "| **å¤§æ¨¡å‹å¾®è°ƒ** | åœ¨ LLaMAã€Mistral ç­‰å¤§æ¨¡å‹ä¸Šåº”ç”¨ | â­â­â­â­ | LLaMA-Factory |\n",
    "| **LoRA èåˆ** | åˆå¹¶å¤šä¸ª LoRA é€‚é…å™¨ | â­â­â­â­ | PEFT è¿›é˜¶æ–‡æ¡£ |\n",
    "| **åŠ¨æ€ LoRA** | è®­ç»ƒè¿‡ç¨‹ä¸­è‡ªé€‚åº”è°ƒæ•´ rank | â­â­â­â­â­ | ç ”ç©¶è®ºæ–‡ |\n",
    "\n",
    "## ğŸ“Š æœ¬æ•™ç¨‹æ€§èƒ½æ€»ç»“\n",
    "\n",
    "| æŒ‡æ ‡ | ç»“æœ |\n",
    "|:----|:----|\n",
    "| **æµ‹è¯•å‡†ç¡®ç‡** | 98.33% |\n",
    "| **è®­ç»ƒæ—¶é—´** | ~20 ç§’/epoch (A10 GPU) |\n",
    "| **å¯è®­ç»ƒå‚æ•°** | 1.18M / 125.6M (0.94%) |\n",
    "| **æ¨¡å‹æ–‡ä»¶å¤§å°** | 4.52 MB (LoRA) vs 500+ MB (å®Œæ•´æ¨¡å‹) |\n",
    "| **æ˜¾å­˜å ç”¨** | ~6 GB (A10 24GB) |\n",
    "\n",
    "ğŸ‰ **æ­å–œå®Œæˆå­¦ä¹ ï¼**\n",
    "\n",
    "ä½ å·²ç»æŒæ¡äº†ï¼š\n",
    "- âœ… ä½¿ç”¨ PEFT åº“åº”ç”¨ LoRA çš„å®Œæ•´æµç¨‹\n",
    "- âœ… LoRA æ ¸å¿ƒè¶…å‚æ•°çš„å«ä¹‰å’Œè°ƒä¼˜æ–¹æ³•\n",
    "- âœ… å·¥ä¸šçº§çš„è®­ç»ƒæœ€ä½³å®è·µ\n",
    "- âœ… æ¨¡å‹ä¿å­˜å’Œéƒ¨ç½²çš„ä¸¤ç§æ–¹å¼\n",
    "\n",
    "ğŸ’¡ **ä¸‹ä¸€æ­¥å»ºè®®**ï¼š\n",
    "1. å°è¯•åœ¨è‡ªå·±çš„æ•°æ®é›†ä¸Šåº”ç”¨ LoRA\n",
    "2. å®éªŒä¸åŒçš„è¶…å‚æ•°ç»„åˆ\n",
    "3. æ¢ç´¢ QLoRA å’Œå¤šä»»åŠ¡ LoRA\n",
    "4. åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLaMAã€Mistralï¼‰ä¸Šå®è·µ\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
