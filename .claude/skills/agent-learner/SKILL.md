# Agent Learner Skill

## è§¦å‘æ¡ä»¶

å½“ç”¨æˆ·æƒ³è¦å­¦ä¹ Agentå¼€å‘è¯¾ç¨‹æ—¶ä½¿ç”¨æ­¤Skill:
- è¾“å…¥ `/learn` - å¼€å§‹æˆ–ç»§ç»­å­¦ä¹ 
- è¾“å…¥ `/learn [è¯¾ç¨‹ID]` - å­¦ä¹ æŒ‡å®šè¯¾ç¨‹ (å¦‚ `/learn 01-1`)
- è¾“å…¥ `/quiz [éš¾åº¦]` - æµ‹è¯•å½“å‰è¯¾ç¨‹ (`easy`/`medium`/`hard`)
- è¾“å…¥ `/review [è¯¾ç¨‹ID]` - å¤ä¹ å·²å­¦è¯¾ç¨‹
- è¾“å…¥ `/status` - æŸ¥çœ‹å­¦ä¹ è¿›åº¦
- è¾“å…¥ `/publish` - å‘å¸ƒç¬”è®°åˆ°ç½‘é¡µ

## å·¥ä½œæµç¨‹

### é˜¶æ®µ1: åˆå§‹åŒ–

1. è¯»å–è¯¾ç¨‹ç´¢å¼• `curriculum/index.json`
2. è¯»å–å­¦ä¹ è¿›åº¦ `data/progress.json`
3. ç¡®å®šå½“å‰å­¦ä¹ ä½ç½®:
   - å¦‚æœç”¨æˆ·æŒ‡å®šè¯¾ç¨‹ID,è·³è½¬åˆ°è¯¥è¯¾ç¨‹
   - å¦‚æœæœªæŒ‡å®š:
     - ä¼˜å…ˆä» `progress.current` è¯»å–å½“å‰ä½ç½®
     - å¦‚æœ `current` ä¸ºç©º,ä½¿ç”¨ `get_first_uncompleted()` æ‰¾ç¬¬ä¸€ä¸ªæœªå®Œæˆçš„
     - å¦‚æœæ‰€æœ‰è¯¾ç¨‹éƒ½å®Œæˆ,æç¤ºç”¨æˆ·

**ä»£ç ç¤ºä¾‹:**
```python
import json

def determine_start_point(user_specified_id=None):
    """ç¡®å®šå­¦ä¹ èµ·ç‚¹"""
    # è¯»å–è¯¾ç¨‹å’Œè¿›åº¦
    with open('.claude/skills/agent-learner/curriculum/index.json') as f:
        curriculum = json.load(f)

    with open('data/progress.json') as f:
        progress = json.load(f)

    # ç¡®å®šèµ·ç‚¹
    if user_specified_id:
        return user_specified_id
    elif progress.get('current'):
        return progress['current']
    else:
        # æ‰¾ç¬¬ä¸€ä¸ªæœªå®Œæˆçš„
        return get_first_uncompleted(progress)
```

### é˜¶æ®µ2: åŠ è½½è¯¾ç¨‹å†…å®¹

**é‡è¦åŸåˆ™**:
- **ä¼˜å…ˆè¯»å– ipynb æ–‡ä»¶** - Jupyter Notebook æ˜¯ä¸»è¦å­¦ä¹ ææ–™ï¼Œåœ¨åˆå§‹åŒ–é˜¶æ®µå®Œæ•´åŠ è½½
- **py æ–‡ä»¶æŒ‰éœ€è¯»å–** - Python æ–‡ä»¶å¯ä»¥åœ¨å­¦ä¹ è¿‡ç¨‹ä¸­æ ¹æ®éœ€è¦è¯»å–ï¼Œä¸å¼ºåˆ¶åˆå§‹åŠ è½½

1. æ ¹æ®è¯¾ç¨‹IDå®šä½åˆ°å…·ä½“è·¯å¾„
2. è¯»å–å¯¹åº”çš„README.mdæ–‡ä»¶
3. **æ™ºèƒ½è¯»å–ä»£ç æ–‡ä»¶**ï¼ˆæ ¹æ® `code_paths` å­—æ®µï¼‰:
   - **ä¼˜å…ˆå¤„ç† `.ipynb` æ–‡ä»¶**:
     - å¯¹äº `type="notebook"` æˆ– code_paths åŒ…å« `.ipynb` çš„è¯¾ç¨‹
     - è§£æ notebook,æå–æ‰€æœ‰ code å’Œ markdown cells
     - è¿™æ˜¯ä¸»è¦å­¦ä¹ ææ–™ï¼Œå¿…é¡»å®Œæ•´åŠ è½½
   - **æŒ‰éœ€å¤„ç† `.py` æ–‡ä»¶**:
     - ä»…åœ¨éœ€è¦æ·±å…¥ä»£ç ç»†èŠ‚æ—¶è¯»å–
     - æˆ–åœ¨è®²è§£å…·ä½“æ¦‚å¿µæ—¶åŠ¨æ€åŠ è½½
     - é¿å…ä¸€æ¬¡æ€§åŠ è½½è¿‡å¤šå†…å®¹
   - å¯¹äº `code_paths` ä¸ºç©ºçš„é¡¹ç›®: è·³è¿‡ä»£ç è¯»å–ï¼Œä»…ä½¿ç”¨ README å†…å®¹
4. è§£æè¯¾ç¨‹ç»“æ„:
   - æå–æ ¸å¿ƒæ¦‚å¿µ (2-3ä¸ª)
   - æå–ä»£ç ç¤ºä¾‹ (ä¸»è¦æ¥è‡ª ipynb æ–‡ä»¶)
   - è¯†åˆ«å…³é”®çŸ¥è¯†ç‚¹

**ä»£ç ç¤ºä¾‹ - ä¼˜åŒ–çš„å†…å®¹åŠ è½½é€»è¾‘ï¼ˆipynb ä¼˜å…ˆï¼Œpy æŒ‰éœ€ï¼‰:**
```python
import json
import subprocess

def read_file_safe(file_path):
    """
    ç®€åŒ–çš„æ–‡ä»¶è¯»å–å‡½æ•°ï¼ˆLinusåŸåˆ™ï¼šç®€å•ç›´æ¥ï¼‰

    Args:
        file_path: æ–‡ä»¶è·¯å¾„

    Returns:
        str: æ–‡ä»¶å†…å®¹ï¼Œæ–‡ä»¶ä¸å­˜åœ¨æ—¶è¿”å›ç©ºå­—ç¬¦ä¸²
    """
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
            print(f"âœ… è¯»å–æˆåŠŸ: {file_path} ({len(content)} å­—ç¬¦)")
            return content
    except FileNotFoundError:
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        return ""
    except Exception as e:
        print(f"âŒ è¯»å–å¤±è´¥: {file_path} - {e}")
        return ""


def load_course_content(project_id, curriculum_file='.claude/skills/agent-learner/curriculum/index.json'):
    """åŠ è½½è¯¾ç¨‹å†…å®¹ï¼ˆä¼˜å…ˆè¯»å– ipynbï¼Œpy æ–‡ä»¶æŒ‰éœ€ï¼‰"""
    # 1. è¯»å–è¯¾ç¨‹ç´¢å¼•
    with open(curriculum_file) as f:
        curriculum = json.load(f)

    # 2. æŸ¥æ‰¾é¡¹ç›®é…ç½®
    project = find_project_by_id(curriculum, project_id)
    if not project:
        raise ValueError(f"é¡¹ç›® {project_id} ä¸å­˜åœ¨")

    module = find_module_by_project(curriculum, project)
    module_path = module['path']
    project_path = project['path']
    project_type = project.get('type', 'default')

    # 3. è¯»å– README.mdï¼ˆå¸¦å®¹é”™æœºåˆ¶ï¼‰
    readme_path = f"{module_path}/{project_path}/README.md"
    readme_content = read_file_safe(readme_path)

    if not readme_content:
        print(f"âŒ é”™è¯¯: æ— æ³•è¯»å– README æ–‡ä»¶: {readme_path}")

    # 4. æ‡’åŠ è½½ .ipynb æ–‡ä»¶ï¼ˆæ‰«æå…ƒæ•°æ®ï¼ŒæŒ‰éœ€åŠ è½½å†…å®¹ï¼‰
    notebook_metadata = {}  # {notebook_path: metadata}
    notebook_files = []
    py_files = []

    # åˆ†ç±»å¤„ç† code_paths
    for code_path in project.get('code_paths', []):
        if code_path.endswith('.ipynb'):
            notebook_files.append(code_path)
        elif code_path.endswith('.py'):
            py_files.append(code_path)

    # æ‰«æ notebook å…ƒæ•°æ®ï¼ˆä¸åŠ è½½å†…å®¹ï¼‰
    if notebook_files:
        for notebook_path in notebook_files:
            full_path = f"{module_path}/{project_path}/{notebook_path}"
            print(f"ğŸ” æ‰«æ Notebook: {notebook_path}")
            try:
                metadata = scan_notebook_metadata(full_path)
                if metadata:
                    notebook_metadata[full_path] = metadata
                    # æ˜¾ç¤ºåŠ è½½é¢„ä¼°
                    tokens = metadata['estimated_tokens']
                    print(f"  âœ… æ€» cells: {metadata['total_cells']}")
                    print(f"  ğŸ“Š ç« èŠ‚: {len(metadata['sections'])} ä¸ª")
                    print(f"  ğŸ’¾ é¢„ä¼° tokens: å…ƒæ•°æ®={tokens['metadata']}, å®Œæ•´={tokens['full']}, æ ¸å¿ƒ={tokens['core_only']}")
            except FileNotFoundError:
                print(f"âš ï¸ è­¦å‘Š: Notebook æ–‡ä»¶æœªæ‰¾åˆ°: {full_path}")
    elif project_type == "notebook":
        # å…¼å®¹æ—§é…ç½®ï¼štype=notebook ä½† code_paths ä¸ºç©º
        notebook_path = f"{project_path}.ipynb"
        full_path = f"{module_path}/{notebook_path}"
        print(f"ğŸ” æ‰«æ Notebook: {notebook_path}")
        try:
            metadata = scan_notebook_metadata(full_path)
            if metadata:
                notebook_metadata[full_path] = metadata
        except FileNotFoundError:
            print(f"âš ï¸ è­¦å‘Š: Notebook æ–‡ä»¶æœªæ‰¾åˆ°: {full_path}")

    # Python æ–‡ä»¶ä¸åœ¨è¿™é‡ŒåŠ è½½ï¼Œä»…è®°å½•è·¯å¾„ä¾›æŒ‰éœ€è¯»å–
    py_file_paths = [f"{module_path}/{project_path}/{p}" for p in py_files]

    return {
        'readme': readme_content,
        'notebook_metadata': notebook_metadata,  # å…ƒæ•°æ®ï¼ˆè½»é‡çº§ï¼‰
        'code_snippets': [],  # åˆå§‹ä¸ºç©ºï¼ŒæŒ‰éœ€åŠ è½½
        'py_file_paths': py_file_paths,
        'project': project,
        'module': module,
        'has_notebooks': len(notebook_files) > 0,
        'has_py_files': len(py_files) > 0
    }

def load_py_file_on_demand(py_file_path):
    """æŒ‰éœ€åŠ è½½ Python æ–‡ä»¶ï¼ˆä»…åœ¨éœ€è¦æ—¶è°ƒç”¨ï¼‰"""
    try:
        code_content = read(py_file_path)
        return {
            'title': py_file_path.split('/')[-1],
            'code': code_content,
            'language': 'python',
            'source': py_file_path,
            'description': f'æ¥æºæ–‡ä»¶: {py_file_path}'
        }
    except FileNotFoundError:
        print(f"âš ï¸ è­¦å‘Š: Python æ–‡ä»¶æœªæ‰¾åˆ°: {py_file_path}")
        return None
```

def scan_notebook_metadata(notebook_path):
    """
    å¿«é€Ÿæ‰«æ notebookï¼Œæå–å…ƒæ•°æ®å’Œç« èŠ‚ç»“æ„

    Args:
        notebook_path: notebook æ–‡ä»¶è·¯å¾„

    Returns:
        dict: {
            'total_cells': int,
            'sections': [
                {
                    'id': int,
                    'title': str,
                    'start_cell': int,
                    'end_cell': int,
                    'cell_count': int,
                    'skip_by_default': bool  # æ˜¯å¦é»˜è®¤è·³è¿‡ï¼ˆå¦‚ç¯å¢ƒé…ç½®ï¼‰
                }
            ],
            'core_concepts': [str],  # æ ¸å¿ƒæ¦‚å¿µåˆ—è¡¨
            'estimated_tokens': {
                'metadata': int,
                'full': int,
                'core_only': int
            }
        }
    """
    import json
    import re

    try:
        with open(notebook_path, 'r', encoding='utf-8') as f:
            notebook_data = json.load(f)
    except (FileNotFoundError, json.JSONDecodeError) as e:
        print(f"âš ï¸ æ— æ³•è§£æ notebook: {notebook_path} - {e}")
        return None

    cells = notebook_data.get('cells', [])
    total_cells = len(cells)

    # è¯†åˆ«ç« èŠ‚å’Œè·³è¿‡è§„åˆ™
    sections = []
    current_section = {
        'id': 0,
        'title': 'å¼€å§‹',
        'start_cell': 0,
        'end_cell': 0,
        'cell_count': 0,
        'skip_by_default': False
    }

    skip_keywords = ['ç¯å¢ƒ', 'é…ç½®', 'å®‰è£…', 'setup', 'config', 'install']

    for idx, cell in enumerate(cells):
        cell_type = cell.get('cell_type', '')
        source = ''.join(cell.get('source', []))

        # æ£€æµ‹ç« èŠ‚æ ‡é¢˜ï¼ˆmarkdown ä¸­çš„ ## æˆ– ### æ ‡é¢˜ï¼‰
        if cell_type == 'markdown':
            match = re.match(r'^##\s+(.+)', source.strip())
            if not match:
                # ä¹Ÿå°è¯•åŒ¹é…ä¸‰çº§æ ‡é¢˜
                match = re.match(r'^###\s+(.+)', source.strip())
            if match:
                # ä¿å­˜ä¸Šä¸€ä¸ªç« èŠ‚
                if current_section['cell_count'] > 0:
                    sections.append(current_section.copy())

                # å¼€å§‹æ–°ç« èŠ‚
                title = match.group(1).strip()
                current_section = {
                    'id': len(sections),
                    'title': title,
                    'start_cell': idx,
                    'end_cell': idx,
                    'cell_count': 0,
                    'skip_by_default': any(kw in title.lower() for kw in skip_keywords)
                }

        current_section['end_cell'] = idx
        current_section['cell_count'] += 1

    # ä¿å­˜æœ€åä¸€ä¸ªç« èŠ‚
    if current_section['cell_count'] > 0:
        sections.append(current_section)

    # æå–æ ¸å¿ƒæ¦‚å¿µï¼ˆä»ç« èŠ‚æ ‡é¢˜ä¸­ï¼‰
    core_concepts = []
    for section in sections:
        if not section['skip_by_default']:
            # ä»æ ‡é¢˜ä¸­æå–å…³é”®è¯
            title = section['title']
            if 'ï¼ˆ' in title:
                concept = title.split('ï¼ˆ')[0].strip()
            elif '(' in title:
                concept = title.split('(')[0].strip()
            else:
                concept = title
            if len(concept) < 20:  # é¿å…è¿‡é•¿çš„æ ‡é¢˜
                core_concepts.append(concept)

    # Token ä¼°ç®—
    estimated_metadata = 500
    estimated_full = total_cells * 3500  # æ¯ä¸ª_cell çº¦ 3.5K tokens
    core_cells = sum(s['cell_count'] for s in sections if not s['skip_by_default'])
    estimated_core_only = core_cells * 3500

    return {
        'total_cells': total_cells,
        'sections': sections,
        'core_concepts': core_concepts[:10],  # æœ€å¤š 10 ä¸ª
        'estimated_tokens': {
            'metadata': estimated_metadata,
            'full': estimated_full,
            'core_only': estimated_core_only
        }
    }


def load_notebook_section(notebook_path, section_id, metadata):
    """
    æŒ‰éœ€åŠ è½½æŒ‡å®šç« èŠ‚çš„å†…å®¹

    Args:
        notebook_path: notebook æ–‡ä»¶è·¯å¾„
        section_id: ç« èŠ‚ IDï¼ˆä» metadata['sections'] ä¸­è·å–ï¼‰
        metadata: scan_notebook_metadata() è¿”å›çš„å…ƒæ•°æ®

    Returns:
        list: snippetsï¼ˆä¸ parse_notebook è¿”å›æ ¼å¼ç›¸åŒï¼‰
    """
    import json

    try:
        with open(notebook_path, 'r', encoding='utf-8') as f:
            notebook_data = json.load(f)
    except (FileNotFoundError, json.JSONDecodeError) as e:
        print(f"âš ï¸ æ— æ³•åŠ è½½ç« èŠ‚ {section_id}: {e}")
        return []

    # æ‰¾åˆ°æŒ‡å®šç« èŠ‚
    section = None
    for s in metadata.get('sections', []):
        if s['id'] == section_id:
            section = s
            break

    if not section:
        print(f"âš ï¸ ç« èŠ‚ {section_id} ä¸å­˜åœ¨")
        return []

    # åªåŠ è½½æŒ‡å®šèŒƒå›´çš„ cells
    start = section['start_cell']
    end = section['end_cell']
    cells = notebook_data.get('cells', [])[start:end+1]

    print(f"ğŸ““ åŠ è½½ç« èŠ‚ {section_id}: {section['title']} (cells {start}-{end}, å…± {len(cells)} ä¸ª)")

    # è§£æ cellsï¼ˆä¸ parse_notebook ç›¸åŒé€»è¾‘ï¼‰
    snippets = []
    for idx, cell in enumerate(cells):
        global_idx = start + idx  # å…¨å±€ cell ç´¢å¼•
        cell_type = cell.get('cell_type', '')
        source_lines = cell.get('source', [])
        content = ''.join(source_lines) if isinstance(source_lines, list) else source_lines

        if not content.strip():
            continue

        if cell_type == 'code':
            snippets.append({
                'title': f'ğŸ““ ä»£ç å•å…ƒæ ¼ {global_idx + 1}',
                'code': content,
                'language': 'python',
                'source': f'{notebook_path}#cell-{global_idx}',
                'description': f'ç« èŠ‚: {section["title"]}'
            })
        elif cell_type == 'markdown':
            snippets.append({
                'title': f'ğŸ“ è¯´æ˜ {global_idx + 1}',
                'code': content,
                'language': 'markdown',
                'source': f'{notebook_path}#cell-{global_idx}',
                'description': f'ç« èŠ‚: {section["title"]}'
            })

    return snippets


def parse_notebook(notebook_path):
    """è§£æ Jupyter notebook æ–‡ä»¶"""
    try:
        # Read å·¥å…·ä¼šè‡ªåŠ¨è§£æ .ipynb å¹¶è¿”å›å¤„ç†åçš„å†…å®¹
        # æˆ‘ä»¬éœ€è¦è¯»å–åŸå§‹ JSON è¿›è¡Œè§£æ
        import json
        with open(notebook_path, 'r', encoding='utf-8') as f:
            notebook_data = json.load(f)
    except (FileNotFoundError, json.JSONDecodeError) as e:
        print(f"âš ï¸ è­¦å‘Š: æ— æ³•è§£æ notebook æ–‡ä»¶: {notebook_path} - {e}")
        return []

    snippets = []
    for idx, cell in enumerate(notebook_data.get('cells', [])):
        cell_type = cell.get('cell_type', '')
        source_lines = cell.get('source', [])
        content = ''.join(source_lines) if isinstance(source_lines, list) else source_lines

        if not content.strip():
            continue

        if cell_type == 'code':
            snippets.append({
                'title': f'ğŸ““ ä»£ç å•å…ƒæ ¼ {idx + 1}',
                'code': content,
                'language': 'python',
                'source': f'{notebook_path}#cell-{idx}',
                'description': f'Notebook ç¬¬ {idx + 1} ä¸ªä»£ç å•å…ƒ'
            })
        elif cell_type == 'markdown':
            # Markdown å†…å®¹ä½œä¸ºè¯´æ˜
            snippets.append({
                'title': f'ğŸ“ è¯´æ˜ {idx + 1}',
                'code': content,
                'language': 'markdown',
                'source': f'{notebook_path}#cell-{idx}',
                'description': 'Notebook ä¸­çš„è¯´æ˜æ–‡æ¡£'
            })

    return snippets

def find_project_by_id(curriculum, project_id):
    """æ ¹æ®é¡¹ç›®IDæŸ¥æ‰¾é¡¹ç›®é…ç½®"""
    for module in curriculum.get('modules', []):
        for project in module.get('projects', []):
            if project['id'] == project_id:
                return project
    return None

def find_module_by_project(curriculum, project):
    """æ ¹æ®é¡¹ç›®æŸ¥æ‰¾æ‰€å±æ¨¡å—"""
    for module in curriculum.get('modules', []):
        for p in module.get('projects', []):
            if p['id'] == project['id']:
                return module
    return None
```

### é˜¶æ®µ3: å¼•å¯¼å¼å­¦ä¹ å¾ªç¯

å¯¹æ¯ä¸ªæ ¸å¿ƒæ¦‚å¿µæ‰§è¡Œ:

```
1. ã€è®²è§£æ¦‚å¿µã€‘
   - ç”¨ç®€å•è¯­è¨€è§£é‡Šæ¦‚å¿µ
   - è¯´æ˜ä¸ºä»€ä¹ˆéœ€è¦è¿™ä¸ªæ¦‚å¿µ
   - ä¸¾ä¾‹è¯´æ˜åº”ç”¨åœºæ™¯

2. ã€å±•ç¤ºä»£ç ã€‘
   - ä» `code_snippets` åˆ—è¡¨ä¸­é€‰æ‹©ç›¸å…³ç‰‡æ®µ
   - æ˜¾ç¤ºä»£ç æ¥æºå’Œå†…å®¹ï¼ˆé™åˆ¶é•¿åº¦é¿å… token è¶…é™ï¼‰
   - é€è¡Œè§£é‡Šå…³é”®éƒ¨åˆ†
   - è¯´æ˜ä»£ç çš„ä½œç”¨

**ä»£ç ç¤ºä¾‹ - å±•ç¤ºä»£ç ç‰‡æ®µï¼ˆæ”¯æŒ ipynb + py æŒ‰éœ€ï¼‰:**
```python
def show_notebook_sections(course_data):
    """
    å±•ç¤º notebook ç« èŠ‚åˆ—è¡¨ï¼Œè®©ç”¨æˆ·é€‰æ‹©è¦å­¦ä¹ çš„ç« èŠ‚

    Args:
        course_data: load_course_content() è¿”å›çš„æ•°æ®

    Returns:
        list: ç”¨æˆ·é€‰æ‹©çš„ç« èŠ‚ ID åˆ—è¡¨
    """
    notebook_metadata = course_data.get('notebook_metadata', {})

    if not notebook_metadata:
        print("ğŸ“„ æ­¤è¯¾ç¨‹æ²¡æœ‰ notebook æ–‡ä»¶")
        return []

    # åªå¤„ç†ç¬¬ä¸€ä¸ª notebookï¼ˆé€šå¸¸ä¸€ä¸ªè¯¾ç¨‹åªæœ‰ä¸€ä¸ªä¸»è¦ notebookï¼‰
    notebook_path = list(notebook_metadata.keys())[0]
    metadata = notebook_metadata[notebook_path]
    sections = metadata.get('sections', [])

    print(f"\nğŸ“š è¯¾ç¨‹ç« èŠ‚: {notebook_path.split('/')[-1]}")
    print("=" * 70)

    # æ˜¾ç¤ºç« èŠ‚åˆ—è¡¨
    core_sections = []
    for section in sections:
        skip_mark = "â­ï¸  " if section['skip_by_default'] else "ğŸ“– "
        section_info = f"{skip_mark} #{section['id']} {section['title']} ({section['cell_count']} cells)"
        print(f"  {section_info}")

        if not section['skip_by_default']:
            core_sections.append(section)

    print("\nğŸ’¡ æç¤º: ç¯å¢ƒé…ç½®ç« èŠ‚å·²è‡ªåŠ¨è·³è¿‡")
    print(f"ğŸ“Š Token é¢„ä¼°: å…ƒæ•°æ®={metadata['estimated_tokens']['metadata']}, å®Œæ•´={metadata['estimated_tokens']['full']:,}")

    # è¿”å›æ ¸å¿ƒç« èŠ‚ï¼ˆéè·³è¿‡çš„ç« èŠ‚ï¼‰
    return [s['id'] for s in core_sections]


def show_relevant_code(concept, course_data, max_snippets=2, max_length=500):
    """
    å±•ç¤ºä¸æ¦‚å¿µç›¸å…³çš„ä»£ç ç‰‡æ®µï¼ˆæ‡’åŠ è½½ç‰ˆæœ¬ï¼‰

    æ–°ç‰¹æ€§:
    - ä»å…ƒæ•°æ®ä¸­æŒ‰éœ€åŠ è½½ç« èŠ‚
    - è‡ªåŠ¨åŒ¹é…æ¦‚å¿µç›¸å…³ç« èŠ‚
    - æ”¯æŒ LRU ç¼“å­˜
    """
    notebook_metadata = course_data.get('notebook_metadata', {})
    py_file_paths = course_data.get('py_file_paths', [])

    if not notebook_metadata and not py_file_paths:
        print("ğŸ“„ æ­¤è¯¾ç¨‹æš‚æ— ä»£ç ç¤ºä¾‹")
        return

    code_snippets = []

    # ä» notebook å…ƒæ•°æ®ä¸­æŒ‰éœ€åŠ è½½
    if notebook_metadata:
        # æ‰¾åˆ°ç›¸å…³çš„ç« èŠ‚
        relevant_sections = []

        for notebook_path, metadata in notebook_metadata.items():
            sections = metadata.get('sections', [])

            # æ ¹æ®æ¦‚å¿µåŒ¹é…ç« èŠ‚
            for section in sections:
                if section['skip_by_default']:
                    continue

                # æ£€æŸ¥ç« èŠ‚æ ‡é¢˜æ˜¯å¦åŒ…å«æ¦‚å¿µå…³é”®è¯
                section_title_lower = section['title'].lower()
                concept_lower = concept.lower()

                # åŒ¹é…é€»è¾‘ï¼šç« èŠ‚æ ‡é¢˜åŒ…å«æ¦‚å¿µè¯
                if (concept_lower in section_title_lower or
                    any(kw in section_title_lower for kw in concept_lower.split()[:3])):
                    relevant_sections.append((notebook_path, section))

        # æŒ‰ç›¸å…³æ€§æ’åºå¹¶åŠ è½½
        for notebook_path, section in relevant_sections[:max_snippets]:
            print(f"ğŸ” åŠ è½½ç« èŠ‚: {section['title']}")
            snippets = load_notebook_section(notebook_path, section['id'], metadata)
            code_snippets.extend(snippets)

    # å¦‚æœ notebook ä¸­æ²¡æ‰¾åˆ°ï¼Œå°è¯• py æ–‡ä»¶
    if not code_snippets and py_file_paths:
        print(f"ğŸ’¡ Notebook ä¸­æœªæ‰¾åˆ°ç›¸å…³ä»£ç ï¼Œå°è¯•åŠ è½½ Python æ–‡ä»¶...")
        for py_path in py_file_paths:
            py_snippet = load_py_file_on_demand(py_path)
            if py_snippet:
                code_snippets.append(py_snippet)
                break

    # å¦‚æœè¿˜æ˜¯æ²¡æ‰¾åˆ°ï¼Œå±•ç¤ºç¬¬ä¸€ä¸ªç« èŠ‚
    if not code_snippets and notebook_metadata:
        print("ğŸ’¡ å±•ç¤ºç¬¬ä¸€ä¸ªæ ¸å¿ƒç« èŠ‚...")
        for notebook_path, metadata in notebook_metadata.items():
            for section in metadata.get('sections', []):
                if not section['skip_by_default']:
                    snippets = load_notebook_section(notebook_path, section['id'], metadata)
                    code_snippets.extend(snippets)
                    break
            if code_snippets:
                break

    # å±•ç¤ºä»£ç 
    for snippet in code_snippets[:max_snippets]:
        print(f"\nğŸ“„ æ¥æº: {snippet['source']}")
        print(f"ğŸ“Œ {snippet.get('description', 'ä»£ç ç¤ºä¾‹')}")
        print(f"```{snippet['language']}")

        # é™åˆ¶ä»£ç é•¿åº¦
        code = snippet['code']
        if len(code) > max_length:
            code = code[:max_length] + "\n... (ä»£ç å·²æˆªæ–­)"
        print(code)
        print("```\n")


def find_relevant_snippets(concept_name, code_snippets):
    """æ ¹æ®æ¦‚å¿µåç§°æŸ¥æ‰¾ç›¸å…³ä»£ç ç‰‡æ®µ"""
    # ç®€å•çš„å…³é”®è¯åŒ¹é…
    relevant = []
    keywords = concept_name.lower().split()

    for snippet in code_snippets:
        # åœ¨æ ‡é¢˜ã€æè¿°ã€ä»£ç ä¸­æœç´¢å…³é”®è¯
        searchable_text = (
            snippet['title'].lower() + ' ' +
            snippet.get('description', '').lower() + ' ' +
            snippet['code'][:200].lower()
        )

        # å¦‚æœåŒ…å«ä»»ä¸€å…³é”®è¯ï¼Œè®¤ä¸ºç›¸å…³
        if any(keyword in searchable_text for keyword in keywords if len(keyword) > 3):
            relevant.append(snippet)

    return relevant
```

3. ã€æé—®æµ‹è¯•ã€‘
   - ç”Ÿæˆ1-2ä¸ªç›¸å…³é—®é¢˜
   - ç­‰å¾…ç”¨æˆ·å›ç­”
   - éªŒè¯ç­”æ¡ˆå¹¶ç»™å‡ºè§£æ
```

### é˜¶æ®µ4: ç»¼åˆæµ‹è¯•

å®Œæˆæ‰€æœ‰æ¦‚å¿µè®²è§£å:

1. ç”Ÿæˆ5-10ä¸ªæµ‹è¯•é¢˜ (æŒ‰éš¾åº¦åˆ†é…):
   - 2é¢˜åŸºç¡€æ¦‚å¿µ (è®°å¿†)
   - 3é¢˜åŸç†ç†è§£ (åº”ç”¨)
   - 3é¢˜ä»£ç åˆ†æ (åˆ†æ)
   - 2é¢˜å®è·µåœºæ™¯ (åˆ›é€ )

2. äº¤äº’å¼é—®ç­”:
   - é€ä¸€æé—®
   - è®°å½•ç”¨æˆ·ç­”æ¡ˆ
   - å®æ—¶åé¦ˆå¯¹é”™
   - ç»™å‡ºè¯¦ç»†è§£æ

3. è®¡ç®—æ€»åˆ†å¹¶è®°å½•

### é˜¶æ®µ5: ç”Ÿæˆç¬”è®°

**ä½¿ç”¨ Jinja2 æ¨¡æ¿å¼•æ“ç”Ÿæˆç¬”è®°:**

```python
from jinja2 import Template
import json

def generate_note(course_data, quiz_results):
    """ç”Ÿæˆå­¦ä¹ ç¬”è®°ï¼ˆç»Ÿä¸€æ ¼å¼ v2.0.0ï¼‰

    Args:
        course_data: åŒ…å«è¯¾ç¨‹ä¿¡æ¯çš„å­—å…¸
            - id: é¡¹ç›®ID (å¦‚ '01-1')
            - module_name: æ¨¡å—åç§°
            - project_name: é¡¹ç›®åç§°
            - difficulty: éš¾åº¦ç­‰çº§
            - concepts: æ ¸å¿ƒæ¦‚å¿µåˆ—è¡¨
            - key_points: å…³é”®è¦ç‚¹åˆ—è¡¨
            - code_snippets: ä»£ç ç‰‡æ®µåˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
            - path: è¯¾ç¨‹è·¯å¾„
            - code_path: ä»£ç è·¯å¾„ï¼ˆå¯é€‰ï¼‰
            - readme_path: READMEè·¯å¾„ï¼ˆå¯é€‰ï¼‰
        quiz_results: æµ‹è¯•ç»“æœå­—å…¸
            - score: å¾—åˆ†
            - questions: é—®é¢˜åˆ—è¡¨
    """
    # åŠ è½½æ¨¡æ¿
    with open('.claude/skills/agent-learner/templates/note.md', 'r') as f:
        template = Template(f.read())

    # å‡†å¤‡æ¨¡æ¿å˜é‡ï¼ˆä¿®å¤å­—æ®µæ˜ å°„ï¼‰
    project_id = course_data.get('id', 'unknown')
    project_name = course_data.get('project_name', 'Unknown Project')
    module_name = course_data.get('module_name', 'Unknown Module')

    context = {
        'course_name': f"{project_id}: {project_name}",  # ä¿®å¤ï¼šæ‹¼æ¥ç”Ÿæˆå®Œæ•´åç§°
        'module_name': module_name,
        'project_name': project_name,
        'learn_date': datetime.now().strftime('%Y-%m-%d'),
        'learn_duration': course_data.get('learn_duration', '2å°æ—¶'),
        'learn_status': course_data.get('learn_status', 'å·²å®Œæˆ'),
        'quiz_score': quiz_results.get('score', 0),
        'difficulty': course_data.get('difficulty', 'â­â­â­'),
        'concepts': course_data.get('concepts', []),
        'key_points': course_data.get('key_points', []),
        'code_snippets': course_data.get('code_snippets', []),
        'quiz_questions': quiz_results.get('questions', []),
        'total_score': quiz_results.get('score', 0),
        'curriculum_path': course_data.get('path', ''),
        'code_path': course_data.get('code_path', ''),
        'project_readme': course_data.get('readme_path', ''),
        'external_links': course_data.get('external_links', []),
        'learner_notes': course_data.get('notes', ''),
        'generated_at': datetime.now().isoformat()
    }

    # æ¸²æŸ“æ¨¡æ¿
    content = template.render(**context)

    # ä¿å­˜ç¬”è®°ï¼ˆæ–‡ä»¶åæ ¼å¼ï¼š{id}-{slug}.mdï¼‰
    slug = course_data.get('slug', project_name.lower().replace(' ', '-'))
    note_file = f"notes/{project_id}-{slug}.md"
    with open(note_file, 'w', encoding='utf-8') as f:
        f.write(content)

    return note_file
```

**å…³é”®å˜é‡è¯´æ˜:**
- `concepts`: åˆ—è¡¨,æ¯ä¸ªå…ƒç´ åŒ…å« `{name, description, code_example}`
- `key_points`: å­—ç¬¦ä¸²åˆ—è¡¨
- `code_snippets`: åˆ—è¡¨,æ¯ä¸ªå…ƒç´ åŒ…å« `{title, code, description}`
- `quiz_questions`: åˆ—è¡¨,æ¯ä¸ªå…ƒç´ åŒ…å« `{question, user_answer, correct_answer, correct, explanation}`

3. ä¿å­˜åˆ° `notes/{project-id}-{name}.md`

### é˜¶æ®µ5.5: å‘å¸ƒè¯¢é—® (å¯é€‰)

**è¯¢é—®ç”¨æˆ·æ˜¯å¦å‘å¸ƒåˆ°ç½‘é¡µ**:

```
âœ… ç¬”è®°å·²ç”Ÿæˆ: notes/01-1-mcp-demo.md

ğŸ“¤ æ˜¯å¦ç«‹å³å‘å¸ƒåˆ°ç½‘é¡µ?

1) GitHub Pages    (æ¨è,å…è´¹æ‰˜ç®¡)
2) Cloudflare Pages (ç°æœ‰éƒ¨ç½²,éœ€è¦é…ç½®)
3) è·³è¿‡å‘å¸ƒ        (ç¨åæ‰‹åŠ¨ /publish)

è¯·è¾“å…¥é€‰é¡¹ (1/2/3):
```

**æ ¹æ®ç”¨æˆ·é€‰æ‹©æ‰§è¡Œ**:

- **é€‰æ‹© 1 (GitHub Pages)**:
  ```python
  # è°ƒç”¨å‘å¸ƒè„šæœ¬
  bash("./scripts/publish.sh", "--platform", "github")
  ```

- **é€‰æ‹© 2 (Cloudflare Pages)**:
  ```python
  # è°ƒç”¨ç°æœ‰å‘å¸ƒè„šæœ¬
  bash("./scripts/publish.sh", "--platform", "cloudflare")
  ```

- **é€‰æ‹© 3 (è·³è¿‡)**:
  ```python
  # ä¸æ‰§è¡Œä»»ä½•æ“ä½œ
  print("ğŸ’¡ æç¤º: ç¨åå¯ç”¨ /publish å‘½ä»¤å‘å¸ƒ")
  ```

**é”™è¯¯å¤„ç†**:
- å‘å¸ƒå¤±è´¥æ—¶æ˜¾ç¤ºè¯¦ç»†é”™è¯¯ä¿¡æ¯
- æä¾›æ•…éšœæ’é™¤å»ºè®®
- ä¸å½±å“å­¦ä¹ æµç¨‹å®Œæˆ

**ä»£ç ç¤ºä¾‹**:
```python
def prompt_publish_options(note_file):
    """è¯¢é—®ç”¨æˆ·å‘å¸ƒé€‰é¡¹"""

    print(f"\nâœ… ç¬”è®°å·²ç”Ÿæˆ: {note_file}")
    print("\nğŸ“¤ æ˜¯å¦ç«‹å³å‘å¸ƒåˆ°ç½‘é¡µ?")
    print("\né€‰æ‹©å‘å¸ƒå¹³å°:")
    print("1) GitHub Pages    (æ¨è,å…è´¹æ‰˜ç®¡)")
    print("2) Cloudflare Pages (ç°æœ‰éƒ¨ç½²,éœ€è¦é…ç½®)")
    print("3) è·³è¿‡å‘å¸ƒ        (ç¨åæ‰‹åŠ¨ /publish)")

    while True:
        choice = input("\nè¯·è¾“å…¥é€‰é¡¹ (1/2/3): ").strip()

        if choice == "1":
            return "github"
        elif choice == "2":
            return "cloudflare"
        elif choice == "3":
            return None
        else:
            print("âŒ æ— æ•ˆé€‰é¡¹,è¯·è¾“å…¥ 1ã€2 æˆ– 3")
```

### é˜¶æ®µ6: æ›´æ–°è¿›åº¦

**æ–­ç‚¹ç»­å­¦æœºåˆ¶ - æ¯ä¸ªé˜¶æ®µåè‡ªåŠ¨ä¿å­˜:**

```python
import fcntl
import json
from datetime import datetime

def update_learning_state(project_id, step_name, data=None):
    """æ›´æ–°å­¦ä¹ çŠ¶æ€ï¼ˆæ”¯æŒæ–­ç‚¹ç»­å­¦ï¼‰- ç»Ÿä¸€æ ¼å¼ v2.0.0

    Args:
        project_id: é¡¹ç›®ID (å¦‚ '01-1')
        step_name: å½“å‰æ­¥éª¤åç§°
        data: è¦ä¿å­˜çš„æ•°æ® (å¦‚å·²å­¦æ¦‚å¿µåˆ—è¡¨)

    Steps:
        'started': å¼€å§‹å­¦ä¹ 
        'concept_1': å­¦å®Œç¬¬1ä¸ªæ¦‚å¿µ
        'concept_2': å­¦å®Œç¬¬2ä¸ªæ¦‚å¿µ
        'quiz_start': å¼€å§‹æµ‹è¯•
        'quiz_complete': æµ‹è¯•å®Œæˆ
        'completed': è¯¾ç¨‹å®Œæˆ

    ç»Ÿä¸€æ ¼å¼:
        {
          "status": "in_progress" | "completed",
          "started_at": "ISO timestamp",
          "completed_at": "ISO timestamp (optional)",
          "current_step": "concept_1 | concept_2 | ... | quiz | completed",
          "completed_concepts": ["æ¦‚å¿µ1", "æ¦‚å¿µ2"],
          "quiz_score": 85 (optional),
          "quiz_taken_at": "ISO timestamp (optional)"
        }
    """
    progress_file = 'data/progress.json'

    # è¯»å–ç°æœ‰è¿›åº¦
    try:
        with open(progress_file, 'r') as f:
            progress = json.load(f)
    except FileNotFoundError:
        progress = {'version': '2.0.0', 'current': None, 'progress': {}}

    # ç¡®ä¿é¡¹ç›®è®°å½•å­˜åœ¨
    if project_id not in progress['progress']:
        progress['progress'][project_id] = {}

    project_data = progress['progress'][project_id]

    # æ›´æ–°çŠ¶æ€ï¼ˆç»Ÿä¸€æ ¼å¼ï¼‰
    if step_name == 'started':
        project_data['status'] = 'in_progress'
        project_data['started_at'] = datetime.now().isoformat()
        project_data['current_step'] = 'concept_1'
        project_data['completed_concepts'] = []
        progress['current'] = project_id

    elif step_name.startswith('concept_'):
        # å­¦å®Œä¸€ä¸ªæ¦‚å¿µ
        concept_num = int(step_name.split('_')[1])
        project_data['current_step'] = f'concept_{concept_num + 1}'
        if data and 'concept' in data:
            project_data['completed_concepts'] = project_data.get('completed_concepts', [])
            project_data['completed_concepts'].append(data['concept'])

    elif step_name == 'quiz_start':
        project_data['current_step'] = 'quiz'

    elif step_name == 'quiz_complete':
        project_data['status'] = 'completed'
        project_data['current_step'] = 'completed'
        project_data['completed_at'] = datetime.now().isoformat()
        project_data['quiz_score'] = data.get('score')
        project_data['quiz_taken_at'] = datetime.now().isoformat()

        # ç§»åŠ¨åˆ°ä¸‹ä¸€ä¸ªé¡¹ç›®
        progress['current'] = get_next_project_id(project_id)

    # å†™å…¥æ–‡ä»¶ï¼ˆå¸¦æ–‡ä»¶é”ï¼‰
    with open(progress_file, 'w') as f:
        fcntl.flock(f.fileno(), fcntl.LOCK_EX)
        json.dump(progress, f, indent=2, ensure_ascii=False)
        fcntl.flock(f.fileno(), fcntl.LOCK_UN)

def get_next_project_id(current_id, curriculum_file='.claude/skills/agent-learner/curriculum/index.json'):
    """è·å–ä¸‹ä¸€ä¸ªé¡¹ç›®çš„ID"""
    with open(curriculum_file, 'r') as f:
        curriculum = json.load(f)

    # è·å–æ‰€æœ‰é¡¹ç›®ï¼ˆæŒ‰é¡ºåºï¼‰
    all_projects = []
    for module in curriculum['modules']:
        for project in module['projects']:
            all_projects.append(project['id'])

    # æ‰¾åˆ°å½“å‰é¡¹ç›®çš„ç´¢å¼•
    try:
        current_index = all_projects.index(current_id)
    except ValueError:
        return all_projects[0] if all_projects else None

    # è¿”å›ä¸‹ä¸€ä¸ªé¡¹ç›®
    next_index = current_index + 1
    if next_index < len(all_projects):
        return all_projects[next_index]

    return None

def get_first_uncompleted(progress, curriculum_file='.claude/skills/agent-learner/curriculum/index.json'):
    """è·å–ç¬¬ä¸€ä¸ªæœªå®Œæˆçš„é¡¹ç›®"""
    with open(curriculum_file, 'r') as f:
        curriculum = json.load(f)

    for module in curriculum['modules']:
        for project in module['projects']:
            project_id = project['id']
            if project_id not in progress.get('progress', {}):
                return project_id

    return None

def resume_learning(project_id):
    """æ¢å¤å­¦ä¹  - ä»ä¸Šæ¬¡ä¸­æ–­çš„åœ°æ–¹ç»§ç»­ï¼ˆç»Ÿä¸€æ ¼å¼ v2.0.0ï¼‰

    Returns:
        dict: {
            'status': 'in_progress' | 'completed' | 'not_started',
            'current_step': 'concept_1' | 'concept_2' | ... | 'quiz' | 'completed',
            'completed_concepts': ['æ¦‚å¿µ1', 'æ¦‚å¿µ2'],
            'started_at': 'ISO timestamp',
            'can_resume': bool
        }
    """
    progress_file = 'data/progress.json'

    with open(progress_file, 'r') as f:
        progress = json.load(f)

    project_data = progress['progress'].get(project_id, {})

    # å…¼å®¹æ—§æ ¼å¼ï¼šå¦‚æœä½¿ç”¨ status å­—æ®µï¼Œç›´æ¥è¯»å–
    # å¦åˆ™æ£€æŸ¥ in_progress å­—æ®µï¼ˆæ—§æ ¼å¼ï¼‰
    if 'status' in project_data:
        status = project_data['status']
        can_resume = (status == 'in_progress')
    elif 'in_progress' in project_data:
        status = 'in_progress'
        can_resume = True
    else:
        status = project_data.get('completed', 'not_started')
        can_resume = False

    # è·å–æ–­ç‚¹ä¿¡æ¯
    current_step = project_data.get('current_step', 'concept_1')
    completed_concepts = project_data.get('completed_concepts', [])
    started_at = project_data.get('started_at', '')

    return {
        'status': status,
        'step': current_step,
        'completed_concepts': completed_concepts,
        'started_at': started_at,
        'can_resume': can_resume
    }
```

**ä½¿ç”¨åœºæ™¯ç¤ºä¾‹:**

```python
# åœºæ™¯1: å­¦ä¹ åˆ°ä¸€åŠæ—¶ä¿å­˜
update_learning_state('01-2', 'concept_2', {'concept': 'MCPåè®®'})
# progress.json: {"current_step": "concept_3", "completed_concepts": ["MCPåè®®"]}

# åœºæ™¯2: æ¢å¤å­¦ä¹ 
state = resume_learning('01-2')
# è¿”å›: {'step': 'concept_3', 'completed_concepts': ['MCPåè®®'], 'can_resume': True}

# åœºæ™¯3: å®Œæˆè¯¾ç¨‹
update_learning_state('01-2', 'quiz_complete', {'score': 85})
# è‡ªåŠ¨ç§»åŠ¨åˆ°ä¸‹ä¸€ä¸ªé¡¹ç›®
```

**å…³é”®ç‚¹:**
- **æ–­ç‚¹ç»­å­¦**: è®°å½• `current_step` å’Œ `completed_concepts`
- **é˜¶æ®µä¿å­˜**: æ¯ä¸ªæ¦‚å¿µå­¦å®Œå°±ä¿å­˜ï¼Œä¸åªæ˜¯ç»“æŸæ—¶ä¿å­˜
- **çŠ¶æ€æ¢å¤**: `resume_learning()` ä»ä¸Šæ¬¡ä¸­æ–­å¤„ç»§ç»­
- **è‡ªåŠ¨æ¨è¿›**: å®Œæˆåè‡ªåŠ¨æ›´æ–° `current` åˆ°ä¸‹ä¸€è¯¾
- **æ–‡ä»¶é”**: é˜²æ­¢å¹¶å‘å†™å…¥å†²çª

**çŠ¶æ€è¡¨ç¤º:**
- `current_step = 'concept_1'` â†’ æ­£åœ¨å­¦ä¹ ç¬¬1ä¸ªæ¦‚å¿µ
- `current_step = 'concept_3'` â†’ æ­£åœ¨å­¦ä¹ ç¬¬3ä¸ªæ¦‚å¿µ
- `current_step = 'quiz'` â†’ æ­£åœ¨åšæµ‹è¯•
- `completed` å­˜åœ¨ â†’ è¯¾ç¨‹å·²å®Œæˆ

## æ ¸å¿ƒè§„åˆ™

### å­¦ä¹ åŸåˆ™

1. **å¼•å¯¼å¼è®²è§£**
   - Claudeä¸»åŠ¨è®²è§£,ä¸åªæ˜¯å›ç­”
   - ç”¨ç±»æ¯”å’Œä¾‹å­å¸®åŠ©ç†è§£
   - ä»ç®€åˆ°éš¾,å¾ªåºæ¸è¿›

2. **äº’åŠ¨å¼å­¦ä¹ **
   - æ¯ä¸ªæ¦‚å¿µåéƒ½è¦æé—®
   - ç¡®ä¿ç”¨æˆ·ç†è§£åå†ç»§ç»­
   - æ ¹æ®å›ç­”è°ƒæ•´è®²è§£æ·±åº¦

3. **å®ç”¨ä¸»ä¹‰**
   - é‡ç‚¹è®²è§£å®é™…åº”ç”¨
   - ä»£ç ç¤ºä¾‹è¦èƒ½è¿è¡Œ
   - è¯´æ˜å¸¸è§é™·é˜±å’Œæœ€ä½³å®è·µ

### æé—®ç­–ç•¥

**æ¦‚å¿µè®°å¿†é¢˜**:
```
"XXçš„å…¨ç§°æ˜¯ä»€ä¹ˆ?"
"XXçš„ä¸»è¦ä½œç”¨æ˜¯ä»€ä¹ˆ?"
```

**ç†è§£åº”ç”¨é¢˜**:
```
"åœ¨ä»€ä¹ˆåœºæ™¯ä¸‹åº”è¯¥ä½¿ç”¨XX?"
"XXå’ŒYYæœ‰ä»€ä¹ˆåŒºåˆ«?"
```

**ä»£ç åˆ†æé¢˜**:
```
"è¿™æ®µä»£ç ä¸­XXçš„ä½œç”¨æ˜¯ä»€ä¹ˆ?"
"å¦‚æœæŠŠXXæ”¹æˆYYä¼šå‘ç”Ÿä»€ä¹ˆ?"
```

**å®è·µåœºæ™¯é¢˜**:
```
"å¦‚æœè¦å®ç°XXåŠŸèƒ½,ä½ ä¼šæ€ä¹ˆåš?"
"ç»™ä½ ä¸€ä¸ªå®é™…é—®é¢˜:XXX,å¦‚ä½•ç”¨æˆ‘ä»¬å­¦åˆ°çš„XXæ¥è§£å†³?"
```

### é¢˜ç›®ç”Ÿæˆ

åŸºäºè¯¾ç¨‹å†…å®¹åŠ¨æ€ç”Ÿæˆ5-10ä¸ªé—®é¢˜:

1. åˆ†æREADMEä¸­çš„æ ¸å¿ƒæ¦‚å¿µ
2. è¯†åˆ«ä»£ç ç¤ºä¾‹ä¸­çš„å…³é”®ç‚¹
3. ç»“åˆå®é™…åº”ç”¨åœºæ™¯
4. ç¡®ä¿è¦†ç›–å¸ƒé²å§†è®¤çŸ¥å±‚çº§:
   - è®°å¿†
   - ç†è§£
   - åº”ç”¨
   - åˆ†æ
   - è¯„ä»·
   - åˆ›é€ 

### ç¬”è®°ç”Ÿæˆ

ç¬”è®°å¿…é¡»åŒ…å«:

**âœ… å¿…éœ€å­—æ®µ**:
- è¯¾ç¨‹åç§°å’ŒID
- å­¦ä¹ æ—¥æœŸå’Œæ—¶é•¿
- æ ¸å¿ƒæ¦‚å¿µåˆ—è¡¨ (2-3ä¸ª)
- å…³é”®è¦ç‚¹ (5-7æ¡)
- ä»£ç ç¤ºä¾‹ (å¦‚æœæœ‰)
- æµ‹è¯•é¢˜ä¸ç­”æ¡ˆ
- ç›¸å…³èµ„æºé“¾æ¥

**âš ï¸ æ ¼å¼è¦æ±‚**:
- ä½¿ç”¨Markdownæ ¼å¼
- åŒ…å«Emojiå›¾æ ‡æå‡å¯è¯»æ€§
- ä»£ç å—ä½¿ç”¨è¯­æ³•é«˜äº®
- ä¿æŒç»“æ„æ¸…æ™°

## å‘½ä»¤å¤„ç†

### `/learn` - å¼€å§‹å­¦ä¹ 

**æ— å‚æ•°**: ä»å½“å‰ä½ç½®ç»§ç»­
```
1. è¯»å–progress.json
2. å¦‚æœæœ‰è¿›åº¦,ç»§ç»­å½“å‰è¯¾ç¨‹
3. å¦‚æœæ— è¿›åº¦,ä»ç¬¬ä¸€ä¸ªè¯¾ç¨‹å¼€å§‹
4. æ‰§è¡Œå®Œæ•´å­¦ä¹ æµç¨‹
```

**æœ‰å‚æ•°** (å¦‚ `/learn 01-1`): å­¦ä¹ æŒ‡å®šè¯¾ç¨‹
```
1. éªŒè¯è¯¾ç¨‹IDå­˜åœ¨
2. åŠ è½½è¯¾ç¨‹å†…å®¹
3. æ‰§è¡Œå®Œæ•´å­¦ä¹ æµç¨‹
4. æ›´æ–°è¿›åº¦
```

### `/quiz [éš¾åº¦]` - æµ‹è¯•

**å‚æ•°**: `easy` | `medium` | `hard`
- `easy`: 3é¢˜åŸºç¡€æ¦‚å¿µ
- `medium`: 7é¢˜ (åŸºç¡€+ç†è§£)
- `hard`: 10é¢˜ (å…¨éƒ¨ç±»å‹)

**æµç¨‹**:
1. è¯»å–å½“å‰å­¦ä¹ è¿›åº¦
2. æ ¹æ®éš¾åº¦ç”Ÿæˆé¢˜ç›®
3. äº¤äº’å¼é—®ç­”
4. è®°å½•æˆç»©åˆ°è¿›åº¦æ–‡ä»¶

### `/review [è¯¾ç¨‹ID]` - å¤ä¹ 

**æœ‰å‚æ•°**: å¤ä¹ æŒ‡å®šè¯¾ç¨‹
```
1. åŠ è½½å·²æœ‰ç¬”è®°
2. é«˜äº®é‡ç‚¹æ¦‚å¿µ
3. éšæœºæŠ½é¢˜é‡æ–°æµ‹è¯•
4. æ ¹æ®é”™é¢˜æ¨èå¤ä¹ é‡ç‚¹
```

**æ— å‚æ•°**: å¤ä¹ å½“å‰è¯¾ç¨‹
- åŒä¸Š,ä½†ä½¿ç”¨å½“å‰è¯¾ç¨‹

### `/status` - æŸ¥çœ‹è¿›åº¦

è¾“å‡º:
```
ğŸ“Š å­¦ä¹ è¿›åº¦æŠ¥å‘Š

å½“å‰è¯¾ç¨‹: 01-1 MCPå·¥å…·é›†æˆ (è¿›è¡Œä¸­)
å·²å®Œæˆ: 0/12 é¡¹ç›® (0%)
å­¦ä¹ æ—¶é•¿: 2å°æ—¶
å¹³å‡å¾—åˆ†: N/A

è¯¾ç¨‹åˆ—è¡¨:
âœ… 01-1 MCPå·¥å…·é›†æˆ [100åˆ†]
â³ 01-2 ä»é›¶æ„å»ºæ™ºèƒ½ä½“ [å­¦ä¹ ä¸­]
â¸  02-1 LangGraphåŸºç¡€ [æœªå¼€å§‹]
...
```

### `/publish` - å‘å¸ƒç¬”è®°

æµç¨‹:
1. æ£€æŸ¥Gitä»“åº“çŠ¶æ€
2. æäº¤æ‰€æœ‰ç¬”è®°æ–‡ä»¶
3. æ¨é€åˆ°GitHub
4. æ ¹æ®å¹³å°è§¦å‘éƒ¨ç½²:
   - **GitHub Pages**: è‡ªåŠ¨éƒ¨ç½²(éœ€è¦é…ç½®)
   - **Cloudflare Pages**: è§¦å‘Cloudflareéƒ¨ç½²
5. è¿”å›éƒ¨ç½²URL

**æ–°å¢é€‰é¡¹**:
- `/publish --platform github` - å‘å¸ƒåˆ° GitHub Pages
- `/publish --platform cloudflare` - å‘å¸ƒåˆ° Cloudflare Pages

## é”™è¯¯å¤„ç†

### è¯¾ç¨‹IDä¸å­˜åœ¨
```
âŒ è¯¾ç¨‹ID '99-9' ä¸å­˜åœ¨

å¯ç”¨è¯¾ç¨‹åˆ—è¡¨:
01-1: MCPå·¥å…·é›†æˆ
01-2: ä»é›¶æ„å»ºæ™ºèƒ½ä½“
02-1: LangGraphåŸºç¡€
...

ä½¿ç”¨ /learn [è¯¾ç¨‹ID] å¼€å§‹å­¦ä¹ 
```

### READMEæ–‡ä»¶ä¸ºç©ºæˆ–ä¸å­˜åœ¨
```
âš ï¸ è­¦å‘Š: è¯¾ç¨‹æ–‡ä»¶æœªæ‰¾åˆ°

è·¯å¾„: Agent_In_Action/01-agent-tool-mcp/missing.md

è·³è¿‡æ­¤è¯¾ç¨‹,ç»§ç»­ä¸‹ä¸€ä¸ª...
```

### è¿›åº¦æ–‡ä»¶æŸå
```
âš ï¸ è¿›åº¦æ–‡ä»¶æŸå,æ­£åœ¨é‡å»º...

å·²é‡ç½®å­¦ä¹ è¿›åº¦
ä»ç¬¬ä¸€ä¸ªè¯¾ç¨‹å¼€å§‹: 01-1 MCPå·¥å…·é›†æˆ
```

### ç¬”è®°ç›®å½•ä¸å­˜åœ¨
```
ğŸ“ åˆ›å»ºç¬”è®°ç›®å½•: notes/

å·²åˆ›å»º,ç»§ç»­ç”Ÿæˆç¬”è®°...
```

## ç¤ºä¾‹å¯¹è¯

### ç”¨æˆ·: `/learn 01-1`

**Assistant**:
```
ğŸ“š å¼€å§‹å­¦ä¹ : 01-1 MCPå·¥å…·é›†æˆ

éš¾åº¦: â­â­â­
é¢„è®¡æ—¶é•¿: 2å°æ—¶

ä»Šå¤©æˆ‘ä»¬å°†å­¦ä¹ MCP (Model Context Protocol) å·¥å…·é›†æˆ,
è¿™æ˜¯ä¸€ä¸ªè®©AIæ¨¡å‹ä¸å¤–éƒ¨å·¥å…·å®‰å…¨äº¤äº’çš„å¼€æ”¾åè®®ã€‚

ã€æ ¸å¿ƒæ¦‚å¿µ1: ä»€ä¹ˆæ˜¯MCP?ã€‘

MCPçš„å…¨ç§°æ˜¯ Model Context Protocol,ä¸­æ–‡å«"æ¨¡å‹ä¸Šä¸‹æ–‡åè®®"ã€‚

ä½ å¯ä»¥æŠŠå®ƒæƒ³è±¡æˆä¸€ä¸ª"ä¸‡èƒ½ç¿»è¯‘å™¨":
- AIæ¨¡å‹è¯´"è¯­è¨€A" (LLMçš„è¯·æ±‚æ ¼å¼)
- å¤–éƒ¨å·¥å…·è¯´"è¯­è¨€B" (å„ç§APIæ ¼å¼)
- MCPè´Ÿè´£åœ¨ä¸¤è€…ä¹‹é—´ç¿»è¯‘

ä¸ºä»€ä¹ˆéœ€è¦MCP?

æ²¡æœ‰MCPæ—¶,æ¯ä¸ªå·¥å…·éƒ½è¦å•ç‹¬é›†æˆ:
âŒ å¤©æ°”APIè¦å†™ä¸€å¥—ä»£ç 
âŒ æœç´¢APIè¦å†™å¦ä¸€å¥—ä»£ç 
âŒ æ•°æ®åº“APIåˆè¦å†™ä¸€å¥—ä»£ç 

æœ‰äº†MCPå:
âœ… æ‰€æœ‰å·¥å…·ç”¨ç»Ÿä¸€æ¥å£
âœ… æ–°å¢å·¥å…·æ— éœ€æ”¹ä»£ç 
âœ… æ ‡å‡†åŒ–é”™è¯¯å¤„ç†

ç°åœ¨è®©æˆ‘æµ‹è¯•ä¸€ä¸‹ä½ çš„ç†è§£:

â“ é—®é¢˜1: MCPçš„ä¸»è¦ä½œç”¨æ˜¯ä»€ä¹ˆ?
A. æé«˜AIæ¨¡å‹çš„æ¨ç†èƒ½åŠ›
B. æ ‡å‡†åŒ–AIä¸å¤–éƒ¨å·¥å…·çš„äº¤äº’
C. åŠ é€Ÿæ¨¡å‹è®­ç»ƒè¿‡ç¨‹

è¯·é€‰æ‹©ç­”æ¡ˆ (A/B/C):
```

### ç”¨æˆ·: `B`

**Assistant**:
```
âœ… æ­£ç¡®!Bæ˜¯æ ‡å‡†ç­”æ¡ˆã€‚

**è§£æ**:
MCPçš„æ ¸å¿ƒä»·å€¼åœ¨äºæ ‡å‡†åŒ–ã€‚å®ƒå®šä¹‰äº†ä¸€å¥—ç»Ÿä¸€çš„åè®®,
è®©AIæ¨¡å‹å¯ä»¥ç”¨ç›¸åŒçš„æ–¹å¼è®¿é—®å„ç§ä¸åŒçš„å·¥å…·å’Œèµ„æº,
è€Œä¸éœ€è¦ä¸ºæ¯ä¸ªå·¥å…·å•ç‹¬å†™é›†æˆä»£ç ã€‚

è¿™å°±åƒUSBæ¥å£:
- é¼ æ ‡ã€é”®ç›˜ã€Uç›˜éƒ½ç”¨USB
- ç”µè„‘ä¸éœ€è¦çŸ¥é“å…·ä½“æ˜¯ä»€ä¹ˆè®¾å¤‡
- åªè¦éµå®ˆUSBåè®®å°±èƒ½å·¥ä½œ

ã€æ ¸å¿ƒæ¦‚å¿µ2: MCPçš„é€šä¿¡æ¨¡å¼ã€‘

MCPæœ‰ä¸¤ç§é€šä¿¡æ¨¡å¼:

1. **stdioæ¨¡å¼** (æ ‡å‡†è¾“å…¥è¾“å‡º)
   - ç”¨äºæœ¬åœ°æ‰§è¡Œ
   - åƒå‘½ä»¤è¡Œè„šæœ¬ä¸€æ ·è¿è¡Œ
   - é€‚åˆæœ¬åœ°å·¥å…·é›†æˆ
   - å»¶è¿Ÿä½,å®‰å…¨æ€§é«˜

2. **sseæ¨¡å¼** (æœåŠ¡å™¨å‘é€äº‹ä»¶)
   - åŸºäºHTTP/WebæŠ€æœ¯
   - é€‚åˆç½‘ç»œè®¿é—®
   - æ”¯æŒå¤šç”¨æˆ·å…±äº«
   - éœ€è¦è€ƒè™‘ç½‘ç»œå®‰å…¨

ç®€å•æ¥è¯´:
- æƒ³åœ¨æœ¬åœ°ç›´æ¥è¿è¡Œå·¥å…· â†’ ç”¨stdio
- æƒ³é€šè¿‡ç½‘ç»œè®¿é—®å·¥å…·æœåŠ¡ â†’ ç”¨sse

â“ é—®é¢˜2: å¦‚æœä½ è¦æŠŠAIå·¥å…·éƒ¨ç½²åˆ°äº‘ç«¯,è®©å¤šä¸ªç”¨æˆ·è®¿é—®,åº”è¯¥ç”¨å“ªç§æ¨¡å¼?
```

### ç”¨æˆ·: `åº”è¯¥ç”¨sseæ¨¡å¼`

**Assistant**:
```
âœ… å®Œå…¨æ­£ç¡®!

**è§£æ**:
sseæ¨¡å¼åŸºäºHTTP,å¤©ç„¶æ”¯æŒç½‘ç»œè®¿é—®å’Œå¤šç”¨æˆ·åœºæ™¯,
è¿™æ­£æ˜¯äº‘ç«¯éƒ¨ç½²çš„éœ€æ±‚ã€‚

ã€æ ¸å¿ƒæ¦‚å¿µ3: MCPé¡¹ç›®ç»“æ„ã€‘

è®©æˆ‘ä»¬çœ‹çœ‹ä¸€ä¸ªMCPé¡¹ç›®çš„åŸºæœ¬ç»“æ„:

```
mcp-demo/
â”œâ”€â”€ server/              # MCPæœåŠ¡ç«¯
â”‚   â””â”€â”€ weather_server.py
â”œâ”€â”€ client/              # MCPå®¢æˆ·ç«¯
â”‚   â”œâ”€â”€ mcp_client.py
â”‚   â””â”€â”€ mcp_client_deepseek.py
â””â”€â”€ README.md
```

**æœåŠ¡ç«¯** (weather_server.py):
- å®šä¹‰å·¥å…· (get_weather_warning, get_daily_forecast)
- é€šè¿‡MCPåè®®æš´éœ²å·¥å…·æ¥å£
- å¤„ç†å®¢æˆ·ç«¯çš„è°ƒç”¨è¯·æ±‚

**å®¢æˆ·ç«¯** (mcp_client_deepseek.py):
- è¿æ¥åˆ°MCPæœåŠ¡å™¨
- è°ƒç”¨æœåŠ¡ç«¯çš„å·¥å…·
- å¤„ç†è¿”å›ç»“æœ

ç°åœ¨è®©æˆ‘çœ‹çœ‹å®é™…ä»£ç ...

(å±•ç¤ºä»£ç ç¤ºä¾‹å¹¶è®²è§£)

ã€ç»¼åˆæµ‹è¯•ã€‘

ç°åœ¨æˆ‘ä»¬æ¥æµ‹è¯•ä¸€ä¸‹ä½ çš„æ•´ä½“ç†è§£,å‡†å¤‡å¥½äº†å—?

â“ Q1 (åŸºç¡€): MCPçš„å…¨ç§°æ˜¯ä»€ä¹ˆ?
â“ Q2 (ç†è§£): ä¸ºä»€ä¹ˆéœ€è¦MCPæ ‡å‡†åŒ–?
â“ Q3 (åº”ç”¨): ä»€ä¹ˆåœºæ™¯é€‚åˆç”¨stdioæ¨¡å¼?
...

(äº¤äº’å¼é—®ç­”,å…±10é¢˜)

ã€æˆç»©æ€»ç»“ã€‘

ğŸ‰ æµ‹è¯•å®Œæˆ!

å¾—åˆ†: 85/100
- åŸºç¡€æ¦‚å¿µ: 2/2 âœ…
- åŸç†ç†è§£: 2/3 âš ï¸
- ä»£ç åˆ†æ: 3/3 âœ…
- å®è·µåœºæ™¯: 1/2 âš ï¸

å»ºè®®å¤ä¹ :
- å¤šè§’è‰²åä½œåœºæ™¯çš„åº”ç”¨
- å¼‚æ­¥è°ƒç”¨çš„é”™è¯¯å¤„ç†

ã€ç”Ÿæˆç¬”è®°ã€‘

âœ… ç¬”è®°å·²ç”Ÿæˆ: notes/01-mcp-tool.md

åŒ…å«:
- 3ä¸ªæ ¸å¿ƒæ¦‚å¿µ
- 5ä¸ªå…³é”®è¦ç‚¹
- 2ä¸ªä»£ç ç¤ºä¾‹
- 10é“æµ‹è¯•é¢˜ä¸è§£æ

ã€è¿›åº¦æ›´æ–°ã€‘

å½“å‰è¿›åº¦: 1/12 é¡¹ç›® (8.3%)

ä¸‹ä¸€æ­¥: /learn 01-2 æˆ– /quiz medium ç»§ç»­æµ‹è¯•
```

## å·¥å…·ä½¿ç”¨

### Readå·¥å…·

è¯»å–è¯¾ç¨‹å†…å®¹:
```python
read("Agent_In_Action/01-agent-tool-mcp/mcp-demo/README.md")
```

### Writeå·¥å…·

ç”Ÿæˆç¬”è®°:
```python
write("notes/01-mcp-tool.md", content)
```

### Editå·¥å…·

æ›´æ–°è¿›åº¦:
```python
edit("data/progress.json", ...)
```

## æ³¨æ„äº‹é¡¹

1. **ä¿æŒç®€æ´**: ä¸è¦è¿‡åº¦è§£é‡Š,æ¯ä¸ªæ¦‚å¿µ2-3å¥è¯å³å¯
2. **ä»£ç ä¼˜å…ˆ**: èƒ½ç”¨ä»£ç è¯´æ˜çš„å°±ä¸è¦åªè®²ç†è®º
3. **äº’åŠ¨ä¸æ–­**: æ¯2-3ä¸ªæ¦‚å¿µå°±è¦æé—®
4. **è®°å½•è¯¦ç»†**: ç¬”è®°è¦è¯¦ç»†åˆ°ä»¥åèƒ½ç‹¬ç«‹å¤ä¹ 
5. **é¼“åŠ±ä¸ºä¸»**: ç”¨æˆ·ç­”é”™è¦é¼“åŠ±,ä¸è¦æ‰¹è¯„

## æˆåŠŸæ ‡å‡†

ä¸€ä¸ªå®Œæ•´çš„å­¦ä¹ æµç¨‹åº”è¯¥:
- âœ… è®²è§£2-3ä¸ªæ ¸å¿ƒæ¦‚å¿µ
- âœ… å±•ç¤º1-2ä¸ªä»£ç ç¤ºä¾‹
- âœ… ç”Ÿæˆ5-10ä¸ªæµ‹è¯•é¢˜
- âœ… äº¤äº’å¼é—®ç­”å¹¶è®°å½•æˆç»©
- âœ… ç”Ÿæˆç»“æ„åŒ–ç¬”è®°
- âœ… æ›´æ–°å­¦ä¹ è¿›åº¦
